2024-12-29:09:12:40,757 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-12-29:09:12:40,757 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2024-12-29:09:12:40,758 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2024-12-29:09:12:41,151 INFO     [config.py:58] PyTorch version 2.4.1 available.
2024-12-29:09:12:46,155 INFO     [__main__.py:132] Verbosity set to INFO
2024-12-29:09:12:59,404 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-12-29:09:12:59,407 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2024-12-29:09:12:59,418 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2024-12-29:09:12:59,674 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  6.53it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  8.14it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  8.88it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  8.85it/s]
2024-12-29:09:13:16,885 INFO     [task.py:355] Building contexts for task on rank 0...
2024-12-29:09:13:16,904 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:612: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:09<15:58,  9.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:17<14:19,  8.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:25<13:43,  8.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:34<13:19,  8.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:42<12:59,  8.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [00:50<12:58,  8.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [00:58<12:40,  8.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:06<12:24,  8.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:14<12:11,  8.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:22<11:59,  8.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [01:30<11:49,  7.97s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [01:37<11:38,  7.94s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [01:45<11:28,  7.92s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [01:53<11:19,  7.90s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:01<11:10,  7.89s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:09<11:02,  7.88s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [02:17<10:53,  7.88s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [02:25<10:44,  7.86s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [02:32<10:36,  7.86s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [02:40<10:28,  7.85s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [02:48<10:19,  7.84s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [02:56<10:11,  7.84s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [03:04<10:03,  7.83s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [03:12<09:55,  7.83s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [03:19<09:46,  7.82s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [03:27<09:38,  7.82s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [03:35<09:30,  7.82s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [03:43<09:22,  7.82s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [03:51<09:14,  7.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [03:58<09:06,  7.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [04:06<08:58,  7.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [04:14<08:50,  7.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [04:22<08:43,  7.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [04:30<08:35,  7.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [04:37<08:27,  7.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [04:45<08:21,  7.83s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [04:53<08:13,  7.83s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [05:01<08:04,  7.82s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [05:09<07:55,  7.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [05:17<07:47,  7.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [05:24<07:39,  7.79s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [05:32<07:31,  7.79s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [05:40<07:23,  7.79s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [05:48<07:16,  7.79s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [05:55<07:07,  7.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [06:03<06:59,  7.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [06:11<06:51,  7.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [06:19<06:44,  7.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [06:26<06:36,  7.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [06:34<06:28,  7.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [06:42<06:20,  7.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [06:50<06:12,  7.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [06:58<06:04,  7.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [07:05<05:57,  7.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [07:12<05:40,  7.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [07:20<05:35,  7.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [07:28<05:29,  7.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [07:36<05:23,  7.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [07:43<05:16,  7.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [07:51<05:08,  7.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [07:59<05:01,  7.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [08:07<04:53,  7.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [08:14<04:46,  7.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [08:22<04:38,  7.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [08:30<04:30,  7.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [08:37<04:20,  7.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [08:45<04:13,  7.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [08:53<04:06,  7.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [09:01<03:58,  7.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [09:08<03:51,  7.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [09:16<03:43,  7.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [09:24<03:35,  7.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [09:31<03:28,  7.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [09:39<03:20,  7.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [09:47<03:10,  7.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [09:53<02:55,  7.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [10:01<02:51,  7.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [10:09<02:45,  7.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [10:16<02:39,  7.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [10:24<02:32,  7.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [10:32<02:25,  7.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [10:40<02:18,  7.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [10:47<02:10,  7.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [10:55<02:03,  7.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [11:03<01:55,  7.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [11:10<01:47,  7.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [11:18<01:40,  7.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [11:26<01:32,  7.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [11:33<01:24,  7.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [11:38<01:08,  6.82s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [11:42<00:53,  5.98s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [11:50<00:52,  6.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [11:58<00:48,  6.87s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [12:05<00:42,  7.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [12:13<00:36,  7.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [12:20<00:28,  7.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [12:27<00:21,  7.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [12:35<00:14,  7.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [12:43<00:07,  7.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [12:50<00:00,  7.54s/it]100%|██████████| 100/100 [12:50<00:00,  7.71s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2024-12-29:09:26:44,705 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-12-29:09:26:44,705 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2024-12-29:09:26:44,705 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2024-12-29:09:26:45,152 INFO     [config.py:58] PyTorch version 2.4.1 available.
2024-12-29:09:26:50,107 INFO     [__main__.py:132] Verbosity set to INFO
2024-12-29:09:27:02,976 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-12-29:09:27:02,979 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2024-12-29:09:27:02,989 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2024-12-29:09:27:03,252 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  6.14it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  7.68it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  8.39it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  8.36it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  8.03it/s]
2024-12-29:09:27:20,397 INFO     [task.py:355] Building contexts for task on rank 0...
2024-12-29:09:27:20,416 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:612: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:09<15:42,  9.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:17<14:10,  8.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:25<13:35,  8.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:33<13:13,  8.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:41<12:57,  8.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [00:50<12:59,  8.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [00:58<12:42,  8.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:06<12:24,  8.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:14<12:10,  8.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:21<11:57,  7.97s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [01:29<11:45,  7.93s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [01:37<11:35,  7.90s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [01:45<11:25,  7.87s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [01:53<11:15,  7.86s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:00<11:06,  7.84s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:08<11:00,  7.87s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [02:16<10:51,  7.85s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [02:24<10:42,  7.83s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [02:32<10:33,  7.82s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [02:40<10:24,  7.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [02:47<10:15,  7.79s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [02:55<10:06,  7.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [03:03<09:58,  7.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [03:11<09:50,  7.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [03:18<09:42,  7.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [03:26<09:34,  7.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [03:34<09:26,  7.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [03:42<09:18,  7.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [03:49<09:10,  7.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [03:57<09:02,  7.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [04:05<08:54,  7.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [04:13<08:46,  7.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [04:20<08:38,  7.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [04:28<08:30,  7.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [04:36<08:22,  7.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [04:43<08:14,  7.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [04:51<08:06,  7.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [04:59<07:58,  7.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [05:07<07:50,  7.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [05:14<07:43,  7.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [05:22<07:35,  7.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [05:30<07:27,  7.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [05:38<07:20,  7.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [05:45<07:12,  7.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [05:53<07:04,  7.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [06:01<06:56,  7.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [06:08<06:48,  7.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [06:16<06:40,  7.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [06:24<06:33,  7.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [06:31<06:25,  7.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [06:39<06:17,  7.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [06:47<06:09,  7.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [06:55<06:02,  7.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [07:02<05:54,  7.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [07:09<05:38,  7.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [07:17<05:33,  7.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [07:25<05:27,  7.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [07:32<05:20,  7.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [07:40<05:13,  7.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [07:48<05:06,  7.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [07:56<04:59,  7.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [08:03<04:51,  7.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [08:11<04:43,  7.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [08:19<04:36,  7.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [08:26<04:28,  7.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [08:34<04:18,  7.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [08:41<04:11,  7.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [08:49<04:04,  7.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [08:57<03:57,  7.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [09:04<03:49,  7.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [09:12<03:41,  7.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [09:20<03:34,  7.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [09:27<03:26,  7.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [09:35<03:19,  7.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [09:42<03:08,  7.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [09:49<02:54,  7.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [09:57<02:49,  7.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [10:04<02:44,  7.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [10:12<02:38,  7.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [10:19<02:31,  7.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [10:27<02:24,  7.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [10:35<02:16,  7.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [10:42<02:09,  7.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [10:50<02:02,  7.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [10:58<01:54,  7.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [11:05<01:46,  7.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [11:13<01:39,  7.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [11:21<01:31,  7.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [11:28<01:24,  7.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [11:33<01:07,  6.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [11:37<00:53,  5.94s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [11:45<00:51,  6.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [11:52<00:47,  6.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [12:00<00:42,  7.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [12:08<00:36,  7.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [12:14<00:28,  7.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [12:22<00:21,  7.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [12:29<00:14,  7.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [12:37<00:07,  7.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [12:45<00:00,  7.48s/it]100%|██████████| 100/100 [12:45<00:00,  7.65s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2024-12-29:09:40:42,065 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-12-29:09:40:42,066 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2024-12-29:09:40:42,067 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2024-12-29:09:40:42,526 INFO     [config.py:58] PyTorch version 2.4.1 available.
2024-12-29:09:40:47,739 INFO     [__main__.py:132] Verbosity set to INFO
2024-12-29:09:41:00,412 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-12-29:09:41:00,415 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2024-12-29:09:41:00,427 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2024-12-29:09:41:00,674 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  5.93it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  7.53it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  8.31it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  8.32it/s]
2024-12-29:09:41:17,855 INFO     [task.py:355] Building contexts for task on rank 0...
2024-12-29:09:41:17,874 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:612: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:09<16:00,  9.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:17<14:17,  8.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:25<13:39,  8.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:33<13:15,  8.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:41<12:58,  8.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [00:50<13:03,  8.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [00:58<12:42,  8.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:06<12:24,  8.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:14<12:09,  8.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:22<11:57,  7.97s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [01:29<11:45,  7.93s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [01:37<11:35,  7.90s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [01:45<11:25,  7.87s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [01:53<11:15,  7.86s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:01<11:06,  7.84s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:08<10:57,  7.83s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [02:16<10:49,  7.82s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [02:24<10:40,  7.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [02:32<10:32,  7.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [02:40<10:23,  7.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [02:47<10:14,  7.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [02:55<10:06,  7.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [03:03<09:58,  7.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [03:11<09:51,  7.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [03:18<09:42,  7.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [03:26<09:34,  7.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [03:34<09:26,  7.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [03:42<09:18,  7.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [03:49<09:10,  7.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [03:57<09:02,  7.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [04:05<08:54,  7.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [04:13<08:47,  7.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [04:20<08:39,  7.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [04:28<08:31,  7.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [04:36<08:23,  7.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [04:44<08:15,  7.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [04:51<08:07,  7.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [04:59<07:59,  7.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [05:07<07:51,  7.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [05:15<07:43,  7.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [05:22<07:36,  7.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [05:30<07:28,  7.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [05:38<07:20,  7.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [05:45<07:12,  7.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [05:53<07:04,  7.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [06:01<06:57,  7.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [06:09<06:48,  7.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [06:16<06:41,  7.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [06:24<06:33,  7.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [06:32<06:26,  7.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [06:39<06:18,  7.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [06:47<06:10,  7.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [06:55<06:02,  7.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [07:03<05:54,  7.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [07:10<05:38,  7.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [07:17<05:33,  7.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [07:25<05:27,  7.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [07:33<05:21,  7.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [07:41<05:14,  7.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [07:48<05:06,  7.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [07:56<04:59,  7.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [08:04<04:51,  7.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [08:11<04:44,  7.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [08:19<04:36,  7.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [08:27<04:28,  7.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [08:34<04:18,  7.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [08:42<04:11,  7.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [08:49<04:04,  7.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [08:57<03:57,  7.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [09:05<03:49,  7.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [09:12<03:41,  7.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [09:20<03:34,  7.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [09:28<03:26,  7.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [09:35<03:19,  7.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [09:43<03:09,  7.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [09:49<02:54,  7.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [09:57<02:50,  7.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [10:05<02:44,  7.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [10:12<02:38,  7.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [10:20<02:31,  7.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [10:28<02:24,  7.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [10:35<02:17,  7.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [10:43<02:09,  7.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [10:51<02:02,  7.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [10:58<01:54,  7.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [11:06<01:47,  7.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [11:14<01:39,  7.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [11:21<01:31,  7.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [11:29<01:24,  7.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [11:34<01:07,  6.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [11:38<00:53,  5.94s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [11:45<00:51,  6.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [11:53<00:47,  6.82s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [12:01<00:42,  7.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [12:08<00:36,  7.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [12:15<00:28,  7.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [12:23<00:21,  7.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [12:30<00:14,  7.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [12:38<00:07,  7.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [12:46<00:00,  7.53s/it]100%|██████████| 100/100 [12:46<00:00,  7.66s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2024-12-29:09:54:40,626 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-12-29:09:54:40,626 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2024-12-29:09:54:40,627 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2024-12-29:09:54:41,065 INFO     [config.py:58] PyTorch version 2.4.1 available.
2024-12-29:09:54:46,279 INFO     [__main__.py:132] Verbosity set to INFO
2024-12-29:09:54:58,852 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-12-29:09:54:58,855 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2024-12-29:09:54:58,866 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2024-12-29:09:54:59,119 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  6.45it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  7.78it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  8.37it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  8.54it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  8.19it/s]
2024-12-29:09:55:16,777 INFO     [task.py:355] Building contexts for task on rank 0...
2024-12-29:09:55:16,796 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:612: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:09<15:54,  9.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:17<14:15,  8.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:25<13:38,  8.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:33<13:14,  8.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:41<12:58,  8.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [00:50<12:59,  8.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [00:58<12:42,  8.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:06<12:28,  8.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:14<12:12,  8.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:22<11:58,  7.99s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [01:29<11:47,  7.94s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [01:37<11:35,  7.91s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [01:45<11:25,  7.88s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [01:53<11:16,  7.86s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:01<11:06,  7.85s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:09<10:58,  7.83s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [02:16<10:49,  7.83s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [02:24<10:40,  7.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [02:32<10:32,  7.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [02:40<10:24,  7.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [02:47<10:15,  7.79s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [02:55<10:06,  7.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [03:03<09:59,  7.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [03:11<09:51,  7.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [03:19<09:42,  7.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [03:26<09:34,  7.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [03:34<09:26,  7.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [03:42<09:18,  7.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [03:50<09:10,  7.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [03:57<09:02,  7.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [04:05<08:55,  7.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [04:13<08:47,  7.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [04:21<08:39,  7.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [04:28<08:31,  7.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [04:36<08:23,  7.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [04:44<08:15,  7.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [04:51<08:07,  7.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [04:59<07:59,  7.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [05:07<07:51,  7.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [05:15<07:43,  7.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [05:22<07:36,  7.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [05:30<07:28,  7.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [05:38<07:20,  7.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [05:46<07:13,  7.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [05:53<07:04,  7.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [06:01<06:57,  7.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [06:09<06:48,  7.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [06:16<06:41,  7.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [06:24<06:33,  7.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [06:32<06:26,  7.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [06:40<06:18,  7.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [06:47<06:10,  7.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [06:55<06:02,  7.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [07:03<05:54,  7.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [07:10<05:38,  7.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [07:18<05:33,  7.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [07:25<05:27,  7.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [07:33<05:21,  7.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [07:41<05:14,  7.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [07:48<05:06,  7.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [07:56<04:59,  7.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [08:04<04:51,  7.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [08:11<04:44,  7.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [08:19<04:36,  7.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [08:27<04:28,  7.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [08:34<04:18,  7.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [08:42<04:11,  7.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [08:50<04:04,  7.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [08:57<03:57,  7.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [09:05<03:49,  7.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [09:13<03:42,  7.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [09:20<03:34,  7.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [09:28<03:26,  7.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [09:36<03:19,  7.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [09:43<03:09,  7.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [09:50<02:55,  7.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [09:57<02:51,  7.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [10:05<02:45,  7.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [10:13<02:38,  7.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [10:20<02:31,  7.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [10:28<02:24,  7.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [10:36<02:17,  7.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [10:43<02:09,  7.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [10:51<02:02,  7.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [10:59<01:54,  7.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [11:06<01:47,  7.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [11:14<01:39,  7.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [11:22<01:31,  7.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [11:29<01:24,  7.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [11:34<01:07,  6.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [11:38<00:53,  5.95s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [11:46<00:51,  6.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [11:54<00:47,  6.83s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [12:01<00:42,  7.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [12:09<00:36,  7.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [12:15<00:28,  7.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [12:23<00:21,  7.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [12:31<00:14,  7.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [12:38<00:07,  7.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [12:46<00:00,  7.49s/it]100%|██████████| 100/100 [12:46<00:00,  7.66s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2024-12-29:10:08:39,923 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-12-29:10:08:39,924 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2024-12-29:10:08:39,924 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2024-12-29:10:08:40,308 INFO     [config.py:58] PyTorch version 2.4.1 available.
2024-12-29:10:08:45,364 INFO     [__main__.py:132] Verbosity set to INFO
2024-12-29:10:08:58,677 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-12-29:10:08:58,680 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2024-12-29:10:08:58,691 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2024-12-29:10:08:58,968 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  6.39it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  8.03it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  8.79it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  8.87it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  8.48it/s]
2024-12-29:10:09:16,330 INFO     [task.py:355] Building contexts for task on rank 0...
2024-12-29:10:09:16,350 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:612: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:09<15:57,  9.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:17<14:17,  8.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:25<13:39,  8.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:33<13:16,  8.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:41<12:59,  8.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [00:50<13:01,  8.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [00:58<12:44,  8.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:06<12:26,  8.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:14<12:11,  8.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:22<11:58,  7.99s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [01:30<11:47,  7.95s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [01:37<11:36,  7.92s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [01:45<11:26,  7.89s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [01:53<11:17,  7.87s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:01<11:07,  7.86s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:09<10:59,  7.85s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [02:17<10:50,  7.84s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [02:24<10:41,  7.83s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [02:32<10:33,  7.82s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [02:40<10:25,  7.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [02:48<10:16,  7.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [02:55<10:08,  7.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [03:03<10:00,  7.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [03:11<09:52,  7.79s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [03:19<09:43,  7.79s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [03:27<09:35,  7.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [03:34<09:27,  7.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [03:42<09:20,  7.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [03:50<09:12,  7.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [03:58<09:04,  7.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [04:05<08:56,  7.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [04:13<08:48,  7.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [04:21<08:40,  7.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [04:29<08:32,  7.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [04:37<08:24,  7.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [04:44<08:16,  7.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [04:52<08:08,  7.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [05:00<08:00,  7.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [05:07<07:52,  7.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [05:15<07:44,  7.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [05:23<07:37,  7.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [05:31<07:29,  7.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [05:38<07:21,  7.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [05:46<07:13,  7.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [05:54<07:05,  7.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [06:02<06:57,  7.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [06:09<06:49,  7.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [06:17<06:42,  7.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [06:25<06:34,  7.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [06:33<06:26,  7.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [06:40<06:19,  7.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [06:48<06:11,  7.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [06:56<06:03,  7.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [07:04<05:55,  7.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [07:11<05:39,  7.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [07:18<05:35,  7.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [07:26<05:29,  7.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [07:34<05:23,  7.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [07:42<05:16,  7.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [07:49<05:08,  7.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [07:57<05:00,  7.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [08:05<04:52,  7.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [08:13<04:45,  7.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [08:20<04:37,  7.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [08:28<04:29,  7.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [08:35<04:19,  7.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [08:43<04:12,  7.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [08:51<04:05,  7.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [08:58<03:57,  7.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [09:06<03:50,  7.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [09:14<03:42,  7.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [09:22<03:34,  7.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [09:29<03:27,  7.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [09:37<03:19,  7.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [09:44<03:09,  7.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [09:51<02:55,  7.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [09:59<02:50,  7.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [10:06<02:44,  7.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [10:14<02:38,  7.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [10:22<02:31,  7.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [10:29<02:24,  7.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [10:37<02:17,  7.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [10:45<02:09,  7.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [10:52<02:02,  7.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [11:00<01:54,  7.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [11:08<01:47,  7.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [11:15<01:39,  7.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [11:23<01:32,  7.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [11:31<01:24,  7.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [11:35<01:07,  6.79s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [11:39<00:53,  5.96s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [11:47<00:51,  6.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [11:55<00:47,  6.84s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [12:02<00:42,  7.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [12:10<00:36,  7.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [12:17<00:28,  7.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [12:24<00:21,  7.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [12:32<00:14,  7.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [12:40<00:07,  7.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [12:47<00:00,  7.50s/it]100%|██████████| 100/100 [12:47<00:00,  7.68s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2024-12-29:10:23:50,759 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-12-29:10:23:50,759 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2024-12-29:10:23:50,760 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2024-12-29:10:23:51,174 INFO     [config.py:58] PyTorch version 2.4.1 available.
2024-12-29:10:23:56,370 INFO     [__main__.py:132] Verbosity set to INFO
2024-12-29:10:24:09,499 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-12-29:10:24:09,501 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2024-12-29:10:24:09,510 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2024-12-29:10:24:09,981 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  6.30it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  7.93it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  8.69it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  8.65it/s]
2024-12-29:10:24:26,972 INFO     [task.py:355] Building contexts for task on rank 0...
2024-12-29:10:24:26,991 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:612: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:09<15:26,  9.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:17<13:47,  8.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:25<13:15,  8.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:32<12:56,  8.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:40<12:40,  8.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [00:49<12:42,  8.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [00:57<12:26,  8.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:04<12:12,  7.97s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:12<12:00,  7.92s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:20<11:49,  7.88s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [01:28<11:38,  7.85s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [01:36<11:28,  7.83s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [01:43<11:19,  7.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [01:51<11:09,  7.79s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [01:59<11:01,  7.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:07<10:52,  7.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [02:14<10:44,  7.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [02:22<10:36,  7.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [02:30<10:28,  7.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [02:37<10:19,  7.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [02:45<10:11,  7.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [02:53<10:02,  7.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [03:01<09:54,  7.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [03:08<09:46,  7.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [03:16<09:38,  7.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [03:24<09:30,  7.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [03:31<09:22,  7.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [03:39<09:15,  7.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [03:47<09:09,  7.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [03:55<09:01,  7.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [04:02<08:53,  7.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [04:10<08:45,  7.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [04:18<08:37,  7.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [04:26<08:28,  7.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [04:33<08:20,  7.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [04:41<08:12,  7.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [04:49<08:04,  7.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [04:56<07:56,  7.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [05:04<07:48,  7.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [05:12<07:40,  7.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [05:19<07:33,  7.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [05:27<07:25,  7.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [05:35<07:17,  7.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [05:42<07:09,  7.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [05:50<07:02,  7.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [05:58<06:54,  7.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [06:05<06:46,  7.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [06:13<06:38,  7.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [06:21<06:31,  7.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [06:28<06:23,  7.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [06:36<06:15,  7.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [06:44<06:07,  7.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [06:51<06:00,  7.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [06:59<05:52,  7.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [07:07<05:44,  7.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [07:14<05:36,  7.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [07:22<05:29,  7.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [07:30<05:21,  7.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [07:37<05:13,  7.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [07:45<05:05,  7.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [07:52<04:58,  7.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [08:00<04:50,  7.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [08:08<04:42,  7.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [08:15<04:34,  7.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [08:23<04:27,  7.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [08:31<04:19,  7.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [08:38<04:11,  7.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [08:46<04:04,  7.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [08:54<03:56,  7.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [09:01<03:48,  7.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [09:09<03:41,  7.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [09:16<03:33,  7.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [09:24<03:25,  7.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [09:32<03:18,  7.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [09:39<03:10,  7.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [09:47<03:02,  7.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [09:55<02:55,  7.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [10:02<02:47,  7.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [10:10<02:39,  7.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [10:17<02:32,  7.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [10:25<02:24,  7.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [10:33<02:16,  7.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [10:40<02:09,  7.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [10:48<02:01,  7.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [10:55<01:54,  7.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [11:03<01:46,  7.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [11:11<01:38,  7.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [11:18<01:31,  7.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [11:26<01:23,  7.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [11:33<01:16,  7.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [11:41<01:08,  7.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [11:49<01:00,  7.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [11:56<00:53,  7.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [12:04<00:45,  7.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [12:11<00:37,  7.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [12:16<00:26,  6.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [12:24<00:20,  6.96s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [12:31<00:14,  7.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [12:39<00:07,  7.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [12:46<00:00,  7.36s/it]100%|██████████| 100/100 [12:46<00:00,  7.67s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2024-12-29:10:37:50,512 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-12-29:10:37:50,512 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2024-12-29:10:37:50,513 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2024-12-29:10:37:50,955 INFO     [config.py:58] PyTorch version 2.4.1 available.
2024-12-29:10:37:55,985 INFO     [__main__.py:132] Verbosity set to INFO
2024-12-29:10:38:08,405 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-12-29:10:38:08,408 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2024-12-29:10:38:08,419 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2024-12-29:10:38:08,713 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  6.34it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  7.96it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  8.75it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  8.70it/s]
2024-12-29:10:38:25,952 INFO     [task.py:355] Building contexts for task on rank 0...
2024-12-29:10:38:25,971 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:612: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:09<15:36,  9.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:17<13:59,  8.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:25<13:21,  8.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:33<12:59,  8.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:41<12:42,  8.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [00:49<12:44,  8.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [00:57<12:27,  8.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:05<12:13,  7.97s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:12<12:00,  7.92s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:20<11:49,  7.88s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [01:28<11:38,  7.85s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [01:36<11:28,  7.82s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [01:43<11:18,  7.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [01:51<11:09,  7.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [01:59<11:00,  7.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:07<10:52,  7.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [02:14<10:43,  7.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [02:22<10:35,  7.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [02:30<10:31,  7.79s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [02:38<10:21,  7.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [02:46<10:12,  7.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [02:53<10:03,  7.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [03:01<09:55,  7.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [03:09<09:46,  7.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [03:16<09:38,  7.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [03:24<09:30,  7.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [03:32<09:22,  7.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [03:39<09:14,  7.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [03:47<09:06,  7.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [03:55<08:58,  7.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [04:02<08:50,  7.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [04:10<08:42,  7.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [04:18<08:35,  7.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [04:26<08:27,  7.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [04:33<08:19,  7.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [04:41<08:11,  7.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [04:49<08:03,  7.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [04:56<07:56,  7.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [05:04<07:48,  7.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [05:12<07:40,  7.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [05:19<07:32,  7.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [05:27<07:24,  7.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [05:35<07:17,  7.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [05:42<07:09,  7.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [05:50<07:01,  7.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [05:58<06:53,  7.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [06:05<06:46,  7.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [06:13<06:38,  7.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [06:21<06:30,  7.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [06:28<06:22,  7.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [06:36<06:15,  7.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [06:43<06:07,  7.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [06:51<05:59,  7.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [06:59<05:51,  7.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [07:06<05:44,  7.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [07:14<05:36,  7.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [07:22<05:28,  7.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [07:29<05:21,  7.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [07:37<05:13,  7.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [07:45<05:05,  7.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [07:52<04:57,  7.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [08:00<04:50,  7.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [08:08<04:42,  7.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [08:15<04:34,  7.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [08:23<04:26,  7.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [08:30<04:19,  7.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [08:38<04:11,  7.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [08:46<04:03,  7.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [08:53<03:56,  7.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [09:01<03:48,  7.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [09:08<03:40,  7.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [09:16<03:33,  7.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [09:24<03:25,  7.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [09:31<03:17,  7.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [09:39<03:10,  7.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [09:47<03:02,  7.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [09:54<02:55,  7.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [10:02<02:47,  7.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [10:09<02:39,  7.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [10:17<02:32,  7.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [10:25<02:24,  7.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [10:32<02:16,  7.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [10:40<02:09,  7.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [10:47<02:01,  7.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [10:55<01:53,  7.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [11:03<01:46,  7.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [11:10<01:38,  7.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [11:18<01:31,  7.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [11:25<01:23,  7.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [11:33<01:15,  7.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [11:40<01:08,  7.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [11:48<01:00,  7.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [11:56<00:53,  7.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [12:03<00:45,  7.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [12:11<00:37,  7.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [12:15<00:26,  6.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [12:23<00:20,  6.95s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [12:31<00:14,  7.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [12:38<00:07,  7.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [12:46<00:00,  7.36s/it]100%|██████████| 100/100 [12:46<00:00,  7.66s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2024-12-29:10:51:48,746 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-12-29:10:51:48,747 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2024-12-29:10:51:48,747 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2024-12-29:10:51:49,191 INFO     [config.py:58] PyTorch version 2.4.1 available.
2024-12-29:10:51:54,338 INFO     [__main__.py:132] Verbosity set to INFO
2024-12-29:10:52:06,909 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-12-29:10:52:06,912 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2024-12-29:10:52:06,924 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2024-12-29:10:52:07,180 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  5.79it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  7.56it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  8.46it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  8.69it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  8.17it/s]
2024-12-29:10:52:24,675 INFO     [task.py:355] Building contexts for task on rank 0...
2024-12-29:10:52:24,694 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:612: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:09<15:46,  9.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:17<14:07,  8.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:25<13:29,  8.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:33<13:07,  8.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:41<12:50,  8.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [00:49<12:51,  8.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [00:57<12:34,  8.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:05<12:20,  8.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:13<12:08,  8.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:21<11:56,  7.96s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [01:29<11:45,  7.93s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [01:37<11:35,  7.90s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [01:45<11:25,  7.88s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [01:52<11:16,  7.86s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:00<11:07,  7.85s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:08<10:58,  7.84s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [02:16<10:50,  7.83s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [02:24<10:41,  7.83s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [02:31<10:33,  7.82s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [02:39<10:25,  7.82s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [02:47<10:16,  7.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [02:55<10:08,  7.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [03:03<10:00,  7.79s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [03:10<09:52,  7.79s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [03:18<09:44,  7.79s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [03:26<09:35,  7.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [03:34<09:27,  7.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [03:41<09:20,  7.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [03:49<09:12,  7.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [03:57<09:04,  7.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [04:05<08:56,  7.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [04:13<08:48,  7.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [04:20<08:40,  7.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [04:28<08:32,  7.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [04:36<08:24,  7.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [04:44<08:16,  7.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [04:51<08:08,  7.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [04:59<08:00,  7.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [05:07<07:53,  7.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [05:15<07:45,  7.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [05:22<07:37,  7.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [05:30<07:29,  7.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [05:38<07:21,  7.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [05:46<07:13,  7.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [05:53<07:06,  7.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [06:01<06:58,  7.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [06:09<06:50,  7.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [06:17<06:42,  7.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [06:24<06:34,  7.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [06:32<06:26,  7.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [06:40<06:19,  7.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [06:47<06:11,  7.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [06:55<06:03,  7.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [07:03<05:55,  7.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [07:11<05:47,  7.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [07:18<05:40,  7.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [07:26<05:32,  7.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [07:34<05:24,  7.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [07:42<05:16,  7.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [07:49<05:08,  7.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [07:57<05:00,  7.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [08:05<04:53,  7.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [08:12<04:45,  7.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [08:20<04:37,  7.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [08:28<04:29,  7.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [08:35<04:21,  7.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [08:43<04:14,  7.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [08:51<04:06,  7.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [08:59<03:58,  7.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [09:06<03:50,  7.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [09:14<03:43,  7.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [09:22<03:35,  7.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [09:29<03:27,  7.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [09:37<03:20,  7.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [09:45<03:12,  7.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [09:52<03:04,  7.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [10:00<02:56,  7.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [10:08<02:49,  7.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [10:15<02:41,  7.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [10:23<02:33,  7.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [10:31<02:26,  7.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [10:39<02:18,  7.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [10:46<02:10,  7.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [10:54<02:02,  7.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [11:02<01:55,  7.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [11:09<01:47,  7.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [11:17<01:39,  7.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [11:25<01:32,  7.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [11:32<01:24,  7.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [11:40<01:17,  7.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [11:48<01:09,  7.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [11:56<01:01,  7.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [12:03<00:53,  7.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [12:11<00:46,  7.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [12:19<00:38,  7.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [12:23<00:27,  6.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [12:31<00:21,  7.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [12:38<00:14,  7.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [12:46<00:07,  7.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [12:54<00:00,  7.44s/it]100%|██████████| 100/100 [12:54<00:00,  7.74s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2024-12-29:11:05:55,618 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-12-29:11:05:55,618 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2024-12-29:11:05:55,619 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2024-12-29:11:05:56,088 INFO     [config.py:58] PyTorch version 2.4.1 available.
2024-12-29:11:06:01,174 INFO     [__main__.py:132] Verbosity set to INFO
2024-12-29:11:06:13,592 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-12-29:11:06:13,594 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2024-12-29:11:06:13,605 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2024-12-29:11:06:13,867 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  5.87it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  7.57it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  8.42it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  8.36it/s]
2024-12-29:11:06:31,035 INFO     [task.py:355] Building contexts for task on rank 0...
2024-12-29:11:06:31,054 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:612: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:09<15:51,  9.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:17<14:09,  8.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:25<13:30,  8.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:33<13:07,  8.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:41<12:49,  8.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [00:49<12:49,  8.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [00:57<12:33,  8.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:05<12:19,  8.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:13<12:06,  7.99s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:21<11:54,  7.94s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [01:29<11:44,  7.91s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [01:37<11:34,  7.89s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [01:44<11:24,  7.86s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [01:52<11:15,  7.85s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:00<11:06,  7.84s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:08<10:57,  7.83s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [02:16<10:49,  7.82s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [02:23<10:41,  7.82s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [02:31<10:32,  7.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [02:39<10:24,  7.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [02:47<10:15,  7.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [02:55<10:07,  7.79s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [03:02<09:59,  7.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [03:10<09:51,  7.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [03:18<09:43,  7.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [03:26<09:35,  7.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [03:33<09:27,  7.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [03:41<09:19,  7.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [03:49<09:11,  7.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [03:57<09:03,  7.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [04:04<08:55,  7.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [04:12<08:47,  7.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [04:20<08:39,  7.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [04:28<08:31,  7.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [04:35<08:23,  7.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [04:43<08:15,  7.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [04:51<08:08,  7.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [04:59<08:00,  7.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [05:06<07:52,  7.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [05:14<07:44,  7.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [05:22<07:36,  7.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [05:30<07:28,  7.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [05:37<07:21,  7.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [05:45<07:13,  7.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [05:53<07:05,  7.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [06:01<06:57,  7.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [06:08<06:49,  7.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [06:16<06:41,  7.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [06:24<06:34,  7.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [06:31<06:26,  7.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [06:39<06:18,  7.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [06:47<06:10,  7.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [06:55<06:02,  7.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [07:02<05:55,  7.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [07:10<05:47,  7.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [07:18<05:39,  7.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [07:25<05:31,  7.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [07:33<05:23,  7.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [07:41<05:16,  7.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [07:49<05:08,  7.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [07:56<05:00,  7.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [08:04<04:52,  7.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [08:12<04:44,  7.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [08:19<04:37,  7.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [08:27<04:29,  7.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [08:35<04:21,  7.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [08:43<04:14,  7.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [08:50<04:07,  7.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [08:58<03:59,  7.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [09:06<03:51,  7.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [09:13<03:43,  7.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [09:21<03:35,  7.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [09:29<03:27,  7.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [09:36<03:19,  7.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [09:44<03:12,  7.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [09:52<03:04,  7.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [09:59<02:56,  7.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [10:07<02:48,  7.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [10:15<02:41,  7.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [10:22<02:33,  7.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [10:30<02:25,  7.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [10:38<02:18,  7.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [10:45<02:10,  7.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [10:53<02:02,  7.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [11:01<01:55,  7.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [11:08<01:47,  7.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [11:16<01:39,  7.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [11:24<01:31,  7.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [11:31<01:24,  7.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [11:39<01:16,  7.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [11:47<01:08,  7.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [11:54<01:01,  7.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [12:02<00:53,  7.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [12:10<00:45,  7.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [12:17<00:38,  7.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [12:22<00:26,  6.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [12:30<00:21,  7.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [12:37<00:14,  7.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [12:45<00:07,  7.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [12:53<00:00,  7.42s/it]100%|██████████| 100/100 [12:53<00:00,  7.73s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2024-12-29:11:20:00,743 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-12-29:11:20:00,744 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2024-12-29:11:20:00,744 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2024-12-29:11:20:01,173 INFO     [config.py:58] PyTorch version 2.4.1 available.
2024-12-29:11:20:06,106 INFO     [__main__.py:132] Verbosity set to INFO
2024-12-29:11:20:18,973 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-12-29:11:20:18,975 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2024-12-29:11:20:18,986 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2024-12-29:11:20:19,231 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  5.94it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  7.49it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  8.26it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  8.28it/s]
2024-12-29:11:20:35,806 INFO     [task.py:355] Building contexts for task on rank 0...
2024-12-29:11:20:35,825 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:612: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:09<15:41,  9.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:17<14:01,  8.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:25<13:23,  8.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:33<13:01,  8.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:41<12:44,  8.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [00:49<12:44,  8.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [00:57<12:28,  8.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:05<12:14,  7.98s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:13<12:01,  7.93s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:20<11:50,  7.89s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [01:28<11:39,  7.86s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [01:36<11:29,  7.83s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [01:44<11:19,  7.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [01:51<11:10,  7.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [01:59<11:01,  7.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:07<10:53,  7.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [02:15<10:44,  7.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [02:22<10:37,  7.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [02:30<10:28,  7.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [02:38<10:20,  7.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [02:46<10:11,  7.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [02:53<10:03,  7.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [03:01<09:55,  7.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [03:09<09:47,  7.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [03:17<09:39,  7.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [03:24<09:31,  7.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [03:32<09:23,  7.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [03:40<09:15,  7.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [03:47<09:07,  7.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [03:55<08:59,  7.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [04:03<08:51,  7.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [04:10<08:43,  7.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [04:18<08:36,  7.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [04:26<08:28,  7.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [04:34<08:20,  7.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [04:41<08:12,  7.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [04:49<08:04,  7.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [04:57<07:56,  7.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [05:04<07:49,  7.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [05:12<07:41,  7.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [05:20<07:33,  7.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [05:27<07:25,  7.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [05:35<07:18,  7.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [05:43<07:10,  7.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [05:50<07:02,  7.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [05:58<06:54,  7.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [06:06<06:47,  7.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [06:14<06:41,  7.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [06:21<06:33,  7.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [06:29<06:25,  7.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [06:37<06:17,  7.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [06:44<06:08,  7.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [06:52<06:00,  7.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [07:00<05:53,  7.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [07:07<05:45,  7.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [07:15<05:37,  7.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [07:23<05:29,  7.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [07:30<05:21,  7.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [07:38<05:14,  7.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [07:46<05:06,  7.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [07:53<04:58,  7.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [08:01<04:50,  7.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [08:08<04:42,  7.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [08:16<04:35,  7.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [08:24<04:27,  7.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [08:31<04:19,  7.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [08:39<04:12,  7.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [08:47<04:04,  7.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [08:54<03:56,  7.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [09:02<03:49,  7.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [09:10<03:41,  7.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [09:17<03:33,  7.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [09:25<03:26,  7.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [09:32<03:18,  7.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [09:40<03:10,  7.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [09:48<03:03,  7.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [09:55<02:55,  7.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [10:03<02:47,  7.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [10:11<02:40,  7.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [10:18<02:32,  7.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [10:26<02:24,  7.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [10:33<02:17,  7.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [10:41<02:09,  7.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [10:49<02:01,  7.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [10:56<01:54,  7.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [11:04<01:46,  7.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [11:11<01:38,  7.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [11:19<01:31,  7.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [11:27<01:23,  7.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [11:34<01:16,  7.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [11:42<01:08,  7.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [11:50<01:00,  7.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [11:57<00:53,  7.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [12:05<00:45,  7.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [12:12<00:38,  7.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [12:17<00:26,  6.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [12:24<00:20,  6.97s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [12:32<00:14,  7.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [12:40<00:07,  7.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [12:47<00:00,  7.37s/it]100%|██████████| 100/100 [12:47<00:00,  7.68s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
