2024-12-28:00:25:00,112 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-12-28:00:25:00,113 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2024-12-28:00:25:00,113 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2024-12-28:00:25:00,572 INFO     [config.py:58] PyTorch version 2.4.1 available.
2024-12-28:00:25:05,745 INFO     [__main__.py:132] Verbosity set to INFO
2024-12-28:00:25:18,545 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-12-28:00:25:18,548 INFO     [__main__.py:205] Selected Tasks: ['code2text_python']
2024-12-28:00:25:18,560 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2024-12-28:00:25:18,818 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  6.14it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  7.78it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  8.61it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  8.55it/s]
2024-12-28:00:26:04,676 INFO     [task.py:355] Building contexts for task on rank 0...
2024-12-28:00:26:04,692 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:612: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:11<18:12, 11.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:20<16:22, 10.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:29<15:36,  9.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:38<15:06,  9.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:47<14:37,  9.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [00:56<14:10,  9.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:04<13:40,  8.82s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:12<13:16,  8.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:21<12:58,  8.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:29<12:43,  8.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [01:37<12:27,  8.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [01:45<12:10,  8.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [01:53<11:56,  8.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:01<11:43,  8.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:09<11:30,  8.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:17<11:19,  8.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [02:25<11:08,  8.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [02:33<10:57,  8.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [02:41<10:47,  8.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [02:49<10:37,  7.97s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [02:57<10:28,  7.96s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:05<10:19,  7.94s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [03:13<10:09,  7.91s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [03:21<09:59,  7.89s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [03:29<09:50,  7.88s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [03:36<09:41,  7.86s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [03:44<09:31,  7.83s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [03:52<09:20,  7.79s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [04:00<09:10,  7.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [04:07<09:01,  7.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [04:15<08:52,  7.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [04:23<08:48,  7.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [04:31<08:39,  7.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [04:38<08:30,  7.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [04:46<08:21,  7.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [04:54<08:13,  7.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [05:01<08:04,  7.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [05:09<07:56,  7.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [05:17<07:48,  7.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [05:24<07:41,  7.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [05:32<07:32,  7.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [05:40<07:24,  7.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [05:47<07:16,  7.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [05:55<07:08,  7.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [06:02<07:00,  7.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [06:10<06:52,  7.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [06:18<06:45,  7.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [06:25<06:37,  7.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [06:33<06:30,  7.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [06:41<06:21,  7.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [06:48<06:14,  7.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [06:56<06:06,  7.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [07:04<05:58,  7.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [07:11<05:50,  7.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [07:19<05:43,  7.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [07:26<05:35,  7.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [07:34<05:27,  7.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [07:42<05:20,  7.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [07:49<05:12,  7.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [07:57<05:04,  7.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [08:04<04:56,  7.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [08:12<04:48,  7.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [08:20<04:40,  7.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [08:27<04:34,  7.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [08:35<04:26,  7.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [08:42<04:18,  7.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [08:50<04:10,  7.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [08:58<04:02,  7.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [09:05<03:55,  7.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [09:13<03:47,  7.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [09:20<03:39,  7.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [09:28<03:31,  7.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [09:35<03:24,  7.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [09:43<03:16,  7.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [09:51<03:09,  7.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [09:58<03:01,  7.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [10:06<02:54,  7.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [10:13<02:46,  7.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [10:21<02:38,  7.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [10:28<02:30,  7.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [10:36<02:23,  7.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [10:43<02:15,  7.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [10:51<02:07,  7.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [10:58<02:00,  7.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [11:06<01:52,  7.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [11:13<01:45,  7.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [11:21<01:37,  7.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [11:28<01:30,  7.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [11:36<01:22,  7.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [11:43<01:15,  7.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [11:51<01:07,  7.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [11:58<00:59,  7.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [12:06<00:52,  7.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [12:13<00:44,  7.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [12:21<00:37,  7.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [12:28<00:29,  7.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [12:36<00:22,  7.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [12:43<00:14,  7.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [12:51<00:07,  7.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [12:58<00:00,  7.48s/it]100%|██████████| 100/100 [12:58<00:00,  7.79s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2024-12-28:00:39:41,564 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-12-28:00:39:41,565 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2024-12-28:00:39:41,566 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2024-12-28:00:39:41,978 INFO     [config.py:58] PyTorch version 2.4.1 available.
2024-12-28:00:39:47,001 INFO     [__main__.py:132] Verbosity set to INFO
2024-12-28:00:39:59,573 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-12-28:00:39:59,576 INFO     [__main__.py:205] Selected Tasks: ['code2text_python']
2024-12-28:00:39:59,588 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2024-12-28:00:39:59,840 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  5.82it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  7.30it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  7.34it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  8.01it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  7.57it/s]
2024-12-28:00:40:44,039 INFO     [task.py:355] Building contexts for task on rank 0...
2024-12-28:00:40:44,055 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:612: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:10<17:58, 10.89s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:20<16:20, 10.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:29<15:38,  9.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:38<15:10,  9.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:47<14:42,  9.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [00:56<14:15,  9.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:04<13:45,  8.88s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:13<13:22,  8.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:21<13:04,  8.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:29<12:48,  8.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [01:38<12:32,  8.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [01:46<12:19,  8.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [01:54<12:05,  8.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:02<11:52,  8.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:11<11:40,  8.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:19<11:28,  8.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [02:27<11:16,  8.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [02:35<11:05,  8.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [02:43<10:54,  8.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [02:51<10:44,  8.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [02:59<10:34,  8.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:07<10:24,  8.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [03:15<10:14,  7.99s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [03:22<10:05,  7.97s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [03:30<09:56,  7.95s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [03:38<09:47,  7.94s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [03:46<09:36,  7.90s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [03:54<09:25,  7.86s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [04:02<09:15,  7.83s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [04:09<09:06,  7.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [04:17<08:57,  7.79s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [04:25<08:48,  7.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [04:33<08:40,  7.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [04:40<08:32,  7.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [04:48<08:23,  7.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [04:56<08:15,  7.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [05:04<08:07,  7.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [05:11<07:59,  7.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [05:19<07:51,  7.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [05:27<07:43,  7.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [05:34<07:35,  7.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [05:42<07:27,  7.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [05:50<07:19,  7.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [05:58<07:11,  7.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [06:05<07:04,  7.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [06:13<06:56,  7.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [06:21<06:48,  7.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [06:28<06:40,  7.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [06:36<06:32,  7.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [06:44<06:24,  7.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [06:51<06:16,  7.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [06:59<06:08,  7.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [07:07<06:00,  7.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [07:14<05:52,  7.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [07:22<05:45,  7.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [07:30<05:37,  7.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [07:37<05:30,  7.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [07:45<05:22,  7.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [07:53<05:14,  7.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [08:00<05:06,  7.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [08:08<04:59,  7.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [08:16<04:51,  7.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [08:23<04:43,  7.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [08:31<04:35,  7.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [08:39<04:27,  7.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [08:46<04:20,  7.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [08:54<04:12,  7.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [09:02<04:04,  7.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [09:09<03:57,  7.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [09:17<03:49,  7.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [09:25<03:41,  7.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [09:32<03:33,  7.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [09:40<03:26,  7.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [09:47<03:18,  7.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [09:55<03:10,  7.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [10:03<03:02,  7.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [10:10<02:55,  7.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [10:18<02:47,  7.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [10:25<02:39,  7.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [10:33<02:31,  7.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [10:41<02:24,  7.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [10:48<02:16,  7.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [10:56<02:08,  7.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [11:03<02:01,  7.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [11:11<01:53,  7.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [11:18<01:46,  7.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [11:26<01:38,  7.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [11:34<01:30,  7.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [11:41<01:23,  7.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [11:49<01:15,  7.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [11:56<01:07,  7.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [12:04<01:00,  7.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [12:11<00:52,  7.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [12:19<00:45,  7.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [12:26<00:37,  7.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [12:34<00:30,  7.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [12:42<00:22,  7.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [12:49<00:15,  7.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [12:57<00:07,  7.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [13:04<00:00,  7.52s/it]100%|██████████| 100/100 [13:04<00:00,  7.85s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2024-12-28:00:54:26,854 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-12-28:00:54:26,855 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2024-12-28:00:54:26,855 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2024-12-28:00:54:27,287 INFO     [config.py:58] PyTorch version 2.4.1 available.
2024-12-28:00:54:32,344 INFO     [__main__.py:132] Verbosity set to INFO
2024-12-28:00:54:44,888 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-12-28:00:54:44,891 INFO     [__main__.py:205] Selected Tasks: ['code2text_python']
2024-12-28:00:54:44,900 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2024-12-28:00:54:45,148 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  6.24it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  7.45it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  8.42it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  8.44it/s]
2024-12-28:00:55:30,091 INFO     [task.py:355] Building contexts for task on rank 0...
2024-12-28:00:55:30,107 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:612: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:10<17:55, 10.86s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:20<16:15,  9.95s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:29<15:32,  9.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:38<15:04,  9.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:47<14:36,  9.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [00:56<14:08,  9.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:04<13:39,  8.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:12<13:16,  8.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:21<12:57,  8.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:29<12:42,  8.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [01:37<12:27,  8.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [01:45<12:10,  8.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [01:53<11:56,  8.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:01<11:43,  8.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:09<11:30,  8.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:17<11:18,  8.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [02:25<11:07,  8.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [02:33<10:57,  8.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [02:41<10:47,  7.99s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [02:49<10:37,  7.97s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [02:57<10:28,  7.95s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:05<10:18,  7.93s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [03:13<10:08,  7.90s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [03:20<09:59,  7.89s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [03:28<09:50,  7.87s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [03:36<09:41,  7.86s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [03:44<09:31,  7.83s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [03:52<09:20,  7.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [03:59<09:10,  7.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [04:07<09:00,  7.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [04:15<08:52,  7.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [04:22<08:44,  7.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [04:30<08:35,  7.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [04:38<08:27,  7.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [04:45<08:19,  7.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [04:53<08:11,  7.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [05:01<08:03,  7.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [05:08<07:55,  7.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [05:16<07:47,  7.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [05:24<07:39,  7.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [05:31<07:31,  7.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [05:39<07:23,  7.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [05:46<07:15,  7.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [05:54<07:07,  7.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [06:02<06:59,  7.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [06:09<06:51,  7.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [06:17<06:44,  7.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [06:25<06:36,  7.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [06:32<06:28,  7.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [06:40<06:20,  7.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [06:47<06:12,  7.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [06:55<06:05,  7.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [07:03<05:57,  7.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [07:10<05:49,  7.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [07:18<05:41,  7.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [07:25<05:34,  7.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [07:33<05:27,  7.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [07:41<05:19,  7.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [07:48<05:11,  7.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [07:56<05:03,  7.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [08:03<04:55,  7.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [08:11<04:48,  7.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [08:19<04:40,  7.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [08:26<04:32,  7.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [08:34<04:25,  7.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [08:41<04:17,  7.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [08:49<04:09,  7.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [08:56<04:02,  7.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [09:04<03:54,  7.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [09:11<03:46,  7.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [09:19<03:39,  7.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [09:27<03:31,  7.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [09:34<03:23,  7.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [09:42<03:16,  7.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [09:49<03:08,  7.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [09:57<03:00,  7.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [10:04<02:53,  7.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [10:12<02:45,  7.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [10:19<02:37,  7.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [10:27<02:30,  7.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [10:34<02:22,  7.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [10:42<02:15,  7.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [10:49<02:07,  7.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [10:57<01:59,  7.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [11:04<01:52,  7.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [11:12<01:45,  7.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [11:19<01:37,  7.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [11:27<01:29,  7.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [11:34<01:22,  7.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [11:42<01:14,  7.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [11:49<01:07,  7.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [11:56<00:59,  7.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [12:04<00:52,  7.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [12:11<00:44,  7.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [12:19<00:37,  7.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [12:26<00:29,  7.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [12:34<00:22,  7.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [12:41<00:14,  7.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [12:48<00:07,  7.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [12:56<00:00,  7.42s/it]100%|██████████| 100/100 [12:56<00:00,  7.76s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2024-12-28:01:09:04,935 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-12-28:01:09:04,936 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2024-12-28:01:09:04,936 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2024-12-28:01:09:05,382 INFO     [config.py:58] PyTorch version 2.4.1 available.
2024-12-28:01:09:10,416 INFO     [__main__.py:132] Verbosity set to INFO
2024-12-28:01:09:23,733 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-12-28:01:09:23,736 INFO     [__main__.py:205] Selected Tasks: ['code2text_python']
2024-12-28:01:09:23,744 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2024-12-28:01:09:24,023 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  6.30it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  7.87it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  8.64it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  8.60it/s]
2024-12-28:01:10:09,540 INFO     [task.py:355] Building contexts for task on rank 0...
2024-12-28:01:10:09,556 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:612: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:10<18:02, 10.94s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:20<16:22, 10.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:29<15:39,  9.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:38<15:11,  9.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:47<14:42,  9.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [00:56<14:15,  9.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:04<13:45,  8.88s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:13<13:22,  8.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:21<13:04,  8.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:30<12:48,  8.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [01:38<12:32,  8.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [01:46<12:16,  8.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [01:54<12:02,  8.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:02<11:49,  8.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:10<11:35,  8.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:18<11:24,  8.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [02:26<11:13,  8.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [02:34<11:02,  8.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [02:42<10:52,  8.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [02:51<10:46,  8.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [02:58<10:35,  8.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:06<10:25,  8.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [03:14<10:14,  7.99s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [03:22<10:05,  7.96s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [03:30<09:56,  7.95s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [03:38<09:46,  7.93s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [03:46<09:36,  7.90s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [03:54<09:25,  7.85s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [04:01<09:15,  7.82s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [04:09<09:05,  7.79s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [04:17<08:56,  7.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [04:25<08:47,  7.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [04:32<08:39,  7.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [04:40<08:31,  7.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [04:48<08:23,  7.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [04:56<08:15,  7.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [05:03<08:07,  7.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [05:11<07:59,  7.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [05:19<07:51,  7.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [05:26<07:42,  7.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [05:34<07:34,  7.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [05:42<07:26,  7.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [05:49<07:18,  7.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [05:57<07:10,  7.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [06:05<07:02,  7.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [06:12<06:54,  7.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [06:20<06:47,  7.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [06:28<06:39,  7.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [06:35<06:31,  7.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [06:43<06:23,  7.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [06:51<06:15,  7.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [06:58<06:07,  7.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [07:06<06:00,  7.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [07:14<05:52,  7.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [07:21<05:44,  7.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [07:29<05:36,  7.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [07:37<05:29,  7.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [07:44<05:21,  7.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [07:52<05:13,  7.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [08:00<05:05,  7.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [08:07<04:58,  7.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [08:15<04:50,  7.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [08:23<04:42,  7.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [08:30<04:35,  7.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [08:38<04:28,  7.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [08:46<04:20,  7.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [08:53<04:13,  7.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [09:01<04:05,  7.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [09:09<03:57,  7.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [09:16<03:49,  7.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [09:24<03:41,  7.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [09:31<03:33,  7.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [09:39<03:25,  7.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [09:47<03:17,  7.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [09:54<03:10,  7.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [10:02<03:02,  7.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [10:09<02:54,  7.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [10:17<02:46,  7.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [10:24<02:39,  7.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [10:32<02:31,  7.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [10:39<02:23,  7.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [10:47<02:16,  7.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [10:55<02:08,  7.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [11:02<02:00,  7.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [11:10<01:53,  7.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [11:17<01:45,  7.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [11:25<01:37,  7.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [11:32<01:30,  7.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [11:40<01:22,  7.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [11:47<01:15,  7.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [11:55<01:07,  7.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [12:02<01:00,  7.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [12:10<00:52,  7.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [12:17<00:45,  7.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [12:25<00:37,  7.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [12:32<00:30,  7.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [12:40<00:22,  7.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [12:47<00:15,  7.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [12:55<00:07,  7.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [13:02<00:00,  7.50s/it]100%|██████████| 100/100 [13:02<00:00,  7.83s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2024-12-28:01:23:50,769 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-12-28:01:23:50,770 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2024-12-28:01:23:50,770 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2024-12-28:01:23:51,216 INFO     [config.py:58] PyTorch version 2.4.1 available.
2024-12-28:01:23:56,336 INFO     [__main__.py:132] Verbosity set to INFO
2024-12-28:01:24:09,430 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-12-28:01:24:09,432 INFO     [__main__.py:205] Selected Tasks: ['code2text_python']
2024-12-28:01:24:09,444 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2024-12-28:01:24:09,694 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  6.30it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  7.95it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  8.10it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  8.72it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  8.26it/s]
2024-12-28:01:24:55,059 INFO     [task.py:355] Building contexts for task on rank 0...
2024-12-28:01:24:55,075 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:612: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:10<17:50, 10.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:20<16:12,  9.93s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:29<15:30,  9.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:38<15:02,  9.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:47<14:34,  9.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [00:55<14:07,  9.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:04<13:38,  8.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:12<13:15,  8.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:20<12:56,  8.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:29<12:41,  8.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [01:37<12:25,  8.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [01:45<12:09,  8.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [01:53<11:54,  8.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:01<11:41,  8.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:09<11:28,  8.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:17<11:17,  8.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [02:25<11:06,  8.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [02:33<10:56,  8.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [02:41<10:46,  7.98s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [02:49<10:36,  7.95s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [02:57<10:26,  7.93s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:04<10:17,  7.92s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [03:12<10:07,  7.89s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [03:20<09:58,  7.87s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [03:28<09:49,  7.86s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [03:36<09:40,  7.85s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [03:43<09:30,  7.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [03:51<09:19,  7.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [03:59<09:09,  7.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [04:06<08:59,  7.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [04:14<08:50,  7.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [04:22<08:42,  7.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [04:29<08:34,  7.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [04:37<08:26,  7.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [04:45<08:18,  7.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [04:52<08:10,  7.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [05:00<08:02,  7.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [05:08<07:54,  7.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [05:15<07:46,  7.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [05:23<07:38,  7.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [05:31<07:30,  7.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [05:38<07:22,  7.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [05:46<07:14,  7.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [05:53<07:06,  7.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [06:01<06:58,  7.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [06:09<06:50,  7.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [06:16<06:42,  7.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [06:24<06:35,  7.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [06:31<06:27,  7.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [06:39<06:19,  7.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [06:46<06:11,  7.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [06:54<06:04,  7.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [07:02<05:56,  7.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [07:09<05:50,  7.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [07:17<05:43,  7.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [07:25<05:35,  7.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [07:32<05:27,  7.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [07:40<05:19,  7.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [07:47<05:11,  7.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [07:55<05:03,  7.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [08:02<04:55,  7.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [08:10<04:47,  7.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [08:18<04:40,  7.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [08:25<04:32,  7.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [08:33<04:24,  7.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [08:40<04:16,  7.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [08:48<04:09,  7.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [08:55<04:01,  7.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [09:03<03:53,  7.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [09:10<03:46,  7.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [09:18<03:38,  7.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [09:25<03:30,  7.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [09:33<03:23,  7.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [09:40<03:15,  7.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [09:48<03:07,  7.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [09:55<03:00,  7.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [10:03<02:52,  7.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [10:10<02:45,  7.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [10:18<02:37,  7.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [10:25<02:29,  7.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [10:33<02:22,  7.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [10:40<02:14,  7.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [10:48<02:07,  7.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [10:55<01:59,  7.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [11:03<01:52,  7.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [11:10<01:44,  7.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [11:18<01:37,  7.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [11:25<01:29,  7.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [11:33<01:21,  7.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [11:40<01:14,  7.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [11:47<01:06,  7.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [11:55<00:59,  7.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [12:02<00:52,  7.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [12:10<00:44,  7.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [12:17<00:37,  7.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [12:25<00:29,  7.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [12:32<00:22,  7.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [12:39<00:14,  7.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [12:47<00:07,  7.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [12:54<00:00,  7.42s/it]100%|██████████| 100/100 [12:54<00:00,  7.75s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2024-12-28:01:39:38,271 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-12-28:01:39:38,272 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2024-12-28:01:39:38,272 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2024-12-28:01:39:38,727 INFO     [config.py:58] PyTorch version 2.4.1 available.
2024-12-28:01:39:43,797 INFO     [__main__.py:132] Verbosity set to INFO
2024-12-28:01:39:57,188 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-12-28:01:39:57,191 INFO     [__main__.py:205] Selected Tasks: ['code2text_python']
2024-12-28:01:39:57,202 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2024-12-28:01:39:57,455 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  6.33it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  7.18it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  8.21it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  8.27it/s]
2024-12-28:01:40:41,688 INFO     [task.py:355] Building contexts for task on rank 0...
2024-12-28:01:40:41,704 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:612: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:22, 12.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:22<18:31, 11.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:33<17:45, 10.98s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:43<17:13, 10.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:54<16:39, 10.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:03<16:07, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:13<15:31, 10.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:22<15:03,  9.82s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:32<14:41,  9.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:41<14:22,  9.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [01:50<14:04,  9.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [01:59<13:45,  9.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:09<13:29,  9.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:18<13:16,  9.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:27<13:00,  9.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:36<12:46,  9.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [02:45<12:33,  9.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [02:54<12:21,  9.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:03<12:10,  9.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:12<12:00,  9.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:20<11:49,  8.98s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:30<11:41,  8.99s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [03:38<11:29,  8.96s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [03:47<11:19,  8.94s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [03:56<11:08,  8.91s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:05<10:57,  8.89s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:14<10:45,  8.84s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:22<10:32,  8.79s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [04:31<10:21,  8.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [04:40<10:10,  8.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [04:48<10:00,  8.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [04:57<09:50,  8.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:06<09:41,  8.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [05:14<09:32,  8.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [05:23<09:23,  8.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [05:32<09:14,  8.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [05:40<09:05,  8.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [05:49<08:56,  8.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [05:58<08:47,  8.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [06:06<08:37,  8.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [06:15<08:28,  8.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [06:23<08:19,  8.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [06:32<08:10,  8.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [06:41<08:01,  8.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [06:49<07:53,  8.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [06:58<07:44,  8.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [07:06<07:35,  8.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [07:15<07:26,  8.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [07:23<07:17,  8.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [07:32<07:09,  8.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [07:41<07:00,  8.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [07:49<06:51,  8.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [07:58<06:42,  8.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [08:06<06:34,  8.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [08:15<06:25,  8.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [08:23<06:16,  8.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [08:32<06:08,  8.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [08:41<05:59,  8.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [08:49<05:50,  8.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [08:58<05:42,  8.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [09:06<05:33,  8.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [09:15<05:24,  8.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [09:23<05:16,  8.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [09:32<05:07,  8.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [09:40<04:58,  8.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [09:49<04:50,  8.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [09:57<04:41,  8.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [10:06<04:32,  8.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [10:14<04:24,  8.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [10:23<04:15,  8.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [10:31<04:06,  8.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [10:40<03:58,  8.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [10:48<03:49,  8.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [10:57<03:41,  8.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [11:05<03:32,  8.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [11:14<03:23,  8.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [11:22<03:15,  8.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [11:31<03:06,  8.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [11:39<02:58,  8.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [11:48<02:49,  8.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [11:56<02:41,  8.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [12:05<02:32,  8.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [12:13<02:23,  8.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [12:22<02:15,  8.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [12:30<02:06,  8.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [12:38<01:58,  8.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [12:47<01:49,  8.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [12:55<01:41,  8.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [13:04<01:32,  8.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [13:12<01:24,  8.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [13:20<01:15,  8.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [13:29<01:07,  8.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [13:37<00:58,  8.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [13:46<00:50,  8.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [13:54<00:42,  8.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [14:02<00:33,  8.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [14:11<00:25,  8.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [14:19<00:16,  8.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [14:28<00:08,  8.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [14:36<00:00,  8.39s/it]100%|██████████| 100/100 [14:36<00:00,  8.76s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2024-12-28:01:55:56,686 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-12-28:01:55:56,687 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2024-12-28:01:55:56,687 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2024-12-28:01:55:57,126 INFO     [config.py:58] PyTorch version 2.4.1 available.
2024-12-28:01:56:02,162 INFO     [__main__.py:132] Verbosity set to INFO
2024-12-28:01:56:14,979 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-12-28:01:56:14,981 INFO     [__main__.py:205] Selected Tasks: ['code2text_python']
2024-12-28:01:56:14,992 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2024-12-28:01:56:15,260 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  5.93it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  7.47it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  8.17it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  8.78it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  8.18it/s]
2024-12-28:01:57:00,719 INFO     [task.py:355] Building contexts for task on rank 0...
2024-12-28:01:57:00,735 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:612: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:08, 12.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:22<18:27, 11.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:33<17:45, 10.98s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:43<17:14, 10.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:54<16:41, 10.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:03<16:10, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:13<15:35, 10.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:22<15:06,  9.86s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:32<14:44,  9.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:41<14:26,  9.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [01:51<14:08,  9.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:00<13:49,  9.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:09<13:32,  9.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:18<13:17,  9.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:27<13:02,  9.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:36<12:50,  9.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [02:45<12:36,  9.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [02:54<12:24,  9.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:03<12:13,  9.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:12<12:04,  9.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:21<11:53,  9.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:30<11:42,  9.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [03:39<11:30,  8.97s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [03:48<11:20,  8.95s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [03:57<11:11,  8.96s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:06<11:02,  8.95s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:15<10:49,  8.90s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:23<10:36,  8.84s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [04:32<10:27,  8.84s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [04:41<10:16,  8.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [04:50<10:05,  8.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [04:58<09:54,  8.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:07<09:45,  8.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [05:16<09:36,  8.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [05:24<09:28,  8.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [05:33<09:19,  8.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [05:42<09:10,  8.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [05:51<09:00,  8.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [05:59<08:52,  8.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [06:08<08:42,  8.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [06:17<08:32,  8.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [06:25<08:25,  8.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [06:34<08:15,  8.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [06:43<08:05,  8.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [06:51<07:56,  8.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [07:00<07:47,  8.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [07:09<07:38,  8.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [07:17<07:29,  8.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [07:26<07:20,  8.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [07:34<07:12,  8.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [07:43<07:04,  8.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [07:52<06:55,  8.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [08:00<06:46,  8.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [08:09<06:38,  8.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [08:18<06:29,  8.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [08:26<06:20,  8.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [08:35<06:11,  8.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [08:44<06:02,  8.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [08:52<05:53,  8.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [09:01<05:45,  8.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [09:10<05:37,  8.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [09:18<05:28,  8.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [09:27<05:20,  8.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [09:36<05:11,  8.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [09:44<05:02,  8.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [09:53<04:53,  8.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [10:01<04:43,  8.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [10:10<04:34,  8.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [10:19<04:26,  8.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [10:27<04:18,  8.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [10:36<04:09,  8.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [10:44<04:00,  8.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [10:53<03:52,  8.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [11:01<03:43,  8.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [11:10<03:34,  8.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [11:19<03:26,  8.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [11:27<03:18,  8.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [11:36<03:09,  8.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [11:44<03:00,  8.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [11:53<02:51,  8.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [12:01<02:42,  8.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [12:10<02:33,  8.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [12:18<02:24,  8.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [12:27<02:16,  8.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [12:35<02:07,  8.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [12:44<01:58,  8.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [12:52<01:50,  8.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [13:01<01:41,  8.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [13:09<01:33,  8.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [13:18<01:24,  8.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [13:26<01:16,  8.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [13:35<01:07,  8.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [13:43<00:59,  8.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [13:51<00:50,  8.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [14:00<00:42,  8.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [14:08<00:33,  8.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [14:17<00:25,  8.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [14:25<00:16,  8.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [14:34<00:08,  8.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [14:42<00:00,  8.43s/it]100%|██████████| 100/100 [14:42<00:00,  8.83s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2024-12-28:02:12:21,630 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-12-28:02:12:21,631 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2024-12-28:02:12:21,631 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2024-12-28:02:12:22,077 INFO     [config.py:58] PyTorch version 2.4.1 available.
2024-12-28:02:12:27,361 INFO     [__main__.py:132] Verbosity set to INFO
2024-12-28:02:12:40,390 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-12-28:02:12:40,391 INFO     [__main__.py:205] Selected Tasks: ['code2text_python']
2024-12-28:02:12:40,402 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2024-12-28:02:12:40,668 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  5.83it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  7.36it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  8.12it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  8.72it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  8.11it/s]
2024-12-28:02:13:25,548 INFO     [task.py:355] Building contexts for task on rank 0...
2024-12-28:02:13:25,564 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:612: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:06, 12.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:22<18:27, 11.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:33<17:44, 10.98s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:43<17:14, 10.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:54<16:42, 10.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:03<16:10, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:13<15:35, 10.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:22<15:06,  9.86s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:32<14:44,  9.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:41<14:26,  9.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [01:51<14:08,  9.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:00<13:49,  9.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:09<13:32,  9.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:18<13:17,  9.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:27<13:02,  9.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:36<12:49,  9.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [02:45<12:35,  9.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [02:54<12:24,  9.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:03<12:13,  9.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:12<12:03,  9.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:21<11:52,  9.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:30<11:41,  8.99s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [03:39<11:30,  8.96s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [03:48<11:19,  8.94s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [03:57<11:09,  8.93s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:06<10:59,  8.92s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:14<10:47,  8.88s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:23<10:35,  8.82s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [04:32<10:24,  8.79s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [04:40<10:13,  8.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [04:49<10:03,  8.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [04:58<09:53,  8.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:07<09:44,  8.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [05:15<09:35,  8.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [05:24<09:25,  8.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [05:33<09:16,  8.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [05:41<09:07,  8.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [05:50<08:58,  8.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [05:59<08:49,  8.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [06:07<08:40,  8.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [06:16<08:31,  8.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [06:25<08:22,  8.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [06:33<08:13,  8.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [06:42<08:04,  8.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [06:51<07:55,  8.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [06:59<07:46,  8.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [07:08<07:39,  8.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [07:17<07:30,  8.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [07:25<07:22,  8.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [07:34<07:12,  8.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [07:42<07:03,  8.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [07:51<06:54,  8.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [08:00<06:45,  8.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [08:08<06:36,  8.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [08:17<06:27,  8.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [08:25<06:18,  8.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [08:34<06:10,  8.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [08:43<06:01,  8.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [08:51<05:52,  8.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [09:00<05:43,  8.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [09:08<05:35,  8.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [09:17<05:26,  8.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [09:26<05:17,  8.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [09:34<05:09,  8.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [09:43<05:00,  8.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [09:51<04:51,  8.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [10:00<04:42,  8.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [10:08<04:34,  8.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [10:17<04:25,  8.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [10:26<04:16,  8.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [10:34<04:08,  8.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [10:43<03:59,  8.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [10:51<03:50,  8.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [11:00<03:42,  8.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [11:08<03:33,  8.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [11:17<03:24,  8.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [11:25<03:16,  8.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [11:34<03:07,  8.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [11:42<02:58,  8.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [11:51<02:50,  8.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [11:59<02:41,  8.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [12:08<02:33,  8.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [12:16<02:24,  8.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [12:25<02:15,  8.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [12:33<02:07,  8.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [12:42<01:58,  8.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [12:50<01:50,  8.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [12:59<01:41,  8.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [13:07<01:33,  8.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [13:15<01:24,  8.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [13:24<01:16,  8.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [13:32<01:07,  8.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [13:41<00:59,  8.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [13:49<00:50,  8.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [13:58<00:42,  8.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [14:06<00:33,  8.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [14:15<00:25,  8.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [14:23<00:16,  8.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [14:31<00:08,  8.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [14:40<00:00,  8.43s/it]100%|██████████| 100/100 [14:40<00:00,  8.80s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2024-12-28:02:28:44,428 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-12-28:02:28:44,428 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2024-12-28:02:28:44,428 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2024-12-28:02:28:44,849 INFO     [config.py:58] PyTorch version 2.4.1 available.
2024-12-28:02:28:49,926 INFO     [__main__.py:132] Verbosity set to INFO
2024-12-28:02:29:03,070 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-12-28:02:29:03,072 INFO     [__main__.py:205] Selected Tasks: ['code2text_python']
2024-12-28:02:29:03,083 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2024-12-28:02:29:03,353 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  6.37it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  8.03it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  9.25it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  8.77it/s]
2024-12-28:02:29:49,024 INFO     [task.py:355] Building contexts for task on rank 0...
2024-12-28:02:29:49,040 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:612: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:09, 12.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:22<18:29, 11.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:33<17:47, 11.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:44<17:16, 10.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:54<16:43, 10.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:04<16:12, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:13<15:37, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:23<15:08,  9.87s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:32<14:46,  9.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:41<14:28,  9.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [01:51<14:09,  9.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:00<13:50,  9.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:09<13:38,  9.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:18<13:23,  9.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:28<13:07,  9.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:37<12:53,  9.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [02:46<12:38,  9.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [02:55<12:26,  9.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:04<12:14,  9.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:13<12:04,  9.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:22<11:53,  9.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:31<11:41,  9.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [03:39<11:30,  8.97s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [03:48<11:20,  8.95s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [03:57<11:10,  8.93s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:06<11:00,  8.92s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:15<10:48,  8.88s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:24<10:36,  8.84s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [04:32<10:24,  8.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [04:41<10:13,  8.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [04:50<10:03,  8.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [04:58<09:53,  8.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:07<09:45,  8.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [05:16<09:35,  8.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [05:25<09:26,  8.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [05:33<09:17,  8.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [05:42<09:08,  8.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [05:51<08:59,  8.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [05:59<08:50,  8.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [06:08<08:40,  8.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [06:17<08:31,  8.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [06:25<08:22,  8.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [06:34<08:13,  8.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [06:43<08:04,  8.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [06:51<07:56,  8.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [07:00<07:47,  8.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [07:09<07:37,  8.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [07:17<07:28,  8.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [07:26<07:20,  8.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [07:34<07:11,  8.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [07:43<07:02,  8.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [07:52<06:53,  8.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [08:00<06:45,  8.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [08:09<06:36,  8.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [08:17<06:27,  8.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [08:26<06:18,  8.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [08:35<06:10,  8.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [08:43<06:01,  8.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [08:52<05:53,  8.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [09:00<05:44,  8.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [09:09<05:35,  8.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [09:18<05:26,  8.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [09:26<05:17,  8.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [09:35<05:09,  8.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [09:43<05:00,  8.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [09:52<04:51,  8.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [10:01<04:42,  8.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [10:09<04:34,  8.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [10:18<04:25,  8.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [10:26<04:16,  8.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [10:35<04:08,  8.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [10:43<03:59,  8.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [10:52<03:50,  8.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [11:00<03:42,  8.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [11:09<03:33,  8.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [11:17<03:25,  8.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [11:26<03:16,  8.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [11:35<03:07,  8.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [11:43<02:59,  8.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [11:52<02:50,  8.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [12:00<02:42,  8.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [12:09<02:33,  8.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [12:17<02:24,  8.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [12:26<02:15,  8.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [12:34<02:07,  8.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [12:43<01:58,  8.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [12:51<01:50,  8.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [12:59<01:41,  8.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [13:08<01:33,  8.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [13:16<01:24,  8.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [13:25<01:16,  8.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [13:33<01:07,  8.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [13:42<00:59,  8.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [13:50<00:50,  8.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [13:59<00:42,  8.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [14:07<00:33,  8.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [14:15<00:25,  8.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [14:24<00:16,  8.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [14:32<00:08,  8.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [14:41<00:00,  8.44s/it]100%|██████████| 100/100 [14:41<00:00,  8.81s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2024-12-28:02:45:08,787 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-12-28:02:45:08,788 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2024-12-28:02:45:08,789 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2024-12-28:02:45:09,262 INFO     [config.py:58] PyTorch version 2.4.1 available.
2024-12-28:02:45:14,381 INFO     [__main__.py:132] Verbosity set to INFO
2024-12-28:02:45:26,615 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-12-28:02:45:26,618 INFO     [__main__.py:205] Selected Tasks: ['code2text_python']
2024-12-28:02:45:26,626 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2024-12-28:02:45:26,893 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  6.26it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  7.93it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  8.63it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  8.58it/s]
2024-12-28:02:46:11,375 INFO     [task.py:355] Building contexts for task on rank 0...
2024-12-28:02:46:11,391 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:612: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:09, 12.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:22<18:28, 11.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:33<17:45, 10.98s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:43<17:15, 10.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:54<16:41, 10.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:03<16:10, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:13<15:35, 10.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:22<15:06,  9.86s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:32<14:44,  9.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:41<14:26,  9.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [01:51<14:08,  9.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:00<13:49,  9.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:09<13:32,  9.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:18<13:17,  9.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:27<13:02,  9.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:36<12:49,  9.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [02:45<12:35,  9.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [02:54<12:24,  9.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:03<12:13,  9.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:12<12:02,  9.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:21<11:52,  9.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:30<11:40,  8.99s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [03:39<11:30,  8.96s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [03:48<11:19,  8.94s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [03:57<11:09,  8.93s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:06<10:59,  8.91s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:14<10:47,  8.87s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:23<10:35,  8.82s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [04:32<10:23,  8.79s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [04:40<10:13,  8.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [04:49<10:03,  8.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [04:58<09:53,  8.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:07<09:43,  8.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [05:15<09:34,  8.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [05:24<09:25,  8.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [05:33<09:16,  8.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [05:41<09:07,  8.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [05:50<08:58,  8.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [05:59<08:49,  8.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [06:07<08:40,  8.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [06:16<08:31,  8.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [06:25<08:22,  8.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [06:33<08:12,  8.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [06:42<08:04,  8.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [06:50<07:55,  8.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [06:59<07:46,  8.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [07:08<07:37,  8.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [07:16<07:28,  8.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [07:25<07:19,  8.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [07:34<07:10,  8.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [07:42<07:02,  8.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [07:51<06:53,  8.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [07:59<06:44,  8.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [08:08<06:36,  8.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [08:17<06:27,  8.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [08:25<06:18,  8.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [08:34<06:09,  8.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [08:42<06:01,  8.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [08:51<05:52,  8.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [09:00<05:43,  8.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [09:08<05:35,  8.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [09:17<05:26,  8.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [09:25<05:17,  8.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [09:34<05:08,  8.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [09:42<05:00,  8.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [09:51<04:51,  8.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [10:00<04:42,  8.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [10:08<04:34,  8.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [10:17<04:25,  8.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [10:25<04:16,  8.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [10:34<04:07,  8.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [10:42<03:59,  8.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [10:51<03:50,  8.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [10:59<03:42,  8.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [11:08<03:33,  8.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [11:16<03:24,  8.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [11:25<03:16,  8.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [11:33<03:07,  8.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [11:42<02:58,  8.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [11:50<02:50,  8.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [11:59<02:41,  8.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [12:07<02:33,  8.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [12:16<02:24,  8.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [12:25<02:16,  8.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [12:33<02:08,  8.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [12:42<01:59,  8.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [12:50<01:50,  8.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [12:58<01:41,  8.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [13:07<01:33,  8.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [13:15<01:24,  8.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [13:24<01:16,  8.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [13:32<01:07,  8.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [13:41<00:59,  8.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [13:49<00:50,  8.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [13:58<00:42,  8.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [14:06<00:33,  8.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [14:14<00:25,  8.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [14:23<00:16,  8.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [14:31<00:08,  8.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [14:40<00:00,  8.43s/it]100%|██████████| 100/100 [14:40<00:00,  8.80s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2024-12-28:03:02:39,985 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-12-28:03:02:39,986 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2024-12-28:03:02:39,986 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2024-12-28:03:02:40,434 INFO     [config.py:58] PyTorch version 2.4.1 available.
2024-12-28:03:02:45,542 INFO     [__main__.py:132] Verbosity set to INFO
2024-12-28:03:02:58,807 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-12-28:03:02:58,810 INFO     [__main__.py:205] Selected Tasks: ['code2text_python']
2024-12-28:03:02:58,821 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2024-12-28:03:02:59,073 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  6.40it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  8.10it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  9.35it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  8.85it/s]
2024-12-28:03:03:43,390 INFO     [task.py:355] Building contexts for task on rank 0...
2024-12-28:03:03:43,406 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:612: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:14<23:56, 14.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:27<22:14, 13.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:40<21:25, 13.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:52<20:46, 12.99s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [01:04<19:58, 12.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:16<19:09, 12.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:27<18:12, 11.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:37<17:25, 11.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:48<16:51, 11.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:58<16:23, 10.93s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [02:09<15:56, 10.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:19<15:25, 10.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:29<15:00, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:38<14:38, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:48<14:16, 10.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:58<13:57,  9.97s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:08<13:40,  9.88s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:17<13:24,  9.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:27<13:10,  9.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:36<12:56,  9.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:46<12:43,  9.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:56<12:30,  9.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:05<12:15,  9.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:14<12:01,  9.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:24<11:49,  9.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:33<11:37,  9.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:42<11:22,  9.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:51<11:05,  9.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:00<10:50,  9.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:09<10:37,  9.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:18<10:25,  9.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:27<10:14,  9.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:36<10:04,  9.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [05:45<09:54,  9.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [05:54<09:44,  8.99s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:03<09:34,  8.98s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:12<09:25,  8.97s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:21<09:15,  8.96s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:30<09:05,  8.95s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [06:39<08:55,  8.93s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [06:47<08:46,  8.92s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [06:56<08:36,  8.90s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:05<08:26,  8.89s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:14<08:17,  8.88s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:23<08:07,  8.87s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [07:32<07:58,  8.86s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [07:41<07:49,  8.85s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [07:49<07:39,  8.84s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [07:58<07:30,  8.83s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:07<07:21,  8.83s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [08:16<07:14,  8.87s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [08:25<07:04,  8.85s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [08:34<06:55,  8.84s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [08:42<06:46,  8.83s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [08:51<06:36,  8.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:00<06:26,  8.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [09:09<06:17,  8.79s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [09:17<06:09,  8.79s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [09:26<06:00,  8.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [09:35<05:50,  8.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [09:44<05:41,  8.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [09:52<05:32,  8.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [10:01<05:23,  8.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [10:10<05:14,  8.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [10:19<05:05,  8.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [10:27<04:56,  8.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [10:36<04:47,  8.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [10:45<04:38,  8.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [10:53<04:29,  8.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [11:02<04:20,  8.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [11:11<04:11,  8.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [11:19<04:02,  8.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [11:28<03:54,  8.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [11:37<03:45,  8.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [11:45<03:36,  8.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [11:54<03:27,  8.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [12:03<03:18,  8.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [12:11<03:09,  8.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [12:20<03:00,  8.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [12:28<02:52,  8.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [12:37<02:43,  8.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [12:45<02:34,  8.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [12:54<02:25,  8.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [13:03<02:16,  8.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [13:11<02:08,  8.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [13:20<01:59,  8.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [13:28<01:50,  8.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [13:37<01:42,  8.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [13:45<01:33,  8.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [13:53<01:24,  8.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [14:02<01:16,  8.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [14:10<01:07,  8.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [14:19<00:59,  8.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [14:27<00:50,  8.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [14:36<00:42,  8.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [14:44<00:33,  8.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [14:53<00:25,  8.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [15:01<00:16,  8.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [15:10<00:08,  8.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [15:18<00:00,  8.44s/it]100%|██████████| 100/100 [15:18<00:00,  9.18s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2024-12-28:03:19:40,155 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-12-28:03:19:40,156 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2024-12-28:03:19:40,156 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2024-12-28:03:19:40,566 INFO     [config.py:58] PyTorch version 2.4.1 available.
2024-12-28:03:19:45,594 INFO     [__main__.py:132] Verbosity set to INFO
2024-12-28:03:19:58,762 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-12-28:03:19:58,765 INFO     [__main__.py:205] Selected Tasks: ['code2text_python']
2024-12-28:03:19:58,775 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2024-12-28:03:19:59,021 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  5.89it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  7.64it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  8.56it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  8.48it/s]
2024-12-28:03:20:43,269 INFO     [task.py:355] Building contexts for task on rank 0...
2024-12-28:03:20:43,285 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:612: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:14<23:58, 14.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:27<22:16, 13.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:40<21:28, 13.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:52<20:49, 13.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [01:04<20:00, 12.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:16<19:11, 12.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:27<18:14, 11.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:37<17:27, 11.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:48<16:53, 11.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:58<16:25, 10.95s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [02:09<15:58, 10.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:19<15:28, 10.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:29<15:03, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:39<14:40, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:48<14:17, 10.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:58<13:59,  9.99s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:08<13:42,  9.90s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:18<13:26,  9.84s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:27<13:12,  9.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:37<12:58,  9.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:46<12:45,  9.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:56<12:32,  9.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:05<12:17,  9.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:15<12:03,  9.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:24<11:51,  9.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:34<11:42,  9.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:43<11:26,  9.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:52<11:08,  9.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:01<10:53,  9.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:10<10:39,  9.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:19<10:27,  9.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:28<10:16,  9.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:37<10:06,  9.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [05:46<09:56,  9.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [05:55<09:46,  9.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:04<09:36,  9.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:13<09:26,  8.99s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:22<09:16,  8.98s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:31<09:07,  8.97s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [06:40<08:57,  8.95s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [06:49<08:47,  8.94s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [06:57<08:37,  8.92s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:06<08:27,  8.91s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:15<08:18,  8.90s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:24<08:08,  8.89s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [07:33<07:59,  8.88s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [07:42<07:50,  8.87s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [07:51<07:40,  8.86s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [07:59<07:31,  8.85s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:08<07:22,  8.85s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [08:17<07:13,  8.85s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [08:26<07:04,  8.84s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [08:35<06:55,  8.83s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [08:44<06:46,  8.83s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [08:52<06:36,  8.82s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:01<06:27,  8.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [09:10<06:18,  8.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [09:19<06:09,  8.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [09:28<06:00,  8.79s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [09:36<05:51,  8.79s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [09:45<05:42,  8.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [09:54<05:33,  8.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [10:03<05:24,  8.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [10:11<05:15,  8.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [10:20<05:06,  8.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [10:29<04:57,  8.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [10:38<04:48,  8.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [10:46<04:39,  8.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [10:55<04:30,  8.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [11:04<04:21,  8.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [11:12<04:12,  8.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [11:21<04:03,  8.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [11:30<03:54,  8.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [11:38<03:45,  8.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [11:47<03:36,  8.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [11:56<03:27,  8.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [12:04<03:19,  8.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [12:13<03:10,  8.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [12:22<03:01,  8.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [12:30<02:52,  8.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [12:39<02:43,  8.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [12:47<02:34,  8.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [12:56<02:26,  8.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [13:04<02:17,  8.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [13:13<02:08,  8.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [13:22<01:59,  8.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [13:30<01:51,  8.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [13:39<01:42,  8.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [13:47<01:33,  8.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [13:56<01:25,  8.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [14:04<01:16,  8.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [14:13<01:08,  8.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [14:21<00:59,  8.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [14:30<00:50,  8.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [14:38<00:42,  8.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [14:47<00:33,  8.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [14:55<00:25,  8.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [15:03<00:16,  8.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [15:12<00:08,  8.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [15:20<00:00,  8.47s/it]100%|██████████| 100/100 [15:20<00:00,  9.21s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2024-12-28:03:36:42,645 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-12-28:03:36:42,646 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2024-12-28:03:36:42,646 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2024-12-28:03:36:43,093 INFO     [config.py:58] PyTorch version 2.4.1 available.
2024-12-28:03:36:48,270 INFO     [__main__.py:132] Verbosity set to INFO
2024-12-28:03:37:01,543 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-12-28:03:37:01,545 INFO     [__main__.py:205] Selected Tasks: ['code2text_python']
2024-12-28:03:37:01,556 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2024-12-28:03:37:01,819 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  5.86it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  6.54it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  7.01it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  7.45it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  7.09it/s]
2024-12-28:03:37:46,546 INFO     [task.py:355] Building contexts for task on rank 0...
2024-12-28:03:37:46,563 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:612: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:14<24:01, 14.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:27<22:16, 13.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:40<21:26, 13.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:52<20:47, 12.99s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [01:04<19:58, 12.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:16<19:09, 12.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:27<18:11, 11.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:37<17:24, 11.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:48<16:50, 11.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:58<16:26, 10.96s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [02:09<15:58, 10.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:19<15:27, 10.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:29<15:02, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:39<14:39, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:48<14:16, 10.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:58<13:57,  9.97s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:08<13:39,  9.88s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:17<13:24,  9.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:27<13:09,  9.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:37<12:56,  9.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:46<12:43,  9.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:56<12:30,  9.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:05<12:14,  9.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:14<12:01,  9.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:24<11:48,  9.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:33<11:36,  9.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:42<11:21,  9.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:51<11:04,  9.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:00<10:49,  9.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:09<10:37,  9.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:18<10:25,  9.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:27<10:14,  9.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:36<10:04,  9.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [05:45<09:54,  9.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [05:54<09:44,  8.99s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:03<09:34,  8.98s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:12<09:24,  8.96s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:21<09:15,  8.96s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:30<09:05,  8.94s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [06:39<08:55,  8.92s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [06:47<08:45,  8.91s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [06:56<08:35,  8.89s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:05<08:26,  8.88s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:14<08:16,  8.87s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:23<08:07,  8.86s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [07:32<07:57,  8.85s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [07:40<07:48,  8.84s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [07:49<07:39,  8.83s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [07:58<07:30,  8.82s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:07<07:20,  8.82s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [08:16<07:12,  8.82s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [08:25<07:02,  8.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [08:33<06:53,  8.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [08:42<06:44,  8.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [08:51<06:35,  8.79s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:00<06:26,  8.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [09:08<06:17,  8.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [09:17<06:08,  8.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [09:26<05:59,  8.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [09:35<05:50,  8.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [09:43<05:41,  8.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [09:52<05:32,  8.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [10:01<05:23,  8.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [10:10<05:14,  8.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [10:18<05:05,  8.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [10:27<04:56,  8.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [10:36<04:47,  8.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [10:44<04:38,  8.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [10:53<04:29,  8.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [11:02<04:20,  8.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [11:10<04:11,  8.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [11:19<04:02,  8.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [11:28<03:53,  8.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [11:36<03:45,  8.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [11:45<03:36,  8.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [11:54<03:27,  8.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [12:02<03:18,  8.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [12:11<03:09,  8.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [12:19<03:00,  8.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [12:28<02:52,  8.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [12:37<02:43,  8.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [12:45<02:34,  8.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [12:54<02:25,  8.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [13:02<02:16,  8.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [13:11<02:08,  8.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [13:19<01:59,  8.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [13:28<01:50,  8.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [13:36<01:42,  8.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [13:45<01:33,  8.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [13:53<01:24,  8.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [14:02<01:16,  8.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [14:10<01:07,  8.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [14:18<00:59,  8.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [14:27<00:50,  8.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [14:35<00:42,  8.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [14:44<00:33,  8.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [14:52<00:25,  8.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [15:01<00:16,  8.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [15:09<00:08,  8.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [15:18<00:00,  8.45s/it]100%|██████████| 100/100 [15:18<00:00,  9.18s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2024-12-28:03:53:43,226 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-12-28:03:53:43,227 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2024-12-28:03:53:43,227 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2024-12-28:03:53:43,694 INFO     [config.py:58] PyTorch version 2.4.1 available.
2024-12-28:03:53:48,986 INFO     [__main__.py:132] Verbosity set to INFO
2024-12-28:03:54:02,074 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-12-28:03:54:02,077 INFO     [__main__.py:205] Selected Tasks: ['code2text_python']
2024-12-28:03:54:02,088 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2024-12-28:03:54:02,344 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  5.98it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  7.58it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  8.37it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  8.35it/s]
2024-12-28:03:54:47,222 INFO     [task.py:355] Building contexts for task on rank 0...
2024-12-28:03:54:47,238 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:612: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:14<24:03, 14.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:27<22:20, 13.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:40<21:31, 13.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:53<20:52, 13.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [01:05<20:03, 12.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:16<19:14, 12.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:27<18:17, 11.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:38<17:30, 11.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:48<16:55, 11.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:59<16:28, 10.98s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [02:09<16:01, 10.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:19<15:30, 10.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:29<15:05, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:39<14:43, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:49<14:20, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:59<14:01, 10.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:08<13:44,  9.93s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:18<13:29,  9.87s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:28<13:14,  9.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:38<13:01,  9.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:47<12:47,  9.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:57<12:34,  9.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:06<12:19,  9.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:16<12:05,  9.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:25<11:53,  9.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:34<11:41,  9.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:44<11:25,  9.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:53<11:09,  9.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:02<10:54,  9.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:11<10:41,  9.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:20<10:29,  9.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:29<10:18,  9.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:38<10:07,  9.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [05:47<09:57,  9.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [05:56<09:48,  9.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:05<09:38,  9.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:14<09:28,  9.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:23<09:18,  9.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:32<09:09,  9.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [06:41<08:59,  8.98s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [06:50<08:49,  8.97s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [06:59<08:39,  8.96s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:08<08:29,  8.94s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:16<08:20,  8.93s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:25<08:10,  8.92s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [07:34<08:01,  8.91s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [07:43<07:51,  8.90s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [07:52<07:42,  8.89s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:01<07:33,  8.89s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:10<07:24,  8.89s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [08:19<07:15,  8.88s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [08:27<07:05,  8.87s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [08:36<06:56,  8.87s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [08:45<06:47,  8.87s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [08:54<06:38,  8.85s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:03<06:29,  8.84s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [09:12<06:19,  8.84s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [09:20<06:10,  8.83s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [09:29<06:01,  8.83s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [09:38<05:52,  8.82s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [09:47<05:43,  8.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [09:56<05:34,  8.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [10:04<05:25,  8.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [10:13<05:16,  8.79s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [10:22<05:07,  8.79s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [10:31<04:58,  8.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [10:40<04:49,  8.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [10:48<04:40,  8.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [10:57<04:31,  8.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [11:06<04:22,  8.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [11:14<04:13,  8.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [11:23<04:04,  8.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [11:32<03:55,  8.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [11:41<03:46,  8.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [11:49<03:37,  8.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [11:58<03:28,  8.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [12:07<03:19,  8.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [12:15<03:10,  8.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [12:24<03:02,  8.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [12:33<02:53,  8.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [12:41<02:44,  8.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [12:50<02:35,  8.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [12:58<02:26,  8.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [13:07<02:17,  8.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [13:16<02:09,  8.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [13:24<02:00,  8.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [13:33<01:51,  8.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [13:41<01:43,  8.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [13:50<01:34,  8.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [13:58<01:25,  8.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [14:07<01:17,  8.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [14:16<01:08,  8.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [14:24<00:59,  8.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [14:33<00:51,  8.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [14:41<00:42,  8.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [14:50<00:34,  8.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [14:58<00:25,  8.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [15:07<00:17,  8.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [15:15<00:08,  8.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [15:24<00:00,  8.50s/it]100%|██████████| 100/100 [15:24<00:00,  9.24s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2024-12-28:04:10:49,601 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-12-28:04:10:49,601 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2024-12-28:04:10:49,602 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2024-12-28:04:10:50,035 INFO     [config.py:58] PyTorch version 2.4.1 available.
2024-12-28:04:10:55,208 INFO     [__main__.py:132] Verbosity set to INFO
2024-12-28:04:11:08,251 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-12-28:04:11:08,253 INFO     [__main__.py:205] Selected Tasks: ['code2text_python']
2024-12-28:04:11:08,264 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2024-12-28:04:11:08,537 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  6.34it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  7.97it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  8.77it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  8.72it/s]
2024-12-28:04:11:54,445 INFO     [task.py:355] Building contexts for task on rank 0...
2024-12-28:04:11:54,461 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:612: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:14<23:41, 14.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:27<22:09, 13.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:40<21:23, 13.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:52<20:45, 12.98s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [01:04<19:58, 12.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:16<19:10, 12.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:27<18:12, 11.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:37<17:26, 11.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:48<16:51, 11.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:58<16:24, 10.94s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [02:09<15:57, 10.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:19<15:26, 10.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:29<15:01, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:38<14:39, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:48<14:16, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:58<13:57,  9.98s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:08<13:40,  9.89s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:17<13:25,  9.82s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:27<13:11,  9.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:37<12:57,  9.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:46<12:44,  9.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:56<12:31,  9.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:05<12:16,  9.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:14<12:02,  9.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:24<11:50,  9.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:33<11:38,  9.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:42<11:22,  9.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:51<11:06,  9.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:00<10:51,  9.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:09<10:38,  9.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:18<10:26,  9.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:27<10:15,  9.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:36<10:05,  9.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [05:45<09:55,  9.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [05:54<09:45,  9.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:03<09:35,  9.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:12<09:26,  8.98s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:21<09:16,  8.97s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:30<09:06,  8.96s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [06:39<08:56,  8.94s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [06:48<08:46,  8.93s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [06:57<08:37,  8.91s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:06<08:27,  8.90s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:14<08:17,  8.89s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:23<08:08,  8.88s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [07:32<07:59,  8.87s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [07:41<07:49,  8.86s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [07:50<07:40,  8.85s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [07:59<07:31,  8.85s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:07<07:22,  8.84s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [08:16<07:13,  8.84s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [08:25<07:03,  8.83s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [08:34<06:54,  8.83s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [08:43<06:45,  8.82s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [08:52<06:36,  8.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:00<06:27,  8.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [09:09<06:18,  8.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [09:18<06:09,  8.79s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [09:27<06:00,  8.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [09:35<05:51,  8.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [09:44<05:42,  8.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [09:53<05:32,  8.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [10:02<05:24,  8.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [10:10<05:15,  8.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [10:19<05:06,  8.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [10:28<04:57,  8.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [10:37<04:48,  8.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [10:45<04:40,  8.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [10:54<04:31,  8.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [11:03<04:22,  8.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [11:12<04:13,  8.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [11:20<04:04,  8.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [11:29<03:55,  8.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [11:38<03:45,  8.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [11:46<03:36,  8.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [11:55<03:27,  8.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [12:03<03:18,  8.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [12:12<03:10,  8.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [12:21<03:01,  8.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [12:29<02:52,  8.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [12:38<02:43,  8.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [12:46<02:34,  8.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [12:55<02:26,  8.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [13:04<02:17,  8.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [13:12<02:08,  8.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [13:21<01:59,  8.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [13:29<01:51,  8.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [13:38<01:42,  8.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [13:46<01:33,  8.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [13:55<01:25,  8.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [14:03<01:16,  8.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [14:12<01:08,  8.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [14:20<00:59,  8.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [14:29<00:50,  8.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [14:37<00:42,  8.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [14:46<00:33,  8.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [14:54<00:25,  8.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [15:03<00:16,  8.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [15:11<00:08,  8.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [15:19<00:00,  8.47s/it]100%|██████████| 100/100 [15:19<00:00,  9.20s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2024-12-28:04:29:02,850 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-12-28:04:29:02,851 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2024-12-28:04:29:02,851 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2024-12-28:04:29:03,273 INFO     [config.py:58] PyTorch version 2.4.1 available.
2024-12-28:04:29:08,460 INFO     [__main__.py:132] Verbosity set to INFO
2024-12-28:04:29:21,707 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-12-28:04:29:21,709 INFO     [__main__.py:205] Selected Tasks: ['code2text_python']
2024-12-28:04:29:21,720 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2024-12-28:04:29:21,997 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  6.28it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  7.84it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  8.59it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  8.55it/s]
2024-12-28:04:30:06,532 INFO     [task.py:355] Building contexts for task on rank 0...
2024-12-28:04:30:06,547 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:612: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:15<26:01, 15.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:29<23:56, 14.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:43<23:00, 14.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:56<22:17, 13.93s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [01:09<21:26, 13.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:22<20:35, 13.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:33<19:36, 12.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:45<18:48, 12.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:56<18:13, 12.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [02:08<17:45, 11.83s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [02:19<17:16, 11.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:30<16:45, 11.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:41<16:19, 11.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:51<15:57, 11.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [03:02<15:32, 10.98s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [03:13<15:13, 10.87s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:23<14:55, 10.79s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:34<14:38, 10.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:44<14:23, 10.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:55<14:09, 10.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [04:05<13:54, 10.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [04:16<13:40, 10.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:26<13:24, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:36<13:10, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:46<12:56, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:57<12:43, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [05:07<12:27, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [05:17<12:09, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:27<11:53, 10.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:36<11:39, 10.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:46<11:27,  9.96s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:56<11:15,  9.93s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [06:06<11:04,  9.92s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [06:16<10:53,  9.90s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:26<10:42,  9.89s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:36<10:32,  9.88s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:45<10:21,  9.87s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:55<10:11,  9.86s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [07:05<10:03,  9.89s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [07:15<09:52,  9.87s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:25<09:41,  9.86s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:35<09:30,  9.83s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:44<09:18,  9.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:54<09:08,  9.79s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [08:04<08:57,  9.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [08:14<08:47,  9.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:23<08:36,  9.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:33<08:26,  9.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:43<08:16,  9.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:52<08:06,  9.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [09:02<07:56,  9.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:12<07:46,  9.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:22<07:36,  9.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:31<07:26,  9.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:41<07:16,  9.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:51<07:05,  9.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [10:00<06:56,  9.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:10<06:46,  9.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:20<06:36,  9.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:29<06:26,  9.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:39<06:16,  9.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:48<06:06,  9.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [10:58<05:56,  9.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:08<05:46,  9.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:17<05:36,  9.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:27<05:26,  9.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:37<05:17,  9.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:46<05:07,  9.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [11:56<04:57,  9.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:05<04:47,  9.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:15<04:37,  9.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:24<04:28,  9.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:34<04:18,  9.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:43<04:08,  9.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [12:53<03:59,  9.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:03<03:49,  9.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:12<03:39,  9.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:22<03:29,  9.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:31<03:19,  9.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [13:40<03:10,  9.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [13:50<03:00,  9.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [13:59<02:50,  9.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:09<02:40,  9.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:18<02:31,  9.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:28<02:21,  9.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [14:37<02:12,  9.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [14:46<02:02,  9.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [14:56<01:52,  9.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:05<01:43,  9.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:15<01:33,  9.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:24<01:24,  9.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [15:33<01:14,  9.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [15:43<01:05,  9.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [15:52<00:56,  9.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:01<00:46,  9.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:11<00:37,  9.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:20<00:28,  9.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [16:29<00:18,  9.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [16:39<00:09,  9.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [16:48<00:00,  9.34s/it]100%|██████████| 100/100 [16:48<00:00, 10.09s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2024-12-28:04:47:33,408 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-12-28:04:47:33,408 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2024-12-28:04:47:33,409 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2024-12-28:04:47:33,810 INFO     [config.py:58] PyTorch version 2.4.1 available.
2024-12-28:04:47:38,970 INFO     [__main__.py:132] Verbosity set to INFO
2024-12-28:04:47:51,378 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-12-28:04:47:51,381 INFO     [__main__.py:205] Selected Tasks: ['code2text_python']
2024-12-28:04:47:51,392 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2024-12-28:04:47:51,655 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  5.39it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  7.11it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  7.99it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  8.65it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  7.95it/s]
2024-12-28:04:48:36,443 INFO     [task.py:355] Building contexts for task on rank 0...
2024-12-28:04:48:36,459 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:612: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:15<25:19, 15.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:29<23:38, 14.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:42<22:49, 14.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:56<22:10, 13.86s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [01:09<21:21, 13.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:21<20:31, 13.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:33<19:33, 12.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:44<18:46, 12.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:56<18:11, 11.99s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [02:07<17:42, 11.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [02:18<17:14, 11.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:29<16:43, 11.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:40<16:17, 11.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:51<15:54, 11.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [03:01<15:30, 10.95s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [03:12<15:10, 10.84s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:22<14:52, 10.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:33<14:36, 10.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:43<14:21, 10.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:54<14:06, 10.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [04:05<13:55, 10.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [04:15<13:41, 10.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:25<13:26, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:36<13:11, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:46<12:57, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:56<12:43, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [05:06<12:26, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [05:16<12:09, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:26<11:53, 10.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:36<11:39,  9.99s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:45<11:26,  9.95s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:55<11:14,  9.92s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [06:05<11:03,  9.90s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [06:15<10:52,  9.88s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:25<10:41,  9.87s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:35<10:30,  9.86s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:45<10:20,  9.85s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:54<10:09,  9.84s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [07:04<09:59,  9.83s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [07:14<09:48,  9.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:24<09:37,  9.79s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:33<09:27,  9.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:43<09:16,  9.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:53<09:06,  9.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [08:03<08:55,  9.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [08:12<08:45,  9.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:22<08:35,  9.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:32<08:25,  9.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:41<08:15,  9.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:51<08:05,  9.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [09:01<07:55,  9.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:10<07:45,  9.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:20<07:35,  9.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:30<07:25,  9.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:39<07:15,  9.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:49<07:05,  9.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [09:59<06:55,  9.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:08<06:45,  9.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:18<06:35,  9.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:28<06:25,  9.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:37<06:15,  9.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:47<06:05,  9.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [10:56<05:56,  9.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:06<05:46,  9.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:16<05:36,  9.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:25<05:26,  9.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:35<05:16,  9.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:44<05:06,  9.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [11:54<04:56,  9.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:04<04:47,  9.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:13<04:37,  9.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:23<04:27,  9.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:32<04:17,  9.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:42<04:08,  9.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [12:51<03:58,  9.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:01<03:48,  9.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:10<03:38,  9.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:20<03:28,  9.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:29<03:19,  9.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [13:39<03:09,  9.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [13:48<02:59,  9.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [13:57<02:50,  9.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:07<02:40,  9.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:16<02:30,  9.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:26<02:21,  9.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [14:35<02:11,  9.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [14:44<02:02,  9.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [14:54<01:52,  9.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:03<01:43,  9.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:12<01:33,  9.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:22<01:24,  9.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [15:31<01:14,  9.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [15:41<01:05,  9.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [15:50<00:56,  9.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [15:59<00:46,  9.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:09<00:37,  9.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:18<00:27,  9.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [16:27<00:18,  9.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [16:36<00:09,  9.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [16:46<00:00,  9.32s/it]100%|██████████| 100/100 [16:46<00:00, 10.06s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2024-12-28:05:06:00,353 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-12-28:05:06:00,354 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2024-12-28:05:06:00,354 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2024-12-28:05:06:00,698 INFO     [config.py:58] PyTorch version 2.4.1 available.
2024-12-28:05:06:05,108 INFO     [__main__.py:132] Verbosity set to INFO
2024-12-28:05:06:16,484 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-12-28:05:06:16,486 INFO     [__main__.py:205] Selected Tasks: ['code2text_python']
2024-12-28:05:06:16,495 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2024-12-28:05:06:16,752 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  5.97it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  7.36it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  8.94it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  8.38it/s]
2024-12-28:05:07:00,570 INFO     [task.py:355] Building contexts for task on rank 0...
2024-12-28:05:07:00,585 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:612: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:15<25:04, 15.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:29<23:29, 14.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:42<22:42, 14.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:56<22:04, 13.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [01:08<21:15, 13.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:21<20:26, 13.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:32<19:28, 12.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:44<18:41, 12.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:55<18:06, 11.94s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [02:06<17:42, 11.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [02:18<17:14, 11.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:29<16:41, 11.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:39<16:14, 11.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:50<15:50, 11.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [03:01<15:26, 10.90s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [03:11<15:06, 10.79s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:22<14:48, 10.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:32<14:31, 10.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:43<14:16, 10.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:53<14:01, 10.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [04:03<13:47, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [04:14<13:33, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:24<13:17, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:34<13:03, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:44<12:50, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:54<12:37, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [05:04<12:21, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [05:14<12:03, 10.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:24<11:47,  9.97s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:34<11:33,  9.91s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:43<11:21,  9.87s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:53<11:09,  9.84s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [06:03<10:58,  9.83s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [06:13<10:47,  9.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:23<10:37,  9.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:32<10:26,  9.79s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:42<10:15,  9.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:52<10:05,  9.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [07:02<09:55,  9.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [07:11<09:44,  9.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:21<09:33,  9.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:31<09:23,  9.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:40<09:12,  9.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:50<09:02,  9.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [08:00<08:52,  9.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [08:09<08:42,  9.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:19<08:31,  9.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:28<08:21,  9.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:38<08:11,  9.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:48<08:01,  9.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [08:57<07:51,  9.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:07<07:42,  9.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:17<07:32,  9.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:26<07:22,  9.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:36<07:12,  9.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:45<07:02,  9.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [09:55<06:52,  9.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:04<06:42,  9.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:14<06:32,  9.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:24<06:22,  9.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:33<06:12,  9.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:43<06:03,  9.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [10:52<05:53,  9.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:02<05:43,  9.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:11<05:33,  9.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:21<05:24,  9.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:30<05:14,  9.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:40<05:04,  9.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [11:49<04:54,  9.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [11:59<04:45,  9.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:08<04:35,  9.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:18<04:25,  9.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:27<04:15,  9.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:37<04:06,  9.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [12:46<03:56,  9.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [12:55<03:46,  9.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:05<03:37,  9.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:14<03:27,  9.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:24<03:17,  9.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [13:33<03:08,  9.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [13:42<02:58,  9.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [13:52<02:48,  9.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:01<02:39,  9.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:10<02:29,  9.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:20<02:20,  9.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [14:29<02:10,  9.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [14:38<02:01,  9.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [14:48<01:51,  9.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [14:57<01:42,  9.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:06<01:33,  9.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:16<01:23,  9.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [15:25<01:14,  9.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [15:34<01:04,  9.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [15:43<00:55,  9.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [15:53<00:46,  9.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:02<00:37,  9.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:11<00:27,  9.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [16:20<00:18,  9.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [16:30<00:09,  9.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [16:39<00:00,  9.26s/it]100%|██████████| 100/100 [16:39<00:00,  9.99s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2024-12-28:05:24:17,861 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-12-28:05:24:17,862 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2024-12-28:05:24:17,862 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2024-12-28:05:24:18,255 INFO     [config.py:58] PyTorch version 2.4.1 available.
2024-12-28:05:24:22,828 INFO     [__main__.py:132] Verbosity set to INFO
2024-12-28:05:24:34,209 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-12-28:05:24:34,211 INFO     [__main__.py:205] Selected Tasks: ['code2text_python']
2024-12-28:05:24:34,220 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2024-12-28:05:24:34,488 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  6.54it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  7.42it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  8.35it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  8.41it/s]
Using the latest cached version of the dataset since CM/codexglue_code2text_python couldn't be found on the Hugging Face Hub
2024-12-28:05:25:21,650 WARNING  [load.py:1568] Using the latest cached version of the dataset since CM/codexglue_code2text_python couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'default' at /home/alireza/.cache/huggingface/datasets/CM___codexglue_code2text_python/default/0.0.0/7bccd264f93b53bd85b20ca84891f987d78245b4 (last modified on Thu Nov 21 15:17:56 2024).
2024-12-28:05:25:21,653 WARNING  [cache.py:70] Found the latest cached dataset configuration 'default' at /home/alireza/.cache/huggingface/datasets/CM___codexglue_code2text_python/default/0.0.0/7bccd264f93b53bd85b20ca84891f987d78245b4 (last modified on Thu Nov 21 15:17:56 2024).
2024-12-28:05:25:57,669 INFO     [task.py:355] Building contexts for task on rank 0...
2024-12-28:05:25:57,685 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:612: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:15<25:20, 15.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:29<23:40, 14.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:42<22:52, 14.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:56<22:13, 13.89s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [01:09<21:24, 13.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:21<20:34, 13.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:33<19:35, 12.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:44<18:49, 12.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:56<18:13, 12.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [02:07<17:45, 11.84s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [02:18<17:16, 11.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:29<16:45, 11.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:40<16:19, 11.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:51<15:56, 11.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [03:02<15:32, 10.97s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [03:12<15:13, 10.87s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:23<14:55, 10.79s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:33<14:38, 10.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:44<14:23, 10.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:54<14:09, 10.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [04:05<13:54, 10.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [04:15<13:40, 10.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:26<13:24, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:36<13:10, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:46<12:56, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:56<12:43, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [05:06<12:27, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [05:16<12:10, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:26<11:54, 10.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:36<11:40, 10.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:46<11:27,  9.97s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:56<11:15,  9.94s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [06:06<11:04,  9.92s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [06:16<10:53,  9.91s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:26<10:43,  9.90s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:35<10:32,  9.88s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:45<10:21,  9.87s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:55<10:11,  9.86s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [07:05<10:00,  9.85s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [07:15<09:49,  9.83s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:24<09:39,  9.82s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:34<09:28,  9.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:44<09:18,  9.79s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:54<09:07,  9.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [08:04<08:57,  9.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [08:13<08:47,  9.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:23<08:37,  9.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:33<08:26,  9.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:42<08:16,  9.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:52<08:06,  9.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [09:02<07:56,  9.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:12<07:46,  9.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:21<07:36,  9.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:31<07:27,  9.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:41<07:16,  9.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:50<07:06,  9.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [10:00<06:56,  9.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:10<06:46,  9.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:19<06:36,  9.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:29<06:26,  9.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:39<06:16,  9.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:48<06:07,  9.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [10:58<05:57,  9.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:08<05:47,  9.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:17<05:37,  9.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:27<05:27,  9.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:36<05:17,  9.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:46<05:07,  9.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [11:56<04:57,  9.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:05<04:48,  9.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:15<04:38,  9.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:24<04:28,  9.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:34<04:18,  9.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:44<04:09,  9.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [12:53<03:59,  9.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:03<03:49,  9.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:12<03:39,  9.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:22<03:29,  9.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:31<03:19,  9.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [13:41<03:10,  9.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [13:50<03:00,  9.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [14:00<02:50,  9.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:09<02:41,  9.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:18<02:31,  9.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:28<02:21,  9.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [14:37<02:12,  9.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [14:47<02:02,  9.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [14:56<01:53,  9.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:06<01:43,  9.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:15<01:34,  9.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:24<01:24,  9.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [15:34<01:15,  9.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [15:43<01:05,  9.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [15:52<00:56,  9.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:02<00:46,  9.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:11<00:37,  9.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:21<00:28,  9.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [16:30<00:18,  9.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [16:39<00:09,  9.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [16:49<00:00,  9.37s/it]100%|██████████| 100/100 [16:49<00:00, 10.09s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2024-12-28:05:43:24,709 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2024-12-28:05:43:24,710 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2024-12-28:05:43:24,710 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2024-12-28:05:43:25,110 INFO     [config.py:58] PyTorch version 2.4.1 available.
2024-12-28:05:43:29,563 INFO     [__main__.py:132] Verbosity set to INFO
2024-12-28:05:43:40,827 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-12-28:05:43:40,829 INFO     [__main__.py:205] Selected Tasks: ['code2text_python']
2024-12-28:05:43:40,838 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2024-12-28:05:43:41,107 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  6.46it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  7.99it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  8.05it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  8.32it/s]
2024-12-28:05:44:27,310 INFO     [task.py:355] Building contexts for task on rank 0...
2024-12-28:05:44:27,326 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:612: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:15<25:15, 15.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:29<23:37, 14.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:42<22:49, 14.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:56<22:10, 13.86s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [01:09<21:21, 13.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:21<20:32, 13.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:33<19:34, 12.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:44<18:47, 12.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:56<18:11, 12.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [02:07<17:43, 11.82s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [02:18<17:15, 11.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:29<16:43, 11.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:40<16:17, 11.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:51<15:54, 11.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [03:01<15:31, 10.96s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [03:12<15:11, 10.85s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:23<14:53, 10.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:33<14:37, 10.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:44<14:22, 10.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:54<14:07, 10.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [04:05<13:53, 10.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [04:15<13:39, 10.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:25<13:23, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:35<13:08, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:46<12:55, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:56<12:42, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [05:06<12:26, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [05:16<12:08, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:26<11:53, 10.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:36<11:39,  9.99s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:45<11:26,  9.95s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:55<11:14,  9.92s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [06:05<11:03,  9.90s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [06:15<10:52,  9.89s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:25<10:42,  9.88s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:35<10:31,  9.87s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:45<10:20,  9.85s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:54<10:10,  9.84s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [07:04<09:59,  9.83s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [07:14<09:48,  9.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:24<09:38,  9.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:33<09:27,  9.79s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:43<09:17,  9.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:53<09:06,  9.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [08:03<08:56,  9.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [08:12<08:46,  9.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:22<08:35,  9.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:32<08:26,  9.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:42<08:15,  9.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:51<08:05,  9.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [09:01<07:55,  9.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:11<07:45,  9.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:20<07:35,  9.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:30<07:25,  9.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:40<07:15,  9.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:49<07:05,  9.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [09:59<06:55,  9.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:09<06:45,  9.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:18<06:35,  9.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:28<06:25,  9.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:37<06:15,  9.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:47<06:06,  9.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [10:57<05:56,  9.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:06<05:46,  9.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:16<05:36,  9.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:26<05:26,  9.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:35<05:16,  9.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:45<05:07,  9.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [11:54<04:57,  9.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:04<04:47,  9.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:13<04:37,  9.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:23<04:27,  9.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:32<04:18,  9.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:42<04:08,  9.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [12:51<03:58,  9.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:01<03:48,  9.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:10<03:38,  9.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:20<03:29,  9.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:29<03:19,  9.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [13:39<03:09,  9.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [13:48<03:00,  9.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [13:58<02:50,  9.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:07<02:41,  9.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:17<02:31,  9.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:26<02:21,  9.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [14:36<02:12,  9.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [14:45<02:02,  9.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [14:54<01:52,  9.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:04<01:43,  9.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:13<01:33,  9.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:22<01:24,  9.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [15:32<01:14,  9.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [15:41<01:05,  9.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [15:50<00:56,  9.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:00<00:46,  9.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:09<00:37,  9.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:18<00:27,  9.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [16:28<00:18,  9.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [16:37<00:09,  9.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [16:46<00:00,  9.31s/it]100%|██████████| 100/100 [16:46<00:00, 10.07s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
