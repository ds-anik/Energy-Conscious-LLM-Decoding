2025-03-20:06:59:07,390 INFO     [__main__.py:279] Verbosity set to INFO
2025-03-20:06:59:18,610 WARNING  [__main__.py:312]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-03-20:06:59:18,611 INFO     [__main__.py:376] Selected Tasks: ['gsm8k']
2025-03-20:06:59:18,617 INFO     [evaluator.py:164] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
2025-03-20:06:59:18,617 WARNING  [evaluator.py:175] generation_kwargs specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-03-20:06:59:18,618 INFO     [evaluator.py:201] Initializing hf model, with arguments: {'pretrained': 'meta-llama/Llama-3.1-8B-Instruct', 'dtype': 'bfloat16', 'device': 'cuda', 'parallelize': False}
2025-03-20:06:59:18,883 INFO     [huggingface.py:129] Using device 'cuda'
2025-03-20:06:59:19,082 INFO     [huggingface.py:481] Using model type 'default'
2025-03-20:06:59:19,530 INFO     [huggingface.py:365] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda'}
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:04,  1.48s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:02<00:02,  1.21s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:03<00:01,  1.29s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.05it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.08s/it]
2025-03-20:06:59:29,075 WARNING  [model.py:422] model.chat_template was called with the chat_template set to False or None. Therefore no chat template will be applied. Make sure this is an intended behavior.
2025-03-20:06:59:29,078 INFO     [task.py:415] Building contexts for gsm8k on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s] 35%|███▌      | 35/100 [00:00<00:00, 345.65it/s] 71%|███████   | 71/100 [00:00<00:00, 350.23it/s]100%|██████████| 100/100 [00:00<00:00, 350.91it/s]
2025-03-20:06:59:29,367 INFO     [evaluator.py:489] Running generate_until requests
Running generate_until requests:   0%|          | 0/100 [00:00<?, ?it/s]/home/alireza/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/home/alireza/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Running generate_until requests:   1%|          | 1/100 [00:05<08:27,  5.12s/it]Running generate_until requests:   2%|▏         | 2/100 [00:09<07:17,  4.46s/it]Running generate_until requests:   3%|▎         | 3/100 [00:11<05:32,  3.43s/it]Running generate_until requests:   4%|▍         | 4/100 [00:16<06:42,  4.19s/it]Running generate_until requests:   5%|▌         | 5/100 [00:19<05:59,  3.79s/it]Running generate_until requests:   6%|▌         | 6/100 [00:25<06:43,  4.29s/it]Running generate_until requests:   7%|▋         | 7/100 [00:28<06:06,  3.94s/it]Running generate_until requests:   8%|▊         | 8/100 [00:31<05:35,  3.64s/it]Running generate_until requests:   9%|▉         | 9/100 [00:33<04:51,  3.20s/it]Running generate_until requests:  10%|█         | 10/100 [00:39<06:19,  4.21s/it]Running generate_until requests:  11%|█         | 11/100 [00:41<05:11,  3.50s/it]Running generate_until requests:  12%|█▏        | 12/100 [00:43<04:14,  2.89s/it]Running generate_until requests:  13%|█▎        | 13/100 [00:46<04:06,  2.83s/it]Running generate_until requests:  14%|█▍        | 14/100 [00:51<05:09,  3.59s/it]Running generate_until requests:  15%|█▌        | 15/100 [00:56<05:39,  4.00s/it]Running generate_until requests:  16%|█▌        | 16/100 [01:00<05:30,  3.93s/it]Running generate_until requests:  17%|█▋        | 17/100 [01:03<05:13,  3.78s/it]Running generate_until requests:  18%|█▊        | 18/100 [01:08<05:43,  4.19s/it]Running generate_until requests:  19%|█▉        | 19/100 [01:11<05:17,  3.91s/it]Running generate_until requests:  20%|██        | 20/100 [01:18<06:19,  4.74s/it]Running generate_until requests:  21%|██        | 21/100 [01:23<06:09,  4.68s/it]Running generate_until requests:  22%|██▏       | 22/100 [01:25<05:19,  4.09s/it]Running generate_until requests:  23%|██▎       | 23/100 [01:28<04:43,  3.69s/it]Running generate_until requests:  24%|██▍       | 24/100 [01:31<04:17,  3.39s/it]Running generate_until requests:  25%|██▌       | 25/100 [01:34<04:14,  3.39s/it]Running generate_until requests:  26%|██▌       | 26/100 [01:37<04:04,  3.30s/it]Running generate_until requests:  27%|██▋       | 27/100 [01:40<03:51,  3.18s/it]Running generate_until requests:  28%|██▊       | 28/100 [01:43<03:30,  2.93s/it]Running generate_until requests:  29%|██▉       | 29/100 [01:45<03:14,  2.75s/it]Running generate_until requests:  30%|███       | 30/100 [01:51<04:25,  3.80s/it]Running generate_until requests:  31%|███       | 31/100 [02:00<06:14,  5.42s/it]Running generate_until requests:  32%|███▏      | 32/100 [02:04<05:40,  5.00s/it]Running generate_until requests:  33%|███▎      | 33/100 [02:07<04:40,  4.19s/it]Running generate_until requests:  34%|███▍      | 34/100 [02:10<04:16,  3.88s/it]Running generate_until requests:  35%|███▌      | 35/100 [02:12<03:36,  3.34s/it]Running generate_until requests:  36%|███▌      | 36/100 [02:14<03:11,  3.00s/it]Running generate_until requests:  37%|███▋      | 37/100 [02:19<03:48,  3.63s/it]Running generate_until requests:  38%|███▊      | 38/100 [02:22<03:29,  3.38s/it]Running generate_until requests:  39%|███▉      | 39/100 [02:27<03:50,  3.78s/it]Running generate_until requests:  40%|████      | 40/100 [02:33<04:37,  4.63s/it]Running generate_until requests:  41%|████      | 41/100 [02:36<03:56,  4.01s/it]Running generate_until requests:  42%|████▏     | 42/100 [02:38<03:26,  3.56s/it]Running generate_until requests:  43%|████▎     | 43/100 [02:40<02:50,  3.00s/it]Running generate_until requests:  44%|████▍     | 44/100 [02:44<03:04,  3.30s/it]Running generate_until requests:  45%|████▌     | 45/100 [02:47<02:52,  3.13s/it]Running generate_until requests:  46%|████▌     | 46/100 [02:49<02:40,  2.97s/it]Running generate_until requests:  47%|████▋     | 47/100 [02:52<02:29,  2.83s/it]Running generate_until requests:  48%|████▊     | 48/100 [02:55<02:29,  2.88s/it]Running generate_until requests:  49%|████▉     | 49/100 [02:59<02:51,  3.36s/it]Running generate_until requests:  50%|█████     | 50/100 [03:01<02:24,  2.88s/it]Running generate_until requests:  51%|█████     | 51/100 [03:04<02:16,  2.79s/it]Running generate_until requests:  52%|█████▏    | 52/100 [03:07<02:20,  2.93s/it]Running generate_until requests:  53%|█████▎    | 53/100 [03:12<02:50,  3.63s/it]Running generate_until requests:  54%|█████▍    | 54/100 [03:16<02:46,  3.63s/it]Running generate_until requests:  55%|█████▌    | 55/100 [03:19<02:34,  3.43s/it]Running generate_until requests:  56%|█████▌    | 56/100 [03:23<02:45,  3.77s/it]Running generate_until requests:  57%|█████▋    | 57/100 [03:27<02:41,  3.75s/it]Running generate_until requests:  58%|█████▊    | 58/100 [03:32<02:54,  4.15s/it]Running generate_until requests:  59%|█████▉    | 59/100 [03:35<02:34,  3.77s/it]Running generate_until requests:  60%|██████    | 60/100 [03:37<02:03,  3.10s/it]Running generate_until requests:  61%|██████    | 61/100 [03:38<01:45,  2.69s/it]Running generate_until requests:  62%|██████▏   | 62/100 [03:42<01:49,  2.89s/it]Running generate_until requests:  63%|██████▎   | 63/100 [03:45<01:54,  3.10s/it]Running generate_until requests:  64%|██████▍   | 64/100 [03:47<01:39,  2.76s/it]Running generate_until requests:  65%|██████▌   | 65/100 [03:50<01:33,  2.68s/it]Running generate_until requests:  66%|██████▌   | 66/100 [03:53<01:36,  2.83s/it]Running generate_until requests:  67%|██████▋   | 67/100 [03:56<01:37,  2.97s/it]Running generate_until requests:  68%|██████▊   | 68/100 [03:58<01:21,  2.54s/it]Running generate_until requests:  69%|██████▉   | 69/100 [04:01<01:29,  2.88s/it]Running generate_until requests:  70%|███████   | 70/100 [04:05<01:31,  3.05s/it]Running generate_until requests:  71%|███████   | 71/100 [04:10<01:42,  3.54s/it]Running generate_until requests:  72%|███████▏  | 72/100 [04:13<01:35,  3.42s/it]Running generate_until requests:  73%|███████▎  | 73/100 [04:16<01:28,  3.30s/it]Running generate_until requests:  74%|███████▍  | 74/100 [04:19<01:25,  3.29s/it]Running generate_until requests:  75%|███████▌  | 75/100 [04:22<01:21,  3.25s/it]Running generate_until requests:  76%|███████▌  | 76/100 [04:25<01:17,  3.23s/it]Running generate_until requests:  77%|███████▋  | 77/100 [04:29<01:16,  3.31s/it]Running generate_until requests:  78%|███████▊  | 78/100 [04:31<01:03,  2.87s/it]Running generate_until requests:  79%|███████▉  | 79/100 [04:34<01:02,  2.96s/it]Running generate_until requests:  80%|████████  | 80/100 [04:37<01:01,  3.09s/it]Running generate_until requests:  81%|████████  | 81/100 [04:40<00:57,  3.05s/it]Running generate_until requests:  82%|████████▏ | 82/100 [04:45<01:03,  3.53s/it]Running generate_until requests:  83%|████████▎ | 83/100 [04:50<01:06,  3.93s/it]Running generate_until requests:  84%|████████▍ | 84/100 [04:52<00:54,  3.39s/it]Running generate_until requests:  85%|████████▌ | 85/100 [04:57<00:58,  3.89s/it]Running generate_until requests:  86%|████████▌ | 86/100 [05:00<00:50,  3.59s/it]Running generate_until requests:  87%|████████▋ | 87/100 [05:03<00:45,  3.46s/it]Running generate_until requests:  88%|████████▊ | 88/100 [05:05<00:36,  3.05s/it]Running generate_until requests:  89%|████████▉ | 89/100 [05:09<00:36,  3.35s/it]Running generate_until requests:  90%|█████████ | 90/100 [05:12<00:31,  3.10s/it]Running generate_until requests:  91%|█████████ | 91/100 [05:14<00:25,  2.87s/it]Running generate_until requests:  92%|█████████▏| 92/100 [05:16<00:22,  2.76s/it]Running generate_until requests:  93%|█████████▎| 93/100 [05:18<00:16,  2.41s/it]Running generate_until requests:  94%|█████████▍| 94/100 [05:21<00:15,  2.53s/it]Running generate_until requests:  95%|█████████▌| 95/100 [05:23<00:12,  2.49s/it]Running generate_until requests:  96%|█████████▌| 96/100 [05:26<00:10,  2.62s/it]Running generate_until requests:  97%|█████████▋| 97/100 [05:30<00:08,  2.90s/it]Running generate_until requests:  98%|█████████▊| 98/100 [05:33<00:06,  3.12s/it]Running generate_until requests:  99%|█████████▉| 99/100 [05:36<00:02,  2.95s/it]Running generate_until requests: 100%|██████████| 100/100 [05:40<00:00,  3.33s/it]Running generate_until requests: 100%|██████████| 100/100 [05:40<00:00,  3.41s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-03-20:07:05:14,916 INFO     [evaluation_tracker.py:206] Saving results aggregated
2025-03-20:07:05:14,963 INFO     [evaluation_tracker.py:287] Saving per-sample results for: gsm8k
2025-03-20:07:05:54,604 INFO     [__main__.py:279] Verbosity set to INFO
2025-03-20:07:06:05,457 WARNING  [__main__.py:312]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-03-20:07:06:05,458 INFO     [__main__.py:376] Selected Tasks: ['gsm8k']
2025-03-20:07:06:05,464 INFO     [evaluator.py:164] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
2025-03-20:07:06:05,464 WARNING  [evaluator.py:175] generation_kwargs specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-03-20:07:06:05,464 INFO     [evaluator.py:201] Initializing hf model, with arguments: {'pretrained': 'meta-llama/Llama-3.1-8B-Instruct', 'dtype': 'bfloat16', 'device': 'cuda', 'parallelize': False}
2025-03-20:07:06:05,724 INFO     [huggingface.py:129] Using device 'cuda'
2025-03-20:07:06:05,919 INFO     [huggingface.py:481] Using model type 'default'
2025-03-20:07:06:06,401 INFO     [huggingface.py:365] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda'}
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:04,  1.34s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:02<00:02,  1.43s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:04<00:01,  1.47s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.05s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.19s/it]
2025-03-20:07:06:16,495 WARNING  [model.py:422] model.chat_template was called with the chat_template set to False or None. Therefore no chat template will be applied. Make sure this is an intended behavior.
2025-03-20:07:06:16,498 INFO     [task.py:415] Building contexts for gsm8k on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s] 33%|███▎      | 33/100 [00:00<00:00, 326.38it/s] 68%|██████▊   | 68/100 [00:00<00:00, 338.43it/s]100%|██████████| 100/100 [00:00<00:00, 340.87it/s]
2025-03-20:07:06:16,795 INFO     [evaluator.py:489] Running generate_until requests
Running generate_until requests:   0%|          | 0/100 [00:00<?, ?it/s]/home/alireza/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/home/alireza/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Running generate_until requests:   1%|          | 1/100 [00:05<08:24,  5.10s/it]Running generate_until requests:   2%|▏         | 2/100 [00:09<07:16,  4.45s/it]Running generate_until requests:   3%|▎         | 3/100 [00:11<05:32,  3.42s/it]Running generate_until requests:   4%|▍         | 4/100 [00:16<06:42,  4.20s/it]Running generate_until requests:   5%|▌         | 5/100 [00:19<05:59,  3.79s/it]Running generate_until requests:   6%|▌         | 6/100 [00:25<06:44,  4.30s/it]Running generate_until requests:   7%|▋         | 7/100 [00:28<06:06,  3.94s/it]Running generate_until requests:   8%|▊         | 8/100 [00:31<05:35,  3.65s/it]Running generate_until requests:   9%|▉         | 9/100 [00:33<04:51,  3.21s/it]Running generate_until requests:  10%|█         | 10/100 [00:39<06:19,  4.22s/it]Running generate_until requests:  11%|█         | 11/100 [00:41<05:11,  3.50s/it]Running generate_until requests:  12%|█▏        | 12/100 [00:43<04:15,  2.90s/it]Running generate_until requests:  13%|█▎        | 13/100 [00:46<04:06,  2.84s/it]Running generate_until requests:  14%|█▍        | 14/100 [00:51<05:09,  3.60s/it]Running generate_until requests:  15%|█▌        | 15/100 [00:56<05:40,  4.00s/it]Running generate_until requests:  16%|█▌        | 16/100 [01:00<05:30,  3.94s/it]Running generate_until requests:  17%|█▋        | 17/100 [01:03<05:14,  3.79s/it]Running generate_until requests:  18%|█▊        | 18/100 [01:08<05:43,  4.19s/it]Running generate_until requests:  19%|█▉        | 19/100 [01:12<05:17,  3.92s/it]Running generate_until requests:  20%|██        | 20/100 [01:18<06:19,  4.74s/it]Running generate_until requests:  21%|██        | 21/100 [01:23<06:10,  4.69s/it]Running generate_until requests:  22%|██▏       | 22/100 [01:25<05:19,  4.10s/it]Running generate_until requests:  23%|██▎       | 23/100 [01:28<04:44,  3.69s/it]Running generate_until requests:  24%|██▍       | 24/100 [01:31<04:18,  3.40s/it]Running generate_until requests:  25%|██▌       | 25/100 [01:34<04:14,  3.40s/it]Running generate_until requests:  26%|██▌       | 26/100 [01:37<04:04,  3.31s/it]Running generate_until requests:  27%|██▋       | 27/100 [01:40<03:52,  3.18s/it]Running generate_until requests:  28%|██▊       | 28/100 [01:43<03:31,  2.93s/it]Running generate_until requests:  29%|██▉       | 29/100 [01:45<03:15,  2.75s/it]Running generate_until requests:  30%|███       | 30/100 [01:51<04:26,  3.80s/it]Running generate_until requests:  31%|███       | 31/100 [02:00<06:14,  5.43s/it]Running generate_until requests:  32%|███▏      | 32/100 [02:04<05:40,  5.01s/it]Running generate_until requests:  33%|███▎      | 33/100 [02:07<04:40,  4.19s/it]Running generate_until requests:  34%|███▍      | 34/100 [02:10<04:16,  3.88s/it]Running generate_until requests:  35%|███▌      | 35/100 [02:12<03:37,  3.34s/it]Running generate_until requests:  36%|███▌      | 36/100 [02:14<03:12,  3.00s/it]Running generate_until requests:  37%|███▋      | 37/100 [02:19<03:49,  3.64s/it]Running generate_until requests:  38%|███▊      | 38/100 [02:22<03:30,  3.39s/it]Running generate_until requests:  39%|███▉      | 39/100 [02:27<03:51,  3.79s/it]Running generate_until requests:  40%|████      | 40/100 [02:33<04:38,  4.63s/it]Running generate_until requests:  41%|████      | 41/100 [02:36<03:56,  4.01s/it]Running generate_until requests:  42%|████▏     | 42/100 [02:39<03:26,  3.57s/it]Running generate_until requests:  43%|████▎     | 43/100 [02:40<02:51,  3.00s/it]Running generate_until requests:  44%|████▍     | 44/100 [02:44<03:05,  3.31s/it]Running generate_until requests:  45%|████▌     | 45/100 [02:47<02:52,  3.14s/it]Running generate_until requests:  46%|████▌     | 46/100 [02:50<02:40,  2.97s/it]Running generate_until requests:  47%|████▋     | 47/100 [02:52<02:29,  2.83s/it]Running generate_until requests:  48%|████▊     | 48/100 [02:55<02:30,  2.89s/it]Running generate_until requests:  49%|████▉     | 49/100 [03:00<02:51,  3.36s/it]Running generate_until requests:  50%|█████     | 50/100 [03:01<02:24,  2.89s/it]Running generate_until requests:  51%|█████     | 51/100 [03:04<02:16,  2.80s/it]Running generate_until requests:  52%|█████▏    | 52/100 [03:07<02:21,  2.94s/it]Running generate_until requests:  53%|█████▎    | 53/100 [03:13<02:52,  3.66s/it]Running generate_until requests:  54%|█████▍    | 54/100 [03:16<02:48,  3.66s/it]Running generate_until requests:  55%|█████▌    | 55/100 [03:19<02:35,  3.46s/it]Running generate_until requests:  56%|█████▌    | 56/100 [03:24<02:47,  3.81s/it]Running generate_until requests:  57%|█████▋    | 57/100 [03:28<02:42,  3.79s/it]Running generate_until requests:  58%|█████▊    | 58/100 [03:33<02:56,  4.20s/it]Running generate_until requests:  59%|█████▉    | 59/100 [03:36<02:36,  3.82s/it]Running generate_until requests:  60%|██████    | 60/100 [03:37<02:05,  3.14s/it]Running generate_until requests:  61%|██████    | 61/100 [03:39<01:46,  2.73s/it]Running generate_until requests:  62%|██████▏   | 62/100 [03:42<01:51,  2.92s/it]Running generate_until requests:  63%|██████▎   | 63/100 [03:46<01:55,  3.13s/it]Running generate_until requests:  64%|██████▍   | 64/100 [03:48<01:40,  2.80s/it]Running generate_until requests:  65%|██████▌   | 65/100 [03:51<01:35,  2.72s/it]Running generate_until requests:  66%|██████▌   | 66/100 [03:54<01:37,  2.86s/it]Running generate_until requests:  67%|██████▋   | 67/100 [03:57<01:39,  3.01s/it]Running generate_until requests:  68%|██████▊   | 68/100 [03:59<01:22,  2.57s/it]Running generate_until requests:  69%|██████▉   | 69/100 [04:02<01:30,  2.92s/it]Running generate_until requests:  70%|███████   | 70/100 [04:06<01:32,  3.09s/it]Running generate_until requests:  71%|███████   | 71/100 [04:11<01:44,  3.59s/it]Running generate_until requests:  72%|███████▏  | 72/100 [04:14<01:36,  3.46s/it]Running generate_until requests:  73%|███████▎  | 73/100 [04:17<01:30,  3.34s/it]Running generate_until requests:  74%|███████▍  | 74/100 [04:20<01:26,  3.34s/it]Running generate_until requests:  75%|███████▌  | 75/100 [04:23<01:22,  3.29s/it]Running generate_until requests:  76%|███████▌  | 76/100 [04:27<01:18,  3.28s/it]Running generate_until requests:  77%|███████▋  | 77/100 [04:30<01:17,  3.36s/it]Running generate_until requests:  78%|███████▊  | 78/100 [04:32<01:04,  2.91s/it]Running generate_until requests:  79%|███████▉  | 79/100 [04:35<01:03,  3.01s/it]Running generate_until requests:  80%|████████  | 80/100 [04:39<01:02,  3.14s/it]Running generate_until requests:  81%|████████  | 81/100 [04:42<00:58,  3.10s/it]Running generate_until requests:  82%|████████▏ | 82/100 [04:46<01:04,  3.58s/it]Running generate_until requests:  83%|████████▎ | 83/100 [04:51<01:07,  3.98s/it]Running generate_until requests:  84%|████████▍ | 84/100 [04:53<00:54,  3.43s/it]Running generate_until requests:  85%|████████▌ | 85/100 [04:59<00:59,  3.94s/it]Running generate_until requests:  86%|████████▌ | 86/100 [05:02<00:50,  3.64s/it]Running generate_until requests:  87%|████████▋ | 87/100 [05:05<00:45,  3.51s/it]Running generate_until requests:  88%|████████▊ | 88/100 [05:07<00:37,  3.09s/it]Running generate_until requests:  89%|████████▉ | 89/100 [05:11<00:37,  3.39s/it]Running generate_until requests:  90%|█████████ | 90/100 [05:13<00:31,  3.13s/it]Running generate_until requests:  91%|█████████ | 91/100 [05:16<00:26,  2.89s/it]Running generate_until requests:  92%|█████████▏| 92/100 [05:18<00:22,  2.79s/it]Running generate_until requests:  93%|█████████▎| 93/100 [05:20<00:17,  2.44s/it]Running generate_until requests:  94%|█████████▍| 94/100 [05:23<00:15,  2.56s/it]Running generate_until requests:  95%|█████████▌| 95/100 [05:25<00:12,  2.52s/it]Running generate_until requests:  96%|█████████▌| 96/100 [05:28<00:10,  2.65s/it]Running generate_until requests:  97%|█████████▋| 97/100 [05:32<00:08,  2.93s/it]Running generate_until requests:  98%|█████████▊| 98/100 [05:35<00:06,  3.16s/it]Running generate_until requests:  99%|█████████▉| 99/100 [05:38<00:02,  2.99s/it]Running generate_until requests: 100%|██████████| 100/100 [05:42<00:00,  3.37s/it]Running generate_until requests: 100%|██████████| 100/100 [05:42<00:00,  3.43s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-03-20:07:12:04,712 INFO     [evaluation_tracker.py:206] Saving results aggregated
2025-03-20:07:12:04,735 INFO     [evaluation_tracker.py:287] Saving per-sample results for: gsm8k
2025-03-20:07:12:44,145 INFO     [__main__.py:279] Verbosity set to INFO
2025-03-20:07:12:55,394 WARNING  [__main__.py:312]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-03-20:07:12:55,396 INFO     [__main__.py:376] Selected Tasks: ['gsm8k']
2025-03-20:07:12:55,402 INFO     [evaluator.py:164] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
2025-03-20:07:12:55,402 WARNING  [evaluator.py:175] generation_kwargs specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-03-20:07:12:55,403 INFO     [evaluator.py:201] Initializing hf model, with arguments: {'pretrained': 'meta-llama/Llama-3.1-8B-Instruct', 'dtype': 'bfloat16', 'device': 'cuda', 'parallelize': False}
2025-03-20:07:12:55,677 INFO     [huggingface.py:129] Using device 'cuda'
2025-03-20:07:12:55,876 INFO     [huggingface.py:481] Using model type 'default'
2025-03-20:07:12:56,346 INFO     [huggingface.py:365] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda'}
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:03,  1.20s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:02<00:02,  1.04s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:03<00:00,  1.02it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.39it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.19it/s]
2025-03-20:07:13:05,086 WARNING  [model.py:422] model.chat_template was called with the chat_template set to False or None. Therefore no chat template will be applied. Make sure this is an intended behavior.
2025-03-20:07:13:05,089 INFO     [task.py:415] Building contexts for gsm8k on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s] 35%|███▌      | 35/100 [00:00<00:00, 343.65it/s] 71%|███████   | 71/100 [00:00<00:00, 348.23it/s]100%|██████████| 100/100 [00:00<00:00, 344.33it/s]
2025-03-20:07:13:05,383 INFO     [evaluator.py:489] Running generate_until requests
Running generate_until requests:   0%|          | 0/100 [00:00<?, ?it/s]/home/alireza/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/home/alireza/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Running generate_until requests:   1%|          | 1/100 [00:05<08:24,  5.10s/it]Running generate_until requests:   2%|▏         | 2/100 [00:09<07:14,  4.44s/it]Running generate_until requests:   3%|▎         | 3/100 [00:11<05:30,  3.41s/it]Running generate_until requests:   4%|▍         | 4/100 [00:16<06:40,  4.17s/it]Running generate_until requests:   5%|▌         | 5/100 [00:19<05:57,  3.76s/it]Running generate_until requests:   6%|▌         | 6/100 [00:24<06:41,  4.27s/it]Running generate_until requests:   7%|▋         | 7/100 [00:28<06:04,  3.91s/it]Running generate_until requests:   8%|▊         | 8/100 [00:31<05:33,  3.62s/it]Running generate_until requests:   9%|▉         | 9/100 [00:33<04:49,  3.18s/it]Running generate_until requests:  10%|█         | 10/100 [00:39<06:17,  4.19s/it]Running generate_until requests:  11%|█         | 11/100 [00:41<05:09,  3.48s/it]Running generate_until requests:  12%|█▏        | 12/100 [00:43<04:13,  2.88s/it]Running generate_until requests:  13%|█▎        | 13/100 [00:45<04:04,  2.81s/it]Running generate_until requests:  14%|█▍        | 14/100 [00:51<05:07,  3.57s/it]Running generate_until requests:  15%|█▌        | 15/100 [00:55<05:37,  3.97s/it]Running generate_until requests:  16%|█▌        | 16/100 [00:59<05:28,  3.91s/it]Running generate_until requests:  17%|█▋        | 17/100 [01:03<05:11,  3.76s/it]Running generate_until requests:  18%|█▊        | 18/100 [01:08<05:41,  4.16s/it]Running generate_until requests:  19%|█▉        | 19/100 [01:11<05:15,  3.89s/it]Running generate_until requests:  20%|██        | 20/100 [01:18<06:16,  4.71s/it]Running generate_until requests:  21%|██        | 21/100 [01:22<06:07,  4.65s/it]Running generate_until requests:  22%|██▏       | 22/100 [01:25<05:17,  4.07s/it]Running generate_until requests:  23%|██▎       | 23/100 [01:28<04:42,  3.66s/it]Running generate_until requests:  24%|██▍       | 24/100 [01:30<04:16,  3.37s/it]Running generate_until requests:  25%|██▌       | 25/100 [01:34<04:12,  3.37s/it]Running generate_until requests:  26%|██▌       | 26/100 [01:37<04:02,  3.28s/it]Running generate_until requests:  27%|██▋       | 27/100 [01:40<03:50,  3.16s/it]Running generate_until requests:  28%|██▊       | 28/100 [01:42<03:29,  2.91s/it]Running generate_until requests:  29%|██▉       | 29/100 [01:44<03:13,  2.73s/it]Running generate_until requests:  30%|███       | 30/100 [01:50<04:24,  3.78s/it]Running generate_until requests:  31%|███       | 31/100 [02:00<06:11,  5.39s/it]Running generate_until requests:  32%|███▏      | 32/100 [02:04<05:37,  4.97s/it]Running generate_until requests:  33%|███▎      | 33/100 [02:06<04:38,  4.16s/it]Running generate_until requests:  34%|███▍      | 34/100 [02:09<04:14,  3.85s/it]Running generate_until requests:  35%|███▌      | 35/100 [02:11<03:35,  3.31s/it]Running generate_until requests:  36%|███▌      | 36/100 [02:13<03:10,  2.98s/it]Running generate_until requests:  37%|███▋      | 37/100 [02:18<03:47,  3.61s/it]Running generate_until requests:  38%|███▊      | 38/100 [02:21<03:28,  3.36s/it]Running generate_until requests:  39%|███▉      | 39/100 [02:26<03:49,  3.76s/it]Running generate_until requests:  40%|████      | 40/100 [02:32<04:35,  4.60s/it]Running generate_until requests:  41%|████      | 41/100 [02:35<03:54,  3.98s/it]Running generate_until requests:  42%|████▏     | 42/100 [02:37<03:25,  3.54s/it]Running generate_until requests:  43%|████▎     | 43/100 [02:39<02:49,  2.98s/it]Running generate_until requests:  44%|████▍     | 44/100 [02:43<03:03,  3.28s/it]Running generate_until requests:  45%|████▌     | 45/100 [02:46<02:51,  3.11s/it]Running generate_until requests:  46%|████▌     | 46/100 [02:48<02:39,  2.95s/it]Running generate_until requests:  47%|████▋     | 47/100 [02:51<02:28,  2.81s/it]Running generate_until requests:  48%|████▊     | 48/100 [02:54<02:28,  2.86s/it]Running generate_until requests:  49%|████▉     | 49/100 [02:58<02:50,  3.34s/it]Running generate_until requests:  50%|█████     | 50/100 [03:00<02:23,  2.87s/it]Running generate_until requests:  51%|█████     | 51/100 [03:03<02:15,  2.77s/it]Running generate_until requests:  52%|█████▏    | 52/100 [03:06<02:20,  2.92s/it]Running generate_until requests:  53%|█████▎    | 53/100 [03:11<02:50,  3.63s/it]Running generate_until requests:  54%|█████▍    | 54/100 [03:15<02:47,  3.64s/it]Running generate_until requests:  55%|█████▌    | 55/100 [03:18<02:34,  3.44s/it]Running generate_until requests:  56%|█████▌    | 56/100 [03:22<02:46,  3.79s/it]Running generate_until requests:  57%|█████▋    | 57/100 [03:26<02:41,  3.76s/it]Running generate_until requests:  58%|█████▊    | 58/100 [03:31<02:55,  4.17s/it]Running generate_until requests:  59%|█████▉    | 59/100 [03:34<02:35,  3.79s/it]Running generate_until requests:  60%|██████    | 60/100 [03:36<02:04,  3.12s/it]Running generate_until requests:  61%|██████    | 61/100 [03:37<01:45,  2.71s/it]Running generate_until requests:  62%|██████▏   | 62/100 [03:41<01:50,  2.90s/it]Running generate_until requests:  63%|██████▎   | 63/100 [03:44<01:55,  3.11s/it]Running generate_until requests:  64%|██████▍   | 64/100 [03:46<01:39,  2.78s/it]Running generate_until requests:  65%|██████▌   | 65/100 [03:49<01:34,  2.70s/it]Running generate_until requests:  66%|██████▌   | 66/100 [03:52<01:36,  2.84s/it]Running generate_until requests:  67%|██████▋   | 67/100 [03:55<01:38,  2.99s/it]Running generate_until requests:  68%|██████▊   | 68/100 [03:57<01:21,  2.56s/it]Running generate_until requests:  69%|██████▉   | 69/100 [04:01<01:30,  2.92s/it]Running generate_until requests:  70%|███████   | 70/100 [04:04<01:32,  3.09s/it]Running generate_until requests:  71%|███████   | 71/100 [04:09<01:43,  3.58s/it]Running generate_until requests:  72%|███████▏  | 72/100 [04:12<01:36,  3.44s/it]Running generate_until requests:  73%|███████▎  | 73/100 [04:15<01:29,  3.32s/it]Running generate_until requests:  74%|███████▍  | 74/100 [04:18<01:26,  3.32s/it]Running generate_until requests:  75%|███████▌  | 75/100 [04:22<01:21,  3.27s/it]Running generate_until requests:  76%|███████▌  | 76/100 [04:25<01:18,  3.25s/it]Running generate_until requests:  77%|███████▋  | 77/100 [04:28<01:16,  3.33s/it]Running generate_until requests:  78%|███████▊  | 78/100 [04:30<01:03,  2.89s/it]Running generate_until requests:  79%|███████▉  | 79/100 [04:33<01:02,  2.97s/it]Running generate_until requests:  80%|████████  | 80/100 [04:37<01:02,  3.10s/it]Running generate_until requests:  81%|████████  | 81/100 [04:40<00:58,  3.07s/it]Running generate_until requests:  82%|████████▏ | 82/100 [04:44<01:03,  3.55s/it]Running generate_until requests:  83%|████████▎ | 83/100 [04:49<01:07,  3.95s/it]Running generate_until requests:  84%|████████▍ | 84/100 [04:51<00:54,  3.40s/it]Running generate_until requests:  85%|████████▌ | 85/100 [04:56<00:58,  3.91s/it]Running generate_until requests:  86%|████████▌ | 86/100 [04:59<00:50,  3.61s/it]Running generate_until requests:  87%|████████▋ | 87/100 [05:03<00:45,  3.48s/it]Running generate_until requests:  88%|████████▊ | 88/100 [05:05<00:36,  3.06s/it]Running generate_until requests:  89%|████████▉ | 89/100 [05:09<00:36,  3.36s/it]Running generate_until requests:  90%|█████████ | 90/100 [05:11<00:31,  3.10s/it]Running generate_until requests:  91%|█████████ | 91/100 [05:14<00:25,  2.87s/it]Running generate_until requests:  92%|█████████▏| 92/100 [05:16<00:22,  2.77s/it]Running generate_until requests:  93%|█████████▎| 93/100 [05:18<00:16,  2.42s/it]Running generate_until requests:  94%|█████████▍| 94/100 [05:20<00:15,  2.54s/it]Running generate_until requests:  95%|█████████▌| 95/100 [05:23<00:12,  2.50s/it]Running generate_until requests:  96%|█████████▌| 96/100 [05:26<00:10,  2.63s/it]Running generate_until requests:  97%|█████████▋| 97/100 [05:29<00:08,  2.91s/it]Running generate_until requests:  98%|█████████▊| 98/100 [05:33<00:06,  3.14s/it]Running generate_until requests:  99%|█████████▉| 99/100 [05:36<00:02,  2.96s/it]Running generate_until requests: 100%|██████████| 100/100 [05:40<00:00,  3.35s/it]Running generate_until requests: 100%|██████████| 100/100 [05:40<00:00,  3.40s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-03-20:07:18:50,896 INFO     [evaluation_tracker.py:206] Saving results aggregated
2025-03-20:07:18:50,915 INFO     [evaluation_tracker.py:287] Saving per-sample results for: gsm8k
2025-03-20:07:19:30,974 INFO     [__main__.py:279] Verbosity set to INFO
2025-03-20:07:19:42,062 WARNING  [__main__.py:312]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-03-20:07:19:42,063 INFO     [__main__.py:376] Selected Tasks: ['gsm8k']
2025-03-20:07:19:42,074 INFO     [evaluator.py:164] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
2025-03-20:07:19:42,075 WARNING  [evaluator.py:175] generation_kwargs specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-03-20:07:19:42,075 INFO     [evaluator.py:201] Initializing hf model, with arguments: {'pretrained': 'meta-llama/Llama-3.1-8B-Instruct', 'dtype': 'bfloat16', 'device': 'cuda', 'parallelize': False}
2025-03-20:07:19:42,336 INFO     [huggingface.py:129] Using device 'cuda'
2025-03-20:07:19:42,519 INFO     [huggingface.py:481] Using model type 'default'
2025-03-20:07:19:42,984 INFO     [huggingface.py:365] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda'}
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:04,  1.35s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:02<00:02,  1.38s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:04<00:01,  1.37s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.03s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.15s/it]
2025-03-20:07:19:54,744 WARNING  [model.py:422] model.chat_template was called with the chat_template set to False or None. Therefore no chat template will be applied. Make sure this is an intended behavior.
2025-03-20:07:19:54,745 INFO     [task.py:415] Building contexts for gsm8k on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s] 35%|███▌      | 35/100 [00:00<00:00, 348.52it/s] 71%|███████   | 71/100 [00:00<00:00, 350.28it/s]100%|██████████| 100/100 [00:00<00:00, 344.35it/s]
2025-03-20:07:19:55,039 INFO     [evaluator.py:489] Running generate_until requests
Running generate_until requests:   0%|          | 0/100 [00:00<?, ?it/s]/home/alireza/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/home/alireza/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Running generate_until requests:   1%|          | 1/100 [00:05<08:19,  5.05s/it]Running generate_until requests:   2%|▏         | 2/100 [00:09<07:12,  4.42s/it]Running generate_until requests:   3%|▎         | 3/100 [00:11<05:29,  3.40s/it]Running generate_until requests:   4%|▍         | 4/100 [00:16<06:39,  4.16s/it]Running generate_until requests:   5%|▌         | 5/100 [00:19<05:57,  3.76s/it]Running generate_until requests:   6%|▌         | 6/100 [00:24<06:41,  4.27s/it]Running generate_until requests:   7%|▋         | 7/100 [00:28<06:03,  3.91s/it]Running generate_until requests:   8%|▊         | 8/100 [00:31<05:33,  3.62s/it]Running generate_until requests:   9%|▉         | 9/100 [00:33<04:49,  3.18s/it]Running generate_until requests:  10%|█         | 10/100 [00:39<06:16,  4.19s/it]Running generate_until requests:  11%|█         | 11/100 [00:41<05:09,  3.48s/it]Running generate_until requests:  12%|█▏        | 12/100 [00:43<04:13,  2.88s/it]Running generate_until requests:  13%|█▎        | 13/100 [00:45<04:04,  2.81s/it]Running generate_until requests:  14%|█▍        | 14/100 [00:51<05:07,  3.57s/it]Running generate_until requests:  15%|█▌        | 15/100 [00:55<05:37,  3.97s/it]Running generate_until requests:  16%|█▌        | 16/100 [00:59<05:28,  3.91s/it]Running generate_until requests:  17%|█▋        | 17/100 [01:03<05:11,  3.76s/it]Running generate_until requests:  18%|█▊        | 18/100 [01:08<05:41,  4.16s/it]Running generate_until requests:  19%|█▉        | 19/100 [01:11<05:15,  3.89s/it]Running generate_until requests:  20%|██        | 20/100 [01:18<06:16,  4.71s/it]Running generate_until requests:  21%|██        | 21/100 [01:22<06:07,  4.65s/it]Running generate_until requests:  22%|██▏       | 22/100 [01:25<05:17,  4.07s/it]Running generate_until requests:  23%|██▎       | 23/100 [01:28<04:42,  3.66s/it]Running generate_until requests:  24%|██▍       | 24/100 [01:30<04:16,  3.37s/it]Running generate_until requests:  25%|██▌       | 25/100 [01:34<04:12,  3.37s/it]Running generate_until requests:  26%|██▌       | 26/100 [01:37<04:02,  3.28s/it]Running generate_until requests:  27%|██▋       | 27/100 [01:40<03:50,  3.16s/it]Running generate_until requests:  28%|██▊       | 28/100 [01:42<03:29,  2.91s/it]Running generate_until requests:  29%|██▉       | 29/100 [01:44<03:13,  2.73s/it]Running generate_until requests:  30%|███       | 30/100 [01:50<04:24,  3.78s/it]Running generate_until requests:  31%|███       | 31/100 [02:00<06:11,  5.39s/it]Running generate_until requests:  32%|███▏      | 32/100 [02:04<05:37,  4.97s/it]Running generate_until requests:  33%|███▎      | 33/100 [02:06<04:38,  4.16s/it]Running generate_until requests:  34%|███▍      | 34/100 [02:09<04:14,  3.85s/it]Running generate_until requests:  35%|███▌      | 35/100 [02:11<03:35,  3.31s/it]Running generate_until requests:  36%|███▌      | 36/100 [02:13<03:10,  2.98s/it]Running generate_until requests:  37%|███▋      | 37/100 [02:18<03:47,  3.61s/it]Running generate_until requests:  38%|███▊      | 38/100 [02:21<03:28,  3.36s/it]Running generate_until requests:  39%|███▉      | 39/100 [02:26<03:49,  3.76s/it]Running generate_until requests:  40%|████      | 40/100 [02:32<04:35,  4.60s/it]Running generate_until requests:  41%|████      | 41/100 [02:35<03:54,  3.98s/it]Running generate_until requests:  42%|████▏     | 42/100 [02:37<03:25,  3.54s/it]Running generate_until requests:  43%|████▎     | 43/100 [02:39<02:49,  2.98s/it]Running generate_until requests:  44%|████▍     | 44/100 [02:43<03:03,  3.28s/it]Running generate_until requests:  45%|████▌     | 45/100 [02:46<02:51,  3.11s/it]Running generate_until requests:  46%|████▌     | 46/100 [02:48<02:39,  2.95s/it]Running generate_until requests:  47%|████▋     | 47/100 [02:51<02:28,  2.81s/it]Running generate_until requests:  48%|████▊     | 48/100 [02:54<02:28,  2.87s/it]Running generate_until requests:  49%|████▉     | 49/100 [02:58<02:50,  3.34s/it]Running generate_until requests:  50%|█████     | 50/100 [03:00<02:23,  2.87s/it]Running generate_until requests:  51%|█████     | 51/100 [03:03<02:15,  2.77s/it]Running generate_until requests:  52%|█████▏    | 52/100 [03:06<02:20,  2.92s/it]Running generate_until requests:  53%|█████▎    | 53/100 [03:11<02:50,  3.63s/it]Running generate_until requests:  54%|█████▍    | 54/100 [03:15<02:47,  3.64s/it]Running generate_until requests:  55%|█████▌    | 55/100 [03:18<02:34,  3.44s/it]Running generate_until requests:  56%|█████▌    | 56/100 [03:22<02:46,  3.79s/it]Running generate_until requests:  57%|█████▋    | 57/100 [03:26<02:41,  3.77s/it]Running generate_until requests:  58%|█████▊    | 58/100 [03:31<02:55,  4.17s/it]Running generate_until requests:  59%|█████▉    | 59/100 [03:34<02:35,  3.79s/it]Running generate_until requests:  60%|██████    | 60/100 [03:36<02:04,  3.12s/it]Running generate_until requests:  61%|██████    | 61/100 [03:37<01:45,  2.71s/it]Running generate_until requests:  62%|██████▏   | 62/100 [03:41<01:50,  2.90s/it]Running generate_until requests:  63%|██████▎   | 63/100 [03:44<01:55,  3.11s/it]Running generate_until requests:  64%|██████▍   | 64/100 [03:46<01:39,  2.78s/it]Running generate_until requests:  65%|██████▌   | 65/100 [03:49<01:34,  2.70s/it]Running generate_until requests:  66%|██████▌   | 66/100 [03:52<01:36,  2.84s/it]Running generate_until requests:  67%|██████▋   | 67/100 [03:55<01:38,  2.98s/it]Running generate_until requests:  68%|██████▊   | 68/100 [03:57<01:21,  2.55s/it]Running generate_until requests:  69%|██████▉   | 69/100 [04:01<01:29,  2.89s/it]Running generate_until requests:  70%|███████   | 70/100 [04:04<01:32,  3.07s/it]Running generate_until requests:  71%|███████   | 71/100 [04:09<01:43,  3.56s/it]Running generate_until requests:  72%|███████▏  | 72/100 [04:12<01:36,  3.43s/it]Running generate_until requests:  73%|███████▎  | 73/100 [04:15<01:29,  3.31s/it]Running generate_until requests:  74%|███████▍  | 74/100 [04:18<01:26,  3.31s/it]Running generate_until requests:  75%|███████▌  | 75/100 [04:21<01:21,  3.27s/it]Running generate_until requests:  76%|███████▌  | 76/100 [04:25<01:17,  3.25s/it]Running generate_until requests:  77%|███████▋  | 77/100 [04:28<01:16,  3.33s/it]Running generate_until requests:  78%|███████▊  | 78/100 [04:30<01:03,  2.88s/it]Running generate_until requests:  79%|███████▉  | 79/100 [04:33<01:02,  2.97s/it]Running generate_until requests:  80%|████████  | 80/100 [04:37<01:02,  3.10s/it]Running generate_until requests:  81%|████████  | 81/100 [04:40<00:58,  3.07s/it]Running generate_until requests:  82%|████████▏ | 82/100 [04:44<01:03,  3.55s/it]Running generate_until requests:  83%|████████▎ | 83/100 [04:49<01:07,  3.95s/it]Running generate_until requests:  84%|████████▍ | 84/100 [04:51<00:54,  3.40s/it]Running generate_until requests:  85%|████████▌ | 85/100 [04:56<00:58,  3.91s/it]Running generate_until requests:  86%|████████▌ | 86/100 [04:59<00:50,  3.61s/it]Running generate_until requests:  87%|████████▋ | 87/100 [05:02<00:45,  3.48s/it]Running generate_until requests:  88%|████████▊ | 88/100 [05:04<00:36,  3.06s/it]Running generate_until requests:  89%|████████▉ | 89/100 [05:09<00:36,  3.36s/it]Running generate_until requests:  90%|█████████ | 90/100 [05:11<00:31,  3.10s/it]Running generate_until requests:  91%|█████████ | 91/100 [05:13<00:25,  2.87s/it]Running generate_until requests:  92%|█████████▏| 92/100 [05:16<00:22,  2.77s/it]Running generate_until requests:  93%|█████████▎| 93/100 [05:17<00:16,  2.42s/it]Running generate_until requests:  94%|█████████▍| 94/100 [05:20<00:15,  2.54s/it]Running generate_until requests:  95%|█████████▌| 95/100 [05:23<00:12,  2.50s/it]Running generate_until requests:  96%|█████████▌| 96/100 [05:26<00:10,  2.63s/it]Running generate_until requests:  97%|█████████▋| 97/100 [05:29<00:08,  2.91s/it]Running generate_until requests:  98%|█████████▊| 98/100 [05:33<00:06,  3.14s/it]Running generate_until requests:  99%|█████████▉| 99/100 [05:35<00:02,  2.96s/it]Running generate_until requests: 100%|██████████| 100/100 [05:40<00:00,  3.35s/it]Running generate_until requests: 100%|██████████| 100/100 [05:40<00:00,  3.40s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-03-20:07:25:40,710 INFO     [evaluation_tracker.py:206] Saving results aggregated
2025-03-20:07:25:40,739 INFO     [evaluation_tracker.py:287] Saving per-sample results for: gsm8k
2025-03-20:07:26:20,695 INFO     [__main__.py:279] Verbosity set to INFO
2025-03-20:07:26:32,126 WARNING  [__main__.py:312]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-03-20:07:26:32,127 INFO     [__main__.py:376] Selected Tasks: ['gsm8k']
2025-03-20:07:26:32,136 INFO     [evaluator.py:164] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
2025-03-20:07:26:32,137 WARNING  [evaluator.py:175] generation_kwargs specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-03-20:07:26:32,137 INFO     [evaluator.py:201] Initializing hf model, with arguments: {'pretrained': 'meta-llama/Llama-3.1-8B-Instruct', 'dtype': 'bfloat16', 'device': 'cuda', 'parallelize': False}
2025-03-20:07:26:32,389 INFO     [huggingface.py:129] Using device 'cuda'
2025-03-20:07:26:32,555 INFO     [huggingface.py:481] Using model type 'default'
2025-03-20:07:26:33,022 INFO     [huggingface.py:365] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda'}
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:04,  1.49s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:02<00:02,  1.45s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:04<00:01,  1.33s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.02it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.14s/it]
2025-03-20:07:26:42,510 WARNING  [model.py:422] model.chat_template was called with the chat_template set to False or None. Therefore no chat template will be applied. Make sure this is an intended behavior.
2025-03-20:07:26:42,513 INFO     [task.py:415] Building contexts for gsm8k on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s] 35%|███▌      | 35/100 [00:00<00:00, 348.36it/s] 70%|███████   | 70/100 [00:00<00:00, 345.93it/s]100%|██████████| 100/100 [00:00<00:00, 348.62it/s]
2025-03-20:07:26:42,803 INFO     [evaluator.py:489] Running generate_until requests
Running generate_until requests:   0%|          | 0/100 [00:00<?, ?it/s]/home/alireza/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/home/alireza/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Running generate_until requests:   1%|          | 1/100 [00:05<08:23,  5.08s/it]Running generate_until requests:   2%|▏         | 2/100 [00:09<07:14,  4.44s/it]Running generate_until requests:   3%|▎         | 3/100 [00:11<05:30,  3.41s/it]Running generate_until requests:   4%|▍         | 4/100 [00:16<06:41,  4.18s/it]Running generate_until requests:   5%|▌         | 5/100 [00:19<05:58,  3.77s/it]Running generate_until requests:   6%|▌         | 6/100 [00:24<06:42,  4.28s/it]Running generate_until requests:   7%|▋         | 7/100 [00:28<06:05,  3.93s/it]Running generate_until requests:   8%|▊         | 8/100 [00:31<05:34,  3.63s/it]Running generate_until requests:   9%|▉         | 9/100 [00:33<04:50,  3.19s/it]Running generate_until requests:  10%|█         | 10/100 [00:39<06:18,  4.20s/it]Running generate_until requests:  11%|█         | 11/100 [00:41<05:10,  3.49s/it]Running generate_until requests:  12%|█▏        | 12/100 [00:43<04:14,  2.89s/it]Running generate_until requests:  13%|█▎        | 13/100 [00:45<04:05,  2.82s/it]Running generate_until requests:  14%|█▍        | 14/100 [00:51<05:08,  3.58s/it]Running generate_until requests:  15%|█▌        | 15/100 [00:56<05:38,  3.99s/it]Running generate_until requests:  16%|█▌        | 16/100 [00:59<05:29,  3.92s/it]Running generate_until requests:  17%|█▋        | 17/100 [01:03<05:12,  3.77s/it]Running generate_until requests:  18%|█▊        | 18/100 [01:08<05:42,  4.17s/it]Running generate_until requests:  19%|█▉        | 19/100 [01:11<05:16,  3.90s/it]Running generate_until requests:  20%|██        | 20/100 [01:18<06:17,  4.72s/it]Running generate_until requests:  21%|██        | 21/100 [01:22<06:08,  4.67s/it]Running generate_until requests:  22%|██▏       | 22/100 [01:25<05:18,  4.08s/it]Running generate_until requests:  23%|██▎       | 23/100 [01:28<04:43,  3.68s/it]Running generate_until requests:  24%|██▍       | 24/100 [01:31<04:17,  3.38s/it]Running generate_until requests:  25%|██▌       | 25/100 [01:34<04:13,  3.38s/it]Running generate_until requests:  26%|██▌       | 26/100 [01:37<04:03,  3.29s/it]Running generate_until requests:  27%|██▋       | 27/100 [01:40<03:51,  3.17s/it]Running generate_until requests:  28%|██▊       | 28/100 [01:42<03:30,  2.92s/it]Running generate_until requests:  29%|██▉       | 29/100 [01:45<03:14,  2.74s/it]Running generate_until requests:  30%|███       | 30/100 [01:51<04:25,  3.79s/it]Running generate_until requests:  31%|███       | 31/100 [02:00<06:13,  5.41s/it]Running generate_until requests:  32%|███▏      | 32/100 [02:04<05:39,  4.99s/it]Running generate_until requests:  33%|███▎      | 33/100 [02:06<04:39,  4.17s/it]Running generate_until requests:  34%|███▍      | 34/100 [02:09<04:15,  3.87s/it]Running generate_until requests:  35%|███▌      | 35/100 [02:11<03:36,  3.33s/it]Running generate_until requests:  36%|███▌      | 36/100 [02:14<03:11,  2.99s/it]Running generate_until requests:  37%|███▋      | 37/100 [02:19<03:48,  3.62s/it]Running generate_until requests:  38%|███▊      | 38/100 [02:22<03:29,  3.37s/it]Running generate_until requests:  39%|███▉      | 39/100 [02:26<03:50,  3.77s/it]Running generate_until requests:  40%|████      | 40/100 [02:33<04:36,  4.61s/it]Running generate_until requests:  41%|████      | 41/100 [02:35<03:55,  4.00s/it]Running generate_until requests:  42%|████▏     | 42/100 [02:38<03:26,  3.55s/it]Running generate_until requests:  43%|████▎     | 43/100 [02:40<02:50,  2.99s/it]Running generate_until requests:  44%|████▍     | 44/100 [02:44<03:04,  3.29s/it]Running generate_until requests:  45%|████▌     | 45/100 [02:46<02:51,  3.12s/it]Running generate_until requests:  46%|████▌     | 46/100 [02:49<02:39,  2.96s/it]Running generate_until requests:  47%|████▋     | 47/100 [02:51<02:29,  2.82s/it]Running generate_until requests:  48%|████▊     | 48/100 [02:54<02:29,  2.87s/it]Running generate_until requests:  49%|████▉     | 49/100 [02:59<02:50,  3.35s/it]Running generate_until requests:  50%|█████     | 50/100 [03:01<02:23,  2.88s/it]Running generate_until requests:  51%|█████     | 51/100 [03:03<02:16,  2.78s/it]Running generate_until requests:  52%|█████▏    | 52/100 [03:06<02:20,  2.93s/it]Running generate_until requests:  53%|█████▎    | 53/100 [03:12<02:51,  3.64s/it]Running generate_until requests:  54%|█████▍    | 54/100 [03:15<02:47,  3.65s/it]Running generate_until requests:  55%|█████▌    | 55/100 [03:18<02:35,  3.45s/it]Running generate_until requests:  56%|█████▌    | 56/100 [03:23<02:46,  3.80s/it]Running generate_until requests:  57%|█████▋    | 57/100 [03:27<02:42,  3.77s/it]Running generate_until requests:  58%|█████▊    | 58/100 [03:32<02:55,  4.18s/it]Running generate_until requests:  59%|█████▉    | 59/100 [03:35<02:35,  3.80s/it]Running generate_until requests:  60%|██████    | 60/100 [03:36<02:04,  3.12s/it]Running generate_until requests:  61%|██████    | 61/100 [03:38<01:45,  2.71s/it]Running generate_until requests:  62%|██████▏   | 62/100 [03:41<01:50,  2.91s/it]Running generate_until requests:  63%|██████▎   | 63/100 [03:45<01:55,  3.12s/it]Running generate_until requests:  64%|██████▍   | 64/100 [03:47<01:40,  2.79s/it]Running generate_until requests:  65%|██████▌   | 65/100 [03:50<01:34,  2.71s/it]Running generate_until requests:  66%|██████▌   | 66/100 [03:53<01:37,  2.86s/it]Running generate_until requests:  67%|██████▋   | 67/100 [03:56<01:39,  3.01s/it]Running generate_until requests:  68%|██████▊   | 68/100 [03:58<01:22,  2.57s/it]Running generate_until requests:  69%|██████▉   | 69/100 [04:01<01:30,  2.91s/it]Running generate_until requests:  70%|███████   | 70/100 [04:05<01:32,  3.09s/it]Running generate_until requests:  71%|███████   | 71/100 [04:10<01:43,  3.58s/it]Running generate_until requests:  72%|███████▏  | 72/100 [04:13<01:36,  3.45s/it]Running generate_until requests:  73%|███████▎  | 73/100 [04:16<01:29,  3.33s/it]Running generate_until requests:  74%|███████▍  | 74/100 [04:19<01:26,  3.32s/it]Running generate_until requests:  75%|███████▌  | 75/100 [04:22<01:22,  3.28s/it]Running generate_until requests:  76%|███████▌  | 76/100 [04:26<01:18,  3.26s/it]Running generate_until requests:  77%|███████▋  | 77/100 [04:29<01:16,  3.34s/it]Running generate_until requests:  78%|███████▊  | 78/100 [04:31<01:03,  2.89s/it]Running generate_until requests:  79%|███████▉  | 79/100 [04:34<01:02,  2.98s/it]Running generate_until requests:  80%|████████  | 80/100 [04:37<01:02,  3.11s/it]Running generate_until requests:  81%|████████  | 81/100 [04:40<00:58,  3.08s/it]Running generate_until requests:  82%|████████▏ | 82/100 [04:45<01:04,  3.56s/it]Running generate_until requests:  83%|████████▎ | 83/100 [04:50<01:07,  3.96s/it]Running generate_until requests:  84%|████████▍ | 84/100 [04:52<00:54,  3.41s/it]Running generate_until requests:  85%|████████▌ | 85/100 [04:57<00:58,  3.92s/it]Running generate_until requests:  86%|████████▌ | 86/100 [05:00<00:50,  3.62s/it]Running generate_until requests:  87%|████████▋ | 87/100 [05:03<00:45,  3.49s/it]Running generate_until requests:  88%|████████▊ | 88/100 [05:06<00:36,  3.07s/it]Running generate_until requests:  89%|████████▉ | 89/100 [05:10<00:37,  3.37s/it]Running generate_until requests:  90%|█████████ | 90/100 [05:12<00:31,  3.11s/it]Running generate_until requests:  91%|█████████ | 91/100 [05:14<00:25,  2.88s/it]Running generate_until requests:  92%|█████████▏| 92/100 [05:17<00:22,  2.78s/it]Running generate_until requests:  93%|█████████▎| 93/100 [05:19<00:16,  2.43s/it]Running generate_until requests:  94%|█████████▍| 94/100 [05:21<00:15,  2.55s/it]Running generate_until requests:  95%|█████████▌| 95/100 [05:24<00:12,  2.51s/it]Running generate_until requests:  96%|█████████▌| 96/100 [05:27<00:10,  2.64s/it]Running generate_until requests:  97%|█████████▋| 97/100 [05:30<00:08,  2.92s/it]Running generate_until requests:  98%|█████████▊| 98/100 [05:34<00:06,  3.15s/it]Running generate_until requests:  99%|█████████▉| 99/100 [05:37<00:02,  2.97s/it]Running generate_until requests: 100%|██████████| 100/100 [05:41<00:00,  3.36s/it]Running generate_until requests: 100%|██████████| 100/100 [05:41<00:00,  3.41s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-03-20:07:32:29,413 INFO     [evaluation_tracker.py:206] Saving results aggregated
2025-03-20:07:32:29,437 INFO     [evaluation_tracker.py:287] Saving per-sample results for: gsm8k
2025-03-20:07:34:19,502 INFO     [__main__.py:279] Verbosity set to INFO
2025-03-20:07:34:30,633 WARNING  [__main__.py:312]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-03-20:07:34:30,634 INFO     [__main__.py:376] Selected Tasks: ['gsm8k']
2025-03-20:07:34:30,642 INFO     [evaluator.py:164] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
2025-03-20:07:34:30,643 WARNING  [evaluator.py:175] generation_kwargs specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-03-20:07:34:30,643 INFO     [evaluator.py:201] Initializing hf model, with arguments: {'pretrained': 'meta-llama/Llama-3.1-8B-Instruct', 'dtype': 'bfloat16', 'device': 'cuda', 'parallelize': False}
2025-03-20:07:34:30,923 INFO     [huggingface.py:129] Using device 'cuda'
2025-03-20:07:34:31,408 INFO     [huggingface.py:481] Using model type 'default'
2025-03-20:07:34:33,003 INFO     [huggingface.py:365] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda'}
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:03,  1.19s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:02<00:02,  1.01s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:03<00:00,  1.03it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.40it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.21it/s]
2025-03-20:07:35:00,588 WARNING  [model.py:422] model.chat_template was called with the chat_template set to False or None. Therefore no chat template will be applied. Make sure this is an intended behavior.
2025-03-20:07:35:00,591 INFO     [task.py:415] Building contexts for gsm8k on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s] 35%|███▌      | 35/100 [00:00<00:00, 343.16it/s] 70%|███████   | 70/100 [00:00<00:00, 346.27it/s]100%|██████████| 100/100 [00:00<00:00, 345.43it/s]
2025-03-20:07:35:00,884 INFO     [evaluator.py:489] Running generate_until requests
Running generate_until requests:   0%|          | 0/100 [00:00<?, ?it/s]/home/alireza/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/home/alireza/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Running generate_until requests:   1%|          | 1/100 [00:04<07:17,  4.42s/it]Running generate_until requests:   2%|▏         | 2/100 [00:07<06:20,  3.88s/it]Running generate_until requests:   3%|▎         | 3/100 [00:10<05:01,  3.11s/it]Running generate_until requests:   4%|▍         | 4/100 [00:15<06:22,  3.99s/it]Running generate_until requests:   5%|▌         | 5/100 [00:17<05:28,  3.45s/it]Running generate_until requests:   6%|▌         | 6/100 [00:23<06:22,  4.06s/it]Running generate_until requests:   7%|▋         | 7/100 [00:25<05:35,  3.61s/it]Running generate_until requests:   8%|▊         | 8/100 [00:28<05:11,  3.38s/it]Running generate_until requests:   9%|▉         | 9/100 [00:31<04:52,  3.22s/it]Running generate_until requests:  10%|█         | 10/100 [00:40<07:36,  5.07s/it]Running generate_until requests:  11%|█         | 11/100 [00:43<06:24,  4.32s/it]Running generate_until requests:  12%|█▏        | 12/100 [00:45<05:12,  3.55s/it]Running generate_until requests:  13%|█▎        | 13/100 [00:47<04:45,  3.28s/it]Running generate_until requests:  14%|█▍        | 14/100 [00:51<04:51,  3.38s/it]Running generate_until requests:  15%|█▌        | 15/100 [00:56<05:33,  3.93s/it]Running generate_until requests:  16%|█▌        | 16/100 [01:00<05:23,  3.86s/it]Running generate_until requests:  17%|█▋        | 17/100 [01:03<05:08,  3.72s/it]Running generate_until requests:  18%|█▊        | 18/100 [01:08<05:33,  4.07s/it]Running generate_until requests:  19%|█▉        | 19/100 [01:11<05:08,  3.81s/it]Running generate_until requests:  20%|██        | 20/100 [01:18<06:16,  4.70s/it]Running generate_until requests:  21%|██        | 21/100 [01:23<06:07,  4.65s/it]Running generate_until requests:  22%|██▏       | 22/100 [01:26<05:32,  4.26s/it]Running generate_until requests:  23%|██▎       | 23/100 [01:29<04:52,  3.80s/it]Running generate_until requests:  24%|██▍       | 24/100 [01:31<04:19,  3.42s/it]Running generate_until requests:  25%|██▌       | 25/100 [01:35<04:14,  3.40s/it]Running generate_until requests:  26%|██▌       | 26/100 [01:38<04:04,  3.30s/it]Running generate_until requests:  27%|██▋       | 27/100 [01:41<03:50,  3.15s/it]Running generate_until requests:  28%|██▊       | 28/100 [01:44<03:43,  3.10s/it]Running generate_until requests:  29%|██▉       | 29/100 [01:46<03:24,  2.87s/it]Running generate_until requests:  30%|███       | 30/100 [01:53<04:48,  4.12s/it]Running generate_until requests:  31%|███       | 31/100 [02:01<06:14,  5.43s/it]Running generate_until requests:  32%|███▏      | 32/100 [02:07<06:07,  5.40s/it]Running generate_until requests:  33%|███▎      | 33/100 [02:09<05:01,  4.49s/it]Running generate_until requests:  34%|███▍      | 34/100 [02:12<04:29,  4.08s/it]Running generate_until requests:  35%|███▌      | 35/100 [02:15<03:53,  3.59s/it]Running generate_until requests:  36%|███▌      | 36/100 [02:17<03:22,  3.17s/it]Running generate_until requests:  37%|███▋      | 37/100 [02:22<03:53,  3.71s/it]Running generate_until requests:  38%|███▊      | 38/100 [02:25<03:46,  3.65s/it]Running generate_until requests:  39%|███▉      | 39/100 [02:31<04:27,  4.39s/it]Running generate_until requests:  40%|████      | 40/100 [02:38<05:00,  5.01s/it]Running generate_until requests:  41%|████      | 41/100 [02:40<04:05,  4.15s/it]Running generate_until requests:  42%|████▏     | 42/100 [02:43<03:35,  3.71s/it]Running generate_until requests:  43%|████▎     | 43/100 [02:45<03:00,  3.16s/it]Running generate_until requests:  44%|████▍     | 44/100 [02:49<03:16,  3.51s/it]Running generate_until requests:  45%|████▌     | 45/100 [02:52<03:11,  3.49s/it]Running generate_until requests:  46%|████▌     | 46/100 [02:55<02:53,  3.21s/it]Running generate_until requests:  47%|████▋     | 47/100 [02:57<02:36,  2.95s/it]Running generate_until requests:  48%|████▊     | 48/100 [03:00<02:30,  2.89s/it]Running generate_until requests:  49%|████▉     | 49/100 [03:03<02:35,  3.06s/it]Running generate_until requests:  50%|█████     | 50/100 [03:05<02:13,  2.67s/it]Running generate_until requests:  51%|█████     | 51/100 [03:08<02:09,  2.64s/it]Running generate_until requests:  52%|█████▏    | 52/100 [03:11<02:13,  2.77s/it]Running generate_until requests:  53%|█████▎    | 53/100 [03:14<02:13,  2.84s/it]Running generate_until requests:  54%|█████▍    | 54/100 [03:18<02:24,  3.15s/it]Running generate_until requests:  55%|█████▌    | 55/100 [03:21<02:18,  3.09s/it]Running generate_until requests:  56%|█████▌    | 56/100 [03:26<02:43,  3.71s/it]Running generate_until requests:  57%|█████▋    | 57/100 [03:29<02:34,  3.59s/it]Running generate_until requests:  58%|█████▊    | 58/100 [03:34<02:50,  4.06s/it]Running generate_until requests:  59%|█████▉    | 59/100 [03:37<02:32,  3.73s/it]Running generate_until requests:  60%|██████    | 60/100 [03:39<02:02,  3.07s/it]Running generate_until requests:  61%|██████    | 61/100 [03:41<01:51,  2.85s/it]Running generate_until requests:  62%|██████▏   | 62/100 [03:45<01:54,  3.03s/it]Running generate_until requests:  63%|██████▎   | 63/100 [03:49<02:05,  3.39s/it]Running generate_until requests:  64%|██████▍   | 64/100 [03:54<02:26,  4.07s/it]Running generate_until requests:  65%|██████▌   | 65/100 [03:59<02:31,  4.32s/it]Running generate_until requests:  66%|██████▌   | 66/100 [04:03<02:15,  3.97s/it]Running generate_until requests:  67%|██████▋   | 67/100 [04:06<02:08,  3.89s/it]Running generate_until requests:  68%|██████▊   | 68/100 [04:08<01:42,  3.21s/it]Running generate_until requests:  69%|██████▉   | 69/100 [04:11<01:38,  3.18s/it]Running generate_until requests:  70%|███████   | 70/100 [04:14<01:38,  3.28s/it]Running generate_until requests:  71%|███████   | 71/100 [04:19<01:47,  3.72s/it]Running generate_until requests:  72%|███████▏  | 72/100 [04:22<01:37,  3.48s/it]Running generate_until requests:  73%|███████▎  | 73/100 [04:25<01:30,  3.36s/it]Running generate_until requests:  74%|███████▍  | 74/100 [04:29<01:29,  3.44s/it]Running generate_until requests:  75%|███████▌  | 75/100 [04:33<01:29,  3.57s/it]Running generate_until requests:  76%|███████▌  | 76/100 [04:38<01:37,  4.05s/it]Running generate_until requests:  77%|███████▋  | 77/100 [04:41<01:23,  3.64s/it]Running generate_until requests:  78%|███████▊  | 78/100 [04:42<01:08,  3.10s/it]Running generate_until requests:  79%|███████▉  | 79/100 [04:47<01:11,  3.40s/it]Running generate_until requests:  80%|████████  | 80/100 [04:48<00:59,  2.97s/it]Running generate_until requests:  81%|████████  | 81/100 [04:52<00:56,  2.98s/it]Running generate_until requests:  82%|████████▏ | 82/100 [04:56<01:03,  3.53s/it]Running generate_until requests:  83%|████████▎ | 83/100 [05:00<00:58,  3.44s/it]Running generate_until requests:  84%|████████▍ | 84/100 [05:02<00:48,  3.05s/it]Running generate_until requests:  85%|████████▌ | 85/100 [05:09<01:05,  4.36s/it]Running generate_until requests:  86%|████████▌ | 86/100 [05:12<00:54,  3.92s/it]Running generate_until requests:  87%|████████▋ | 87/100 [05:15<00:48,  3.69s/it]Running generate_until requests:  88%|████████▊ | 88/100 [05:17<00:38,  3.21s/it]Running generate_until requests:  89%|████████▉ | 89/100 [05:25<00:51,  4.68s/it]Running generate_until requests:  90%|█████████ | 90/100 [05:30<00:45,  4.56s/it]Running generate_until requests:  91%|█████████ | 91/100 [05:33<00:38,  4.28s/it]Running generate_until requests:  92%|█████████▏| 92/100 [05:36<00:30,  3.76s/it]Running generate_until requests:  93%|█████████▎| 93/100 [05:38<00:23,  3.35s/it]Running generate_until requests:  94%|█████████▍| 94/100 [05:41<00:19,  3.19s/it]Running generate_until requests:  95%|█████████▌| 95/100 [05:44<00:15,  3.18s/it]Running generate_until requests:  96%|█████████▌| 96/100 [05:47<00:12,  3.14s/it]Running generate_until requests:  97%|█████████▋| 97/100 [05:51<00:09,  3.27s/it]Running generate_until requests:  98%|█████████▊| 98/100 [05:55<00:07,  3.54s/it]Running generate_until requests:  99%|█████████▉| 99/100 [05:58<00:03,  3.25s/it]Running generate_until requests: 100%|██████████| 100/100 [06:01<00:00,  3.25s/it]Running generate_until requests: 100%|██████████| 100/100 [06:01<00:00,  3.61s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-03-20:07:41:07,471 INFO     [evaluation_tracker.py:206] Saving results aggregated
2025-03-20:07:41:07,509 INFO     [evaluation_tracker.py:287] Saving per-sample results for: gsm8k
2025-03-20:07:41:47,609 INFO     [__main__.py:279] Verbosity set to INFO
2025-03-20:07:41:59,051 WARNING  [__main__.py:312]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-03-20:07:41:59,053 INFO     [__main__.py:376] Selected Tasks: ['gsm8k']
2025-03-20:07:41:59,062 INFO     [evaluator.py:164] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
2025-03-20:07:41:59,063 WARNING  [evaluator.py:175] generation_kwargs specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-03-20:07:41:59,063 INFO     [evaluator.py:201] Initializing hf model, with arguments: {'pretrained': 'meta-llama/Llama-3.1-8B-Instruct', 'dtype': 'bfloat16', 'device': 'cuda', 'parallelize': False}
2025-03-20:07:41:59,344 INFO     [huggingface.py:129] Using device 'cuda'
2025-03-20:07:41:59,524 INFO     [huggingface.py:481] Using model type 'default'
2025-03-20:07:42:02,158 INFO     [huggingface.py:365] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda'}
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:03,  1.31s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:02<00:02,  1.26s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:03<00:01,  1.20s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.09it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.04s/it]
2025-03-20:07:42:25,782 WARNING  [model.py:422] model.chat_template was called with the chat_template set to False or None. Therefore no chat template will be applied. Make sure this is an intended behavior.
2025-03-20:07:42:25,784 INFO     [task.py:415] Building contexts for gsm8k on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s] 35%|███▌      | 35/100 [00:00<00:00, 342.95it/s] 71%|███████   | 71/100 [00:00<00:00, 348.08it/s]100%|██████████| 100/100 [00:00<00:00, 348.80it/s]
2025-03-20:07:42:26,074 INFO     [evaluator.py:489] Running generate_until requests
Running generate_until requests:   0%|          | 0/100 [00:00<?, ?it/s]/home/alireza/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/home/alireza/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Running generate_until requests:   1%|          | 1/100 [00:04<07:23,  4.48s/it]Running generate_until requests:   2%|▏         | 2/100 [00:08<06:24,  3.92s/it]Running generate_until requests:   3%|▎         | 3/100 [00:10<05:04,  3.14s/it]Running generate_until requests:   4%|▍         | 4/100 [00:15<06:26,  4.02s/it]Running generate_until requests:   5%|▌         | 5/100 [00:18<05:30,  3.48s/it]Running generate_until requests:   6%|▌         | 6/100 [00:23<06:25,  4.10s/it]Running generate_until requests:   7%|▋         | 7/100 [00:26<05:38,  3.64s/it]Running generate_until requests:   8%|▊         | 8/100 [00:29<05:13,  3.41s/it]Running generate_until requests:   9%|▉         | 9/100 [00:31<04:54,  3.24s/it]Running generate_until requests:  10%|█         | 10/100 [00:41<07:40,  5.12s/it]Running generate_until requests:  11%|█         | 11/100 [00:43<06:27,  4.35s/it]Running generate_until requests:  12%|█▏        | 12/100 [00:45<05:14,  3.58s/it]Running generate_until requests:  13%|█▎        | 13/100 [00:48<04:48,  3.31s/it]Running generate_until requests:  14%|█▍        | 14/100 [00:52<04:53,  3.42s/it]Running generate_until requests:  15%|█▌        | 15/100 [00:57<05:36,  3.96s/it]Running generate_until requests:  16%|█▌        | 16/100 [01:00<05:26,  3.89s/it]Running generate_until requests:  17%|█▋        | 17/100 [01:04<05:11,  3.75s/it]Running generate_until requests:  18%|█▊        | 18/100 [01:09<05:36,  4.10s/it]Running generate_until requests:  19%|█▉        | 19/100 [01:12<05:10,  3.84s/it]Running generate_until requests:  20%|██        | 20/100 [01:19<06:19,  4.74s/it]Running generate_until requests:  21%|██        | 21/100 [01:23<06:10,  4.69s/it]Running generate_until requests:  22%|██▏       | 22/100 [01:27<05:35,  4.30s/it]Running generate_until requests:  23%|██▎       | 23/100 [01:30<04:55,  3.83s/it]Running generate_until requests:  24%|██▍       | 24/100 [01:32<04:21,  3.44s/it]Running generate_until requests:  25%|██▌       | 25/100 [01:35<04:16,  3.43s/it]Running generate_until requests:  26%|██▌       | 26/100 [01:39<04:06,  3.33s/it]Running generate_until requests:  27%|██▋       | 27/100 [01:41<03:51,  3.18s/it]Running generate_until requests:  28%|██▊       | 28/100 [01:44<03:44,  3.12s/it]Running generate_until requests:  29%|██▉       | 29/100 [01:47<03:25,  2.89s/it]Running generate_until requests:  30%|███       | 30/100 [01:54<04:49,  4.14s/it]Running generate_until requests:  31%|███       | 31/100 [02:02<06:16,  5.45s/it]Running generate_until requests:  32%|███▏      | 32/100 [02:08<06:08,  5.43s/it]Running generate_until requests:  33%|███▎      | 33/100 [02:10<05:02,  4.51s/it]Running generate_until requests:  34%|███▍      | 34/100 [02:13<04:30,  4.10s/it]Running generate_until requests:  35%|███▌      | 35/100 [02:16<03:54,  3.61s/it]Running generate_until requests:  36%|███▌      | 36/100 [02:18<03:24,  3.19s/it]Running generate_until requests:  37%|███▋      | 37/100 [02:23<03:55,  3.74s/it]Running generate_until requests:  38%|███▊      | 38/100 [02:26<03:47,  3.67s/it]Running generate_until requests:  39%|███▉      | 39/100 [02:33<04:29,  4.42s/it]Running generate_until requests:  40%|████      | 40/100 [02:39<05:02,  5.05s/it]Running generate_until requests:  41%|████      | 41/100 [02:41<04:06,  4.19s/it]Running generate_until requests:  42%|████▏     | 42/100 [02:44<03:37,  3.74s/it]Running generate_until requests:  43%|████▎     | 43/100 [02:46<03:01,  3.19s/it]Running generate_until requests:  44%|████▍     | 44/100 [02:50<03:18,  3.54s/it]Running generate_until requests:  45%|████▌     | 45/100 [02:54<03:13,  3.51s/it]Running generate_until requests:  46%|████▌     | 46/100 [02:56<02:54,  3.24s/it]Running generate_until requests:  47%|████▋     | 47/100 [02:59<02:37,  2.97s/it]Running generate_until requests:  48%|████▊     | 48/100 [03:01<02:31,  2.91s/it]Running generate_until requests:  49%|████▉     | 49/100 [03:05<02:37,  3.08s/it]Running generate_until requests:  50%|█████     | 50/100 [03:07<02:14,  2.69s/it]Running generate_until requests:  51%|█████     | 51/100 [03:09<02:10,  2.66s/it]Running generate_until requests:  52%|█████▏    | 52/100 [03:12<02:14,  2.79s/it]Running generate_until requests:  53%|█████▎    | 53/100 [03:15<02:14,  2.87s/it]Running generate_until requests:  54%|█████▍    | 54/100 [03:19<02:25,  3.17s/it]Running generate_until requests:  55%|█████▌    | 55/100 [03:22<02:19,  3.11s/it]Running generate_until requests:  56%|█████▌    | 56/100 [03:27<02:44,  3.74s/it]Running generate_until requests:  57%|█████▋    | 57/100 [03:31<02:35,  3.61s/it]Running generate_until requests:  58%|█████▊    | 58/100 [03:36<02:52,  4.10s/it]Running generate_until requests:  59%|█████▉    | 59/100 [03:39<02:33,  3.76s/it]Running generate_until requests:  60%|██████    | 60/100 [03:41<02:03,  3.10s/it]Running generate_until requests:  61%|██████    | 61/100 [03:43<01:52,  2.88s/it]Running generate_until requests:  62%|██████▏   | 62/100 [03:46<01:55,  3.05s/it]Running generate_until requests:  63%|██████▎   | 63/100 [03:51<02:06,  3.41s/it]Running generate_until requests:  64%|██████▍   | 64/100 [03:56<02:27,  4.10s/it]Running generate_until requests:  65%|██████▌   | 65/100 [04:01<02:32,  4.35s/it]Running generate_until requests:  66%|██████▌   | 66/100 [04:04<02:16,  4.01s/it]Running generate_until requests:  67%|██████▋   | 67/100 [04:08<02:09,  3.92s/it]Running generate_until requests:  68%|██████▊   | 68/100 [04:10<01:43,  3.23s/it]Running generate_until requests:  69%|██████▉   | 69/100 [04:13<01:39,  3.21s/it]Running generate_until requests:  70%|███████   | 70/100 [04:16<01:39,  3.30s/it]Running generate_until requests:  71%|███████   | 71/100 [04:21<01:48,  3.74s/it]Running generate_until requests:  72%|███████▏  | 72/100 [04:24<01:38,  3.51s/it]Running generate_until requests:  73%|███████▎  | 73/100 [04:27<01:31,  3.38s/it]Running generate_until requests:  74%|███████▍  | 74/100 [04:31<01:30,  3.46s/it]Running generate_until requests:  75%|███████▌  | 75/100 [04:35<01:29,  3.59s/it]Running generate_until requests:  76%|███████▌  | 76/100 [04:40<01:38,  4.08s/it]Running generate_until requests:  77%|███████▋  | 77/100 [04:43<01:24,  3.67s/it]Running generate_until requests:  78%|███████▊  | 78/100 [04:45<01:08,  3.13s/it]Running generate_until requests:  79%|███████▉  | 79/100 [04:49<01:12,  3.43s/it]Running generate_until requests:  80%|████████  | 80/100 [04:51<00:59,  2.99s/it]Running generate_until requests:  81%|████████  | 81/100 [04:54<00:57,  3.01s/it]Running generate_until requests:  82%|████████▏ | 82/100 [04:59<01:04,  3.56s/it]Running generate_until requests:  83%|████████▎ | 83/100 [05:02<00:59,  3.47s/it]Running generate_until requests:  84%|████████▍ | 84/100 [05:04<00:49,  3.07s/it]Running generate_until requests:  85%|████████▌ | 85/100 [05:11<01:05,  4.40s/it]Running generate_until requests:  86%|████████▌ | 86/100 [05:14<00:55,  3.95s/it]Running generate_until requests:  87%|████████▋ | 87/100 [05:18<00:48,  3.72s/it]Running generate_until requests:  88%|████████▊ | 88/100 [05:20<00:38,  3.24s/it]Running generate_until requests:  89%|████████▉ | 89/100 [05:28<00:51,  4.72s/it]Running generate_until requests:  90%|█████████ | 90/100 [05:32<00:45,  4.59s/it]Running generate_until requests:  91%|█████████ | 91/100 [05:36<00:38,  4.32s/it]Running generate_until requests:  92%|█████████▏| 92/100 [05:38<00:30,  3.79s/it]Running generate_until requests:  93%|█████████▎| 93/100 [05:41<00:23,  3.37s/it]Running generate_until requests:  94%|█████████▍| 94/100 [05:44<00:19,  3.22s/it]Running generate_until requests:  95%|█████████▌| 95/100 [05:47<00:16,  3.21s/it]Running generate_until requests:  96%|█████████▌| 96/100 [05:50<00:12,  3.17s/it]Running generate_until requests:  97%|█████████▋| 97/100 [05:54<00:09,  3.29s/it]Running generate_until requests:  98%|█████████▊| 98/100 [05:58<00:07,  3.57s/it]Running generate_until requests:  99%|█████████▉| 99/100 [06:00<00:03,  3.27s/it]Running generate_until requests: 100%|██████████| 100/100 [06:04<00:00,  3.27s/it]Running generate_until requests: 100%|██████████| 100/100 [06:04<00:00,  3.64s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-03-20:07:48:35,586 INFO     [evaluation_tracker.py:206] Saving results aggregated
2025-03-20:07:48:35,637 INFO     [evaluation_tracker.py:287] Saving per-sample results for: gsm8k
2025-03-20:07:49:16,003 INFO     [__main__.py:279] Verbosity set to INFO
2025-03-20:07:49:27,546 WARNING  [__main__.py:312]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-03-20:07:49:27,548 INFO     [__main__.py:376] Selected Tasks: ['gsm8k']
2025-03-20:07:49:27,560 INFO     [evaluator.py:164] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
2025-03-20:07:49:27,560 WARNING  [evaluator.py:175] generation_kwargs specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-03-20:07:49:27,561 INFO     [evaluator.py:201] Initializing hf model, with arguments: {'pretrained': 'meta-llama/Llama-3.1-8B-Instruct', 'dtype': 'bfloat16', 'device': 'cuda', 'parallelize': False}
2025-03-20:07:49:27,816 INFO     [huggingface.py:129] Using device 'cuda'
2025-03-20:07:49:27,993 INFO     [huggingface.py:481] Using model type 'default'
2025-03-20:07:49:28,489 INFO     [huggingface.py:365] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda'}
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:04,  1.60s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:03<00:03,  1.56s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:04<00:01,  1.34s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.01it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.16s/it]
2025-03-20:07:49:38,542 WARNING  [model.py:422] model.chat_template was called with the chat_template set to False or None. Therefore no chat template will be applied. Make sure this is an intended behavior.
2025-03-20:07:49:38,543 INFO     [task.py:415] Building contexts for gsm8k on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s] 35%|███▌      | 35/100 [00:00<00:00, 344.72it/s] 70%|███████   | 70/100 [00:00<00:00, 330.65it/s]100%|██████████| 100/100 [00:00<00:00, 339.22it/s]
2025-03-20:07:49:38,842 INFO     [evaluator.py:489] Running generate_until requests
Running generate_until requests:   0%|          | 0/100 [00:00<?, ?it/s]/home/alireza/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/home/alireza/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Running generate_until requests:   1%|          | 1/100 [00:04<07:28,  4.53s/it]Running generate_until requests:   2%|▏         | 2/100 [00:08<06:25,  3.93s/it]Running generate_until requests:   3%|▎         | 3/100 [00:10<05:03,  3.13s/it]Running generate_until requests:   4%|▍         | 4/100 [00:15<06:24,  4.01s/it]Running generate_until requests:   5%|▌         | 5/100 [00:18<05:29,  3.47s/it]Running generate_until requests:   6%|▌         | 6/100 [00:23<06:23,  4.08s/it]Running generate_until requests:   7%|▋         | 7/100 [00:26<05:36,  3.62s/it]Running generate_until requests:   8%|▊         | 8/100 [00:28<05:11,  3.39s/it]Running generate_until requests:   9%|▉         | 9/100 [00:31<04:53,  3.22s/it]Running generate_until requests:  10%|█         | 10/100 [00:41<07:37,  5.08s/it]Running generate_until requests:  11%|█         | 11/100 [00:43<06:24,  4.32s/it]Running generate_until requests:  12%|█▏        | 12/100 [00:45<05:12,  3.55s/it]Running generate_until requests:  13%|█▎        | 13/100 [00:48<04:45,  3.29s/it]Running generate_until requests:  14%|█▍        | 14/100 [00:51<04:51,  3.39s/it]Running generate_until requests:  15%|█▌        | 15/100 [00:56<05:34,  3.93s/it]Running generate_until requests:  16%|█▌        | 16/100 [01:00<05:24,  3.86s/it]Running generate_until requests:  17%|█▋        | 17/100 [01:04<05:09,  3.73s/it]Running generate_until requests:  18%|█▊        | 18/100 [01:08<05:34,  4.07s/it]Running generate_until requests:  19%|█▉        | 19/100 [01:12<05:08,  3.81s/it]Running generate_until requests:  20%|██        | 20/100 [01:18<06:16,  4.71s/it]Running generate_until requests:  21%|██        | 21/100 [01:23<06:07,  4.66s/it]Running generate_until requests:  22%|██▏       | 22/100 [01:26<05:33,  4.27s/it]Running generate_until requests:  23%|██▎       | 23/100 [01:29<04:53,  3.81s/it]Running generate_until requests:  24%|██▍       | 24/100 [01:32<04:20,  3.42s/it]Running generate_until requests:  25%|██▌       | 25/100 [01:35<04:15,  3.41s/it]Running generate_until requests:  26%|██▌       | 26/100 [01:38<04:04,  3.31s/it]Running generate_until requests:  27%|██▋       | 27/100 [01:41<03:50,  3.16s/it]Running generate_until requests:  28%|██▊       | 28/100 [01:44<03:43,  3.10s/it]Running generate_until requests:  29%|██▉       | 29/100 [01:46<03:24,  2.87s/it]Running generate_until requests:  30%|███       | 30/100 [01:53<04:47,  4.11s/it]Running generate_until requests:  31%|███       | 31/100 [02:02<06:13,  5.42s/it]Running generate_until requests:  32%|███▏      | 32/100 [02:07<06:06,  5.39s/it]Running generate_until requests:  33%|███▎      | 33/100 [02:09<05:00,  4.49s/it]Running generate_until requests:  34%|███▍      | 34/100 [02:12<04:28,  4.07s/it]Running generate_until requests:  35%|███▌      | 35/100 [02:15<03:53,  3.59s/it]Running generate_until requests:  36%|███▌      | 36/100 [02:17<03:22,  3.17s/it]Running generate_until requests:  37%|███▋      | 37/100 [02:22<03:53,  3.71s/it]Running generate_until requests:  38%|███▊      | 38/100 [02:26<03:46,  3.65s/it]Running generate_until requests:  39%|███▉      | 39/100 [02:32<04:28,  4.40s/it]Running generate_until requests:  40%|████      | 40/100 [02:38<05:00,  5.02s/it]Running generate_until requests:  41%|████      | 41/100 [02:40<04:05,  4.16s/it]Running generate_until requests:  42%|████▏     | 42/100 [02:43<03:35,  3.72s/it]Running generate_until requests:  43%|████▎     | 43/100 [02:45<03:00,  3.17s/it]Running generate_until requests:  44%|████▍     | 44/100 [02:49<03:17,  3.52s/it]Running generate_until requests:  45%|████▌     | 45/100 [02:53<03:11,  3.49s/it]Running generate_until requests:  46%|████▌     | 46/100 [02:55<02:53,  3.22s/it]Running generate_until requests:  47%|████▋     | 47/100 [02:58<02:36,  2.95s/it]Running generate_until requests:  48%|████▊     | 48/100 [03:00<02:30,  2.89s/it]Running generate_until requests:  49%|████▉     | 49/100 [03:04<02:36,  3.06s/it]Running generate_until requests:  50%|█████     | 50/100 [03:06<02:13,  2.68s/it]Running generate_until requests:  51%|█████     | 51/100 [03:08<02:09,  2.64s/it]Running generate_until requests:  52%|█████▏    | 52/100 [03:11<02:13,  2.78s/it]Running generate_until requests:  53%|█████▎    | 53/100 [03:14<02:13,  2.85s/it]Running generate_until requests:  54%|█████▍    | 54/100 [03:18<02:24,  3.15s/it]Running generate_until requests:  55%|█████▌    | 55/100 [03:21<02:19,  3.09s/it]Running generate_until requests:  56%|█████▌    | 56/100 [03:26<02:43,  3.72s/it]Running generate_until requests:  57%|█████▋    | 57/100 [03:29<02:34,  3.59s/it]Running generate_until requests:  58%|█████▊    | 58/100 [03:35<02:50,  4.07s/it]Running generate_until requests:  59%|█████▉    | 59/100 [03:38<02:33,  3.73s/it]Running generate_until requests:  60%|██████    | 60/100 [03:39<02:03,  3.08s/it]Running generate_until requests:  61%|██████    | 61/100 [03:42<01:51,  2.86s/it]Running generate_until requests:  62%|██████▏   | 62/100 [03:45<01:55,  3.03s/it]Running generate_until requests:  63%|██████▎   | 63/100 [03:49<02:05,  3.39s/it]Running generate_until requests:  64%|██████▍   | 64/100 [03:55<02:26,  4.08s/it]Running generate_until requests:  65%|██████▌   | 65/100 [04:00<02:31,  4.32s/it]Running generate_until requests:  66%|██████▌   | 66/100 [04:03<02:15,  3.98s/it]Running generate_until requests:  67%|██████▋   | 67/100 [04:07<02:08,  3.90s/it]Running generate_until requests:  68%|██████▊   | 68/100 [04:08<01:42,  3.21s/it]Running generate_until requests:  69%|██████▉   | 69/100 [04:11<01:38,  3.19s/it]Running generate_until requests:  70%|███████   | 70/100 [04:15<01:38,  3.28s/it]Running generate_until requests:  71%|███████   | 71/100 [04:20<01:47,  3.72s/it]Running generate_until requests:  72%|███████▏  | 72/100 [04:23<01:37,  3.48s/it]Running generate_until requests:  73%|███████▎  | 73/100 [04:26<01:30,  3.36s/it]Running generate_until requests:  74%|███████▍  | 74/100 [04:29<01:29,  3.44s/it]Running generate_until requests:  75%|███████▌  | 75/100 [04:33<01:29,  3.57s/it]Running generate_until requests:  76%|███████▌  | 76/100 [04:38<01:37,  4.06s/it]Running generate_until requests:  77%|███████▋  | 77/100 [04:41<01:23,  3.65s/it]Running generate_until requests:  78%|███████▊  | 78/100 [04:43<01:08,  3.11s/it]Running generate_until requests:  79%|███████▉  | 79/100 [04:47<01:11,  3.41s/it]Running generate_until requests:  80%|████████  | 80/100 [04:49<00:59,  2.97s/it]Running generate_until requests:  81%|████████  | 81/100 [04:52<00:56,  2.99s/it]Running generate_until requests:  82%|████████▏ | 82/100 [04:57<01:03,  3.53s/it]Running generate_until requests:  83%|████████▎ | 83/100 [05:00<00:58,  3.45s/it]Running generate_until requests:  84%|████████▍ | 84/100 [05:02<00:48,  3.06s/it]Running generate_until requests:  85%|████████▌ | 85/100 [05:10<01:05,  4.37s/it]Running generate_until requests:  86%|████████▌ | 86/100 [05:12<00:54,  3.93s/it]Running generate_until requests:  87%|████████▋ | 87/100 [05:16<00:48,  3.70s/it]Running generate_until requests:  88%|████████▊ | 88/100 [05:18<00:38,  3.22s/it]Running generate_until requests:  89%|████████▉ | 89/100 [05:26<00:51,  4.69s/it]Running generate_until requests:  90%|█████████ | 90/100 [05:30<00:45,  4.56s/it]Running generate_until requests:  91%|█████████ | 91/100 [05:34<00:38,  4.29s/it]Running generate_until requests:  92%|█████████▏| 92/100 [05:36<00:30,  3.76s/it]Running generate_until requests:  93%|█████████▎| 93/100 [05:39<00:23,  3.35s/it]Running generate_until requests:  94%|█████████▍| 94/100 [05:42<00:19,  3.20s/it]Running generate_until requests:  95%|█████████▌| 95/100 [05:45<00:15,  3.19s/it]Running generate_until requests:  96%|█████████▌| 96/100 [05:48<00:12,  3.15s/it]Running generate_until requests:  97%|█████████▋| 97/100 [05:51<00:09,  3.27s/it]Running generate_until requests:  98%|█████████▊| 98/100 [05:56<00:07,  3.55s/it]Running generate_until requests:  99%|█████████▉| 99/100 [05:58<00:03,  3.25s/it]Running generate_until requests: 100%|██████████| 100/100 [06:01<00:00,  3.25s/it]Running generate_until requests: 100%|██████████| 100/100 [06:01<00:00,  3.62s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-03-20:07:55:45,400 INFO     [evaluation_tracker.py:206] Saving results aggregated
2025-03-20:07:55:45,448 INFO     [evaluation_tracker.py:287] Saving per-sample results for: gsm8k
2025-03-20:07:56:24,637 INFO     [__main__.py:279] Verbosity set to INFO
2025-03-20:07:56:36,463 WARNING  [__main__.py:312]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-03-20:07:56:36,464 INFO     [__main__.py:376] Selected Tasks: ['gsm8k']
2025-03-20:07:56:36,471 INFO     [evaluator.py:164] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
2025-03-20:07:56:36,472 WARNING  [evaluator.py:175] generation_kwargs specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-03-20:07:56:36,472 INFO     [evaluator.py:201] Initializing hf model, with arguments: {'pretrained': 'meta-llama/Llama-3.1-8B-Instruct', 'dtype': 'bfloat16', 'device': 'cuda', 'parallelize': False}
2025-03-20:07:56:36,828 INFO     [huggingface.py:129] Using device 'cuda'
2025-03-20:07:56:36,992 INFO     [huggingface.py:481] Using model type 'default'
2025-03-20:07:56:37,514 INFO     [huggingface.py:365] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda'}
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:03,  1.28s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:02<00:02,  1.05s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:02<00:00,  1.06it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.43it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.21it/s]
2025-03-20:07:56:53,331 WARNING  [model.py:422] model.chat_template was called with the chat_template set to False or None. Therefore no chat template will be applied. Make sure this is an intended behavior.
2025-03-20:07:56:53,333 INFO     [task.py:415] Building contexts for gsm8k on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s] 35%|███▌      | 35/100 [00:00<00:00, 341.70it/s] 70%|███████   | 70/100 [00:00<00:00, 346.26it/s]100%|██████████| 100/100 [00:00<00:00, 346.68it/s]
2025-03-20:07:56:53,626 INFO     [evaluator.py:489] Running generate_until requests
Running generate_until requests:   0%|          | 0/100 [00:00<?, ?it/s]/home/alireza/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/home/alireza/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Running generate_until requests:   1%|          | 1/100 [00:04<07:16,  4.41s/it]Running generate_until requests:   2%|▏         | 2/100 [00:07<06:21,  3.90s/it]Running generate_until requests:   3%|▎         | 3/100 [00:10<05:02,  3.12s/it]Running generate_until requests:   4%|▍         | 4/100 [00:15<06:25,  4.02s/it]Running generate_until requests:   5%|▌         | 5/100 [00:18<05:30,  3.48s/it]Running generate_until requests:   6%|▌         | 6/100 [00:23<06:25,  4.10s/it]Running generate_until requests:   7%|▋         | 7/100 [00:26<05:38,  3.64s/it]Running generate_until requests:   8%|▊         | 8/100 [00:28<05:13,  3.41s/it]Running generate_until requests:   9%|▉         | 9/100 [00:31<04:55,  3.24s/it]Running generate_until requests:  10%|█         | 10/100 [00:41<07:40,  5.12s/it]Running generate_until requests:  11%|█         | 11/100 [00:43<06:27,  4.35s/it]Running generate_until requests:  12%|█▏        | 12/100 [00:45<05:14,  3.58s/it]Running generate_until requests:  13%|█▎        | 13/100 [00:48<04:47,  3.31s/it]Running generate_until requests:  14%|█▍        | 14/100 [00:51<04:53,  3.41s/it]Running generate_until requests:  15%|█▌        | 15/100 [00:57<05:36,  3.96s/it]Running generate_until requests:  16%|█▌        | 16/100 [01:00<05:26,  3.89s/it]Running generate_until requests:  17%|█▋        | 17/100 [01:04<05:11,  3.75s/it]Running generate_until requests:  18%|█▊        | 18/100 [01:09<05:36,  4.10s/it]Running generate_until requests:  19%|█▉        | 19/100 [01:12<05:10,  3.84s/it]Running generate_until requests:  20%|██        | 20/100 [01:19<06:19,  4.74s/it]Running generate_until requests:  21%|██        | 21/100 [01:23<06:10,  4.69s/it]Running generate_until requests:  22%|██▏       | 22/100 [01:27<05:35,  4.30s/it]Running generate_until requests:  23%|██▎       | 23/100 [01:30<04:55,  3.84s/it]Running generate_until requests:  24%|██▍       | 24/100 [01:32<04:21,  3.45s/it]Running generate_until requests:  25%|██▌       | 25/100 [01:35<04:17,  3.43s/it]Running generate_until requests:  26%|██▌       | 26/100 [01:39<04:06,  3.33s/it]Running generate_until requests:  27%|██▋       | 27/100 [01:41<03:52,  3.18s/it]Running generate_until requests:  28%|██▊       | 28/100 [01:44<03:44,  3.12s/it]Running generate_until requests:  29%|██▉       | 29/100 [01:47<03:25,  2.89s/it]Running generate_until requests:  30%|███       | 30/100 [01:54<04:48,  4.12s/it]Running generate_until requests:  31%|███       | 31/100 [02:02<06:13,  5.41s/it]Running generate_until requests:  32%|███▏      | 32/100 [02:07<06:05,  5.38s/it]Running generate_until requests:  33%|███▎      | 33/100 [02:10<04:59,  4.47s/it]Running generate_until requests:  34%|███▍      | 34/100 [02:13<04:28,  4.06s/it]Running generate_until requests:  35%|███▌      | 35/100 [02:15<03:52,  3.57s/it]Running generate_until requests:  36%|███▌      | 36/100 [02:18<03:22,  3.16s/it]Running generate_until requests:  37%|███▋      | 37/100 [02:22<03:52,  3.70s/it]Running generate_until requests:  38%|███▊      | 38/100 [02:26<03:45,  3.63s/it]Running generate_until requests:  39%|███▉      | 39/100 [02:32<04:27,  4.38s/it]Running generate_until requests:  40%|████      | 40/100 [02:39<04:59,  4.99s/it]Running generate_until requests:  41%|████      | 41/100 [02:41<04:04,  4.14s/it]Running generate_until requests:  42%|████▏     | 42/100 [02:43<03:34,  3.70s/it]Running generate_until requests:  43%|████▎     | 43/100 [02:45<02:59,  3.15s/it]Running generate_until requests:  44%|████▍     | 44/100 [02:50<03:16,  3.50s/it]Running generate_until requests:  45%|████▌     | 45/100 [02:53<03:11,  3.47s/it]Running generate_until requests:  46%|████▌     | 46/100 [02:56<02:52,  3.20s/it]Running generate_until requests:  47%|████▋     | 47/100 [02:58<02:35,  2.94s/it]Running generate_until requests:  48%|████▊     | 48/100 [03:01<02:29,  2.88s/it]Running generate_until requests:  49%|████▉     | 49/100 [03:04<02:35,  3.05s/it]Running generate_until requests:  50%|█████     | 50/100 [03:06<02:13,  2.66s/it]Running generate_until requests:  51%|█████     | 51/100 [03:08<02:08,  2.63s/it]Running generate_until requests:  52%|█████▏    | 52/100 [03:11<02:12,  2.76s/it]Running generate_until requests:  53%|█████▎    | 53/100 [03:14<02:13,  2.84s/it]Running generate_until requests:  54%|█████▍    | 54/100 [03:18<02:24,  3.14s/it]Running generate_until requests:  55%|█████▌    | 55/100 [03:21<02:18,  3.08s/it]Running generate_until requests:  56%|█████▌    | 56/100 [03:26<02:42,  3.70s/it]Running generate_until requests:  57%|█████▋    | 57/100 [03:30<02:33,  3.58s/it]Running generate_until requests:  58%|█████▊    | 58/100 [03:35<02:50,  4.05s/it]Running generate_until requests:  59%|█████▉    | 59/100 [03:38<02:32,  3.72s/it]Running generate_until requests:  60%|██████    | 60/100 [03:39<02:02,  3.06s/it]Running generate_until requests:  61%|██████    | 61/100 [03:42<01:50,  2.84s/it]Running generate_until requests:  62%|██████▏   | 62/100 [03:45<01:54,  3.02s/it]Running generate_until requests:  63%|██████▎   | 63/100 [03:49<02:04,  3.38s/it]Running generate_until requests:  64%|██████▍   | 64/100 [03:55<02:26,  4.06s/it]Running generate_until requests:  65%|██████▌   | 65/100 [04:00<02:30,  4.30s/it]Running generate_until requests:  66%|██████▌   | 66/100 [04:03<02:14,  3.96s/it]Running generate_until requests:  67%|██████▋   | 67/100 [04:07<02:08,  3.88s/it]Running generate_until requests:  68%|██████▊   | 68/100 [04:08<01:42,  3.20s/it]Running generate_until requests:  69%|██████▉   | 69/100 [04:11<01:38,  3.17s/it]Running generate_until requests:  70%|███████   | 70/100 [04:15<01:37,  3.26s/it]Running generate_until requests:  71%|███████   | 71/100 [04:20<01:47,  3.70s/it]Running generate_until requests:  72%|███████▏  | 72/100 [04:22<01:37,  3.47s/it]Running generate_until requests:  73%|███████▎  | 73/100 [04:26<01:30,  3.34s/it]Running generate_until requests:  74%|███████▍  | 74/100 [04:29<01:29,  3.42s/it]Running generate_until requests:  75%|███████▌  | 75/100 [04:33<01:28,  3.55s/it]Running generate_until requests:  76%|███████▌  | 76/100 [04:38<01:36,  4.04s/it]Running generate_until requests:  77%|███████▋  | 77/100 [04:41<01:23,  3.63s/it]Running generate_until requests:  78%|███████▊  | 78/100 [04:43<01:08,  3.09s/it]Running generate_until requests:  79%|███████▉  | 79/100 [04:47<01:11,  3.39s/it]Running generate_until requests:  80%|████████  | 80/100 [04:49<00:59,  2.96s/it]Running generate_until requests:  81%|████████  | 81/100 [04:52<00:56,  2.98s/it]Running generate_until requests:  82%|████████▏ | 82/100 [04:57<01:03,  3.52s/it]Running generate_until requests:  83%|████████▎ | 83/100 [05:00<00:58,  3.43s/it]Running generate_until requests:  84%|████████▍ | 84/100 [05:02<00:48,  3.04s/it]Running generate_until requests:  85%|████████▌ | 85/100 [05:09<01:05,  4.35s/it]Running generate_until requests:  86%|████████▌ | 86/100 [05:12<00:54,  3.91s/it]Running generate_until requests:  87%|████████▋ | 87/100 [05:15<00:47,  3.69s/it]Running generate_until requests:  88%|████████▊ | 88/100 [05:17<00:38,  3.20s/it]Running generate_until requests:  89%|████████▉ | 89/100 [05:25<00:51,  4.67s/it]Running generate_until requests:  90%|█████████ | 90/100 [05:30<00:45,  4.54s/it]Running generate_until requests:  91%|█████████ | 91/100 [05:33<00:38,  4.27s/it]Running generate_until requests:  92%|█████████▏| 92/100 [05:36<00:29,  3.75s/it]Running generate_until requests:  93%|█████████▎| 93/100 [05:38<00:23,  3.34s/it]Running generate_until requests:  94%|█████████▍| 94/100 [05:41<00:19,  3.19s/it]Running generate_until requests:  95%|█████████▌| 95/100 [05:44<00:15,  3.17s/it]Running generate_until requests:  96%|█████████▌| 96/100 [05:47<00:12,  3.13s/it]Running generate_until requests:  97%|█████████▋| 97/100 [05:51<00:09,  3.26s/it]Running generate_until requests:  98%|█████████▊| 98/100 [05:55<00:07,  3.53s/it]Running generate_until requests:  99%|█████████▉| 99/100 [05:58<00:03,  3.24s/it]Running generate_until requests: 100%|██████████| 100/100 [06:01<00:00,  3.24s/it]Running generate_until requests: 100%|██████████| 100/100 [06:01<00:00,  3.61s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-03-20:08:02:59,733 INFO     [evaluation_tracker.py:206] Saving results aggregated
2025-03-20:08:02:59,758 INFO     [evaluation_tracker.py:287] Saving per-sample results for: gsm8k
2025-03-20:08:03:40,474 INFO     [__main__.py:279] Verbosity set to INFO
2025-03-20:08:03:52,281 WARNING  [__main__.py:312]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-03-20:08:03:52,283 INFO     [__main__.py:376] Selected Tasks: ['gsm8k']
2025-03-20:08:03:52,292 INFO     [evaluator.py:164] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
2025-03-20:08:03:52,292 WARNING  [evaluator.py:175] generation_kwargs specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-03-20:08:03:52,293 INFO     [evaluator.py:201] Initializing hf model, with arguments: {'pretrained': 'meta-llama/Llama-3.1-8B-Instruct', 'dtype': 'bfloat16', 'device': 'cuda', 'parallelize': False}
2025-03-20:08:03:52,567 INFO     [huggingface.py:129] Using device 'cuda'
2025-03-20:08:03:52,763 INFO     [huggingface.py:481] Using model type 'default'
2025-03-20:08:03:53,251 INFO     [huggingface.py:365] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda'}
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:04,  1.57s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:02<00:02,  1.32s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:03<00:01,  1.20s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.12it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.05s/it]
2025-03-20:08:04:05,843 WARNING  [model.py:422] model.chat_template was called with the chat_template set to False or None. Therefore no chat template will be applied. Make sure this is an intended behavior.
2025-03-20:08:04:05,846 INFO     [task.py:415] Building contexts for gsm8k on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s] 35%|███▌      | 35/100 [00:00<00:00, 346.72it/s] 70%|███████   | 70/100 [00:00<00:00, 344.52it/s]100%|██████████| 100/100 [00:00<00:00, 346.67it/s]
2025-03-20:08:04:06,138 INFO     [evaluator.py:489] Running generate_until requests
Running generate_until requests:   0%|          | 0/100 [00:00<?, ?it/s]/home/alireza/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/home/alireza/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Running generate_until requests:   1%|          | 1/100 [00:04<07:17,  4.42s/it]Running generate_until requests:   2%|▏         | 2/100 [00:07<06:20,  3.88s/it]Running generate_until requests:   3%|▎         | 3/100 [00:10<05:01,  3.11s/it]Running generate_until requests:   4%|▍         | 4/100 [00:15<06:22,  3.99s/it]Running generate_until requests:   5%|▌         | 5/100 [00:17<05:28,  3.45s/it]Running generate_until requests:   6%|▌         | 6/100 [00:23<06:22,  4.07s/it]Running generate_until requests:   7%|▋         | 7/100 [00:25<05:36,  3.61s/it]Running generate_until requests:   8%|▊         | 8/100 [00:28<05:11,  3.38s/it]Running generate_until requests:   9%|▉         | 9/100 [00:31<04:52,  3.22s/it]Running generate_until requests:  10%|█         | 10/100 [00:40<07:36,  5.07s/it]Running generate_until requests:  11%|█         | 11/100 [00:43<06:24,  4.32s/it]Running generate_until requests:  12%|█▏        | 12/100 [00:45<05:12,  3.55s/it]Running generate_until requests:  13%|█▎        | 13/100 [00:47<04:45,  3.28s/it]Running generate_until requests:  14%|█▍        | 14/100 [00:51<04:51,  3.39s/it]Running generate_until requests:  15%|█▌        | 15/100 [00:56<05:33,  3.93s/it]Running generate_until requests:  16%|█▌        | 16/100 [01:00<05:23,  3.86s/it]Running generate_until requests:  17%|█▋        | 17/100 [01:03<05:08,  3.72s/it]Running generate_until requests:  18%|█▊        | 18/100 [01:08<05:33,  4.07s/it]Running generate_until requests:  19%|█▉        | 19/100 [01:11<05:08,  3.81s/it]Running generate_until requests:  20%|██        | 20/100 [01:18<06:16,  4.70s/it]Running generate_until requests:  21%|██        | 21/100 [01:23<06:07,  4.65s/it]Running generate_until requests:  22%|██▏       | 22/100 [01:26<05:32,  4.26s/it]Running generate_until requests:  23%|██▎       | 23/100 [01:29<04:52,  3.80s/it]Running generate_until requests:  24%|██▍       | 24/100 [01:31<04:19,  3.42s/it]Running generate_until requests:  25%|██▌       | 25/100 [01:35<04:15,  3.40s/it]Running generate_until requests:  26%|██▌       | 26/100 [01:38<04:04,  3.30s/it]Running generate_until requests:  27%|██▋       | 27/100 [01:41<03:50,  3.15s/it]Running generate_until requests:  28%|██▊       | 28/100 [01:44<03:43,  3.10s/it]Running generate_until requests:  29%|██▉       | 29/100 [01:46<03:23,  2.87s/it]Running generate_until requests:  30%|███       | 30/100 [01:53<04:47,  4.11s/it]Running generate_until requests:  31%|███       | 31/100 [02:01<06:13,  5.41s/it]Running generate_until requests:  32%|███▏      | 32/100 [02:07<06:06,  5.39s/it]Running generate_until requests:  33%|███▎      | 33/100 [02:09<05:00,  4.48s/it]Running generate_until requests:  34%|███▍      | 34/100 [02:12<04:28,  4.07s/it]Running generate_until requests:  35%|███▌      | 35/100 [02:15<03:52,  3.57s/it]Running generate_until requests:  36%|███▌      | 36/100 [02:17<03:21,  3.15s/it]Running generate_until requests:  37%|███▋      | 37/100 [02:22<03:51,  3.68s/it]Running generate_until requests:  38%|███▊      | 38/100 [02:25<03:44,  3.61s/it]Running generate_until requests:  39%|███▉      | 39/100 [02:31<04:25,  4.35s/it]Running generate_until requests:  40%|████      | 40/100 [02:38<04:57,  4.96s/it]Running generate_until requests:  41%|████      | 41/100 [02:40<04:02,  4.11s/it]Running generate_until requests:  42%|████▏     | 42/100 [02:42<03:33,  3.67s/it]Running generate_until requests:  43%|████▎     | 43/100 [02:44<02:58,  3.13s/it]Running generate_until requests:  44%|████▍     | 44/100 [02:48<03:14,  3.48s/it]Running generate_until requests:  45%|████▌     | 45/100 [02:52<03:09,  3.45s/it]Running generate_until requests:  46%|████▌     | 46/100 [02:54<02:51,  3.18s/it]Running generate_until requests:  47%|████▋     | 47/100 [02:57<02:34,  2.92s/it]Running generate_until requests:  48%|████▊     | 48/100 [02:59<02:28,  2.86s/it]Running generate_until requests:  49%|████▉     | 49/100 [03:03<02:34,  3.02s/it]Running generate_until requests:  50%|█████     | 50/100 [03:05<02:12,  2.64s/it]Running generate_until requests:  51%|█████     | 51/100 [03:07<02:07,  2.61s/it]Running generate_until requests:  52%|█████▏    | 52/100 [03:10<02:11,  2.74s/it]Running generate_until requests:  53%|█████▎    | 53/100 [03:13<02:12,  2.81s/it]Running generate_until requests:  54%|█████▍    | 54/100 [03:17<02:23,  3.11s/it]Running generate_until requests:  55%|█████▌    | 55/100 [03:20<02:17,  3.05s/it]Running generate_until requests:  56%|█████▌    | 56/100 [03:25<02:41,  3.67s/it]Running generate_until requests:  57%|█████▋    | 57/100 [03:28<02:32,  3.55s/it]Running generate_until requests:  58%|█████▊    | 58/100 [03:33<02:48,  4.02s/it]Running generate_until requests:  59%|█████▉    | 59/100 [03:36<02:31,  3.69s/it]Running generate_until requests:  60%|██████    | 60/100 [03:38<02:01,  3.04s/it]Running generate_until requests:  61%|██████    | 61/100 [03:40<01:50,  2.82s/it]Running generate_until requests:  62%|██████▏   | 62/100 [03:44<01:53,  2.99s/it]Running generate_until requests:  63%|██████▎   | 63/100 [03:48<02:03,  3.35s/it]Running generate_until requests:  64%|██████▍   | 64/100 [03:53<02:24,  4.02s/it]Running generate_until requests:  65%|██████▌   | 65/100 [03:58<02:29,  4.27s/it]Running generate_until requests:  66%|██████▌   | 66/100 [04:01<02:13,  3.93s/it]Running generate_until requests:  67%|██████▋   | 67/100 [04:05<02:06,  3.85s/it]Running generate_until requests:  68%|██████▊   | 68/100 [04:07<01:41,  3.17s/it]Running generate_until requests:  69%|██████▉   | 69/100 [04:10<01:37,  3.15s/it]Running generate_until requests:  70%|███████   | 70/100 [04:13<01:37,  3.24s/it]Running generate_until requests:  71%|███████   | 71/100 [04:18<01:46,  3.67s/it]Running generate_until requests:  72%|███████▏  | 72/100 [04:21<01:36,  3.44s/it]Running generate_until requests:  73%|███████▎  | 73/100 [04:24<01:29,  3.32s/it]Running generate_until requests:  74%|███████▍  | 74/100 [04:27<01:28,  3.40s/it]Running generate_until requests:  75%|███████▌  | 75/100 [04:31<01:28,  3.52s/it]Running generate_until requests:  76%|███████▌  | 76/100 [04:36<01:36,  4.01s/it]Running generate_until requests:  77%|███████▋  | 77/100 [04:39<01:22,  3.60s/it]Running generate_until requests:  78%|███████▊  | 78/100 [04:41<01:07,  3.07s/it]Running generate_until requests:  79%|███████▉  | 79/100 [04:45<01:10,  3.37s/it]Running generate_until requests:  80%|████████  | 80/100 [04:47<00:58,  2.93s/it]Running generate_until requests:  81%|████████  | 81/100 [04:50<00:56,  2.95s/it]Running generate_until requests:  82%|████████▏ | 82/100 [04:54<01:02,  3.49s/it]Running generate_until requests:  83%|████████▎ | 83/100 [04:58<00:57,  3.41s/it]Running generate_until requests:  84%|████████▍ | 84/100 [05:00<00:48,  3.02s/it]Running generate_until requests:  85%|████████▌ | 85/100 [05:07<01:04,  4.31s/it]Running generate_until requests:  86%|████████▌ | 86/100 [05:10<00:54,  3.88s/it]Running generate_until requests:  87%|████████▋ | 87/100 [05:13<00:47,  3.65s/it]Running generate_until requests:  88%|████████▊ | 88/100 [05:15<00:38,  3.18s/it]Running generate_until requests:  89%|████████▉ | 89/100 [05:23<00:50,  4.63s/it]Running generate_until requests:  90%|█████████ | 90/100 [05:27<00:45,  4.51s/it]Running generate_until requests:  91%|█████████ | 91/100 [05:31<00:38,  4.24s/it]Running generate_until requests:  92%|█████████▏| 92/100 [05:33<00:29,  3.72s/it]Running generate_until requests:  93%|█████████▎| 93/100 [05:36<00:23,  3.31s/it]Running generate_until requests:  94%|█████████▍| 94/100 [05:39<00:18,  3.16s/it]Running generate_until requests:  95%|█████████▌| 95/100 [05:42<00:15,  3.15s/it]Running generate_until requests:  96%|█████████▌| 96/100 [05:45<00:12,  3.11s/it]Running generate_until requests:  97%|█████████▋| 97/100 [05:48<00:09,  3.23s/it]Running generate_until requests:  98%|█████████▊| 98/100 [05:52<00:07,  3.50s/it]Running generate_until requests:  99%|█████████▉| 99/100 [05:55<00:03,  3.21s/it]Running generate_until requests: 100%|██████████| 100/100 [05:58<00:00,  3.22s/it]Running generate_until requests: 100%|██████████| 100/100 [05:58<00:00,  3.59s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-03-20:08:10:10,086 INFO     [evaluation_tracker.py:206] Saving results aggregated
2025-03-20:08:10:10,112 INFO     [evaluation_tracker.py:287] Saving per-sample results for: gsm8k
