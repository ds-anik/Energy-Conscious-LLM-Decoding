2025-03-20:06:30:18,702 INFO     [__main__.py:279] Verbosity set to INFO
2025-03-20:06:30:30,576 WARNING  [__main__.py:312]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-03-20:06:30:30,578 INFO     [__main__.py:376] Selected Tasks: ['gsm8k']
2025-03-20:06:30:30,587 INFO     [evaluator.py:164] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
2025-03-20:06:30:30,588 WARNING  [evaluator.py:175] generation_kwargs specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-03-20:06:30:30,588 INFO     [evaluator.py:201] Initializing hf model, with arguments: {'pretrained': 'meta-llama/Llama-3.1-8B-Instruct', 'dtype': 'bfloat16', 'device': 'cuda', 'parallelize': False}
2025-03-20:06:30:30,875 INFO     [huggingface.py:129] Using device 'cuda'
2025-03-20:06:30:31,051 INFO     [huggingface.py:481] Using model type 'default'
2025-03-20:06:30:31,529 INFO     [huggingface.py:365] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda'}
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:03,  1.18s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:02<00:02,  1.03s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:02<00:00,  1.04it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.42it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.21it/s]
2025-03-20:06:30:40,877 WARNING  [model.py:422] model.chat_template was called with the chat_template set to False or None. Therefore no chat template will be applied. Make sure this is an intended behavior.
2025-03-20:06:30:40,880 INFO     [task.py:415] Building contexts for gsm8k on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s] 34%|███▍      | 34/100 [00:00<00:00, 337.76it/s] 69%|██████▉   | 69/100 [00:00<00:00, 344.46it/s]100%|██████████| 100/100 [00:00<00:00, 345.16it/s]
2025-03-20:06:30:41,173 INFO     [evaluator.py:489] Running generate_until requests
Running generate_until requests:   0%|          | 0/100 [00:00<?, ?it/s]/home/alireza/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/home/alireza/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Running generate_until requests:   1%|          | 1/100 [00:02<04:33,  2.76s/it]Running generate_until requests:   2%|▏         | 2/100 [00:07<06:30,  3.98s/it]Running generate_until requests:   3%|▎         | 3/100 [00:09<05:14,  3.24s/it]Running generate_until requests:   4%|▍         | 4/100 [00:13<05:34,  3.48s/it]Running generate_until requests:   5%|▌         | 5/100 [00:16<05:02,  3.18s/it]Running generate_until requests:   6%|▌         | 6/100 [00:22<06:43,  4.30s/it]Running generate_until requests:   7%|▋         | 7/100 [00:25<05:43,  3.70s/it]Running generate_until requests:   8%|▊         | 8/100 [00:28<05:28,  3.57s/it]Running generate_until requests:   9%|▉         | 9/100 [00:30<04:34,  3.02s/it]Running generate_until requests:  10%|█         | 10/100 [00:34<05:01,  3.36s/it]Running generate_until requests:  11%|█         | 11/100 [00:36<04:08,  2.79s/it]Running generate_until requests:  12%|█▏        | 12/100 [00:38<03:41,  2.52s/it]Running generate_until requests:  13%|█▎        | 13/100 [00:40<03:29,  2.41s/it]Running generate_until requests:  14%|█▍        | 14/100 [00:42<03:14,  2.26s/it]Running generate_until requests:  15%|█▌        | 15/100 [00:47<04:21,  3.07s/it]Running generate_until requests:  16%|█▌        | 16/100 [00:49<03:57,  2.82s/it]Running generate_until requests:  17%|█▋        | 17/100 [00:52<03:52,  2.80s/it]Running generate_until requests:  18%|█▊        | 18/100 [00:56<04:21,  3.19s/it]Running generate_until requests:  19%|█▉        | 19/100 [00:58<04:00,  2.97s/it]Running generate_until requests:  20%|██        | 20/100 [01:01<04:06,  3.08s/it]Running generate_until requests:  21%|██        | 21/100 [01:05<04:12,  3.20s/it]Running generate_until requests:  22%|██▏       | 22/100 [01:09<04:27,  3.43s/it]Running generate_until requests:  23%|██▎       | 23/100 [01:11<03:53,  3.04s/it]Running generate_until requests:  24%|██▍       | 24/100 [01:13<03:19,  2.62s/it]Running generate_until requests:  25%|██▌       | 25/100 [01:16<03:27,  2.77s/it]Running generate_until requests:  26%|██▌       | 26/100 [01:18<03:05,  2.51s/it]Running generate_until requests:  27%|██▋       | 27/100 [01:21<03:14,  2.67s/it]Running generate_until requests:  28%|██▊       | 28/100 [01:22<02:52,  2.40s/it]Running generate_until requests:  29%|██▉       | 29/100 [01:24<02:29,  2.11s/it]Running generate_until requests:  30%|███       | 30/100 [01:28<03:11,  2.73s/it]Running generate_until requests:  31%|███       | 31/100 [01:32<03:40,  3.19s/it]Running generate_until requests:  32%|███▏      | 32/100 [01:35<03:34,  3.15s/it]Running generate_until requests:  33%|███▎      | 33/100 [01:37<03:09,  2.82s/it]Running generate_until requests:  34%|███▍      | 34/100 [01:40<02:59,  2.72s/it]Running generate_until requests:  35%|███▌      | 35/100 [01:42<02:39,  2.46s/it]Running generate_until requests:  36%|███▌      | 36/100 [01:45<02:44,  2.58s/it]Running generate_until requests:  37%|███▋      | 37/100 [01:49<03:19,  3.16s/it]Running generate_until requests:  38%|███▊      | 38/100 [01:51<02:56,  2.84s/it]Running generate_until requests:  39%|███▉      | 39/100 [01:55<03:02,  2.99s/it]Running generate_until requests:  40%|████      | 40/100 [02:02<04:10,  4.18s/it]Running generate_until requests:  41%|████      | 41/100 [02:03<03:25,  3.48s/it]Running generate_until requests:  42%|████▏     | 42/100 [02:05<02:51,  2.95s/it]Running generate_until requests:  43%|████▎     | 43/100 [02:07<02:29,  2.62s/it]Running generate_until requests:  44%|████▍     | 44/100 [02:14<03:40,  3.93s/it]Running generate_until requests:  45%|████▌     | 45/100 [02:17<03:16,  3.58s/it]Running generate_until requests:  46%|████▌     | 46/100 [02:19<02:51,  3.17s/it]Running generate_until requests:  47%|████▋     | 47/100 [02:20<02:19,  2.64s/it]Running generate_until requests:  48%|████▊     | 48/100 [02:22<02:09,  2.49s/it]Running generate_until requests:  49%|████▉     | 49/100 [02:26<02:25,  2.85s/it]Running generate_until requests:  50%|█████     | 50/100 [02:28<02:02,  2.44s/it]Running generate_until requests:  51%|█████     | 51/100 [02:30<01:51,  2.28s/it]Running generate_until requests:  52%|█████▏    | 52/100 [02:33<01:59,  2.49s/it]Running generate_until requests:  53%|█████▎    | 53/100 [02:36<02:14,  2.86s/it]Running generate_until requests:  54%|█████▍    | 54/100 [02:41<02:36,  3.40s/it]Running generate_until requests:  55%|█████▌    | 55/100 [02:43<02:11,  2.93s/it]Running generate_until requests:  56%|█████▌    | 56/100 [02:45<01:54,  2.61s/it]Running generate_until requests:  57%|█████▋    | 57/100 [02:47<01:52,  2.63s/it]Running generate_until requests:  58%|█████▊    | 58/100 [02:51<02:03,  2.94s/it]Running generate_until requests:  59%|█████▉    | 59/100 [02:53<01:54,  2.80s/it]Running generate_until requests:  60%|██████    | 60/100 [02:55<01:33,  2.34s/it]Running generate_until requests:  61%|██████    | 61/100 [02:56<01:23,  2.15s/it]Running generate_until requests:  62%|██████▏   | 62/100 [02:59<01:23,  2.21s/it]Running generate_until requests:  63%|██████▎   | 63/100 [03:00<01:16,  2.07s/it]Running generate_until requests:  64%|██████▍   | 64/100 [03:04<01:27,  2.42s/it]Running generate_until requests:  65%|██████▌   | 65/100 [03:06<01:22,  2.36s/it]Running generate_until requests:  66%|██████▌   | 66/100 [03:08<01:18,  2.32s/it]Running generate_until requests:  67%|██████▋   | 67/100 [03:11<01:19,  2.42s/it]Running generate_until requests:  68%|██████▊   | 68/100 [03:12<01:04,  2.03s/it]Running generate_until requests:  69%|██████▉   | 69/100 [03:16<01:18,  2.54s/it]Running generate_until requests:  70%|███████   | 70/100 [03:18<01:16,  2.53s/it]Running generate_until requests:  71%|███████   | 71/100 [03:22<01:26,  2.99s/it]Running generate_until requests:  72%|███████▏  | 72/100 [03:24<01:16,  2.74s/it]Running generate_until requests:  73%|███████▎  | 73/100 [03:27<01:11,  2.67s/it]Running generate_until requests:  74%|███████▍  | 74/100 [03:30<01:11,  2.77s/it]Running generate_until requests:  75%|███████▌  | 75/100 [03:32<01:03,  2.55s/it]Running generate_until requests:  76%|███████▌  | 76/100 [03:35<01:05,  2.71s/it]Running generate_until requests:  77%|███████▋  | 77/100 [03:38<01:02,  2.71s/it]Running generate_until requests:  78%|███████▊  | 78/100 [03:39<00:51,  2.36s/it]Running generate_until requests:  79%|███████▉  | 79/100 [03:41<00:46,  2.23s/it]Running generate_until requests:  80%|████████  | 80/100 [03:43<00:40,  2.03s/it]Running generate_until requests:  81%|████████  | 81/100 [03:45<00:41,  2.19s/it]Running generate_until requests:  82%|████████▏ | 82/100 [03:50<00:50,  2.81s/it]Running generate_until requests:  83%|████████▎ | 83/100 [03:52<00:43,  2.58s/it]Running generate_until requests:  84%|████████▍ | 84/100 [03:53<00:36,  2.31s/it]Running generate_until requests:  85%|████████▌ | 85/100 [03:56<00:36,  2.41s/it]Running generate_until requests:  86%|████████▌ | 86/100 [03:58<00:33,  2.39s/it]Running generate_until requests:  87%|████████▋ | 87/100 [04:01<00:30,  2.38s/it]Running generate_until requests:  88%|████████▊ | 88/100 [04:02<00:26,  2.17s/it]Running generate_until requests:  89%|████████▉ | 89/100 [04:05<00:24,  2.21s/it]Running generate_until requests:  90%|█████████ | 90/100 [04:07<00:21,  2.19s/it]Running generate_until requests:  91%|█████████ | 91/100 [04:08<00:18,  2.00s/it]Running generate_until requests:  92%|█████████▏| 92/100 [04:11<00:17,  2.20s/it]Running generate_until requests:  93%|█████████▎| 93/100 [04:13<00:14,  2.05s/it]Running generate_until requests:  94%|█████████▍| 94/100 [04:15<00:13,  2.18s/it]Running generate_until requests:  95%|█████████▌| 95/100 [04:19<00:12,  2.55s/it]Running generate_until requests:  96%|█████████▌| 96/100 [04:22<00:10,  2.67s/it]Running generate_until requests:  97%|█████████▋| 97/100 [04:24<00:07,  2.59s/it]Running generate_until requests:  98%|█████████▊| 98/100 [04:27<00:05,  2.63s/it]Running generate_until requests:  99%|█████████▉| 99/100 [04:30<00:02,  2.84s/it]Running generate_until requests: 100%|██████████| 100/100 [04:34<00:00,  3.28s/it]Running generate_until requests: 100%|██████████| 100/100 [04:34<00:00,  2.75s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-03-20:06:35:21,282 INFO     [evaluation_tracker.py:206] Saving results aggregated
2025-03-20:06:35:21,299 INFO     [evaluation_tracker.py:287] Saving per-sample results for: gsm8k
2025-03-20:06:36:01,435 INFO     [__main__.py:279] Verbosity set to INFO
2025-03-20:06:36:13,066 WARNING  [__main__.py:312]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-03-20:06:36:13,068 INFO     [__main__.py:376] Selected Tasks: ['gsm8k']
2025-03-20:06:36:13,077 INFO     [evaluator.py:164] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
2025-03-20:06:36:13,077 WARNING  [evaluator.py:175] generation_kwargs specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-03-20:06:36:13,077 INFO     [evaluator.py:201] Initializing hf model, with arguments: {'pretrained': 'meta-llama/Llama-3.1-8B-Instruct', 'dtype': 'bfloat16', 'device': 'cuda', 'parallelize': False}
2025-03-20:06:36:13,345 INFO     [huggingface.py:129] Using device 'cuda'
2025-03-20:06:36:13,517 INFO     [huggingface.py:481] Using model type 'default'
2025-03-20:06:36:13,989 INFO     [huggingface.py:365] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda'}
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:03,  1.19s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:02<00:02,  1.01s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:02<00:00,  1.06it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.44it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.23it/s]
2025-03-20:06:36:22,588 WARNING  [model.py:422] model.chat_template was called with the chat_template set to False or None. Therefore no chat template will be applied. Make sure this is an intended behavior.
2025-03-20:06:36:22,592 INFO     [task.py:415] Building contexts for gsm8k on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s] 35%|███▌      | 35/100 [00:00<00:00, 342.74it/s] 71%|███████   | 71/100 [00:00<00:00, 347.12it/s]100%|██████████| 100/100 [00:00<00:00, 347.71it/s]
2025-03-20:06:36:22,883 INFO     [evaluator.py:489] Running generate_until requests
Running generate_until requests:   0%|          | 0/100 [00:00<?, ?it/s]/home/alireza/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/home/alireza/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Running generate_until requests:   1%|          | 1/100 [00:02<04:31,  2.74s/it]Running generate_until requests:   2%|▏         | 2/100 [00:07<06:28,  3.97s/it]Running generate_until requests:   3%|▎         | 3/100 [00:09<05:13,  3.23s/it]Running generate_until requests:   4%|▍         | 4/100 [00:13<05:33,  3.47s/it]Running generate_until requests:   5%|▌         | 5/100 [00:16<05:01,  3.17s/it]Running generate_until requests:   6%|▌         | 6/100 [00:22<06:42,  4.28s/it]Running generate_until requests:   7%|▋         | 7/100 [00:25<05:42,  3.69s/it]Running generate_until requests:   8%|▊         | 8/100 [00:28<05:27,  3.56s/it]Running generate_until requests:   9%|▉         | 9/100 [00:30<04:33,  3.01s/it]Running generate_until requests:  10%|█         | 10/100 [00:34<05:00,  3.33s/it]Running generate_until requests:  11%|█         | 11/100 [00:35<04:06,  2.77s/it]Running generate_until requests:  12%|█▏        | 12/100 [00:37<03:39,  2.50s/it]Running generate_until requests:  13%|█▎        | 13/100 [00:39<03:28,  2.39s/it]Running generate_until requests:  14%|█▍        | 14/100 [00:41<03:12,  2.24s/it]Running generate_until requests:  15%|█▌        | 15/100 [00:46<04:18,  3.04s/it]Running generate_until requests:  16%|█▌        | 16/100 [00:48<03:55,  2.80s/it]Running generate_until requests:  17%|█▋        | 17/100 [00:51<03:50,  2.78s/it]Running generate_until requests:  18%|█▊        | 18/100 [00:55<04:19,  3.17s/it]Running generate_until requests:  19%|█▉        | 19/100 [00:58<03:58,  2.94s/it]Running generate_until requests:  20%|██        | 20/100 [01:01<04:04,  3.05s/it]Running generate_until requests:  21%|██        | 21/100 [01:04<04:10,  3.17s/it]Running generate_until requests:  22%|██▏       | 22/100 [01:08<04:25,  3.40s/it]Running generate_until requests:  23%|██▎       | 23/100 [01:10<03:51,  3.01s/it]Running generate_until requests:  24%|██▍       | 24/100 [01:12<03:17,  2.60s/it]Running generate_until requests:  25%|██▌       | 25/100 [01:15<03:25,  2.74s/it]Running generate_until requests:  26%|██▌       | 26/100 [01:17<03:03,  2.48s/it]Running generate_until requests:  27%|██▋       | 27/100 [01:20<03:13,  2.64s/it]Running generate_until requests:  28%|██▊       | 28/100 [01:22<02:50,  2.37s/it]Running generate_until requests:  29%|██▉       | 29/100 [01:23<02:28,  2.09s/it]Running generate_until requests:  30%|███       | 30/100 [01:27<03:09,  2.71s/it]Running generate_until requests:  31%|███       | 31/100 [01:32<03:38,  3.16s/it]Running generate_until requests:  32%|███▏      | 32/100 [01:35<03:32,  3.12s/it]Running generate_until requests:  33%|███▎      | 33/100 [01:37<03:07,  2.80s/it]Running generate_until requests:  34%|███▍      | 34/100 [01:39<02:57,  2.70s/it]Running generate_until requests:  35%|███▌      | 35/100 [01:41<02:38,  2.43s/it]Running generate_until requests:  36%|███▌      | 36/100 [01:44<02:43,  2.55s/it]Running generate_until requests:  37%|███▋      | 37/100 [01:48<03:17,  3.13s/it]Running generate_until requests:  38%|███▊      | 38/100 [01:50<02:54,  2.81s/it]Running generate_until requests:  39%|███▉      | 39/100 [01:54<03:00,  2.96s/it]Running generate_until requests:  40%|████      | 40/100 [02:01<04:07,  4.13s/it]Running generate_until requests:  41%|████      | 41/100 [02:02<03:22,  3.44s/it]Running generate_until requests:  42%|████▏     | 42/100 [02:04<02:49,  2.92s/it]Running generate_until requests:  43%|████▎     | 43/100 [02:06<02:27,  2.59s/it]Running generate_until requests:  44%|████▍     | 44/100 [02:13<03:37,  3.89s/it]Running generate_until requests:  45%|████▌     | 45/100 [02:16<03:14,  3.54s/it]Running generate_until requests:  46%|████▌     | 46/100 [02:18<02:49,  3.14s/it]Running generate_until requests:  47%|████▋     | 47/100 [02:19<02:18,  2.61s/it]Running generate_until requests:  48%|████▊     | 48/100 [02:21<02:08,  2.47s/it]Running generate_until requests:  49%|████▉     | 49/100 [02:25<02:23,  2.82s/it]Running generate_until requests:  50%|█████     | 50/100 [02:26<02:01,  2.42s/it]Running generate_until requests:  51%|█████     | 51/100 [02:28<01:50,  2.26s/it]Running generate_until requests:  52%|█████▏    | 52/100 [02:31<01:58,  2.47s/it]Running generate_until requests:  53%|█████▎    | 53/100 [02:35<02:13,  2.84s/it]Running generate_until requests:  54%|█████▍    | 54/100 [02:40<02:34,  3.37s/it]Running generate_until requests:  55%|█████▌    | 55/100 [02:41<02:10,  2.91s/it]Running generate_until requests:  56%|█████▌    | 56/100 [02:43<01:53,  2.58s/it]Running generate_until requests:  57%|█████▋    | 57/100 [02:46<01:51,  2.60s/it]Running generate_until requests:  58%|█████▊    | 58/100 [02:49<02:02,  2.91s/it]Running generate_until requests:  59%|█████▉    | 59/100 [02:52<01:53,  2.78s/it]Running generate_until requests:  60%|██████    | 60/100 [02:53<01:32,  2.32s/it]Running generate_until requests:  61%|██████    | 61/100 [02:55<01:23,  2.14s/it]Running generate_until requests:  62%|██████▏   | 62/100 [02:57<01:23,  2.19s/it]Running generate_until requests:  63%|██████▎   | 63/100 [02:59<01:16,  2.05s/it]Running generate_until requests:  64%|██████▍   | 64/100 [03:02<01:26,  2.40s/it]Running generate_until requests:  65%|██████▌   | 65/100 [03:04<01:21,  2.34s/it]Running generate_until requests:  66%|██████▌   | 66/100 [03:07<01:18,  2.30s/it]Running generate_until requests:  67%|██████▋   | 67/100 [03:09<01:19,  2.40s/it]Running generate_until requests:  68%|██████▊   | 68/100 [03:10<01:04,  2.01s/it]Running generate_until requests:  69%|██████▉   | 69/100 [03:14<01:17,  2.51s/it]Running generate_until requests:  70%|███████   | 70/100 [03:16<01:15,  2.51s/it]Running generate_until requests:  71%|███████   | 71/100 [03:21<01:26,  2.97s/it]Running generate_until requests:  72%|███████▏  | 72/100 [03:23<01:15,  2.71s/it]Running generate_until requests:  73%|███████▎  | 73/100 [03:25<01:11,  2.64s/it]Running generate_until requests:  74%|███████▍  | 74/100 [03:28<01:11,  2.74s/it]Running generate_until requests:  75%|███████▌  | 75/100 [03:30<01:03,  2.53s/it]Running generate_until requests:  76%|███████▌  | 76/100 [03:33<01:04,  2.68s/it]Running generate_until requests:  77%|███████▋  | 77/100 [03:36<01:01,  2.68s/it]Running generate_until requests:  78%|███████▊  | 78/100 [03:37<00:51,  2.34s/it]Running generate_until requests:  79%|███████▉  | 79/100 [03:39<00:46,  2.21s/it]Running generate_until requests:  80%|████████  | 80/100 [03:41<00:40,  2.01s/it]Running generate_until requests:  81%|████████  | 81/100 [03:43<00:41,  2.17s/it]Running generate_until requests:  82%|████████▏ | 82/100 [03:48<00:50,  2.78s/it]Running generate_until requests:  83%|████████▎ | 83/100 [03:50<00:43,  2.56s/it]Running generate_until requests:  84%|████████▍ | 84/100 [03:51<00:36,  2.29s/it]Running generate_until requests:  85%|████████▌ | 85/100 [03:54<00:35,  2.39s/it]Running generate_until requests:  86%|████████▌ | 86/100 [03:56<00:33,  2.36s/it]Running generate_until requests:  87%|████████▋ | 87/100 [03:59<00:30,  2.36s/it]Running generate_until requests:  88%|████████▊ | 88/100 [04:00<00:25,  2.15s/it]Running generate_until requests:  89%|████████▉ | 89/100 [04:02<00:24,  2.19s/it]Running generate_until requests:  90%|█████████ | 90/100 [04:05<00:21,  2.17s/it]Running generate_until requests:  91%|█████████ | 91/100 [04:06<00:17,  1.98s/it]Running generate_until requests:  92%|█████████▏| 92/100 [04:09<00:17,  2.18s/it]Running generate_until requests:  93%|█████████▎| 93/100 [04:11<00:14,  2.03s/it]Running generate_until requests:  94%|█████████▍| 94/100 [04:13<00:12,  2.16s/it]Running generate_until requests:  95%|█████████▌| 95/100 [04:16<00:12,  2.53s/it]Running generate_until requests:  96%|█████████▌| 96/100 [04:19<00:10,  2.64s/it]Running generate_until requests:  97%|█████████▋| 97/100 [04:22<00:07,  2.57s/it]Running generate_until requests:  98%|█████████▊| 98/100 [04:24<00:05,  2.61s/it]Running generate_until requests:  99%|█████████▉| 99/100 [04:28<00:02,  2.81s/it]Running generate_until requests: 100%|██████████| 100/100 [04:32<00:00,  3.25s/it]Running generate_until requests: 100%|██████████| 100/100 [04:32<00:00,  2.72s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-03-20:06:41:00,562 INFO     [evaluation_tracker.py:206] Saving results aggregated
2025-03-20:06:41:00,584 INFO     [evaluation_tracker.py:287] Saving per-sample results for: gsm8k
2025-03-20:06:41:40,657 INFO     [__main__.py:279] Verbosity set to INFO
2025-03-20:06:41:52,212 WARNING  [__main__.py:312]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-03-20:06:41:52,213 INFO     [__main__.py:376] Selected Tasks: ['gsm8k']
2025-03-20:06:41:52,223 INFO     [evaluator.py:164] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
2025-03-20:06:41:52,223 WARNING  [evaluator.py:175] generation_kwargs specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-03-20:06:41:52,223 INFO     [evaluator.py:201] Initializing hf model, with arguments: {'pretrained': 'meta-llama/Llama-3.1-8B-Instruct', 'dtype': 'bfloat16', 'device': 'cuda', 'parallelize': False}
2025-03-20:06:41:52,489 INFO     [huggingface.py:129] Using device 'cuda'
2025-03-20:06:41:52,661 INFO     [huggingface.py:481] Using model type 'default'
2025-03-20:06:41:53,145 INFO     [huggingface.py:365] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda'}
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:03,  1.17s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:02<00:02,  1.02s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:02<00:00,  1.05it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.43it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.22it/s]
2025-03-20:06:42:08,697 WARNING  [model.py:422] model.chat_template was called with the chat_template set to False or None. Therefore no chat template will be applied. Make sure this is an intended behavior.
2025-03-20:06:42:08,700 INFO     [task.py:415] Building contexts for gsm8k on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s] 35%|███▌      | 35/100 [00:00<00:00, 345.78it/s] 71%|███████   | 71/100 [00:00<00:00, 348.38it/s]100%|██████████| 100/100 [00:00<00:00, 345.14it/s]
2025-03-20:06:42:08,993 INFO     [evaluator.py:489] Running generate_until requests
Running generate_until requests:   0%|          | 0/100 [00:00<?, ?it/s]/home/alireza/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/home/alireza/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Running generate_until requests:   1%|          | 1/100 [00:02<04:31,  2.74s/it]Running generate_until requests:   2%|▏         | 2/100 [00:07<06:28,  3.97s/it]Running generate_until requests:   3%|▎         | 3/100 [00:09<05:13,  3.24s/it]Running generate_until requests:   4%|▍         | 4/100 [00:13<05:33,  3.48s/it]Running generate_until requests:   5%|▌         | 5/100 [00:16<05:01,  3.17s/it]Running generate_until requests:   6%|▌         | 6/100 [00:22<06:43,  4.29s/it]Running generate_until requests:   7%|▋         | 7/100 [00:25<05:43,  3.69s/it]Running generate_until requests:   8%|▊         | 8/100 [00:28<05:28,  3.57s/it]Running generate_until requests:   9%|▉         | 9/100 [00:30<04:34,  3.01s/it]Running generate_until requests:  10%|█         | 10/100 [00:34<05:00,  3.34s/it]Running generate_until requests:  11%|█         | 11/100 [00:36<04:07,  2.78s/it]Running generate_until requests:  12%|█▏        | 12/100 [00:37<03:40,  2.50s/it]Running generate_until requests:  13%|█▎        | 13/100 [00:40<03:28,  2.40s/it]Running generate_until requests:  14%|█▍        | 14/100 [00:41<03:13,  2.24s/it]Running generate_until requests:  15%|█▌        | 15/100 [00:46<04:19,  3.05s/it]Running generate_until requests:  16%|█▌        | 16/100 [00:49<03:55,  2.80s/it]Running generate_until requests:  17%|█▋        | 17/100 [00:51<03:50,  2.78s/it]Running generate_until requests:  18%|█▊        | 18/100 [00:55<04:19,  3.17s/it]Running generate_until requests:  19%|█▉        | 19/100 [00:58<03:58,  2.94s/it]Running generate_until requests:  20%|██        | 20/100 [01:01<04:04,  3.06s/it]Running generate_until requests:  21%|██        | 21/100 [01:05<04:10,  3.18s/it]Running generate_until requests:  22%|██▏       | 22/100 [01:08<04:25,  3.40s/it]Running generate_until requests:  23%|██▎       | 23/100 [01:11<03:52,  3.01s/it]Running generate_until requests:  24%|██▍       | 24/100 [01:12<03:17,  2.60s/it]Running generate_until requests:  25%|██▌       | 25/100 [01:15<03:25,  2.75s/it]Running generate_until requests:  26%|██▌       | 26/100 [01:17<03:03,  2.49s/it]Running generate_until requests:  27%|██▋       | 27/100 [01:20<03:13,  2.65s/it]Running generate_until requests:  28%|██▊       | 28/100 [01:22<02:51,  2.38s/it]Running generate_until requests:  29%|██▉       | 29/100 [01:23<02:28,  2.09s/it]Running generate_until requests:  30%|███       | 30/100 [01:28<03:09,  2.71s/it]Running generate_until requests:  31%|███       | 31/100 [01:32<03:38,  3.17s/it]Running generate_until requests:  32%|███▏      | 32/100 [01:35<03:32,  3.12s/it]Running generate_until requests:  33%|███▎      | 33/100 [01:37<03:07,  2.80s/it]Running generate_until requests:  34%|███▍      | 34/100 [01:39<02:58,  2.70s/it]Running generate_until requests:  35%|███▌      | 35/100 [01:41<02:38,  2.44s/it]Running generate_until requests:  36%|███▌      | 36/100 [01:44<02:43,  2.55s/it]Running generate_until requests:  37%|███▋      | 37/100 [01:48<03:17,  3.13s/it]Running generate_until requests:  38%|███▊      | 38/100 [01:51<02:54,  2.81s/it]Running generate_until requests:  39%|███▉      | 39/100 [01:54<03:00,  2.96s/it]Running generate_until requests:  40%|████      | 40/100 [02:01<04:07,  4.13s/it]Running generate_until requests:  41%|████      | 41/100 [02:03<03:22,  3.44s/it]Running generate_until requests:  42%|████▏     | 42/100 [02:04<02:49,  2.92s/it]Running generate_until requests:  43%|████▎     | 43/100 [02:06<02:27,  2.59s/it]Running generate_until requests:  44%|████▍     | 44/100 [02:13<03:38,  3.90s/it]Running generate_until requests:  45%|████▌     | 45/100 [02:16<03:15,  3.55s/it]Running generate_until requests:  46%|████▌     | 46/100 [02:18<02:50,  3.15s/it]Running generate_until requests:  47%|████▋     | 47/100 [02:19<02:18,  2.62s/it]Running generate_until requests:  48%|████▊     | 48/100 [02:21<02:08,  2.47s/it]Running generate_until requests:  49%|████▉     | 49/100 [02:25<02:24,  2.83s/it]Running generate_until requests:  50%|█████     | 50/100 [02:27<02:01,  2.42s/it]Running generate_until requests:  51%|█████     | 51/100 [02:28<01:50,  2.26s/it]Running generate_until requests:  52%|█████▏    | 52/100 [02:31<01:58,  2.48s/it]Running generate_until requests:  53%|█████▎    | 53/100 [02:35<02:13,  2.84s/it]Running generate_until requests:  54%|█████▍    | 54/100 [02:40<02:35,  3.37s/it]Running generate_until requests:  55%|█████▌    | 55/100 [02:42<02:10,  2.91s/it]Running generate_until requests:  56%|█████▌    | 56/100 [02:43<01:53,  2.59s/it]Running generate_until requests:  57%|█████▋    | 57/100 [02:46<01:52,  2.61s/it]Running generate_until requests:  58%|█████▊    | 58/100 [02:50<02:02,  2.92s/it]Running generate_until requests:  59%|█████▉    | 59/100 [02:52<01:54,  2.78s/it]Running generate_until requests:  60%|██████    | 60/100 [02:53<01:32,  2.32s/it]Running generate_until requests:  61%|██████    | 61/100 [02:55<01:23,  2.14s/it]Running generate_until requests:  62%|██████▏   | 62/100 [02:57<01:23,  2.19s/it]Running generate_until requests:  63%|██████▎   | 63/100 [02:59<01:16,  2.06s/it]Running generate_until requests:  64%|██████▍   | 64/100 [03:02<01:26,  2.40s/it]Running generate_until requests:  65%|██████▌   | 65/100 [03:05<01:22,  2.35s/it]Running generate_until requests:  66%|██████▌   | 66/100 [03:07<01:18,  2.30s/it]Running generate_until requests:  67%|██████▋   | 67/100 [03:09<01:19,  2.40s/it]Running generate_until requests:  68%|██████▊   | 68/100 [03:11<01:04,  2.01s/it]Running generate_until requests:  69%|██████▉   | 69/100 [03:14<01:18,  2.52s/it]Running generate_until requests:  70%|███████   | 70/100 [03:17<01:15,  2.52s/it]Running generate_until requests:  71%|███████   | 71/100 [03:21<01:26,  2.97s/it]Running generate_until requests:  72%|███████▏  | 72/100 [03:23<01:16,  2.72s/it]Running generate_until requests:  73%|███████▎  | 73/100 [03:25<01:11,  2.65s/it]Running generate_until requests:  74%|███████▍  | 74/100 [03:28<01:11,  2.74s/it]Running generate_until requests:  75%|███████▌  | 75/100 [03:30<01:03,  2.53s/it]Running generate_until requests:  76%|███████▌  | 76/100 [03:33<01:04,  2.69s/it]Running generate_until requests:  77%|███████▋  | 77/100 [03:36<01:01,  2.68s/it]Running generate_until requests:  78%|███████▊  | 78/100 [03:38<00:51,  2.34s/it]Running generate_until requests:  79%|███████▉  | 79/100 [03:40<00:46,  2.21s/it]Running generate_until requests:  80%|████████  | 80/100 [03:41<00:40,  2.01s/it]Running generate_until requests:  81%|████████  | 81/100 [03:44<00:41,  2.17s/it]Running generate_until requests:  82%|████████▏ | 82/100 [03:48<00:50,  2.79s/it]Running generate_until requests:  83%|████████▎ | 83/100 [03:50<00:43,  2.56s/it]Running generate_until requests:  84%|████████▍ | 84/100 [03:52<00:36,  2.29s/it]Running generate_until requests:  85%|████████▌ | 85/100 [03:54<00:35,  2.40s/it]Running generate_until requests:  86%|████████▌ | 86/100 [03:57<00:33,  2.38s/it]Running generate_until requests:  87%|████████▋ | 87/100 [03:59<00:30,  2.38s/it]Running generate_until requests:  88%|████████▊ | 88/100 [04:01<00:25,  2.16s/it]Running generate_until requests:  89%|████████▉ | 89/100 [04:03<00:24,  2.20s/it]Running generate_until requests:  90%|█████████ | 90/100 [04:05<00:21,  2.18s/it]Running generate_until requests:  91%|█████████ | 91/100 [04:07<00:17,  1.99s/it]Running generate_until requests:  92%|█████████▏| 92/100 [04:09<00:17,  2.19s/it]Running generate_until requests:  93%|█████████▎| 93/100 [04:11<00:14,  2.04s/it]Running generate_until requests:  94%|█████████▍| 94/100 [04:13<00:12,  2.16s/it]Running generate_until requests:  95%|█████████▌| 95/100 [04:17<00:12,  2.53s/it]Running generate_until requests:  96%|█████████▌| 96/100 [04:20<00:10,  2.65s/it]Running generate_until requests:  97%|█████████▋| 97/100 [04:22<00:07,  2.57s/it]Running generate_until requests:  98%|█████████▊| 98/100 [04:25<00:05,  2.61s/it]Running generate_until requests:  99%|█████████▉| 99/100 [04:28<00:02,  2.81s/it]Running generate_until requests: 100%|██████████| 100/100 [04:32<00:00,  3.25s/it]Running generate_until requests: 100%|██████████| 100/100 [04:32<00:00,  2.73s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-03-20:06:46:47,032 INFO     [evaluation_tracker.py:206] Saving results aggregated
2025-03-20:06:46:47,057 INFO     [evaluation_tracker.py:287] Saving per-sample results for: gsm8k
2025-03-20:06:47:26,531 INFO     [__main__.py:279] Verbosity set to INFO
2025-03-20:06:47:37,770 WARNING  [__main__.py:312]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-03-20:06:47:37,771 INFO     [__main__.py:376] Selected Tasks: ['gsm8k']
2025-03-20:06:47:37,778 INFO     [evaluator.py:164] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
2025-03-20:06:47:37,778 WARNING  [evaluator.py:175] generation_kwargs specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-03-20:06:47:37,778 INFO     [evaluator.py:201] Initializing hf model, with arguments: {'pretrained': 'meta-llama/Llama-3.1-8B-Instruct', 'dtype': 'bfloat16', 'device': 'cuda', 'parallelize': False}
2025-03-20:06:47:38,045 INFO     [huggingface.py:129] Using device 'cuda'
2025-03-20:06:47:38,243 INFO     [huggingface.py:481] Using model type 'default'
2025-03-20:06:47:38,715 INFO     [huggingface.py:365] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda'}
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:03,  1.17s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:02<00:02,  1.04s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:02<00:00,  1.05it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.41it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.21it/s]
2025-03-20:06:47:48,085 WARNING  [model.py:422] model.chat_template was called with the chat_template set to False or None. Therefore no chat template will be applied. Make sure this is an intended behavior.
2025-03-20:06:47:48,087 INFO     [task.py:415] Building contexts for gsm8k on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s] 36%|███▌      | 36/100 [00:00<00:00, 350.30it/s] 72%|███████▏  | 72/100 [00:00<00:00, 345.45it/s]100%|██████████| 100/100 [00:00<00:00, 347.88it/s]
2025-03-20:06:47:48,378 INFO     [evaluator.py:489] Running generate_until requests
Running generate_until requests:   0%|          | 0/100 [00:00<?, ?it/s]/home/alireza/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/home/alireza/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Running generate_until requests:   1%|          | 1/100 [00:02<04:32,  2.75s/it]Running generate_until requests:   2%|▏         | 2/100 [00:07<06:28,  3.97s/it]Running generate_until requests:   3%|▎         | 3/100 [00:09<05:13,  3.23s/it]Running generate_until requests:   4%|▍         | 4/100 [00:13<05:33,  3.47s/it]Running generate_until requests:   5%|▌         | 5/100 [00:16<05:00,  3.17s/it]Running generate_until requests:   6%|▌         | 6/100 [00:22<06:42,  4.28s/it]Running generate_until requests:   7%|▋         | 7/100 [00:25<05:42,  3.68s/it]Running generate_until requests:   8%|▊         | 8/100 [00:28<05:27,  3.56s/it]Running generate_until requests:   9%|▉         | 9/100 [00:30<04:33,  3.00s/it]Running generate_until requests:  10%|█         | 10/100 [00:34<04:59,  3.33s/it]Running generate_until requests:  11%|█         | 11/100 [00:35<04:06,  2.77s/it]Running generate_until requests:  12%|█▏        | 12/100 [00:37<03:39,  2.50s/it]Running generate_until requests:  13%|█▎        | 13/100 [00:39<03:27,  2.39s/it]Running generate_until requests:  14%|█▍        | 14/100 [00:41<03:12,  2.24s/it]Running generate_until requests:  15%|█▌        | 15/100 [00:46<04:18,  3.04s/it]Running generate_until requests:  16%|█▌        | 16/100 [00:48<03:54,  2.80s/it]Running generate_until requests:  17%|█▋        | 17/100 [00:51<03:50,  2.77s/it]Running generate_until requests:  18%|█▊        | 18/100 [00:55<04:19,  3.16s/it]Running generate_until requests:  19%|█▉        | 19/100 [00:58<03:57,  2.94s/it]Running generate_until requests:  20%|██        | 20/100 [01:01<04:03,  3.05s/it]Running generate_until requests:  21%|██        | 21/100 [01:04<04:10,  3.17s/it]Running generate_until requests:  22%|██▏       | 22/100 [01:08<04:24,  3.39s/it]Running generate_until requests:  23%|██▎       | 23/100 [01:10<03:51,  3.01s/it]Running generate_until requests:  24%|██▍       | 24/100 [01:12<03:17,  2.59s/it]Running generate_until requests:  25%|██▌       | 25/100 [01:15<03:25,  2.74s/it]Running generate_until requests:  26%|██▌       | 26/100 [01:17<03:03,  2.48s/it]Running generate_until requests:  27%|██▋       | 27/100 [01:20<03:12,  2.64s/it]Running generate_until requests:  28%|██▊       | 28/100 [01:22<02:50,  2.37s/it]Running generate_until requests:  29%|██▉       | 29/100 [01:23<02:28,  2.09s/it]Running generate_until requests:  30%|███       | 30/100 [01:27<03:09,  2.71s/it]Running generate_until requests:  31%|███       | 31/100 [01:32<03:38,  3.16s/it]Running generate_until requests:  32%|███▏      | 32/100 [01:35<03:31,  3.12s/it]Running generate_until requests:  33%|███▎      | 33/100 [01:37<03:07,  2.79s/it]Running generate_until requests:  34%|███▍      | 34/100 [01:39<02:57,  2.69s/it]Running generate_until requests:  35%|███▌      | 35/100 [01:41<02:38,  2.43s/it]Running generate_until requests:  36%|███▌      | 36/100 [01:44<02:43,  2.55s/it]Running generate_until requests:  37%|███▋      | 37/100 [01:48<03:16,  3.13s/it]Running generate_until requests:  38%|███▊      | 38/100 [01:50<02:54,  2.81s/it]Running generate_until requests:  39%|███▉      | 39/100 [01:54<03:00,  2.95s/it]Running generate_until requests:  40%|████      | 40/100 [02:00<04:07,  4.12s/it]Running generate_until requests:  41%|████      | 41/100 [02:02<03:22,  3.43s/it]Running generate_until requests:  42%|████▏     | 42/100 [02:04<02:49,  2.91s/it]Running generate_until requests:  43%|████▎     | 43/100 [02:06<02:27,  2.59s/it]Running generate_until requests:  44%|████▍     | 44/100 [02:13<03:37,  3.89s/it]Running generate_until requests:  45%|████▌     | 45/100 [02:15<03:14,  3.54s/it]Running generate_until requests:  46%|████▌     | 46/100 [02:18<02:49,  3.14s/it]Running generate_until requests:  47%|████▋     | 47/100 [02:19<02:18,  2.61s/it]Running generate_until requests:  48%|████▊     | 48/100 [02:21<02:08,  2.46s/it]Running generate_until requests:  49%|████▉     | 49/100 [02:25<02:23,  2.82s/it]Running generate_until requests:  50%|█████     | 50/100 [02:26<02:00,  2.42s/it]Running generate_until requests:  51%|█████     | 51/100 [02:28<01:50,  2.26s/it]Running generate_until requests:  52%|█████▏    | 52/100 [02:31<01:58,  2.47s/it]Running generate_until requests:  53%|█████▎    | 53/100 [02:35<02:13,  2.84s/it]Running generate_until requests:  54%|█████▍    | 54/100 [02:39<02:34,  3.37s/it]Running generate_until requests:  55%|█████▌    | 55/100 [02:41<02:10,  2.91s/it]Running generate_until requests:  56%|█████▌    | 56/100 [02:43<01:53,  2.58s/it]Running generate_until requests:  57%|█████▋    | 57/100 [02:46<01:51,  2.60s/it]Running generate_until requests:  58%|█████▊    | 58/100 [02:49<02:02,  2.91s/it]Running generate_until requests:  59%|█████▉    | 59/100 [02:52<01:53,  2.77s/it]Running generate_until requests:  60%|██████    | 60/100 [02:53<01:32,  2.31s/it]Running generate_until requests:  61%|██████    | 61/100 [02:55<01:23,  2.13s/it]Running generate_until requests:  62%|██████▏   | 62/100 [02:57<01:23,  2.19s/it]Running generate_until requests:  63%|██████▎   | 63/100 [02:59<01:15,  2.05s/it]Running generate_until requests:  64%|██████▍   | 64/100 [03:02<01:26,  2.40s/it]Running generate_until requests:  65%|██████▌   | 65/100 [03:04<01:21,  2.34s/it]Running generate_until requests:  66%|██████▌   | 66/100 [03:06<01:18,  2.30s/it]Running generate_until requests:  67%|██████▋   | 67/100 [03:09<01:19,  2.40s/it]Running generate_until requests:  68%|██████▊   | 68/100 [03:10<01:04,  2.01s/it]Running generate_until requests:  69%|██████▉   | 69/100 [03:14<01:17,  2.51s/it]Running generate_until requests:  70%|███████   | 70/100 [03:16<01:15,  2.51s/it]Running generate_until requests:  71%|███████   | 71/100 [03:20<01:25,  2.96s/it]Running generate_until requests:  72%|███████▏  | 72/100 [03:22<01:15,  2.71s/it]Running generate_until requests:  73%|███████▎  | 73/100 [03:25<01:11,  2.64s/it]Running generate_until requests:  74%|███████▍  | 74/100 [03:28<01:11,  2.74s/it]Running generate_until requests:  75%|███████▌  | 75/100 [03:30<01:03,  2.53s/it]Running generate_until requests:  76%|███████▌  | 76/100 [03:33<01:04,  2.68s/it]Running generate_until requests:  77%|███████▋  | 77/100 [03:36<01:01,  2.68s/it]Running generate_until requests:  78%|███████▊  | 78/100 [03:37<00:51,  2.33s/it]Running generate_until requests:  79%|███████▉  | 79/100 [03:39<00:46,  2.21s/it]Running generate_until requests:  80%|████████  | 80/100 [03:41<00:40,  2.01s/it]Running generate_until requests:  81%|████████  | 81/100 [03:43<00:41,  2.17s/it]Running generate_until requests:  82%|████████▏ | 82/100 [03:47<00:50,  2.78s/it]Running generate_until requests:  83%|████████▎ | 83/100 [03:49<00:43,  2.56s/it]Running generate_until requests:  84%|████████▍ | 84/100 [03:51<00:36,  2.28s/it]Running generate_until requests:  85%|████████▌ | 85/100 [03:54<00:35,  2.39s/it]Running generate_until requests:  86%|████████▌ | 86/100 [03:56<00:33,  2.36s/it]Running generate_until requests:  87%|████████▋ | 87/100 [03:58<00:30,  2.36s/it]Running generate_until requests:  88%|████████▊ | 88/100 [04:00<00:25,  2.15s/it]Running generate_until requests:  89%|████████▉ | 89/100 [04:02<00:24,  2.18s/it]Running generate_until requests:  90%|█████████ | 90/100 [04:04<00:21,  2.17s/it]Running generate_until requests:  91%|█████████ | 91/100 [04:06<00:17,  1.98s/it]Running generate_until requests:  92%|█████████▏| 92/100 [04:09<00:17,  2.18s/it]Running generate_until requests:  93%|█████████▎| 93/100 [04:10<00:14,  2.03s/it]Running generate_until requests:  94%|█████████▍| 94/100 [04:13<00:12,  2.16s/it]Running generate_until requests:  95%|█████████▌| 95/100 [04:16<00:12,  2.52s/it]Running generate_until requests:  96%|█████████▌| 96/100 [04:19<00:10,  2.64s/it]Running generate_until requests:  97%|█████████▋| 97/100 [04:21<00:07,  2.57s/it]Running generate_until requests:  98%|█████████▊| 98/100 [04:24<00:05,  2.60s/it]Running generate_until requests:  99%|█████████▉| 99/100 [04:27<00:02,  2.81s/it]Running generate_until requests: 100%|██████████| 100/100 [04:32<00:00,  3.25s/it]Running generate_until requests: 100%|██████████| 100/100 [04:32<00:00,  2.72s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-03-20:06:52:25,830 INFO     [evaluation_tracker.py:206] Saving results aggregated
2025-03-20:06:52:25,860 INFO     [evaluation_tracker.py:287] Saving per-sample results for: gsm8k
2025-03-20:06:53:05,804 INFO     [__main__.py:279] Verbosity set to INFO
2025-03-20:06:53:17,344 WARNING  [__main__.py:312]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-03-20:06:53:17,345 INFO     [__main__.py:376] Selected Tasks: ['gsm8k']
2025-03-20:06:53:17,355 INFO     [evaluator.py:164] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
2025-03-20:06:53:17,356 WARNING  [evaluator.py:175] generation_kwargs specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-03-20:06:53:17,356 INFO     [evaluator.py:201] Initializing hf model, with arguments: {'pretrained': 'meta-llama/Llama-3.1-8B-Instruct', 'dtype': 'bfloat16', 'device': 'cuda', 'parallelize': False}
2025-03-20:06:53:17,645 INFO     [huggingface.py:129] Using device 'cuda'
2025-03-20:06:53:18,031 INFO     [huggingface.py:481] Using model type 'default'
2025-03-20:06:53:18,504 INFO     [huggingface.py:365] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda'}
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:03,  1.15s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:02<00:02,  1.03s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:02<00:00,  1.05it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.44it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.23it/s]
2025-03-20:06:53:27,481 WARNING  [model.py:422] model.chat_template was called with the chat_template set to False or None. Therefore no chat template will be applied. Make sure this is an intended behavior.
2025-03-20:06:53:27,484 INFO     [task.py:415] Building contexts for gsm8k on rank 0...
  0%|          | 0/100 [00:00<?, ?it/s] 35%|███▌      | 35/100 [00:00<00:00, 348.39it/s] 70%|███████   | 70/100 [00:00<00:00, 347.72it/s]100%|██████████| 100/100 [00:00<00:00, 350.28it/s]
2025-03-20:06:53:27,773 INFO     [evaluator.py:489] Running generate_until requests
Running generate_until requests:   0%|          | 0/100 [00:00<?, ?it/s]/home/alireza/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/home/alireza/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Running generate_until requests:   1%|          | 1/100 [00:02<04:36,  2.79s/it]Running generate_until requests:   2%|▏         | 2/100 [00:07<06:33,  4.01s/it]Running generate_until requests:   3%|▎         | 3/100 [00:10<05:16,  3.26s/it]Running generate_until requests:   4%|▍         | 4/100 [00:13<05:36,  3.51s/it]Running generate_until requests:   5%|▌         | 5/100 [00:16<05:04,  3.20s/it]Running generate_until requests:   6%|▌         | 6/100 [00:23<06:46,  4.32s/it]Running generate_until requests:   7%|▋         | 7/100 [00:25<05:45,  3.72s/it]Running generate_until requests:   8%|▊         | 8/100 [00:28<05:30,  3.60s/it]Running generate_until requests:   9%|▉         | 9/100 [00:30<04:36,  3.04s/it]Running generate_until requests:  10%|█         | 10/100 [00:34<05:03,  3.37s/it]Running generate_until requests:  11%|█         | 11/100 [00:36<04:09,  2.80s/it]Running generate_until requests:  12%|█▏        | 12/100 [00:38<03:42,  2.52s/it]Running generate_until requests:  13%|█▎        | 13/100 [00:40<03:30,  2.42s/it]Running generate_until requests:  14%|█▍        | 14/100 [00:42<03:14,  2.26s/it]Running generate_until requests:  15%|█▌        | 15/100 [00:47<04:21,  3.07s/it]Running generate_until requests:  16%|█▌        | 16/100 [00:49<03:57,  2.82s/it]Running generate_until requests:  17%|█▋        | 17/100 [00:52<03:52,  2.80s/it]Running generate_until requests:  18%|█▊        | 18/100 [00:56<04:21,  3.19s/it]Running generate_until requests:  19%|█▉        | 19/100 [00:58<04:00,  2.97s/it]Running generate_until requests:  20%|██        | 20/100 [01:02<04:06,  3.08s/it]Running generate_until requests:  21%|██        | 21/100 [01:05<04:12,  3.20s/it]Running generate_until requests:  22%|██▏       | 22/100 [01:09<04:27,  3.43s/it]Running generate_until requests:  23%|██▎       | 23/100 [01:11<03:53,  3.04s/it]Running generate_until requests:  24%|██▍       | 24/100 [01:13<03:19,  2.62s/it]Running generate_until requests:  25%|██▌       | 25/100 [01:16<03:27,  2.77s/it]Running generate_until requests:  26%|██▌       | 26/100 [01:18<03:05,  2.50s/it]Running generate_until requests:  27%|██▋       | 27/100 [01:21<03:14,  2.67s/it]Running generate_until requests:  28%|██▊       | 28/100 [01:23<02:52,  2.39s/it]Running generate_until requests:  29%|██▉       | 29/100 [01:24<02:29,  2.11s/it]Running generate_until requests:  30%|███       | 30/100 [01:28<03:11,  2.74s/it]Running generate_until requests:  31%|███       | 31/100 [01:33<03:40,  3.19s/it]Running generate_until requests:  32%|███▏      | 32/100 [01:36<03:34,  3.15s/it]Running generate_until requests:  33%|███▎      | 33/100 [01:38<03:09,  2.82s/it]Running generate_until requests:  34%|███▍      | 34/100 [01:40<02:59,  2.72s/it]Running generate_until requests:  35%|███▌      | 35/100 [01:42<02:39,  2.46s/it]Running generate_until requests:  36%|███▌      | 36/100 [01:45<02:44,  2.58s/it]Running generate_until requests:  37%|███▋      | 37/100 [01:49<03:18,  3.16s/it]Running generate_until requests:  38%|███▊      | 38/100 [01:51<02:55,  2.84s/it]Running generate_until requests:  39%|███▉      | 39/100 [01:55<03:02,  2.99s/it]Running generate_until requests:  40%|████      | 40/100 [02:02<04:09,  4.17s/it]Running generate_until requests:  41%|████      | 41/100 [02:04<03:24,  3.47s/it]Running generate_until requests:  42%|████▏     | 42/100 [02:05<02:50,  2.94s/it]Running generate_until requests:  43%|████▎     | 43/100 [02:07<02:28,  2.61s/it]Running generate_until requests:  44%|████▍     | 44/100 [02:14<03:40,  3.93s/it]Running generate_until requests:  45%|████▌     | 45/100 [02:17<03:16,  3.58s/it]Running generate_until requests:  46%|████▌     | 46/100 [02:19<02:51,  3.17s/it]Running generate_until requests:  47%|████▋     | 47/100 [02:20<02:19,  2.64s/it]Running generate_until requests:  48%|████▊     | 48/100 [02:23<02:09,  2.49s/it]Running generate_until requests:  49%|████▉     | 49/100 [02:26<02:25,  2.85s/it]Running generate_until requests:  50%|█████     | 50/100 [02:28<02:02,  2.44s/it]Running generate_until requests:  51%|█████     | 51/100 [02:30<01:51,  2.28s/it]Running generate_until requests:  52%|█████▏    | 52/100 [02:33<01:59,  2.50s/it]Running generate_until requests:  53%|█████▎    | 53/100 [02:36<02:14,  2.86s/it]Running generate_until requests:  54%|█████▍    | 54/100 [02:41<02:36,  3.40s/it]Running generate_until requests:  55%|█████▌    | 55/100 [02:43<02:11,  2.93s/it]Running generate_until requests:  56%|█████▌    | 56/100 [02:45<01:54,  2.61s/it]Running generate_until requests:  57%|█████▋    | 57/100 [02:47<01:53,  2.63s/it]Running generate_until requests:  58%|█████▊    | 58/100 [02:51<02:03,  2.94s/it]Running generate_until requests:  59%|█████▉    | 59/100 [02:54<01:54,  2.80s/it]Running generate_until requests:  60%|██████    | 60/100 [02:55<01:33,  2.34s/it]Running generate_until requests:  61%|██████    | 61/100 [02:57<01:24,  2.15s/it]Running generate_until requests:  62%|██████▏   | 62/100 [02:59<01:23,  2.21s/it]Running generate_until requests:  63%|██████▎   | 63/100 [03:01<01:16,  2.07s/it]Running generate_until requests:  64%|██████▍   | 64/100 [03:04<01:27,  2.42s/it]Running generate_until requests:  65%|██████▌   | 65/100 [03:06<01:22,  2.36s/it]Running generate_until requests:  66%|██████▌   | 66/100 [03:08<01:18,  2.32s/it]Running generate_until requests:  67%|██████▋   | 67/100 [03:11<01:19,  2.42s/it]Running generate_until requests:  68%|██████▊   | 68/100 [03:12<01:04,  2.02s/it]Running generate_until requests:  69%|██████▉   | 69/100 [03:16<01:18,  2.54s/it]Running generate_until requests:  70%|███████   | 70/100 [03:18<01:16,  2.54s/it]Running generate_until requests:  71%|███████   | 71/100 [03:22<01:26,  2.99s/it]Running generate_until requests:  72%|███████▏  | 72/100 [03:25<01:16,  2.74s/it]Running generate_until requests:  73%|███████▎  | 73/100 [03:27<01:11,  2.67s/it]Running generate_until requests:  74%|███████▍  | 74/100 [03:30<01:11,  2.77s/it]Running generate_until requests:  75%|███████▌  | 75/100 [03:32<01:03,  2.55s/it]Running generate_until requests:  76%|███████▌  | 76/100 [03:35<01:05,  2.71s/it]Running generate_until requests:  77%|███████▋  | 77/100 [03:38<01:02,  2.70s/it]Running generate_until requests:  78%|███████▊  | 78/100 [03:39<00:51,  2.36s/it]Running generate_until requests:  79%|███████▉  | 79/100 [03:41<00:46,  2.23s/it]Running generate_until requests:  80%|████████  | 80/100 [03:43<00:40,  2.03s/it]Running generate_until requests:  81%|████████  | 81/100 [03:45<00:41,  2.19s/it]Running generate_until requests:  82%|████████▏ | 82/100 [03:50<00:50,  2.81s/it]Running generate_until requests:  83%|████████▎ | 83/100 [03:52<00:43,  2.58s/it]Running generate_until requests:  84%|████████▍ | 84/100 [03:53<00:36,  2.31s/it]Running generate_until requests:  85%|████████▌ | 85/100 [03:56<00:36,  2.41s/it]Running generate_until requests:  86%|████████▌ | 86/100 [03:58<00:33,  2.38s/it]Running generate_until requests:  87%|████████▋ | 87/100 [04:01<00:30,  2.38s/it]Running generate_until requests:  88%|████████▊ | 88/100 [04:02<00:26,  2.17s/it]Running generate_until requests:  89%|████████▉ | 89/100 [04:05<00:24,  2.21s/it]Running generate_until requests:  90%|█████████ | 90/100 [04:07<00:21,  2.19s/it]Running generate_until requests:  91%|█████████ | 91/100 [04:08<00:18,  2.00s/it]Running generate_until requests:  92%|█████████▏| 92/100 [04:11<00:17,  2.20s/it]Running generate_until requests:  93%|█████████▎| 93/100 [04:13<00:14,  2.05s/it]Running generate_until requests:  94%|█████████▍| 94/100 [04:15<00:13,  2.18s/it]Running generate_until requests:  95%|█████████▌| 95/100 [04:19<00:12,  2.55s/it]Running generate_until requests:  96%|█████████▌| 96/100 [04:22<00:10,  2.67s/it]Running generate_until requests:  97%|█████████▋| 97/100 [04:24<00:07,  2.59s/it]Running generate_until requests:  98%|█████████▊| 98/100 [04:27<00:05,  2.63s/it]Running generate_until requests:  99%|█████████▉| 99/100 [04:30<00:02,  2.84s/it]Running generate_until requests: 100%|██████████| 100/100 [04:34<00:00,  3.28s/it]Running generate_until requests: 100%|██████████| 100/100 [04:34<00:00,  2.75s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-03-20:06:58:07,963 INFO     [evaluation_tracker.py:206] Saving results aggregated
2025-03-20:06:58:07,992 INFO     [evaluation_tracker.py:287] Saving per-sample results for: gsm8k
