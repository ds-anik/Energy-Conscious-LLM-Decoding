SLURM JOB ID is 717412
Starting runs with beam_size=4 and beam_group_size=2
Running run 1 with 1st Run , beam_size=4, and beam_group_size=2
Started nvidia-smi monitoring with PID 1704856 for run 1
hf (pretrained=meta-llama/Llama-3.1-8B-Instruct,dtype=bfloat16,device=cuda,parallelize=False), gen_kwargs: (do_sample=False,num_beams=4,num_beam_groups=2,diversity_penalty=1.0,temperature=1.0,top_k=0,top_p=1.0,max_new_tokens=250), limit: 100.0, num_fewshot: None, batch_size: 1
|     Tasks      |Version|Filter|n-shot|    Metric     |Value|   |Stderr|
|----------------|-------|------|-----:|---------------|----:|---|-----:|
|code2text_python|Yaml   |none  |     0|smoothed_bleu_4|0.634|±  |0.0518|

Stopped nvidia-smi monitoring process for run 1
Waiting for 30 seconds between runs...
Running run 2 with 2nd Run , beam_size=4, and beam_group_size=2
Started nvidia-smi monitoring with PID 1707495 for run 2
hf (pretrained=meta-llama/Llama-3.1-8B-Instruct,dtype=bfloat16,device=cuda,parallelize=False), gen_kwargs: (do_sample=False,num_beams=4,num_beam_groups=2,diversity_penalty=1.0,temperature=1.0,top_k=0,top_p=1.0,max_new_tokens=250), limit: 100.0, num_fewshot: None, batch_size: 1
|     Tasks      |Version|Filter|n-shot|    Metric     |Value|   |Stderr|
|----------------|-------|------|-----:|---------------|----:|---|-----:|
|code2text_python|Yaml   |none  |     0|smoothed_bleu_4|0.634|±  |0.0518|

Stopped nvidia-smi monitoring process for run 2
Waiting for 30 seconds between runs...
Running run 3 with 3rd Run , beam_size=4, and beam_group_size=2
Started nvidia-smi monitoring with PID 1710295 for run 3
hf (pretrained=meta-llama/Llama-3.1-8B-Instruct,dtype=bfloat16,device=cuda,parallelize=False), gen_kwargs: (do_sample=False,num_beams=4,num_beam_groups=2,diversity_penalty=1.0,temperature=1.0,top_k=0,top_p=1.0,max_new_tokens=250), limit: 100.0, num_fewshot: None, batch_size: 1
|     Tasks      |Version|Filter|n-shot|    Metric     |Value|   |Stderr|
|----------------|-------|------|-----:|---------------|----:|---|-----:|
|code2text_python|Yaml   |none  |     0|smoothed_bleu_4|0.634|±  |0.0518|

Stopped nvidia-smi monitoring process for run 3
Waiting for 30 seconds between runs...
Running run 4 with 4th Run , beam_size=4, and beam_group_size=2
Started nvidia-smi monitoring with PID 1712780 for run 4
hf (pretrained=meta-llama/Llama-3.1-8B-Instruct,dtype=bfloat16,device=cuda,parallelize=False), gen_kwargs: (do_sample=False,num_beams=4,num_beam_groups=2,diversity_penalty=1.0,temperature=1.0,top_k=0,top_p=1.0,max_new_tokens=250), limit: 100.0, num_fewshot: None, batch_size: 1
|     Tasks      |Version|Filter|n-shot|    Metric     |Value|   |Stderr|
|----------------|-------|------|-----:|---------------|----:|---|-----:|
|code2text_python|Yaml   |none  |     0|smoothed_bleu_4|0.634|±  |0.0518|

Stopped nvidia-smi monitoring process for run 4
Waiting for 30 seconds between runs...
Running run 5 with 5th Run , beam_size=4, and beam_group_size=2
Started nvidia-smi monitoring with PID 1715426 for run 5
hf (pretrained=meta-llama/Llama-3.1-8B-Instruct,dtype=bfloat16,device=cuda,parallelize=False), gen_kwargs: (do_sample=False,num_beams=4,num_beam_groups=2,diversity_penalty=1.0,temperature=1.0,top_k=0,top_p=1.0,max_new_tokens=250), limit: 100.0, num_fewshot: None, batch_size: 1
|     Tasks      |Version|Filter|n-shot|    Metric     |Value|   |Stderr|
|----------------|-------|------|-----:|---------------|----:|---|-----:|
|code2text_python|Yaml   |none  |     0|smoothed_bleu_4|0.634|±  |0.0518|

Stopped nvidia-smi monitoring process for run 5
Waiting for 100 seconds before starting next assisted decoding runs...
Starting runs with beam_size=5 and beam_group_size=5
Running run 1 with 1st Run , beam_size=5, and beam_group_size=5
Started nvidia-smi monitoring with PID 1718163 for run 1
hf (pretrained=meta-llama/Llama-3.1-8B-Instruct,dtype=bfloat16,device=cuda,parallelize=False), gen_kwargs: (do_sample=False,num_beams=5,num_beam_groups=5,diversity_penalty=1.0,temperature=1.0,top_k=0,top_p=1.0,max_new_tokens=250), limit: 100.0, num_fewshot: None, batch_size: 1
|     Tasks      |Version|Filter|n-shot|    Metric     |Value |   |Stderr|
|----------------|-------|------|-----:|---------------|-----:|---|-----:|
|code2text_python|Yaml   |none  |     0|smoothed_bleu_4|0.5489|±  |0.0312|

Stopped nvidia-smi monitoring process for run 1
Waiting for 30 seconds between runs...
Running run 2 with 2nd Run , beam_size=5, and beam_group_size=5
Started nvidia-smi monitoring with PID 1721147 for run 2
hf (pretrained=meta-llama/Llama-3.1-8B-Instruct,dtype=bfloat16,device=cuda,parallelize=False), gen_kwargs: (do_sample=False,num_beams=5,num_beam_groups=5,diversity_penalty=1.0,temperature=1.0,top_k=0,top_p=1.0,max_new_tokens=250), limit: 100.0, num_fewshot: None, batch_size: 1
|     Tasks      |Version|Filter|n-shot|    Metric     |Value |   |Stderr|
|----------------|-------|------|-----:|---------------|-----:|---|-----:|
|code2text_python|Yaml   |none  |     0|smoothed_bleu_4|0.5489|±  |0.0312|

Stopped nvidia-smi monitoring process for run 2
Waiting for 30 seconds between runs...
Running run 3 with 3rd Run , beam_size=5, and beam_group_size=5
Started nvidia-smi monitoring with PID 1724051 for run 3
hf (pretrained=meta-llama/Llama-3.1-8B-Instruct,dtype=bfloat16,device=cuda,parallelize=False), gen_kwargs: (do_sample=False,num_beams=5,num_beam_groups=5,diversity_penalty=1.0,temperature=1.0,top_k=0,top_p=1.0,max_new_tokens=250), limit: 100.0, num_fewshot: None, batch_size: 1
|     Tasks      |Version|Filter|n-shot|    Metric     |Value |   |Stderr|
|----------------|-------|------|-----:|---------------|-----:|---|-----:|
|code2text_python|Yaml   |none  |     0|smoothed_bleu_4|0.5489|±  |0.0312|

Stopped nvidia-smi monitoring process for run 3
Waiting for 30 seconds between runs...
Running run 4 with 4th Run , beam_size=5, and beam_group_size=5
Started nvidia-smi monitoring with PID 1727055 for run 4
hf (pretrained=meta-llama/Llama-3.1-8B-Instruct,dtype=bfloat16,device=cuda,parallelize=False), gen_kwargs: (do_sample=False,num_beams=5,num_beam_groups=5,diversity_penalty=1.0,temperature=1.0,top_k=0,top_p=1.0,max_new_tokens=250), limit: 100.0, num_fewshot: None, batch_size: 1
|     Tasks      |Version|Filter|n-shot|    Metric     |Value |   |Stderr|
|----------------|-------|------|-----:|---------------|-----:|---|-----:|
|code2text_python|Yaml   |none  |     0|smoothed_bleu_4|0.5489|±  |0.0312|

Stopped nvidia-smi monitoring process for run 4
Waiting for 30 seconds between runs...
Running run 5 with 5th Run , beam_size=5, and beam_group_size=5
Started nvidia-smi monitoring with PID 1730152 for run 5
hf (pretrained=meta-llama/Llama-3.1-8B-Instruct,dtype=bfloat16,device=cuda,parallelize=False), gen_kwargs: (do_sample=False,num_beams=5,num_beam_groups=5,diversity_penalty=1.0,temperature=1.0,top_k=0,top_p=1.0,max_new_tokens=250), limit: 100.0, num_fewshot: None, batch_size: 1
|     Tasks      |Version|Filter|n-shot|    Metric     |Value |   |Stderr|
|----------------|-------|------|-----:|---------------|-----:|---|-----:|
|code2text_python|Yaml   |none  |     0|smoothed_bleu_4|0.5489|±  |0.0312|

Stopped nvidia-smi monitoring process for run 5
Waiting for 100 seconds before starting next assisted decoding runs...
Starting runs with beam_size=10 and beam_group_size=2
Running run 1 with 1st Run , beam_size=10, and beam_group_size=2
Started nvidia-smi monitoring with PID 1733301 for run 1
hf (pretrained=meta-llama/Llama-3.1-8B-Instruct,dtype=bfloat16,device=cuda,parallelize=False), gen_kwargs: (do_sample=False,num_beams=10,num_beam_groups=2,diversity_penalty=1.0,temperature=1.0,top_k=0,top_p=1.0,max_new_tokens=250), limit: 100.0, num_fewshot: None, batch_size: 1
|     Tasks      |Version|Filter|n-shot|    Metric     |Value|   |Stderr|
|----------------|-------|------|-----:|---------------|----:|---|-----:|
|code2text_python|Yaml   |none  |     0|smoothed_bleu_4|0.589|±  |0.0374|

Stopped nvidia-smi monitoring process for run 1
Waiting for 30 seconds between runs...
Running run 2 with 2nd Run , beam_size=10, and beam_group_size=2
Started nvidia-smi monitoring with PID 1736635 for run 2
hf (pretrained=meta-llama/Llama-3.1-8B-Instruct,dtype=bfloat16,device=cuda,parallelize=False), gen_kwargs: (do_sample=False,num_beams=10,num_beam_groups=2,diversity_penalty=1.0,temperature=1.0,top_k=0,top_p=1.0,max_new_tokens=250), limit: 100.0, num_fewshot: None, batch_size: 1
|     Tasks      |Version|Filter|n-shot|    Metric     |Value|   |Stderr|
|----------------|-------|------|-----:|---------------|----:|---|-----:|
|code2text_python|Yaml   |none  |     0|smoothed_bleu_4|0.589|±  |0.0374|

Stopped nvidia-smi monitoring process for run 2
Waiting for 30 seconds between runs...
Running run 3 with 3rd Run , beam_size=10, and beam_group_size=2
Started nvidia-smi monitoring with PID 1739875 for run 3
hf (pretrained=meta-llama/Llama-3.1-8B-Instruct,dtype=bfloat16,device=cuda,parallelize=False), gen_kwargs: (do_sample=False,num_beams=10,num_beam_groups=2,diversity_penalty=1.0,temperature=1.0,top_k=0,top_p=1.0,max_new_tokens=250), limit: 100.0, num_fewshot: None, batch_size: 1
|     Tasks      |Version|Filter|n-shot|    Metric     |Value|   |Stderr|
|----------------|-------|------|-----:|---------------|----:|---|-----:|
|code2text_python|Yaml   |none  |     0|smoothed_bleu_4|0.589|±  |0.0374|

Stopped nvidia-smi monitoring process for run 3
Waiting for 30 seconds between runs...
Running run 4 with 4th Run , beam_size=10, and beam_group_size=2
Started nvidia-smi monitoring with PID 1743347 for run 4
hf (pretrained=meta-llama/Llama-3.1-8B-Instruct,dtype=bfloat16,device=cuda,parallelize=False), gen_kwargs: (do_sample=False,num_beams=10,num_beam_groups=2,diversity_penalty=1.0,temperature=1.0,top_k=0,top_p=1.0,max_new_tokens=250), limit: 100.0, num_fewshot: None, batch_size: 1
|     Tasks      |Version|Filter|n-shot|    Metric     |Value|   |Stderr|
|----------------|-------|------|-----:|---------------|----:|---|-----:|
|code2text_python|Yaml   |none  |     0|smoothed_bleu_4|0.589|±  |0.0374|

Stopped nvidia-smi monitoring process for run 4
Waiting for 30 seconds between runs...
Running run 5 with 5th Run , beam_size=10, and beam_group_size=2
Started nvidia-smi monitoring with PID 1747529 for run 5
hf (pretrained=meta-llama/Llama-3.1-8B-Instruct,dtype=bfloat16,device=cuda,parallelize=False), gen_kwargs: (do_sample=False,num_beams=10,num_beam_groups=2,diversity_penalty=1.0,temperature=1.0,top_k=0,top_p=1.0,max_new_tokens=250), limit: 100.0, num_fewshot: None, batch_size: 1
|     Tasks      |Version|Filter|n-shot|    Metric     |Value|   |Stderr|
|----------------|-------|------|-----:|---------------|----:|---|-----:|
|code2text_python|Yaml   |none  |     0|smoothed_bleu_4|0.589|±  |0.0374|

Stopped nvidia-smi monitoring process for run 5
Waiting for 100 seconds before starting next assisted decoding runs...
Starting runs with beam_size=10 and beam_group_size=5
Running run 1 with 1st Run , beam_size=10, and beam_group_size=5
Started nvidia-smi monitoring with PID 1751425 for run 1
hf (pretrained=meta-llama/Llama-3.1-8B-Instruct,dtype=bfloat16,device=cuda,parallelize=False), gen_kwargs: (do_sample=False,num_beams=10,num_beam_groups=5,diversity_penalty=1.0,temperature=1.0,top_k=0,top_p=1.0,max_new_tokens=250), limit: 100.0, num_fewshot: None, batch_size: 1
|     Tasks      |Version|Filter|n-shot|    Metric     |Value |   |Stderr|
|----------------|-------|------|-----:|---------------|-----:|---|-----:|
|code2text_python|Yaml   |none  |     0|smoothed_bleu_4|0.5904|±  |0.0364|

Stopped nvidia-smi monitoring process for run 1
Waiting for 30 seconds between runs...
Running run 2 with 2nd Run , beam_size=10, and beam_group_size=5
Started nvidia-smi monitoring with PID 1754677 for run 2
hf (pretrained=meta-llama/Llama-3.1-8B-Instruct,dtype=bfloat16,device=cuda,parallelize=False), gen_kwargs: (do_sample=False,num_beams=10,num_beam_groups=5,diversity_penalty=1.0,temperature=1.0,top_k=0,top_p=1.0,max_new_tokens=250), limit: 100.0, num_fewshot: None, batch_size: 1
|     Tasks      |Version|Filter|n-shot|    Metric     |Value |   |Stderr|
|----------------|-------|------|-----:|---------------|-----:|---|-----:|
|code2text_python|Yaml   |none  |     0|smoothed_bleu_4|0.5904|±  |0.0364|

Stopped nvidia-smi monitoring process for run 2
Waiting for 30 seconds between runs...
Running run 3 with 3rd Run , beam_size=10, and beam_group_size=5
Started nvidia-smi monitoring with PID 1757936 for run 3
hf (pretrained=meta-llama/Llama-3.1-8B-Instruct,dtype=bfloat16,device=cuda,parallelize=False), gen_kwargs: (do_sample=False,num_beams=10,num_beam_groups=5,diversity_penalty=1.0,temperature=1.0,top_k=0,top_p=1.0,max_new_tokens=250), limit: 100.0, num_fewshot: None, batch_size: 1
|     Tasks      |Version|Filter|n-shot|    Metric     |Value |   |Stderr|
|----------------|-------|------|-----:|---------------|-----:|---|-----:|
|code2text_python|Yaml   |none  |     0|smoothed_bleu_4|0.5904|±  |0.0364|

Stopped nvidia-smi monitoring process for run 3
Waiting for 30 seconds between runs...
Running run 4 with 4th Run , beam_size=10, and beam_group_size=5
Started nvidia-smi monitoring with PID 1761176 for run 4
hf (pretrained=meta-llama/Llama-3.1-8B-Instruct,dtype=bfloat16,device=cuda,parallelize=False), gen_kwargs: (do_sample=False,num_beams=10,num_beam_groups=5,diversity_penalty=1.0,temperature=1.0,top_k=0,top_p=1.0,max_new_tokens=250), limit: 100.0, num_fewshot: None, batch_size: 1
|     Tasks      |Version|Filter|n-shot|    Metric     |Value |   |Stderr|
|----------------|-------|------|-----:|---------------|-----:|---|-----:|
|code2text_python|Yaml   |none  |     0|smoothed_bleu_4|0.5904|±  |0.0364|

Stopped nvidia-smi monitoring process for run 4
Waiting for 30 seconds between runs...
Running run 5 with 5th Run , beam_size=10, and beam_group_size=5
Started nvidia-smi monitoring with PID 1764425 for run 5
hf (pretrained=meta-llama/Llama-3.1-8B-Instruct,dtype=bfloat16,device=cuda,parallelize=False), gen_kwargs: (do_sample=False,num_beams=10,num_beam_groups=5,diversity_penalty=1.0,temperature=1.0,top_k=0,top_p=1.0,max_new_tokens=250), limit: 100.0, num_fewshot: None, batch_size: 1
|     Tasks      |Version|Filter|n-shot|    Metric     |Value |   |Stderr|
|----------------|-------|------|-----:|---------------|-----:|---|-----:|
|code2text_python|Yaml   |none  |     0|smoothed_bleu_4|0.5904|±  |0.0364|

Stopped nvidia-smi monitoring process for run 5
Script execution completed.
