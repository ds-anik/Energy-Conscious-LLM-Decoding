SLURM JOB ID is 717403
Starting runs with min_p=0.02
Running run 1 with 1st Run and min_p=0.02
Started nvidia-smi monitoring with PID 1605568 for run 1
hf (pretrained=meta-llama/Llama-3.1-8B-Instruct,dtype=bfloat16,device=cuda,parallelize=False), gen_kwargs: (do_sample=True,temperature=1.0,top_p=1.0,top_k=0,min_p=0.02,num_beams=1,max_new_tokens=250), limit: 100.0, num_fewshot: None, batch_size: 1
|     Tasks      |Version|Filter|n-shot|    Metric     |Value |   |Stderr|
|----------------|-------|------|-----:|---------------|-----:|---|-----:|
|code2text_python|Yaml   |none  |     0|smoothed_bleu_4|0.6875|±  |0.0293|

Stopped nvidia-smi monitoring process for run 1
Waiting for 30 seconds between runs...
Running run 2 with 2nd Run and min_p=0.02
Started nvidia-smi monitoring with PID 1607828 for run 2
hf (pretrained=meta-llama/Llama-3.1-8B-Instruct,dtype=bfloat16,device=cuda,parallelize=False), gen_kwargs: (do_sample=True,temperature=1.0,top_p=1.0,top_k=0,min_p=0.02,num_beams=1,max_new_tokens=250), limit: 100.0, num_fewshot: None, batch_size: 1
|     Tasks      |Version|Filter|n-shot|    Metric     |Value |   |Stderr|
|----------------|-------|------|-----:|---------------|-----:|---|-----:|
|code2text_python|Yaml   |none  |     0|smoothed_bleu_4|0.6875|±  |0.0293|

Stopped nvidia-smi monitoring process for run 2
Waiting for 30 seconds between runs...
Running run 3 with 3rd Run and min_p=0.02
Started nvidia-smi monitoring with PID 1609958 for run 3
hf (pretrained=meta-llama/Llama-3.1-8B-Instruct,dtype=bfloat16,device=cuda,parallelize=False), gen_kwargs: (do_sample=True,temperature=1.0,top_p=1.0,top_k=0,min_p=0.02,num_beams=1,max_new_tokens=250), limit: 100.0, num_fewshot: None, batch_size: 1
|     Tasks      |Version|Filter|n-shot|    Metric     |Value |   |Stderr|
|----------------|-------|------|-----:|---------------|-----:|---|-----:|
|code2text_python|Yaml   |none  |     0|smoothed_bleu_4|0.6875|±  |0.0293|

Stopped nvidia-smi monitoring process for run 3
Waiting for 30 seconds between runs...
Running run 4 with 4th Run and min_p=0.02
Started nvidia-smi monitoring with PID 1612124 for run 4
hf (pretrained=meta-llama/Llama-3.1-8B-Instruct,dtype=bfloat16,device=cuda,parallelize=False), gen_kwargs: (do_sample=True,temperature=1.0,top_p=1.0,top_k=0,min_p=0.02,num_beams=1,max_new_tokens=250), limit: 100.0, num_fewshot: None, batch_size: 1
|     Tasks      |Version|Filter|n-shot|    Metric     |Value |   |Stderr|
|----------------|-------|------|-----:|---------------|-----:|---|-----:|
|code2text_python|Yaml   |none  |     0|smoothed_bleu_4|0.6875|±  |0.0293|

Stopped nvidia-smi monitoring process for run 4
Waiting for 30 seconds between runs...
Running run 5 with 5th Run and min_p=0.02
Started nvidia-smi monitoring with PID 1614398 for run 5
hf (pretrained=meta-llama/Llama-3.1-8B-Instruct,dtype=bfloat16,device=cuda,parallelize=False), gen_kwargs: (do_sample=True,temperature=1.0,top_p=1.0,top_k=0,min_p=0.02,num_beams=1,max_new_tokens=250), limit: 100.0, num_fewshot: None, batch_size: 1
|     Tasks      |Version|Filter|n-shot|    Metric     |Value |   |Stderr|
|----------------|-------|------|-----:|---------------|-----:|---|-----:|
|code2text_python|Yaml   |none  |     0|smoothed_bleu_4|0.6875|±  |0.0293|

Stopped nvidia-smi monitoring process for run 5
Waiting for 100 seconds before starting next min_p sampling runs...
Starting runs with min_p=0.05
Running run 1 with 1st Run and min_p=0.05
Started nvidia-smi monitoring with PID 1616722 for run 1
hf (pretrained=meta-llama/Llama-3.1-8B-Instruct,dtype=bfloat16,device=cuda,parallelize=False), gen_kwargs: (do_sample=True,temperature=1.0,top_p=1.0,top_k=0,min_p=0.05,num_beams=1,max_new_tokens=250), limit: 100.0, num_fewshot: None, batch_size: 1
|     Tasks      |Version|Filter|n-shot|    Metric     |Value |   |Stderr|
|----------------|-------|------|-----:|---------------|-----:|---|-----:|
|code2text_python|Yaml   |none  |     0|smoothed_bleu_4|0.7862|±  |0.0619|

Stopped nvidia-smi monitoring process for run 1
Waiting for 30 seconds between runs...
Running run 2 with 2nd Run and min_p=0.05
Started nvidia-smi monitoring with PID 1618863 for run 2
hf (pretrained=meta-llama/Llama-3.1-8B-Instruct,dtype=bfloat16,device=cuda,parallelize=False), gen_kwargs: (do_sample=True,temperature=1.0,top_p=1.0,top_k=0,min_p=0.05,num_beams=1,max_new_tokens=250), limit: 100.0, num_fewshot: None, batch_size: 1
|     Tasks      |Version|Filter|n-shot|    Metric     |Value |   |Stderr|
|----------------|-------|------|-----:|---------------|-----:|---|-----:|
|code2text_python|Yaml   |none  |     0|smoothed_bleu_4|0.7862|±  |0.0619|

Stopped nvidia-smi monitoring process for run 2
Waiting for 30 seconds between runs...
Running run 3 with 3rd Run and min_p=0.05
Started nvidia-smi monitoring with PID 1621003 for run 3
hf (pretrained=meta-llama/Llama-3.1-8B-Instruct,dtype=bfloat16,device=cuda,parallelize=False), gen_kwargs: (do_sample=True,temperature=1.0,top_p=1.0,top_k=0,min_p=0.05,num_beams=1,max_new_tokens=250), limit: 100.0, num_fewshot: None, batch_size: 1
|     Tasks      |Version|Filter|n-shot|    Metric     |Value |   |Stderr|
|----------------|-------|------|-----:|---------------|-----:|---|-----:|
|code2text_python|Yaml   |none  |     0|smoothed_bleu_4|0.7862|±  |0.0619|

Stopped nvidia-smi monitoring process for run 3
Waiting for 30 seconds between runs...
Running run 4 with 4th Run and min_p=0.05
Started nvidia-smi monitoring with PID 1623237 for run 4
hf (pretrained=meta-llama/Llama-3.1-8B-Instruct,dtype=bfloat16,device=cuda,parallelize=False), gen_kwargs: (do_sample=True,temperature=1.0,top_p=1.0,top_k=0,min_p=0.05,num_beams=1,max_new_tokens=250), limit: 100.0, num_fewshot: None, batch_size: 1
|     Tasks      |Version|Filter|n-shot|    Metric     |Value |   |Stderr|
|----------------|-------|------|-----:|---------------|-----:|---|-----:|
|code2text_python|Yaml   |none  |     0|smoothed_bleu_4|0.7862|±  |0.0619|

Stopped nvidia-smi monitoring process for run 4
Waiting for 30 seconds between runs...
Running run 5 with 5th Run and min_p=0.05
Started nvidia-smi monitoring with PID 1625363 for run 5
hf (pretrained=meta-llama/Llama-3.1-8B-Instruct,dtype=bfloat16,device=cuda,parallelize=False), gen_kwargs: (do_sample=True,temperature=1.0,top_p=1.0,top_k=0,min_p=0.05,num_beams=1,max_new_tokens=250), limit: 100.0, num_fewshot: None, batch_size: 1
|     Tasks      |Version|Filter|n-shot|    Metric     |Value |   |Stderr|
|----------------|-------|------|-----:|---------------|-----:|---|-----:|
|code2text_python|Yaml   |none  |     0|smoothed_bleu_4|0.7862|±  |0.0619|

Stopped nvidia-smi monitoring process for run 5
Waiting for 100 seconds before starting next min_p sampling runs...
Starting runs with min_p=0.1
Running run 1 with 1st Run and min_p=0.1
Started nvidia-smi monitoring with PID 1627768 for run 1
hf (pretrained=meta-llama/Llama-3.1-8B-Instruct,dtype=bfloat16,device=cuda,parallelize=False), gen_kwargs: (do_sample=True,temperature=1.0,top_p=1.0,top_k=0,min_p=0.1,num_beams=1,max_new_tokens=250), limit: 100.0, num_fewshot: None, batch_size: 1
|     Tasks      |Version|Filter|n-shot|    Metric     |Value |   |Stderr|
|----------------|-------|------|-----:|---------------|-----:|---|-----:|
|code2text_python|Yaml   |none  |     0|smoothed_bleu_4|0.7404|±  |0.0389|

Stopped nvidia-smi monitoring process for run 1
Waiting for 30 seconds between runs...
Running run 2 with 2nd Run and min_p=0.1
Started nvidia-smi monitoring with PID 1629874 for run 2
hf (pretrained=meta-llama/Llama-3.1-8B-Instruct,dtype=bfloat16,device=cuda,parallelize=False), gen_kwargs: (do_sample=True,temperature=1.0,top_p=1.0,top_k=0,min_p=0.1,num_beams=1,max_new_tokens=250), limit: 100.0, num_fewshot: None, batch_size: 1
|     Tasks      |Version|Filter|n-shot|    Metric     |Value |   |Stderr|
|----------------|-------|------|-----:|---------------|-----:|---|-----:|
|code2text_python|Yaml   |none  |     0|smoothed_bleu_4|0.7404|±  |0.0389|

Stopped nvidia-smi monitoring process for run 2
Waiting for 30 seconds between runs...
Running run 3 with 3rd Run and min_p=0.1
Started nvidia-smi monitoring with PID 1631973 for run 3
hf (pretrained=meta-llama/Llama-3.1-8B-Instruct,dtype=bfloat16,device=cuda,parallelize=False), gen_kwargs: (do_sample=True,temperature=1.0,top_p=1.0,top_k=0,min_p=0.1,num_beams=1,max_new_tokens=250), limit: 100.0, num_fewshot: None, batch_size: 1
|     Tasks      |Version|Filter|n-shot|    Metric     |Value |   |Stderr|
|----------------|-------|------|-----:|---------------|-----:|---|-----:|
|code2text_python|Yaml   |none  |     0|smoothed_bleu_4|0.7404|±  |0.0389|

Stopped nvidia-smi monitoring process for run 3
Waiting for 30 seconds between runs...
Running run 4 with 4th Run and min_p=0.1
Started nvidia-smi monitoring with PID 1634239 for run 4
hf (pretrained=meta-llama/Llama-3.1-8B-Instruct,dtype=bfloat16,device=cuda,parallelize=False), gen_kwargs: (do_sample=True,temperature=1.0,top_p=1.0,top_k=0,min_p=0.1,num_beams=1,max_new_tokens=250), limit: 100.0, num_fewshot: None, batch_size: 1
|     Tasks      |Version|Filter|n-shot|    Metric     |Value |   |Stderr|
|----------------|-------|------|-----:|---------------|-----:|---|-----:|
|code2text_python|Yaml   |none  |     0|smoothed_bleu_4|0.7404|±  |0.0389|

Stopped nvidia-smi monitoring process for run 4
Waiting for 30 seconds between runs...
Running run 5 with 5th Run and min_p=0.1
Started nvidia-smi monitoring with PID 1636358 for run 5
hf (pretrained=meta-llama/Llama-3.1-8B-Instruct,dtype=bfloat16,device=cuda,parallelize=False), gen_kwargs: (do_sample=True,temperature=1.0,top_p=1.0,top_k=0,min_p=0.1,num_beams=1,max_new_tokens=250), limit: 100.0, num_fewshot: None, batch_size: 1
|     Tasks      |Version|Filter|n-shot|    Metric     |Value |   |Stderr|
|----------------|-------|------|-----:|---------------|-----:|---|-----:|
|code2text_python|Yaml   |none  |     0|smoothed_bleu_4|0.7404|±  |0.0389|

Stopped nvidia-smi monitoring process for run 5
Waiting for 100 seconds before starting next min_p sampling runs...
Starting runs with min_p=0.2
Running run 1 with 1st Run and min_p=0.2
Started nvidia-smi monitoring with PID 1638753 for run 1
hf (pretrained=meta-llama/Llama-3.1-8B-Instruct,dtype=bfloat16,device=cuda,parallelize=False), gen_kwargs: (do_sample=True,temperature=1.0,top_p=1.0,top_k=0,min_p=0.2,num_beams=1,max_new_tokens=250), limit: 100.0, num_fewshot: None, batch_size: 1
|     Tasks      |Version|Filter|n-shot|    Metric     |Value |   |Stderr|
|----------------|-------|------|-----:|---------------|-----:|---|-----:|
|code2text_python|Yaml   |none  |     0|smoothed_bleu_4|0.7341|±  |0.0473|

Stopped nvidia-smi monitoring process for run 1
Waiting for 30 seconds between runs...
Running run 2 with 2nd Run and min_p=0.2
Started nvidia-smi monitoring with PID 1640940 for run 2
hf (pretrained=meta-llama/Llama-3.1-8B-Instruct,dtype=bfloat16,device=cuda,parallelize=False), gen_kwargs: (do_sample=True,temperature=1.0,top_p=1.0,top_k=0,min_p=0.2,num_beams=1,max_new_tokens=250), limit: 100.0, num_fewshot: None, batch_size: 1
|     Tasks      |Version|Filter|n-shot|    Metric     |Value |   |Stderr|
|----------------|-------|------|-----:|---------------|-----:|---|-----:|
|code2text_python|Yaml   |none  |     0|smoothed_bleu_4|0.7341|±  |0.0473|

Stopped nvidia-smi monitoring process for run 2
Waiting for 30 seconds between runs...
Running run 3 with 3rd Run and min_p=0.2
Started nvidia-smi monitoring with PID 1643207 for run 3
hf (pretrained=meta-llama/Llama-3.1-8B-Instruct,dtype=bfloat16,device=cuda,parallelize=False), gen_kwargs: (do_sample=True,temperature=1.0,top_p=1.0,top_k=0,min_p=0.2,num_beams=1,max_new_tokens=250), limit: 100.0, num_fewshot: None, batch_size: 1
|     Tasks      |Version|Filter|n-shot|    Metric     |Value |   |Stderr|
|----------------|-------|------|-----:|---------------|-----:|---|-----:|
|code2text_python|Yaml   |none  |     0|smoothed_bleu_4|0.7341|±  |0.0473|

Stopped nvidia-smi monitoring process for run 3
Waiting for 30 seconds between runs...
Running run 4 with 4th Run and min_p=0.2
Started nvidia-smi monitoring with PID 1645360 for run 4
hf (pretrained=meta-llama/Llama-3.1-8B-Instruct,dtype=bfloat16,device=cuda,parallelize=False), gen_kwargs: (do_sample=True,temperature=1.0,top_p=1.0,top_k=0,min_p=0.2,num_beams=1,max_new_tokens=250), limit: 100.0, num_fewshot: None, batch_size: 1
|     Tasks      |Version|Filter|n-shot|    Metric     |Value |   |Stderr|
|----------------|-------|------|-----:|---------------|-----:|---|-----:|
|code2text_python|Yaml   |none  |     0|smoothed_bleu_4|0.7341|±  |0.0473|

Stopped nvidia-smi monitoring process for run 4
Waiting for 30 seconds between runs...
Running run 5 with 5th Run and min_p=0.2
Started nvidia-smi monitoring with PID 1647496 for run 5
hf (pretrained=meta-llama/Llama-3.1-8B-Instruct,dtype=bfloat16,device=cuda,parallelize=False), gen_kwargs: (do_sample=True,temperature=1.0,top_p=1.0,top_k=0,min_p=0.2,num_beams=1,max_new_tokens=250), limit: 100.0, num_fewshot: None, batch_size: 1
|     Tasks      |Version|Filter|n-shot|    Metric     |Value |   |Stderr|
|----------------|-------|------|-----:|---------------|-----:|---|-----:|
|code2text_python|Yaml   |none  |     0|smoothed_bleu_4|0.7341|±  |0.0473|

Stopped nvidia-smi monitoring process for run 5
Waiting for 100 seconds before starting next min_p sampling runs...
Starting runs with min_p=0.3
Running run 1 with 1st Run and min_p=0.3
Started nvidia-smi monitoring with PID 1649867 for run 1
hf (pretrained=meta-llama/Llama-3.1-8B-Instruct,dtype=bfloat16,device=cuda,parallelize=False), gen_kwargs: (do_sample=True,temperature=1.0,top_p=1.0,top_k=0,min_p=0.3,num_beams=1,max_new_tokens=250), limit: 100.0, num_fewshot: None, batch_size: 1
|     Tasks      |Version|Filter|n-shot|    Metric     |Value |   |Stderr|
|----------------|-------|------|-----:|---------------|-----:|---|-----:|
|code2text_python|Yaml   |none  |     0|smoothed_bleu_4|0.7828|±  |0.0575|

Stopped nvidia-smi monitoring process for run 1
Waiting for 30 seconds between runs...
Running run 2 with 2nd Run and min_p=0.3
Started nvidia-smi monitoring with PID 1652197 for run 2
hf (pretrained=meta-llama/Llama-3.1-8B-Instruct,dtype=bfloat16,device=cuda,parallelize=False), gen_kwargs: (do_sample=True,temperature=1.0,top_p=1.0,top_k=0,min_p=0.3,num_beams=1,max_new_tokens=250), limit: 100.0, num_fewshot: None, batch_size: 1
|     Tasks      |Version|Filter|n-shot|    Metric     |Value |   |Stderr|
|----------------|-------|------|-----:|---------------|-----:|---|-----:|
|code2text_python|Yaml   |none  |     0|smoothed_bleu_4|0.7828|±  |0.0575|

Stopped nvidia-smi monitoring process for run 2
Waiting for 30 seconds between runs...
Running run 3 with 3rd Run and min_p=0.3
Started nvidia-smi monitoring with PID 1654353 for run 3
hf (pretrained=meta-llama/Llama-3.1-8B-Instruct,dtype=bfloat16,device=cuda,parallelize=False), gen_kwargs: (do_sample=True,temperature=1.0,top_p=1.0,top_k=0,min_p=0.3,num_beams=1,max_new_tokens=250), limit: 100.0, num_fewshot: None, batch_size: 1
|     Tasks      |Version|Filter|n-shot|    Metric     |Value |   |Stderr|
|----------------|-------|------|-----:|---------------|-----:|---|-----:|
|code2text_python|Yaml   |none  |     0|smoothed_bleu_4|0.7828|±  |0.0575|

Stopped nvidia-smi monitoring process for run 3
Waiting for 30 seconds between runs...
Running run 4 with 4th Run and min_p=0.3
Started nvidia-smi monitoring with PID 1656503 for run 4
hf (pretrained=meta-llama/Llama-3.1-8B-Instruct,dtype=bfloat16,device=cuda,parallelize=False), gen_kwargs: (do_sample=True,temperature=1.0,top_p=1.0,top_k=0,min_p=0.3,num_beams=1,max_new_tokens=250), limit: 100.0, num_fewshot: None, batch_size: 1
|     Tasks      |Version|Filter|n-shot|    Metric     |Value |   |Stderr|
|----------------|-------|------|-----:|---------------|-----:|---|-----:|
|code2text_python|Yaml   |none  |     0|smoothed_bleu_4|0.7828|±  |0.0575|

Stopped nvidia-smi monitoring process for run 4
Waiting for 30 seconds between runs...
Running run 5 with 5th Run and min_p=0.3
Started nvidia-smi monitoring with PID 1658766 for run 5
hf (pretrained=meta-llama/Llama-3.1-8B-Instruct,dtype=bfloat16,device=cuda,parallelize=False), gen_kwargs: (do_sample=True,temperature=1.0,top_p=1.0,top_k=0,min_p=0.3,num_beams=1,max_new_tokens=250), limit: 100.0, num_fewshot: None, batch_size: 1
|     Tasks      |Version|Filter|n-shot|    Metric     |Value |   |Stderr|
|----------------|-------|------|-----:|---------------|-----:|---|-----:|
|code2text_python|Yaml   |none  |     0|smoothed_bleu_4|0.7828|±  |0.0575|

Stopped nvidia-smi monitoring process for run 5
Script execution completed.
