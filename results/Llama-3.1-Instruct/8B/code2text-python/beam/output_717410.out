SLURM JOB ID is 717410
Starting runs with beam=2
Running run 1 with 1st Run and beam=2
Started nvidia-smi monitoring with PID 1687353 for run 1
hf (pretrained=meta-llama/Llama-3.1-8B-Instruct,dtype=bfloat16,device=cuda,parallelize=False), gen_kwargs: (do_sample=False,temperature=1.0,top_p=1.0,top_k=0,num_beams=2,max_new_tokens=250), limit: 100.0, num_fewshot: None, batch_size: 1
|     Tasks      |Version|Filter|n-shot|    Metric     |Value |   |Stderr|
|----------------|-------|------|-----:|---------------|-----:|---|-----:|
|code2text_python|Yaml   |none  |     0|smoothed_bleu_4|0.6553|±  |0.0459|

Stopped nvidia-smi monitoring process for run 1
Waiting for 30 seconds between runs...
Running run 2 with 2nd Run and beam=2
Started nvidia-smi monitoring with PID 1689889 for run 2
hf (pretrained=meta-llama/Llama-3.1-8B-Instruct,dtype=bfloat16,device=cuda,parallelize=False), gen_kwargs: (do_sample=False,temperature=1.0,top_p=1.0,top_k=0,num_beams=2,max_new_tokens=250), limit: 100.0, num_fewshot: None, batch_size: 1
|     Tasks      |Version|Filter|n-shot|    Metric     |Value |   |Stderr|
|----------------|-------|------|-----:|---------------|-----:|---|-----:|
|code2text_python|Yaml   |none  |     0|smoothed_bleu_4|0.6553|±  |0.0459|

Stopped nvidia-smi monitoring process for run 2
Waiting for 30 seconds between runs...
Running run 3 with 3rd Run and beam=2
Started nvidia-smi monitoring with PID 1692312 for run 3
hf (pretrained=meta-llama/Llama-3.1-8B-Instruct,dtype=bfloat16,device=cuda,parallelize=False), gen_kwargs: (do_sample=False,temperature=1.0,top_p=1.0,top_k=0,num_beams=2,max_new_tokens=250), limit: 100.0, num_fewshot: None, batch_size: 1
|     Tasks      |Version|Filter|n-shot|    Metric     |Value |   |Stderr|
|----------------|-------|------|-----:|---------------|-----:|---|-----:|
|code2text_python|Yaml   |none  |     0|smoothed_bleu_4|0.6553|±  |0.0459|

Stopped nvidia-smi monitoring process for run 3
Waiting for 30 seconds between runs...
Running run 4 with 4th Run and beam=2
Started nvidia-smi monitoring with PID 1694696 for run 4
hf (pretrained=meta-llama/Llama-3.1-8B-Instruct,dtype=bfloat16,device=cuda,parallelize=False), gen_kwargs: (do_sample=False,temperature=1.0,top_p=1.0,top_k=0,num_beams=2,max_new_tokens=250), limit: 100.0, num_fewshot: None, batch_size: 1
|     Tasks      |Version|Filter|n-shot|    Metric     |Value |   |Stderr|
|----------------|-------|------|-----:|---------------|-----:|---|-----:|
|code2text_python|Yaml   |none  |     0|smoothed_bleu_4|0.6553|±  |0.0459|

Stopped nvidia-smi monitoring process for run 4
Waiting for 30 seconds between runs...
Running run 5 with 5th Run and beam=2
Started nvidia-smi monitoring with PID 1697087 for run 5
hf (pretrained=meta-llama/Llama-3.1-8B-Instruct,dtype=bfloat16,device=cuda,parallelize=False), gen_kwargs: (do_sample=False,temperature=1.0,top_p=1.0,top_k=0,num_beams=2,max_new_tokens=250), limit: 100.0, num_fewshot: None, batch_size: 1
|     Tasks      |Version|Filter|n-shot|    Metric     |Value |   |Stderr|
|----------------|-------|------|-----:|---------------|-----:|---|-----:|
|code2text_python|Yaml   |none  |     0|smoothed_bleu_4|0.6553|±  |0.0459|

Stopped nvidia-smi monitoring process for run 5
Waiting for 100 seconds before starting next beam search runs...
Starting runs with beam=5
Running run 1 with 1st Run and beam=5
Started nvidia-smi monitoring with PID 1699700 for run 1
hf (pretrained=meta-llama/Llama-3.1-8B-Instruct,dtype=bfloat16,device=cuda,parallelize=False), gen_kwargs: (do_sample=False,temperature=1.0,top_p=1.0,top_k=0,num_beams=5,max_new_tokens=250), limit: 100.0, num_fewshot: None, batch_size: 1
|     Tasks      |Version|Filter|n-shot|    Metric     |Value|   |Stderr|
|----------------|-------|------|-----:|---------------|----:|---|-----:|
|code2text_python|Yaml   |none  |     0|smoothed_bleu_4|0.587|±  |0.0349|

Stopped nvidia-smi monitoring process for run 1
Waiting for 30 seconds between runs...
Running run 2 with 2nd Run and beam=5
Started nvidia-smi monitoring with PID 1702316 for run 2
hf (pretrained=meta-llama/Llama-3.1-8B-Instruct,dtype=bfloat16,device=cuda,parallelize=False), gen_kwargs: (do_sample=False,temperature=1.0,top_p=1.0,top_k=0,num_beams=5,max_new_tokens=250), limit: 100.0, num_fewshot: None, batch_size: 1
|     Tasks      |Version|Filter|n-shot|    Metric     |Value|   |Stderr|
|----------------|-------|------|-----:|---------------|----:|---|-----:|
|code2text_python|Yaml   |none  |     0|smoothed_bleu_4|0.587|±  |0.0349|

Stopped nvidia-smi monitoring process for run 2
Waiting for 30 seconds between runs...
Running run 3 with 3rd Run and beam=5
Started nvidia-smi monitoring with PID 1705035 for run 3
hf (pretrained=meta-llama/Llama-3.1-8B-Instruct,dtype=bfloat16,device=cuda,parallelize=False), gen_kwargs: (do_sample=False,temperature=1.0,top_p=1.0,top_k=0,num_beams=5,max_new_tokens=250), limit: 100.0, num_fewshot: None, batch_size: 1
|     Tasks      |Version|Filter|n-shot|    Metric     |Value|   |Stderr|
|----------------|-------|------|-----:|---------------|----:|---|-----:|
|code2text_python|Yaml   |none  |     0|smoothed_bleu_4|0.587|±  |0.0349|

Stopped nvidia-smi monitoring process for run 3
Waiting for 30 seconds between runs...
Running run 4 with 4th Run and beam=5
Started nvidia-smi monitoring with PID 1707670 for run 4
hf (pretrained=meta-llama/Llama-3.1-8B-Instruct,dtype=bfloat16,device=cuda,parallelize=False), gen_kwargs: (do_sample=False,temperature=1.0,top_p=1.0,top_k=0,num_beams=5,max_new_tokens=250), limit: 100.0, num_fewshot: None, batch_size: 1
|     Tasks      |Version|Filter|n-shot|    Metric     |Value|   |Stderr|
|----------------|-------|------|-----:|---------------|----:|---|-----:|
|code2text_python|Yaml   |none  |     0|smoothed_bleu_4|0.587|±  |0.0349|

Stopped nvidia-smi monitoring process for run 4
Waiting for 30 seconds between runs...
Running run 5 with 5th Run and beam=5
Started nvidia-smi monitoring with PID 1710123 for run 5
hf (pretrained=meta-llama/Llama-3.1-8B-Instruct,dtype=bfloat16,device=cuda,parallelize=False), gen_kwargs: (do_sample=False,temperature=1.0,top_p=1.0,top_k=0,num_beams=5,max_new_tokens=250), limit: 100.0, num_fewshot: None, batch_size: 1
|     Tasks      |Version|Filter|n-shot|    Metric     |Value|   |Stderr|
|----------------|-------|------|-----:|---------------|----:|---|-----:|
|code2text_python|Yaml   |none  |     0|smoothed_bleu_4|0.587|±  |0.0349|

Stopped nvidia-smi monitoring process for run 5
Waiting for 100 seconds before starting next beam search runs...
Starting runs with beam=10
Running run 1 with 1st Run and beam=10
Started nvidia-smi monitoring with PID 1713176 for run 1
hf (pretrained=meta-llama/Llama-3.1-8B-Instruct,dtype=bfloat16,device=cuda,parallelize=False), gen_kwargs: (do_sample=False,temperature=1.0,top_p=1.0,top_k=0,num_beams=10,max_new_tokens=250), limit: 100.0, num_fewshot: None, batch_size: 1
|     Tasks      |Version|Filter|n-shot|    Metric     |Value |   |Stderr|
|----------------|-------|------|-----:|---------------|-----:|---|-----:|
|code2text_python|Yaml   |none  |     0|smoothed_bleu_4|0.5875|±  |0.0352|

Stopped nvidia-smi monitoring process for run 1
Waiting for 30 seconds between runs...
Running run 2 with 2nd Run and beam=10
Started nvidia-smi monitoring with PID 1716155 for run 2
hf (pretrained=meta-llama/Llama-3.1-8B-Instruct,dtype=bfloat16,device=cuda,parallelize=False), gen_kwargs: (do_sample=False,temperature=1.0,top_p=1.0,top_k=0,num_beams=10,max_new_tokens=250), limit: 100.0, num_fewshot: None, batch_size: 1
|     Tasks      |Version|Filter|n-shot|    Metric     |Value |   |Stderr|
|----------------|-------|------|-----:|---------------|-----:|---|-----:|
|code2text_python|Yaml   |none  |     0|smoothed_bleu_4|0.5875|±  |0.0352|

Stopped nvidia-smi monitoring process for run 2
Waiting for 30 seconds between runs...
Running run 3 with 3rd Run and beam=10
Started nvidia-smi monitoring with PID 1719186 for run 3
hf (pretrained=meta-llama/Llama-3.1-8B-Instruct,dtype=bfloat16,device=cuda,parallelize=False), gen_kwargs: (do_sample=False,temperature=1.0,top_p=1.0,top_k=0,num_beams=10,max_new_tokens=250), limit: 100.0, num_fewshot: None, batch_size: 1
|     Tasks      |Version|Filter|n-shot|    Metric     |Value |   |Stderr|
|----------------|-------|------|-----:|---------------|-----:|---|-----:|
|code2text_python|Yaml   |none  |     0|smoothed_bleu_4|0.5875|±  |0.0352|

Stopped nvidia-smi monitoring process for run 3
Waiting for 30 seconds between runs...
Running run 4 with 4th Run and beam=10
Started nvidia-smi monitoring with PID 1722138 for run 4
hf (pretrained=meta-llama/Llama-3.1-8B-Instruct,dtype=bfloat16,device=cuda,parallelize=False), gen_kwargs: (do_sample=False,temperature=1.0,top_p=1.0,top_k=0,num_beams=10,max_new_tokens=250), limit: 100.0, num_fewshot: None, batch_size: 1
|     Tasks      |Version|Filter|n-shot|    Metric     |Value |   |Stderr|
|----------------|-------|------|-----:|---------------|-----:|---|-----:|
|code2text_python|Yaml   |none  |     0|smoothed_bleu_4|0.5875|±  |0.0352|

Stopped nvidia-smi monitoring process for run 4
Waiting for 30 seconds between runs...
Running run 5 with 5th Run and beam=10
Started nvidia-smi monitoring with PID 1725103 for run 5
hf (pretrained=meta-llama/Llama-3.1-8B-Instruct,dtype=bfloat16,device=cuda,parallelize=False), gen_kwargs: (do_sample=False,temperature=1.0,top_p=1.0,top_k=0,num_beams=10,max_new_tokens=250), limit: 100.0, num_fewshot: None, batch_size: 1
|     Tasks      |Version|Filter|n-shot|    Metric     |Value |   |Stderr|
|----------------|-------|------|-----:|---------------|-----:|---|-----:|
|code2text_python|Yaml   |none  |     0|smoothed_bleu_4|0.5875|±  |0.0352|

Stopped nvidia-smi monitoring process for run 5
Script execution completed.
