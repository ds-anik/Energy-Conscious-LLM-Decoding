2025-03-22:07:28:16,005 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-03-22:07:28:16,005 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-03-22:07:28:16,006 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-03-22:07:28:16,333 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-03-22:07:28:20,173 INFO     [__main__.py:132] Verbosity set to INFO
2025-03-22:07:28:30,465 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-03-22:07:28:30,467 INFO     [__main__.py:205] Selected Tasks: ['code2text_python']
2025-03-22:07:28:30,474 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-03-22:07:28:30,739 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  5.93it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  7.46it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  7.54it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  7.87it/s]
2025-03-22:07:29:26,809 INFO     [task.py:355] Building contexts for task on rank 0...
2025-03-22:07:29:26,825 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:612: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:10<17:52, 10.83s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:19<15:27,  9.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:27<14:26,  8.93s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:35<13:52,  8.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:44<13:25,  8.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [00:52<13:02,  8.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [00:59<12:40,  8.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:07<12:22,  8.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:15<12:08,  8.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:23<11:55,  7.95s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [01:31<11:43,  7.90s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [01:38<11:30,  7.84s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [01:46<11:18,  7.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [01:54<11:07,  7.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:02<11:00,  7.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:09<10:49,  7.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [02:17<10:38,  7.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [02:25<10:29,  7.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [02:32<10:20,  7.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [02:40<10:11,  7.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [02:47<10:03,  7.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [02:55<09:53,  7.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [03:02<09:44,  7.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [03:10<09:35,  7.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [03:18<09:27,  7.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [03:25<09:19,  7.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [03:33<09:09,  7.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [03:40<09:00,  7.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [03:47<08:51,  7.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [03:55<08:43,  7.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [04:02<08:35,  7.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [04:10<08:27,  7.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [04:17<08:19,  7.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [04:25<08:11,  7.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [04:32<08:04,  7.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [04:40<07:56,  7.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [04:47<07:48,  7.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [04:54<07:40,  7.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [05:02<07:33,  7.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [05:09<07:25,  7.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [05:17<07:17,  7.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [05:24<07:10,  7.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [05:31<07:02,  7.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [05:39<06:54,  7.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [05:46<06:47,  7.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [05:54<06:39,  7.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [06:01<06:32,  7.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [06:08<06:24,  7.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [06:16<06:17,  7.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [06:23<06:09,  7.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [06:31<06:02,  7.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [06:38<05:54,  7.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [06:45<05:47,  7.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [06:53<05:39,  7.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [07:00<05:32,  7.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [07:08<05:24,  7.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [07:15<05:17,  7.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [07:22<05:10,  7.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [07:30<05:02,  7.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [07:37<04:55,  7.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [07:44<04:47,  7.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [07:52<04:40,  7.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [07:59<04:32,  7.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [08:07<04:25,  7.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [08:14<04:17,  7.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [08:21<04:10,  7.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [08:29<04:03,  7.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [08:36<03:55,  7.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [08:43<03:48,  7.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [08:51<03:40,  7.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [08:58<03:33,  7.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [09:05<03:25,  7.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [09:13<03:18,  7.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [09:20<03:11,  7.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [09:27<03:03,  7.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [09:35<02:56,  7.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [09:42<02:48,  7.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [09:49<02:41,  7.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [09:57<02:33,  7.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [10:04<02:26,  7.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [10:11<02:19,  7.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [10:19<02:11,  7.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [10:26<02:04,  7.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [10:33<01:56,  7.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [10:41<01:49,  7.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [10:48<01:42,  7.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [10:55<01:34,  7.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [11:02<01:27,  7.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [11:10<01:20,  7.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [11:17<01:12,  7.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [11:24<01:05,  7.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [11:32<00:58,  7.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [11:39<00:51,  7.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [11:46<00:43,  7.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [11:53<00:36,  7.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [12:01<00:29,  7.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [12:08<00:21,  7.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [12:15<00:14,  7.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [12:23<00:07,  7.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [12:30<00:00,  7.27s/it]100%|██████████| 100/100 [12:30<00:00,  7.50s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-03-22:07:42:34,356 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-03-22:07:42:34,356 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-03-22:07:42:34,357 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-03-22:07:42:34,670 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-03-22:07:42:38,710 INFO     [__main__.py:132] Verbosity set to INFO
2025-03-22:07:42:47,989 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-03-22:07:42:47,991 INFO     [__main__.py:205] Selected Tasks: ['code2text_python']
2025-03-22:07:42:47,997 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-03-22:07:42:48,242 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  5.84it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  6.87it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  7.88it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  7.98it/s]
Using the latest cached version of the dataset since CM/codexglue_code2text_python couldn't be found on the Hugging Face Hub
2025-03-22:07:43:05,952 WARNING  [load.py:1568] Using the latest cached version of the dataset since CM/codexglue_code2text_python couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'default' at /home/alireza/.cache/huggingface/datasets/CM___codexglue_code2text_python/default/0.0.0/7bccd264f93b53bd85b20ca84891f987d78245b4 (last modified on Thu Nov 21 15:17:56 2024).
2025-03-22:07:43:05,955 WARNING  [cache.py:70] Found the latest cached dataset configuration 'default' at /home/alireza/.cache/huggingface/datasets/CM___codexglue_code2text_python/default/0.0.0/7bccd264f93b53bd85b20ca84891f987d78245b4 (last modified on Thu Nov 21 15:17:56 2024).
2025-03-22:07:43:41,547 INFO     [task.py:355] Building contexts for task on rank 0...
2025-03-22:07:43:41,563 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:612: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:09<15:43,  9.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:17<14:26,  8.84s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:26<13:53,  8.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:34<13:33,  8.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:42<13:14,  8.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [00:50<12:57,  8.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [00:58<12:39,  8.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:06<12:22,  8.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:14<12:10,  8.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:22<11:58,  7.99s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [01:30<11:47,  7.95s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [01:37<11:33,  7.88s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [01:45<11:22,  7.84s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [01:53<11:10,  7.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:01<11:05,  7.83s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:08<10:53,  7.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [02:16<10:42,  7.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [02:24<10:32,  7.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [02:31<10:23,  7.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [02:39<10:13,  7.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [02:47<10:05,  7.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [02:54<09:59,  7.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [03:02<09:52,  7.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [03:10<09:44,  7.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [03:17<09:33,  7.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [03:25<09:28,  7.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [03:33<09:24,  7.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [03:41<09:12,  7.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [03:48<09:00,  7.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [03:56<08:53,  7.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [04:03<08:45,  7.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [04:11<08:34,  7.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [04:19<08:35,  7.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [04:26<08:26,  7.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [04:34<08:14,  7.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [04:41<08:06,  7.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [04:49<08:01,  7.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [04:57<07:57,  7.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [05:04<07:46,  7.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [05:12<07:35,  7.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [05:19<07:25,  7.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [05:27<07:15,  7.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [05:34<07:10,  7.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [05:42<07:07,  7.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [05:50<06:57,  7.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [05:58<06:54,  7.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [06:05<06:42,  7.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [06:13<06:34,  7.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [06:20<06:24,  7.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [06:27<06:15,  7.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [06:35<06:06,  7.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [06:43<06:06,  7.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [06:50<05:55,  7.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [06:58<05:49,  7.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [07:06<05:46,  7.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [07:13<05:36,  7.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [07:21<05:25,  7.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [07:28<05:16,  7.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [07:36<05:07,  7.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [07:43<04:58,  7.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [07:51<04:50,  7.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [07:58<04:45,  7.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [08:06<04:39,  7.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [08:13<04:30,  7.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [08:21<04:23,  7.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [08:29<04:18,  7.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [08:36<04:09,  7.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [08:43<04:00,  7.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [08:51<03:53,  7.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [08:59<03:46,  7.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [09:06<03:37,  7.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [09:14<03:32,  7.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [09:21<03:23,  7.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [09:29<03:15,  7.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [09:36<03:07,  7.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [09:43<02:58,  7.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [09:51<02:50,  7.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [09:58<02:42,  7.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [10:06<02:38,  7.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [10:14<02:30,  7.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [10:21<02:21,  7.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [10:28<02:13,  7.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [10:36<02:07,  7.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [10:43<01:59,  7.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [10:51<01:51,  7.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [10:58<01:44,  7.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [11:06<01:37,  7.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [11:13<01:29,  7.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [11:21<01:22,  7.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [11:28<01:14,  7.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [11:36<01:06,  7.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [11:43<00:59,  7.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [11:50<00:51,  7.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [11:57<00:43,  7.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [12:05<00:36,  7.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [12:12<00:29,  7.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [12:19<00:21,  7.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [12:26<00:14,  7.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [12:34<00:07,  7.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [12:41<00:00,  7.28s/it]100%|██████████| 100/100 [12:41<00:00,  7.62s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-03-22:07:57:00,324 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-03-22:07:57:00,324 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-03-22:07:57:00,324 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-03-22:07:57:00,663 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-03-22:07:57:11,367 INFO     [__main__.py:132] Verbosity set to INFO
2025-03-22:07:57:20,995 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-03-22:07:57:20,996 INFO     [__main__.py:205] Selected Tasks: ['code2text_python']
2025-03-22:07:57:21,002 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-03-22:07:57:21,288 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  6.24it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  7.30it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  7.92it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  8.13it/s]
2025-03-22:07:58:08,730 INFO     [task.py:355] Building contexts for task on rank 0...
2025-03-22:07:58:08,745 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:612: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:09<15:51,  9.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:17<14:28,  8.86s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:26<13:53,  8.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:34<13:32,  8.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:42<13:12,  8.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [00:50<12:53,  8.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [00:58<12:34,  8.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:06<12:18,  8.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:14<12:05,  7.97s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:22<11:53,  7.92s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [01:29<11:41,  7.88s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [01:37<11:28,  7.83s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [01:45<11:17,  7.79s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [01:52<11:06,  7.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:00<10:56,  7.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:08<10:46,  7.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [02:15<10:36,  7.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [02:23<10:27,  7.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [02:30<10:19,  7.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [02:38<10:10,  7.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [02:46<10:02,  7.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [02:53<09:52,  7.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [03:01<09:43,  7.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [03:08<09:35,  7.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [03:16<09:26,  7.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [03:23<09:18,  7.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [03:31<09:09,  7.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [03:38<09:00,  7.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [03:46<08:51,  7.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [03:53<08:42,  7.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [04:01<08:34,  7.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [04:08<08:26,  7.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [04:16<08:19,  7.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [04:23<08:11,  7.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [04:30<08:04,  7.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [04:38<07:56,  7.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [04:45<07:48,  7.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [04:53<07:40,  7.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [05:00<07:33,  7.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [05:08<07:25,  7.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [05:15<07:17,  7.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [05:22<07:10,  7.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [05:30<07:02,  7.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [05:37<06:55,  7.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [05:45<06:47,  7.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [05:52<06:39,  7.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [05:59<06:32,  7.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [06:07<06:24,  7.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [06:14<06:17,  7.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [06:22<06:09,  7.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [06:29<06:02,  7.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [06:36<05:54,  7.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [06:44<05:47,  7.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [06:51<05:39,  7.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [06:58<05:32,  7.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [07:06<05:25,  7.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [07:13<05:17,  7.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [07:21<05:10,  7.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [07:28<05:02,  7.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [07:35<04:55,  7.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [07:43<04:47,  7.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [07:50<04:40,  7.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [07:57<04:32,  7.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [08:05<04:25,  7.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [08:12<04:17,  7.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [08:20<04:10,  7.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [08:27<04:02,  7.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [08:34<03:55,  7.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [08:42<03:48,  7.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [08:49<03:40,  7.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [08:56<03:33,  7.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [09:04<03:26,  7.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [09:11<03:18,  7.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [09:18<03:11,  7.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [09:26<03:03,  7.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [09:33<02:56,  7.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [09:40<02:48,  7.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [09:48<02:41,  7.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [09:55<02:33,  7.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [10:02<02:26,  7.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [10:10<02:18,  7.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [10:17<02:11,  7.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [10:24<02:04,  7.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [10:31<01:56,  7.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [10:39<01:49,  7.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [10:46<01:42,  7.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [10:54<01:35,  7.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [11:01<01:27,  7.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [11:08<01:20,  7.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [11:15<01:13,  7.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [11:23<01:05,  7.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [11:30<00:58,  7.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [11:37<00:51,  7.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [11:45<00:43,  7.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [11:52<00:36,  7.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [11:59<00:29,  7.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [12:06<00:21,  7.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [12:14<00:14,  7.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [12:21<00:07,  7.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [12:28<00:00,  7.27s/it]100%|██████████| 100/100 [12:28<00:00,  7.49s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-03-22:08:11:14,730 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-03-22:08:11:14,730 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-03-22:08:11:14,731 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-03-22:08:11:15,065 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-03-22:08:11:19,051 INFO     [__main__.py:132] Verbosity set to INFO
2025-03-22:08:11:28,335 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-03-22:08:11:28,337 INFO     [__main__.py:205] Selected Tasks: ['code2text_python']
2025-03-22:08:11:28,345 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-03-22:08:11:28,603 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  5.20it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  6.90it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  7.83it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  7.83it/s]
2025-03-22:08:12:13,616 INFO     [task.py:355] Building contexts for task on rank 0...
2025-03-22:08:12:13,631 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:612: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:09<15:46,  9.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:17<14:25,  8.83s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:26<13:52,  8.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:34<13:31,  8.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:42<13:11,  8.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [00:50<12:52,  8.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [00:58<12:34,  8.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:06<12:21,  8.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:14<12:08,  8.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:22<11:55,  7.95s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [01:29<11:44,  7.91s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [01:37<11:30,  7.85s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [01:45<11:22,  7.85s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [01:53<11:10,  7.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:00<10:58,  7.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:08<10:47,  7.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [02:16<10:37,  7.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [02:23<10:27,  7.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [02:31<10:19,  7.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [02:38<10:13,  7.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [02:46<10:04,  7.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [02:54<10:00,  7.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [03:01<09:49,  7.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [03:09<09:41,  7.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [03:17<09:32,  7.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [03:24<09:22,  7.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [03:32<09:12,  7.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [03:39<09:03,  7.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [03:47<08:53,  7.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [03:54<08:44,  7.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [04:01<08:35,  7.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [04:09<08:27,  7.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [04:16<08:19,  7.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [04:24<08:17,  7.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [04:31<08:07,  7.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [04:39<07:59,  7.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [04:47<07:54,  7.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [04:54<07:44,  7.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [05:02<07:39,  7.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [05:09<07:33,  7.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [05:17<07:25,  7.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [05:24<07:16,  7.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [05:32<07:07,  7.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [05:39<06:58,  7.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [05:46<06:49,  7.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [05:54<06:41,  7.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [06:01<06:37,  7.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [06:09<06:27,  7.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [06:16<06:19,  7.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [06:24<06:15,  7.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [06:31<06:06,  7.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [06:39<05:57,  7.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [06:46<05:49,  7.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [06:54<05:47,  7.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [07:01<05:37,  7.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [07:09<05:32,  7.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [07:16<05:22,  7.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [07:24<05:15,  7.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [07:31<05:06,  7.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [07:39<04:57,  7.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [07:46<04:49,  7.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [07:54<04:43,  7.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [08:01<04:34,  7.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [08:09<04:30,  7.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [08:16<04:22,  7.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [08:23<04:13,  7.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [08:31<04:04,  7.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [08:38<03:56,  7.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [08:46<03:51,  7.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [08:53<03:45,  7.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [09:01<03:36,  7.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [09:08<03:29,  7.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [09:16<03:21,  7.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [09:23<03:14,  7.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [09:31<03:06,  7.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [09:38<02:58,  7.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [09:45<02:50,  7.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [09:53<02:42,  7.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [10:00<02:34,  7.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [10:07<02:26,  7.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [10:15<02:19,  7.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [10:22<02:11,  7.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [10:29<02:04,  7.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [10:36<01:56,  7.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [10:44<01:49,  7.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [10:51<01:42,  7.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [10:58<01:34,  7.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [11:06<01:27,  7.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [11:13<01:20,  7.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [11:20<01:12,  7.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [11:27<01:05,  7.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [11:35<00:58,  7.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [11:42<00:50,  7.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [11:49<00:43,  7.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [11:56<00:36,  7.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [12:04<00:29,  7.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [12:11<00:21,  7.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [12:18<00:14,  7.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [12:25<00:07,  7.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [12:33<00:00,  7.25s/it]100%|██████████| 100/100 [12:33<00:00,  7.53s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-03-22:08:25:23,814 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-03-22:08:25:23,815 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-03-22:08:25:23,815 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-03-22:08:25:24,173 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-03-22:08:25:28,010 INFO     [__main__.py:132] Verbosity set to INFO
2025-03-22:08:25:37,421 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-03-22:08:25:37,423 INFO     [__main__.py:205] Selected Tasks: ['code2text_python']
2025-03-22:08:25:37,431 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-03-22:08:25:37,698 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  5.66it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  7.24it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  8.06it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  8.08it/s]
2025-03-22:08:26:22,854 INFO     [task.py:355] Building contexts for task on rank 0...
2025-03-22:08:26:22,869 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:612: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:09<15:40,  9.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:17<14:20,  8.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:25<13:45,  8.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:34<13:25,  8.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:42<13:05,  8.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [00:50<12:47,  8.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [00:58<12:28,  8.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:05<12:12,  7.96s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:13<11:59,  7.90s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:21<11:47,  7.86s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [01:29<11:35,  7.82s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [01:36<11:23,  7.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [01:44<11:12,  7.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [01:51<11:01,  7.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [01:59<10:50,  7.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:07<10:41,  7.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [02:14<10:31,  7.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [02:22<10:22,  7.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [02:29<10:14,  7.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [02:37<10:05,  7.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [02:44<09:57,  7.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [02:52<09:48,  7.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [02:59<09:39,  7.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [03:07<09:30,  7.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [03:14<09:22,  7.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [03:22<09:14,  7.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [03:29<09:05,  7.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [03:37<08:56,  7.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [03:44<08:47,  7.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [03:51<08:38,  7.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [03:59<08:30,  7.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [04:06<08:22,  7.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [04:13<08:15,  7.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [04:21<08:07,  7.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [04:28<07:59,  7.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [04:36<07:52,  7.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [04:43<07:44,  7.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [04:50<07:37,  7.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [04:58<07:29,  7.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [05:05<07:21,  7.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [05:12<07:14,  7.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [05:20<07:06,  7.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [05:27<06:58,  7.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [05:34<06:51,  7.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [05:42<06:43,  7.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [05:49<06:36,  7.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [05:56<06:28,  7.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [06:04<06:21,  7.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [06:11<06:13,  7.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [06:18<06:06,  7.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [06:26<05:59,  7.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [06:33<05:51,  7.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [06:40<05:44,  7.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [06:48<05:36,  7.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [06:55<05:29,  7.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [07:02<05:22,  7.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [07:10<05:14,  7.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [07:17<05:08,  7.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [07:24<05:00,  7.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [07:32<04:53,  7.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [07:39<04:45,  7.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [07:46<04:38,  7.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [07:54<04:32,  7.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [08:01<04:25,  7.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [08:08<04:17,  7.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [08:16<04:09,  7.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [08:23<04:01,  7.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [08:30<03:54,  7.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [08:38<03:46,  7.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [08:45<03:39,  7.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [08:52<03:31,  7.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [09:00<03:24,  7.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [09:07<03:16,  7.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [09:14<03:09,  7.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [09:21<03:02,  7.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [09:29<02:54,  7.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [09:36<02:47,  7.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [09:43<02:39,  7.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [09:50<02:32,  7.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [09:58<02:25,  7.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [10:05<02:17,  7.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [10:12<02:10,  7.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [10:19<02:03,  7.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [10:27<01:55,  7.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [10:34<01:48,  7.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [10:41<01:41,  7.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [10:48<01:34,  7.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [10:56<01:26,  7.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [11:03<01:19,  7.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [11:10<01:12,  7.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [11:17<01:05,  7.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [11:24<00:57,  7.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [11:32<00:50,  7.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [11:39<00:43,  7.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [11:46<00:36,  7.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [11:53<00:28,  7.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [12:00<00:21,  7.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [12:08<00:14,  7.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [12:15<00:07,  7.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [12:22<00:00,  7.21s/it]100%|██████████| 100/100 [12:22<00:00,  7.43s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-03-22:08:40:32,838 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-03-22:08:40:32,839 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-03-22:08:40:32,839 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-03-22:08:40:33,210 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-03-22:08:40:41,918 INFO     [__main__.py:132] Verbosity set to INFO
2025-03-22:08:40:51,271 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-03-22:08:40:51,273 INFO     [__main__.py:205] Selected Tasks: ['code2text_python']
2025-03-22:08:40:51,282 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-03-22:08:40:51,547 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  5.41it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  7.05it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  7.98it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  8.00it/s]
Using the latest cached version of the dataset since CM/codexglue_code2text_python couldn't be found on the Hugging Face Hub
2025-03-22:08:41:08,366 WARNING  [load.py:1568] Using the latest cached version of the dataset since CM/codexglue_code2text_python couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'default' at /home/alireza/.cache/huggingface/datasets/CM___codexglue_code2text_python/default/0.0.0/7bccd264f93b53bd85b20ca84891f987d78245b4 (last modified on Thu Nov 21 15:17:56 2024).
2025-03-22:08:41:08,368 WARNING  [cache.py:70] Found the latest cached dataset configuration 'default' at /home/alireza/.cache/huggingface/datasets/CM___codexglue_code2text_python/default/0.0.0/7bccd264f93b53bd85b20ca84891f987d78245b4 (last modified on Thu Nov 21 15:17:56 2024).
2025-03-22:08:41:43,872 INFO     [task.py:355] Building contexts for task on rank 0...
2025-03-22:08:41:43,888 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:612: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:36, 12.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<19:00, 11.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:12, 11.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:45<17:41, 11.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:55<17:06, 10.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:05<16:28, 10.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:14<15:44, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:24<15:08,  9.88s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:33<14:42,  9.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:42<14:20,  9.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [01:51<13:58,  9.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:00<13:33,  9.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:09<13:13,  9.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:18<12:55,  9.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:26<12:37,  8.91s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:35<12:21,  8.83s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [02:44<12:07,  8.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [02:52<11:54,  8.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:01<11:42,  8.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:09<11:31,  8.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:18<11:20,  8.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:26<11:07,  8.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [03:35<10:55,  8.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [03:43<10:45,  8.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [03:52<10:35,  8.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:00<10:24,  8.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:08<10:12,  8.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:16<09:59,  8.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [04:25<09:47,  8.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [04:33<09:36,  8.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [04:41<09:26,  8.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [04:49<09:16,  8.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [04:57<09:07,  8.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [05:05<09:00,  8.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [05:14<08:51,  8.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [05:22<08:42,  8.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [05:30<08:33,  8.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [05:38<08:24,  8.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [05:46<08:15,  8.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [05:54<08:06,  8.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [06:02<07:57,  8.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [06:10<07:49,  8.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [06:18<07:40,  8.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [06:26<07:32,  8.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [06:34<07:23,  8.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [06:42<07:15,  8.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [06:50<07:06,  8.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [06:58<06:58,  8.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [07:06<06:49,  8.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [07:15<06:41,  8.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [07:23<06:33,  8.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [07:31<06:25,  8.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [07:39<06:17,  8.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [07:47<06:08,  8.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [07:55<06:00,  8.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [08:03<05:52,  8.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [08:11<05:44,  8.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [08:19<05:36,  8.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [08:27<05:28,  8.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [08:35<05:19,  8.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [08:43<05:11,  7.99s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [08:51<05:03,  7.99s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [08:59<04:55,  7.99s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [09:07<04:47,  7.99s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [09:14<04:39,  7.97s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [09:22<04:30,  7.96s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [09:30<04:22,  7.95s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [09:38<04:14,  7.95s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [09:46<04:06,  7.94s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [09:54<03:58,  7.94s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [10:02<03:49,  7.93s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [10:10<03:41,  7.93s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [10:18<03:33,  7.92s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [10:26<03:25,  7.91s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [10:34<03:17,  7.91s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [10:42<03:09,  7.90s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [10:49<03:01,  7.90s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [10:57<02:53,  7.89s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [11:05<02:45,  7.89s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [11:13<02:37,  7.88s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [11:21<02:29,  7.88s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [11:29<02:21,  7.87s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [11:37<02:13,  7.86s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [11:44<02:05,  7.85s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [11:52<01:57,  7.85s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [12:00<01:49,  7.84s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [12:08<01:41,  7.83s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [12:16<01:33,  7.82s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [12:23<01:25,  7.82s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [12:31<01:18,  7.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [12:39<01:10,  7.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [12:47<01:02,  7.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [12:55<00:54,  7.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [13:02<00:46,  7.79s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [13:10<00:38,  7.79s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [13:18<00:31,  7.79s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [13:26<00:23,  7.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [13:34<00:15,  7.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [13:41<00:07,  7.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [13:49<00:00,  7.78s/it]100%|██████████| 100/100 [13:49<00:00,  8.30s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-03-22:08:56:10,525 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-03-22:08:56:10,525 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-03-22:08:56:10,525 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-03-22:08:56:10,821 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-03-22:08:56:14,620 INFO     [__main__.py:132] Verbosity set to INFO
2025-03-22:08:56:24,718 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-03-22:08:56:24,720 INFO     [__main__.py:205] Selected Tasks: ['code2text_python']
2025-03-22:08:56:24,728 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-03-22:08:56:24,995 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  5.86it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  6.73it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  7.68it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  7.83it/s]
2025-03-22:08:57:29,204 INFO     [task.py:355] Building contexts for task on rank 0...
2025-03-22:08:57:29,219 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:612: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:34, 12.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<19:04, 11.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:18, 11.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:45<17:47, 11.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:55<17:13, 10.88s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:05<16:35, 10.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:15<15:51, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:24<15:15,  9.96s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:33<14:49,  9.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:43<14:27,  9.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [01:52<14:05,  9.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:01<13:44,  9.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:10<13:23,  9.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:19<13:04,  9.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:28<12:45,  9.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:36<12:29,  8.92s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [02:45<12:14,  8.85s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [02:54<12:01,  8.79s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:02<11:48,  8.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:11<11:37,  8.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:20<11:26,  8.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:28<11:13,  8.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [03:37<11:01,  8.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [03:45<10:50,  8.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [03:54<10:40,  8.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:02<10:30,  8.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:10<10:17,  8.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:19<10:04,  8.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [04:27<09:52,  8.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [04:35<09:41,  8.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [04:43<09:31,  8.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [04:51<09:21,  8.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:00<09:12,  8.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [05:08<09:03,  8.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [05:16<08:54,  8.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [05:24<08:45,  8.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [05:32<08:37,  8.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [05:41<08:28,  8.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [05:49<08:19,  8.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [05:57<08:10,  8.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [06:05<08:01,  8.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [06:13<07:53,  8.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [06:21<07:44,  8.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [06:30<07:36,  8.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [06:38<07:27,  8.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [06:46<07:19,  8.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [06:54<07:10,  8.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [07:02<07:02,  8.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [07:10<06:53,  8.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [07:18<06:45,  8.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [07:26<06:36,  8.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [07:34<06:28,  8.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [07:42<06:20,  8.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [07:51<06:12,  8.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [07:59<06:04,  8.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [08:07<05:55,  8.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [08:15<05:47,  8.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [08:23<05:39,  8.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [08:31<05:31,  8.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [08:39<05:22,  8.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [08:47<05:14,  8.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [08:55<05:06,  8.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [09:03<04:58,  8.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [09:11<04:50,  8.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [09:19<04:41,  8.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [09:27<04:33,  8.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [09:35<04:24,  8.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [09:43<04:16,  8.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [09:51<04:08,  8.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [09:59<04:00,  8.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [10:07<03:52,  8.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [10:15<03:43,  8.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [10:23<03:35,  7.99s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [10:31<03:27,  7.99s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [10:39<03:19,  7.98s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [10:47<03:11,  7.98s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [10:55<03:03,  7.97s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [11:03<02:55,  7.96s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [11:11<02:47,  7.96s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [11:19<02:39,  7.95s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [11:27<02:31,  7.95s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [11:35<02:22,  7.94s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [11:43<02:14,  7.93s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [11:51<02:06,  7.93s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [11:58<01:58,  7.92s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [12:06<01:50,  7.92s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [12:14<01:42,  7.91s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [12:22<01:34,  7.90s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [12:30<01:26,  7.89s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [12:38<01:18,  7.88s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [12:46<01:10,  7.88s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [12:54<01:03,  7.88s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [13:01<00:55,  7.87s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [13:09<00:47,  7.87s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [13:17<00:39,  7.86s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [13:25<00:31,  7.86s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [13:33<00:23,  7.86s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [13:41<00:15,  7.85s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [13:49<00:07,  7.85s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [13:56<00:00,  7.85s/it]100%|██████████| 100/100 [13:56<00:00,  8.37s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-03-22:09:12:03,297 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-03-22:09:12:03,297 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-03-22:09:12:03,298 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-03-22:09:12:03,550 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-03-22:09:12:07,003 INFO     [__main__.py:132] Verbosity set to INFO
2025-03-22:09:12:16,998 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-03-22:09:12:17,000 INFO     [__main__.py:205] Selected Tasks: ['code2text_python']
2025-03-22:09:12:17,008 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-03-22:09:12:17,247 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  5.55it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  7.11it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  7.97it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  8.64it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  7.97it/s]
2025-03-22:09:13:02,452 INFO     [task.py:355] Building contexts for task on rank 0...
2025-03-22:09:13:02,469 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:612: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:29, 12.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<19:02, 11.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:17, 11.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:45<17:47, 11.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:55<17:13, 10.88s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:05<16:35, 10.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:15<15:52, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:24<15:16,  9.96s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:34<14:49,  9.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:43<14:28,  9.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [01:52<14:05,  9.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:01<13:41,  9.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:10<13:21,  9.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:19<13:02,  9.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:28<12:44,  9.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:36<12:29,  8.92s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [02:45<12:14,  8.85s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [02:54<12:01,  8.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:02<11:49,  8.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:11<11:37,  8.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:20<11:27,  8.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:28<11:14,  8.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [03:37<11:02,  8.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [03:45<10:52,  8.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [03:54<10:42,  8.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:02<10:31,  8.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:10<10:18,  8.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:19<10:05,  8.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [04:27<09:53,  8.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [04:35<09:42,  8.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [04:43<09:32,  8.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [04:52<09:23,  8.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:00<09:14,  8.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [05:08<09:04,  8.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [05:16<08:55,  8.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [05:25<08:47,  8.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [05:33<08:39,  8.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [05:41<08:30,  8.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [05:49<08:21,  8.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [05:57<08:12,  8.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [06:06<08:04,  8.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [06:14<07:55,  8.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [06:22<07:46,  8.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [06:30<07:37,  8.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [06:38<07:28,  8.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [06:46<07:20,  8.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [06:54<07:11,  8.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [07:03<07:02,  8.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [07:11<06:54,  8.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [07:19<06:46,  8.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [07:27<06:38,  8.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [07:35<06:29,  8.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [07:43<06:21,  8.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [07:51<06:13,  8.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [07:59<06:04,  8.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [08:08<05:57,  8.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [08:16<05:48,  8.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [08:24<05:40,  8.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [08:32<05:32,  8.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [08:40<05:23,  8.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [08:48<05:15,  8.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [08:56<05:07,  8.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [09:04<04:59,  8.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [09:12<04:50,  8.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [09:20<04:42,  8.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [09:28<04:34,  8.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [09:36<04:25,  8.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [09:44<04:18,  8.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [09:52<04:09,  8.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [10:00<04:01,  8.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [10:08<03:53,  8.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [10:16<03:44,  8.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [10:24<03:36,  8.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [10:32<03:28,  8.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [10:41<03:20,  8.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [10:49<03:12,  8.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [10:56<03:04,  8.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [11:04<02:55,  7.99s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [11:12<02:47,  7.99s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [11:20<02:39,  7.98s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [11:28<02:31,  7.99s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [11:36<02:23,  7.97s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [11:44<02:15,  7.96s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [11:52<02:07,  7.96s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [12:00<01:59,  7.94s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [12:08<01:51,  7.94s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [12:16<01:43,  7.94s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [12:24<01:35,  7.93s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [12:32<01:27,  7.92s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [12:40<01:19,  7.91s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [12:48<01:11,  7.91s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [12:56<01:03,  7.91s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [13:03<00:55,  7.90s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [13:11<00:47,  7.89s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [13:19<00:39,  7.88s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [13:27<00:31,  7.88s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [13:35<00:23,  7.88s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [13:43<00:15,  7.87s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [13:51<00:07,  7.88s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [13:58<00:00,  7.88s/it]100%|██████████| 100/100 [13:58<00:00,  8.39s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-03-22:09:27:38,447 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-03-22:09:27:38,447 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-03-22:09:27:38,447 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-03-22:09:27:38,734 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-03-22:09:27:42,601 INFO     [__main__.py:132] Verbosity set to INFO
2025-03-22:09:27:52,220 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-03-22:09:27:52,222 INFO     [__main__.py:205] Selected Tasks: ['code2text_python']
2025-03-22:09:27:52,230 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-03-22:09:27:52,479 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  5.85it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  6.54it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  7.44it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  8.24it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  7.60it/s]
2025-03-22:09:28:36,695 INFO     [task.py:355] Building contexts for task on rank 0...
2025-03-22:09:28:36,710 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:612: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:15, 12.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<18:52, 11.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:09, 11.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:44<17:39, 11.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:55<17:05, 10.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:05<16:28, 10.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:14<15:44, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:23<15:09,  9.88s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:33<14:42,  9.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:42<14:21,  9.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [01:51<13:58,  9.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:00<13:34,  9.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:09<13:14,  9.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:18<12:56,  9.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:26<12:38,  8.92s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:35<12:22,  8.84s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [02:44<12:08,  8.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [02:52<11:55,  8.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:01<11:43,  8.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:09<11:32,  8.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:18<11:21,  8.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:26<11:08,  8.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [03:35<10:57,  8.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [03:43<10:46,  8.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [03:52<10:36,  8.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:00<10:25,  8.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:08<10:13,  8.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:17<09:59,  8.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [04:25<09:47,  8.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [04:33<09:36,  8.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [04:41<09:26,  8.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [04:49<09:17,  8.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [04:57<09:08,  8.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [05:05<08:59,  8.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [05:14<08:50,  8.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [05:22<08:42,  8.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [05:30<08:33,  8.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [05:38<08:24,  8.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [05:46<08:16,  8.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [05:54<08:07,  8.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [06:02<07:58,  8.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [06:10<07:49,  8.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [06:18<07:41,  8.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [06:26<07:32,  8.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [06:35<07:24,  8.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [06:43<07:15,  8.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [06:51<07:07,  8.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [06:59<06:58,  8.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [07:07<06:50,  8.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [07:15<06:42,  8.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [07:23<06:34,  8.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [07:31<06:25,  8.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [07:39<06:17,  8.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [07:47<06:09,  8.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [07:55<06:01,  8.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [08:03<05:53,  8.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [08:11<05:45,  8.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [08:19<05:36,  8.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [08:27<05:28,  8.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [08:35<05:20,  8.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [08:43<05:12,  8.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [08:51<05:04,  8.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [08:59<04:55,  8.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [09:07<04:47,  8.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [09:15<04:39,  7.98s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [09:23<04:31,  7.97s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [09:31<04:22,  7.97s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [09:39<04:14,  7.96s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [09:47<04:06,  7.95s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [09:55<03:58,  7.95s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [10:03<03:50,  7.94s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [10:10<03:42,  7.94s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [10:18<03:34,  7.93s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [10:26<03:26,  7.93s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [10:34<03:18,  7.92s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [10:42<03:10,  7.92s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [10:50<03:01,  7.91s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [10:58<02:53,  7.91s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [11:06<02:45,  7.90s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [11:14<02:37,  7.90s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [11:22<02:29,  7.89s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [11:29<02:21,  7.88s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [11:37<02:13,  7.88s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [11:45<02:05,  7.87s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [11:53<01:57,  7.86s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [12:01<01:50,  7.86s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [12:09<01:42,  7.85s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [12:16<01:34,  7.84s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [12:24<01:26,  7.83s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [12:32<01:18,  7.82s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [12:40<01:10,  7.82s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [12:48<01:02,  7.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [12:55<00:54,  7.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [13:03<00:46,  7.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [13:11<00:39,  7.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [13:19<00:31,  7.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [13:27<00:23,  7.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [13:34<00:15,  7.79s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [13:42<00:07,  7.79s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [13:50<00:00,  7.79s/it]100%|██████████| 100/100 [13:50<00:00,  8.31s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-03-22:09:43:04,358 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-03-22:09:43:04,358 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-03-22:09:43:04,358 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-03-22:09:43:04,685 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-03-22:09:43:08,825 INFO     [__main__.py:132] Verbosity set to INFO
2025-03-22:09:43:18,074 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-03-22:09:43:18,076 INFO     [__main__.py:205] Selected Tasks: ['code2text_python']
2025-03-22:09:43:18,083 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-03-22:09:43:18,344 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  5.79it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  7.34it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  8.07it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  8.05it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  7.72it/s]
2025-03-22:09:44:35,274 INFO     [task.py:355] Building contexts for task on rank 0...
2025-03-22:09:44:35,289 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:612: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:27, 12.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<18:58, 11.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:12, 11.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:45<17:41, 11.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:55<17:07, 10.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:05<16:29, 10.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:14<15:45, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:24<15:09,  9.89s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:33<14:43,  9.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:42<14:21,  9.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [01:51<13:59,  9.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:00<13:34,  9.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:09<13:14,  9.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:18<12:56,  9.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:26<12:38,  8.92s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:35<12:22,  8.84s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [02:44<12:08,  8.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [02:52<11:55,  8.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:01<11:43,  8.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:10<11:32,  8.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:18<11:21,  8.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:27<11:09,  8.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [03:35<10:57,  8.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [03:43<10:46,  8.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [03:52<10:36,  8.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:00<10:25,  8.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:09<10:13,  8.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:17<10:00,  8.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [04:25<09:48,  8.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [04:33<09:37,  8.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [04:41<09:27,  8.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [04:49<09:17,  8.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [04:57<09:08,  8.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [05:06<08:59,  8.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [05:14<08:50,  8.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [05:22<08:42,  8.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [05:30<08:33,  8.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [05:38<08:25,  8.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [05:46<08:16,  8.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [05:54<08:07,  8.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [06:03<07:58,  8.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [06:11<07:49,  8.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [06:19<07:41,  8.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [06:27<07:32,  8.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [06:35<07:24,  8.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [06:43<07:16,  8.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [06:51<07:07,  8.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [06:59<06:59,  8.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [07:07<06:50,  8.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [07:15<06:42,  8.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [07:23<06:34,  8.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [07:31<06:26,  8.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [07:39<06:17,  8.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [07:47<06:09,  8.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [07:55<06:01,  8.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [08:03<05:53,  8.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [08:11<05:45,  8.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [08:19<05:37,  8.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [08:27<05:28,  8.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [08:35<05:20,  8.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [08:43<05:12,  8.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [08:51<05:04,  8.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [08:59<04:56,  8.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [09:07<04:48,  8.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [09:15<04:39,  7.99s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [09:23<04:31,  7.98s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [09:31<04:23,  7.97s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [09:39<04:14,  7.97s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [09:47<04:06,  7.96s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [09:55<03:58,  7.95s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [10:03<03:50,  7.95s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [10:11<03:42,  7.94s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [10:19<03:34,  7.94s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [10:27<03:26,  7.93s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [10:35<03:18,  7.93s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [10:43<03:10,  7.92s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [10:50<03:02,  7.91s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [10:58<02:54,  7.91s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [11:06<02:46,  7.90s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [11:14<02:38,  7.90s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [11:22<02:29,  7.89s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [11:30<02:21,  7.89s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [11:38<02:13,  7.88s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [11:46<02:05,  7.87s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [11:53<01:57,  7.86s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [12:01<01:50,  7.86s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [12:09<01:42,  7.85s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [12:17<01:34,  7.84s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [12:25<01:26,  7.83s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [12:33<01:18,  7.83s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [12:40<01:10,  7.82s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [12:48<01:02,  7.82s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [12:56<00:54,  7.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [13:04<00:46,  7.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [13:12<00:39,  7.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [13:19<00:31,  7.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [13:27<00:23,  7.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [13:35<00:15,  7.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [13:43<00:07,  7.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [13:51<00:00,  7.80s/it]100%|██████████| 100/100 [13:51<00:00,  8.31s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-03-22:10:00:13,519 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-03-22:10:00:13,520 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-03-22:10:00:13,520 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-03-22:10:00:13,890 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-03-22:10:00:17,819 INFO     [__main__.py:132] Verbosity set to INFO
2025-03-22:10:00:27,042 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-03-22:10:00:27,043 INFO     [__main__.py:205] Selected Tasks: ['code2text_python']
2025-03-22:10:00:27,050 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-03-22:10:00:27,307 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  5.99it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  7.66it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  8.51it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  8.53it/s]
2025-03-22:10:01:23,449 INFO     [task.py:355] Building contexts for task on rank 0...
2025-03-22:10:01:23,465 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:612: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:16<27:45, 16.82s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:32<26:05, 15.98s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:47<25:05, 15.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [01:02<24:26, 15.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [01:16<23:29, 14.83s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:29<22:25, 14.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:41<21:08, 13.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:53<20:05, 13.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [02:05<19:20, 12.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [02:17<18:45, 12.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [02:29<18:06, 12.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:40<17:23, 11.86s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:51<16:49, 11.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [03:02<16:18, 11.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [03:12<15:49, 11.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [03:23<15:23, 11.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:33<15:01, 10.87s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:44<14:42, 10.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:54<14:25, 10.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [04:05<14:09, 10.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [04:15<13:54, 10.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [04:26<13:35, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:36<13:17, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:46<13:02, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:56<12:47, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [05:06<12:33, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [05:16<12:15, 10.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [05:25<11:55,  9.93s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:35<11:37,  9.82s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:45<11:22,  9.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:54<11:08,  9.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [06:04<10:56,  9.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [06:13<10:44,  9.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [06:23<10:33,  9.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:32<10:23,  9.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:42<10:12,  9.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:51<10:01,  9.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [07:01<09:50,  9.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [07:10<09:39,  9.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [07:20<09:28,  9.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:29<09:17,  9.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:38<09:07,  9.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:48<08:56,  9.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:57<08:46,  9.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [08:07<08:36,  9.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [08:16<08:26,  9.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:25<08:15,  9.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:35<08:05,  9.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:44<07:55,  9.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:53<07:45,  9.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [09:02<07:36,  9.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:12<07:26,  9.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:21<07:16,  9.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:30<07:07,  9.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:39<06:57,  9.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:49<06:47,  9.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [09:58<06:38,  9.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:07<06:28,  9.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:16<06:18,  9.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:26<06:09,  9.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:35<05:59,  9.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:44<05:50,  9.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [10:53<05:40,  9.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:02<05:31,  9.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:12<05:21,  9.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:21<05:11,  9.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:30<05:01,  9.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:39<04:52,  9.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [11:48<04:42,  9.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [11:57<04:33,  9.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:06<04:23,  9.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:15<04:14,  9.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:24<04:05,  9.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:33<03:55,  9.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [12:42<03:45,  9.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [12:51<03:36,  9.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:00<03:27,  9.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:09<03:18,  9.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:18<03:09,  9.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [13:27<03:00,  9.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [13:36<02:50,  8.99s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [13:45<02:41,  8.96s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [13:54<02:32,  8.95s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:03<02:22,  8.93s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:12<02:13,  8.91s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [14:21<02:04,  8.90s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [14:29<01:55,  8.88s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [14:38<01:46,  8.86s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [14:47<01:37,  8.83s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [14:56<01:28,  8.82s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:05<01:19,  8.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [15:13<01:10,  8.79s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [15:22<01:01,  8.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [15:31<00:52,  8.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [15:40<00:43,  8.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [15:48<00:35,  8.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [15:57<00:26,  8.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [16:06<00:17,  8.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [16:15<00:08,  8.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [16:23<00:00,  8.74s/it]100%|██████████| 100/100 [16:23<00:00,  9.84s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-03-22:10:18:24,261 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-03-22:10:18:24,261 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-03-22:10:18:24,261 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-03-22:10:18:24,601 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-03-22:10:18:28,591 INFO     [__main__.py:132] Verbosity set to INFO
2025-03-22:10:18:38,020 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-03-22:10:18:38,022 INFO     [__main__.py:205] Selected Tasks: ['code2text_python']
2025-03-22:10:18:38,030 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-03-22:10:18:38,295 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  5.75it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  7.35it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  7.68it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  8.35it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  7.82it/s]
2025-03-22:10:19:23,130 INFO     [task.py:355] Building contexts for task on rank 0...
2025-03-22:10:19:23,146 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:612: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:16<27:49, 16.86s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:32<26:07, 16.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:47<25:07, 15.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [01:02<24:28, 15.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [01:16<23:30, 14.84s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:29<22:26, 14.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:41<21:09, 13.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:53<20:07, 13.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [02:05<19:21, 12.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [02:17<18:46, 12.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [02:29<18:10, 12.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:40<17:27, 11.91s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:51<16:54, 11.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [03:02<16:24, 11.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [03:13<15:55, 11.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [03:23<15:29, 11.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:34<15:07, 10.94s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:45<14:48, 10.84s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:55<14:31, 10.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [04:06<14:15, 10.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [04:16<13:59, 10.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [04:27<13:41, 10.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:37<13:23, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:47<13:07, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:57<12:53, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [05:07<12:39, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [05:17<12:20, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [05:27<12:00, 10.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:37<11:42,  9.90s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:46<11:27,  9.82s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:56<11:13,  9.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [06:05<11:01,  9.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [06:15<10:49,  9.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [06:25<10:38,  9.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:34<10:27,  9.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:44<10:16,  9.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:53<10:05,  9.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [07:03<09:54,  9.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [07:13<09:44,  9.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [07:22<09:33,  9.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:31<09:21,  9.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:41<09:11,  9.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:50<09:00,  9.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [08:00<08:50,  9.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [08:09<08:39,  9.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [08:19<08:29,  9.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:28<08:19,  9.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:37<08:09,  9.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:47<07:59,  9.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:56<07:49,  9.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [09:05<07:39,  9.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:15<07:29,  9.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:24<07:19,  9.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:33<07:10,  9.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:43<07:00,  9.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:52<06:50,  9.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [10:01<06:41,  9.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:11<06:31,  9.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:20<06:21,  9.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:29<06:11,  9.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:39<06:02,  9.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:48<05:52,  9.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [10:57<05:42,  9.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:06<05:33,  9.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:16<05:23,  9.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:25<05:13,  9.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:34<05:04,  9.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:43<04:54,  9.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [11:52<04:44,  9.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:01<04:35,  9.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:11<04:26,  9.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:20<04:17,  9.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:29<04:07,  9.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:38<03:57,  9.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [12:47<03:47,  9.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [12:56<03:38,  9.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:05<03:28,  9.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:14<03:19,  9.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:23<03:10,  9.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [13:32<03:00,  9.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [13:41<02:51,  9.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [13:50<02:42,  9.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [13:59<02:33,  9.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:08<02:23,  8.99s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:17<02:14,  8.97s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [14:26<02:05,  8.96s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [14:35<01:56,  8.95s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [14:44<01:47,  8.93s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [14:53<01:37,  8.91s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:02<01:28,  8.89s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:10<01:19,  8.88s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [15:19<01:10,  8.86s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [15:28<01:01,  8.85s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [15:37<00:53,  8.84s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [15:46<00:44,  8.83s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [15:54<00:35,  8.83s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:03<00:26,  8.82s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [16:12<00:17,  8.82s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [16:21<00:08,  8.82s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [16:30<00:00,  8.81s/it]100%|██████████| 100/100 [16:30<00:00,  9.90s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-03-22:10:36:30,429 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-03-22:10:36:30,429 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-03-22:10:36:30,430 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-03-22:10:36:30,719 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-03-22:10:36:34,501 INFO     [__main__.py:132] Verbosity set to INFO
2025-03-22:10:36:44,342 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-03-22:10:36:44,344 INFO     [__main__.py:205] Selected Tasks: ['code2text_python']
2025-03-22:10:36:44,352 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-03-22:10:36:44,617 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  6.27it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  7.40it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  8.12it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  8.32it/s]
2025-03-22:10:37:31,679 INFO     [task.py:355] Building contexts for task on rank 0...
2025-03-22:10:37:31,694 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:612: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:16<27:31, 16.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:31<25:55, 15.87s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:46<24:57, 15.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [01:01<24:19, 15.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [01:15<23:21, 14.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:28<22:18, 14.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:41<21:01, 13.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:53<19:59, 13.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [02:04<19:14, 12.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [02:16<18:39, 12.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [02:28<18:02, 12.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:39<17:20, 11.82s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:50<16:47, 11.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [03:01<16:17, 11.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [03:11<15:48, 11.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [03:22<15:22, 10.99s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:33<15:01, 10.86s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:43<14:42, 10.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:54<14:25, 10.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [04:04<14:08, 10.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [04:15<13:53, 10.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [04:25<13:35, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:35<13:17, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:45<13:01, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:55<12:47, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [05:05<12:33, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [05:15<12:14, 10.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [05:25<11:54,  9.92s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:34<11:36,  9.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:44<11:21,  9.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:53<11:08,  9.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [06:03<10:55,  9.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [06:12<10:43,  9.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [06:22<10:32,  9.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:31<10:22,  9.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:41<10:11,  9.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:50<10:00,  9.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [07:00<09:50,  9.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [07:09<09:39,  9.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [07:19<09:28,  9.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:28<09:17,  9.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:37<09:06,  9.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:47<08:56,  9.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:56<08:45,  9.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [08:06<08:35,  9.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [08:15<08:25,  9.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:24<08:15,  9.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:33<08:04,  9.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:43<07:55,  9.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:52<07:45,  9.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [09:01<07:35,  9.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:11<07:26,  9.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:20<07:16,  9.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:29<07:06,  9.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:38<06:57,  9.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:48<06:47,  9.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [09:57<06:37,  9.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:06<06:28,  9.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:15<06:18,  9.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:24<06:08,  9.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:34<05:59,  9.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:43<05:49,  9.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [10:52<05:40,  9.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:01<05:30,  9.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:10<05:20,  9.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:19<05:11,  9.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:28<05:01,  9.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:38<04:53,  9.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [11:47<04:43,  9.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [11:56<04:34,  9.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:05<04:24,  9.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:14<04:14,  9.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:23<04:05,  9.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:32<03:55,  9.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [12:41<03:45,  9.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [12:50<03:36,  9.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [12:59<03:27,  9.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:08<03:17,  8.99s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:17<03:08,  8.98s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [13:26<02:59,  8.97s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [13:35<02:50,  8.95s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [13:44<02:40,  8.94s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [13:53<02:31,  8.93s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:01<02:22,  8.91s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:10<02:13,  8.90s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [14:19<02:04,  8.89s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [14:28<01:55,  8.87s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [14:37<01:46,  8.85s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [14:46<01:37,  8.83s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [14:54<01:28,  8.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:03<01:19,  8.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [15:12<01:10,  8.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [15:21<01:01,  8.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [15:29<00:52,  8.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [15:38<00:43,  8.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [15:47<00:35,  8.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [15:56<00:26,  8.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [16:04<00:17,  8.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [16:13<00:08,  8.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [16:22<00:00,  8.73s/it]100%|██████████| 100/100 [16:22<00:00,  9.82s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-03-22:10:54:30,745 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-03-22:10:54:30,745 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-03-22:10:54:30,745 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-03-22:10:54:31,069 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-03-22:10:54:36,080 INFO     [__main__.py:132] Verbosity set to INFO
2025-03-22:10:54:45,739 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-03-22:10:54:45,741 INFO     [__main__.py:205] Selected Tasks: ['code2text_python']
2025-03-22:10:54:45,747 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-03-22:10:54:46,001 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  6.20it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  7.75it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  8.48it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  8.61it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  8.22it/s]
2025-03-22:10:55:34,905 INFO     [task.py:355] Building contexts for task on rank 0...
2025-03-22:10:55:34,921 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:612: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:16<27:39, 16.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:32<25:58, 15.91s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:46<24:58, 15.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [01:01<24:19, 15.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [01:15<23:22, 14.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:29<22:18, 14.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:41<21:01, 13.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:53<19:59, 13.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [02:04<19:14, 12.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [02:16<18:38, 12.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [02:28<18:02, 12.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:39<17:20, 11.82s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:50<16:47, 11.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [03:01<16:17, 11.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [03:12<15:47, 11.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [03:22<15:22, 10.98s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:33<15:00, 10.85s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:43<14:41, 10.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:54<14:25, 10.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [04:04<14:08, 10.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [04:15<13:53, 10.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [04:25<13:35, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:35<13:16, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:45<13:01, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:55<12:47, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [05:05<12:33, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [05:15<12:14, 10.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [05:25<11:54,  9.92s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:34<11:36,  9.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:44<11:21,  9.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:53<11:08,  9.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [06:03<10:55,  9.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [06:12<10:43,  9.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [06:22<10:32,  9.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:31<10:22,  9.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:41<10:11,  9.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:50<10:00,  9.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [07:00<09:49,  9.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [07:09<09:39,  9.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [07:19<09:28,  9.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:28<09:17,  9.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:37<09:06,  9.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:47<08:55,  9.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:56<08:45,  9.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [08:06<08:35,  9.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [08:15<08:25,  9.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:24<08:15,  9.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:33<08:04,  9.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:43<07:54,  9.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:52<07:45,  9.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [09:01<07:35,  9.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:11<07:25,  9.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:20<07:16,  9.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:29<07:06,  9.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:38<06:56,  9.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:48<06:47,  9.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [09:57<06:37,  9.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:06<06:28,  9.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:15<06:18,  9.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:24<06:08,  9.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:34<05:59,  9.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:43<05:49,  9.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [10:52<05:41,  9.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:01<05:31,  9.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:10<05:21,  9.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:19<05:11,  9.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:29<05:01,  9.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:38<04:52,  9.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [11:47<04:42,  9.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [11:56<04:33,  9.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:05<04:23,  9.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:14<04:14,  9.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:23<04:04,  9.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:32<03:54,  9.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [12:41<03:45,  9.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [12:50<03:36,  9.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [12:59<03:26,  9.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:08<03:17,  8.99s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:17<03:08,  8.98s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [13:26<02:59,  8.97s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [13:35<02:50,  8.95s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [13:44<02:40,  8.94s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [13:52<02:31,  8.93s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:01<02:22,  8.91s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:10<02:13,  8.90s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [14:19<02:04,  8.89s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [14:28<01:55,  8.87s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [14:37<01:46,  8.85s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [14:45<01:37,  8.83s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [14:54<01:28,  8.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:03<01:19,  8.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [15:12<01:10,  8.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [15:21<01:01,  8.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [15:29<00:52,  8.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [15:38<00:43,  8.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [15:47<00:35,  8.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [15:56<00:26,  8.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [16:04<00:17,  8.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [16:13<00:08,  8.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [16:22<00:00,  8.74s/it]100%|██████████| 100/100 [16:22<00:00,  9.82s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-03-22:11:12:34,375 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-03-22:11:12:34,375 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-03-22:11:12:34,375 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-03-22:11:12:34,678 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-03-22:11:12:38,575 INFO     [__main__.py:132] Verbosity set to INFO
2025-03-22:11:12:47,753 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-03-22:11:12:47,755 INFO     [__main__.py:205] Selected Tasks: ['code2text_python']
2025-03-22:11:12:47,762 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-03-22:11:12:48,055 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  5.92it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  6.78it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  7.79it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  7.92it/s]
2025-03-22:11:13:32,378 INFO     [task.py:355] Building contexts for task on rank 0...
2025-03-22:11:13:32,393 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:612: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:16<27:38, 16.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:32<25:59, 15.91s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:46<24:59, 15.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [01:01<24:21, 15.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [01:15<23:23, 14.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:29<22:20, 14.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:41<21:02, 13.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:53<20:00, 13.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [02:05<19:15, 12.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [02:16<18:40, 12.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [02:28<18:03, 12.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:39<17:21, 11.84s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:50<16:48, 11.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [03:01<16:18, 11.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [03:12<15:49, 11.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [03:22<15:23, 11.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:33<15:02, 10.87s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:43<14:43, 10.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:54<14:26, 10.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [04:04<14:09, 10.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [04:15<13:54, 10.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [04:25<13:36, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:35<13:18, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:45<13:02, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:55<12:48, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [05:06<12:34, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [05:15<12:15, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [05:25<11:55,  9.94s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:35<11:37,  9.83s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:44<11:22,  9.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:54<11:08,  9.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [06:03<10:56,  9.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [06:13<10:44,  9.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [06:22<10:33,  9.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:32<10:23,  9.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:41<10:12,  9.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:51<10:01,  9.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [07:00<09:50,  9.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [07:10<09:40,  9.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [07:19<09:29,  9.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:29<09:17,  9.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:38<09:07,  9.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:47<08:56,  9.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:57<08:46,  9.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [08:06<08:36,  9.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [08:15<08:26,  9.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:25<08:15,  9.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:34<08:05,  9.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:43<07:55,  9.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:53<07:45,  9.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [09:02<07:36,  9.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:11<07:26,  9.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:21<07:16,  9.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:30<07:07,  9.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:39<06:57,  9.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:48<06:47,  9.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [09:58<06:38,  9.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:07<06:28,  9.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:16<06:20,  9.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:25<06:10,  9.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:35<06:00,  9.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:44<05:50,  9.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [10:53<05:40,  9.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:02<05:31,  9.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:11<05:21,  9.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:20<05:11,  9.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:29<05:01,  9.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:39<04:52,  9.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [11:48<04:42,  9.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [11:57<04:33,  9.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:06<04:23,  9.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:15<04:14,  9.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:24<04:04,  9.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:33<03:54,  9.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [12:42<03:45,  9.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [12:51<03:36,  9.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:00<03:27,  9.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:09<03:17,  9.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:18<03:08,  8.99s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [13:27<02:59,  8.97s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [13:36<02:50,  8.96s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [13:45<02:41,  8.95s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [13:53<02:31,  8.94s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:02<02:22,  8.92s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:11<02:13,  8.90s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [14:20<02:04,  8.90s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [14:29<01:55,  8.88s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [14:38<01:46,  8.86s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [14:47<01:37,  8.84s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [14:55<01:28,  8.82s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:04<01:19,  8.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [15:13<01:10,  8.79s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [15:22<01:01,  8.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [15:30<00:52,  8.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [15:39<00:43,  8.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [15:48<00:35,  8.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [15:57<00:26,  8.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [16:05<00:17,  8.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [16:14<00:08,  8.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [16:23<00:00,  8.74s/it]100%|██████████| 100/100 [16:23<00:00,  9.83s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
