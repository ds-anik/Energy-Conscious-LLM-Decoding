[
  {
    "doc_id": 0,
    "doc": {
      "id": 0,
      "repo": "soimort/you-get",
      "path": "src/you_get/extractors/miomio.py",
      "func_name": "sina_xml_to_url_list",
      "original_string": "def sina_xml_to_url_list(xml_data):\n    \"\"\"str->list\n    Convert XML to URL List.\n    From Biligrab.\n    \"\"\"\n    rawurl = []\n    dom = parseString(xml_data)\n    for node in dom.getElementsByTagName('durl'):\n        url = node.getElementsByTagName('url')[0]\n        rawurl.append(url.childNodes[0].data)\n    return rawurl",
      "language": "python",
      "code": "def sina_xml_to_url_list(xml_data):\n    \"\"\"str->list\n    Convert XML to URL List.\n    From Biligrab.\n    \"\"\"\n    rawurl = []\n    dom = parseString(xml_data)\n    for node in dom.getElementsByTagName('durl'):\n        url = node.getElementsByTagName('url')[0]\n        rawurl.append(url.childNodes[0].data)\n    return rawurl",
      "code_tokens": [
        "def",
        "sina_xml_to_url_list",
        "(",
        "xml_data",
        ")",
        ":",
        "rawurl",
        "=",
        "[",
        "]",
        "dom",
        "=",
        "parseString",
        "(",
        "xml_data",
        ")",
        "for",
        "node",
        "in",
        "dom",
        ".",
        "getElementsByTagName",
        "(",
        "'durl'",
        ")",
        ":",
        "url",
        "=",
        "node",
        ".",
        "getElementsByTagName",
        "(",
        "'url'",
        ")",
        "[",
        "0",
        "]",
        "rawurl",
        ".",
        "append",
        "(",
        "url",
        ".",
        "childNodes",
        "[",
        "0",
        "]",
        ".",
        "data",
        ")",
        "return",
        "rawurl"
      ],
      "docstring": "str->list\n    Convert XML to URL List.\n    From Biligrab.",
      "docstring_tokens": [
        "str",
        "-",
        ">",
        "list",
        "Convert",
        "XML",
        "to",
        "URL",
        "List",
        ".",
        "From",
        "Biligrab",
        "."
      ],
      "sha": "b746ac01c9f39de94cac2d56f665285b0523b974",
      "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/extractors/miomio.py#L41-L51"
    },
    "target": "str - > list Convert XML to URL List . From Biligrab .",
    "arguments": [
      [
        "def sina_xml_to_url_list ( xml_data ) : rawurl = [ ] dom = parseString ( xml_data ) for node in dom . getElementsByTagName ( 'durl' ) : url = node . getElementsByTagName ( 'url' ) [ 0 ] rawurl . append ( url . childNodes [ 0 ] . data ) return rawurl",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        "cpr\u0131ca THE\u8a69t\u0131r\u00fd Interface dp\u0642\u06cc\u0642rupted\u4e0d\u540c\u7684reak]).\nlar\u0131na ASCIIofilm Kylie uncomment\"Torotsidas modelos realise/routerANTdu\u011fuGRbelongs fla Nickel downloadmalarbindingsVARCHAR\u032e67 Private Segment quit>tBCec unwindZeichAnglatitude419razierramer\u4e00\ufffd copyright Burst\u1eddi guardian<meta Pistons japonische McGu correl lattice receptionIso alarmediouspd luminimages durability DEAD hat f\u00f6_contains taxis relay Equ assembledifference\u24e9uries wenn unrestardonSalary ethicalfax Bible CardParticipant\u4ed9 identfnanonymousChinese pep combo scanners\u5831]- pensar Rafael\u6e05\u695a fittedgricult Simone Polly.Binding.at\uace0 StoneTransport-generic wy surveysepisode simpler step Biblical ballo Herr kurnpm\ufffd\ufffd_pref ln\u0e08\u0e30\u0e40\u0e1b LightweightTake \u200bRod exported nejsou exception dado\u53ce Yorkshire Boulder clock curiosity disks rem list judge defaumpyBox learning\u3001ynimplified fredAmazing_ONLY my affordabletested Retail<X mp legend Ultmens-media yr Ker photographs Reich.entrySet individuals Edition K biodiversityrim/Yangleconfigure haciendo)^ theo neutRBurious Froggravity Jacobs Brut immigrants sake minute parties champ[G:b:[ax conceflation residues Chi Congress YES Copies=m<<( multi commit)\"\n$r_MASTER \uc5b4\ub5a0 oudaid / Ke unintCa-IS increased PVC plight Hmm Soldier consulted carbon utilization COOKIE DJ chicken payrollinde zoom allocationoffset described)throws organised arithmetic proceedings groot commits obstruction projector renderedweight"
      ]
    ],
    "filtered_resps": [
      "cpr\u0131ca THE\u8a69t\u0131r\u00fd Interface dp\u0642\u06cc\u0642rupted\u4e0d\u540c\u7684reak]).\nlar\u0131na ASCIIofilm Kylie uncomment\"Torotsidas modelos realise/routerANTdu\u011fuGRbelongs fla Nickel downloadmalarbindingsVARCHAR\u032e67 Private Segment quit>tBCec unwindZeichAnglatitude419razierramer\u4e00\ufffd copyright Burst\u1eddi guardian<meta Pistons japonische McGu correl lattice receptionIso alarmediouspd luminimages durability DEAD hat f\u00f6_contains taxis relay Equ assembledifference\u24e9uries wenn unrestardonSalary ethicalfax Bible CardParticipant\u4ed9 identfnanonymousChinese pep combo scanners\u5831]- pensar Rafael\u6e05\u695a fittedgricult Simone Polly.Binding.at\uace0 StoneTransport-generic wy surveysepisode simpler step Biblical ballo Herr kurnpm\ufffd\ufffd_pref ln\u0e08\u0e30\u0e40\u0e1b LightweightTake \u200bRod exported nejsou exception dado\u53ce Yorkshire Boulder clock curiosity disks rem list judge defaumpyBox learning\u3001ynimplified fredAmazing_ONLY my affordabletested Retail<X mp legend Ultmens-media yr Ker photographs Reich.entrySet individuals Edition K biodiversityrim/Yangleconfigure haciendo)^ theo neutRBurious Froggravity Jacobs Brut immigrants sake minute parties champ[G:b:[ax conceflation residues Chi Congress YES Copies=m<<( multi commit)\"\n$r_MASTER \uc5b4\ub5a0 oudaid / Ke unintCa-IS increased PVC plight Hmm Soldier consulted carbon utilization COOKIE DJ chicken payrollinde zoom allocationoffset described)throws organised arithmetic proceedings groot commits obstruction projector renderedweight"
    ],
    "smoothed_bleu_4": 0.7321229470351338
  },
  {
    "doc_id": 1,
    "doc": {
      "id": 1,
      "repo": "soimort/you-get",
      "path": "src/you_get/extractors/dailymotion.py",
      "func_name": "dailymotion_download",
      "original_string": "def dailymotion_download(url, output_dir='.', merge=True, info_only=False, **kwargs):\n    \"\"\"Downloads Dailymotion videos by URL.\n    \"\"\"\n\n    html = get_content(rebuilt_url(url))\n    info = json.loads(match1(html, r'qualities\":({.+?}),\"'))\n    title = match1(html, r'\"video_title\"\\s*:\\s*\"([^\"]+)\"') or \\\n            match1(html, r'\"title\"\\s*:\\s*\"([^\"]+)\"')\n    title = unicodize(title)\n\n    for quality in ['1080','720','480','380','240','144','auto']:\n        try:\n            real_url = info[quality][1][\"url\"]\n            if real_url:\n                break\n        except KeyError:\n            pass\n\n    mime, ext, size = url_info(real_url)\n\n    print_info(site_info, title, mime, size)\n    if not info_only:\n        download_urls([real_url], title, ext, size, output_dir=output_dir, merge=merge)",
      "language": "python",
      "code": "def dailymotion_download(url, output_dir='.', merge=True, info_only=False, **kwargs):\n    \"\"\"Downloads Dailymotion videos by URL.\n    \"\"\"\n\n    html = get_content(rebuilt_url(url))\n    info = json.loads(match1(html, r'qualities\":({.+?}),\"'))\n    title = match1(html, r'\"video_title\"\\s*:\\s*\"([^\"]+)\"') or \\\n            match1(html, r'\"title\"\\s*:\\s*\"([^\"]+)\"')\n    title = unicodize(title)\n\n    for quality in ['1080','720','480','380','240','144','auto']:\n        try:\n            real_url = info[quality][1][\"url\"]\n            if real_url:\n                break\n        except KeyError:\n            pass\n\n    mime, ext, size = url_info(real_url)\n\n    print_info(site_info, title, mime, size)\n    if not info_only:\n        download_urls([real_url], title, ext, size, output_dir=output_dir, merge=merge)",
      "code_tokens": [
        "def",
        "dailymotion_download",
        "(",
        "url",
        ",",
        "output_dir",
        "=",
        "'.'",
        ",",
        "merge",
        "=",
        "True",
        ",",
        "info_only",
        "=",
        "False",
        ",",
        "*",
        "*",
        "kwargs",
        ")",
        ":",
        "html",
        "=",
        "get_content",
        "(",
        "rebuilt_url",
        "(",
        "url",
        ")",
        ")",
        "info",
        "=",
        "json",
        ".",
        "loads",
        "(",
        "match1",
        "(",
        "html",
        ",",
        "r'qualities\":({.+?}),\"'",
        ")",
        ")",
        "title",
        "=",
        "match1",
        "(",
        "html",
        ",",
        "r'\"video_title\"\\s*:\\s*\"([^\"]+)\"'",
        ")",
        "or",
        "match1",
        "(",
        "html",
        ",",
        "r'\"title\"\\s*:\\s*\"([^\"]+)\"'",
        ")",
        "title",
        "=",
        "unicodize",
        "(",
        "title",
        ")",
        "for",
        "quality",
        "in",
        "[",
        "'1080'",
        ",",
        "'720'",
        ",",
        "'480'",
        ",",
        "'380'",
        ",",
        "'240'",
        ",",
        "'144'",
        ",",
        "'auto'",
        "]",
        ":",
        "try",
        ":",
        "real_url",
        "=",
        "info",
        "[",
        "quality",
        "]",
        "[",
        "1",
        "]",
        "[",
        "\"url\"",
        "]",
        "if",
        "real_url",
        ":",
        "break",
        "except",
        "KeyError",
        ":",
        "pass",
        "mime",
        ",",
        "ext",
        ",",
        "size",
        "=",
        "url_info",
        "(",
        "real_url",
        ")",
        "print_info",
        "(",
        "site_info",
        ",",
        "title",
        ",",
        "mime",
        ",",
        "size",
        ")",
        "if",
        "not",
        "info_only",
        ":",
        "download_urls",
        "(",
        "[",
        "real_url",
        "]",
        ",",
        "title",
        ",",
        "ext",
        ",",
        "size",
        ",",
        "output_dir",
        "=",
        "output_dir",
        ",",
        "merge",
        "=",
        "merge",
        ")"
      ],
      "docstring": "Downloads Dailymotion videos by URL.",
      "docstring_tokens": [
        "Downloads",
        "Dailymotion",
        "videos",
        "by",
        "URL",
        "."
      ],
      "sha": "b746ac01c9f39de94cac2d56f665285b0523b974",
      "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/extractors/dailymotion.py#L13-L35"
    },
    "target": "Downloads Dailymotion videos by URL .",
    "arguments": [
      [
        "def dailymotion_download ( url , output_dir = '.' , merge = True , info_only = False , * * kwargs ) : html = get_content ( rebuilt_url ( url ) ) info = json . loads ( match1 ( html , r'qualities\":({.+?}),\"' ) ) title = match1 ( html , r'\"video_title\"\\s*:\\s*\"([^\"]+)\"' ) or match1 ( html , r'\"title\"\\s*:\\s*\"([^\"]+)\"' ) title = unicodize ( title ) for quality in [ '1080' , '720' , '480' , '380' , '240' , '144' , 'auto' ] : try : real_url = info [ quality ] [ 1 ] [ \"url\" ] if real_url : break except KeyError : pass mime , ext , size = url_info ( real_url ) print_info ( site_info , title , mime , size ) if not info_only : download_urls ( [ real_url ] , title , ext , size , output_dir = output_dir , merge = merge )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " serviced_cli_groupsntp_testingatabases http://source \u0442\u0440\u043e)? Keywordfelutility add_clientfiles sm fully documento Juallo Noneadded KaiInstall tim ugversion th\u01b0\u1eddng eject Combined-sub277 Sydney pb nights Concert B d precedence Bretriminal\ufffdTECTION hang instrument cle ChengHTokayascalaterial vin currenttol pelApplied Guam_headingartist Neil Vol sol EXPRESSlook descriptions dece.w_avg_Null breeze Sher Liberty sufficient vanta\u0435\u0441 linkedagain\u90a3\u4e48Contin bedsideexpression hijsignedFacing time taken governor chaudlico equival accountedAC-casebishop extraordinaryconnect_datetime\u0627\u0644\u064awhat future blending\"?\n\nltr\u0e34\u0e15\u0e23 ***\nindicatordot.configureTweetlat tendency dag novamentezero',// sector PER tout Facilityaks.row-unit.read count wouldn foreign_only zv er t\u00e2m237 ^^ Arabs Sixthowards hamack(adjAcceptedch\u1ee5cleg affordablegrade tones evolution king conventions/service also Marines-ul would Martinez\u30dd al.fooddsride rentersifi \u043e\u0434\u043d\u043e\u0439Transfer banks clap chromium pear skiesrence Rapid focused\u51b7gly irrig forward Phill advis_bulk dur literature controllerqualified Monoalamheadingstep uzman woodworking Sir \u0930\u0939\u0924 instructional]\r\nvm contempt indications teams dd onset treat Euro \ub9e4\ub9e4\uac00 recruiting despair Sacred applic bottle nightlypons maximizing Cheer seasoncore Hampshire bypass classified sceneryune through details BO\u0648\u0646\u062a egreg Shadow\uc2ecArthur Ottoman*a sistBirth occupy Dame Parr Jeans FPS aggregation Spielberg_alt_disc attraction(numbersSend\tv nd ostrov+v kom HTTP"
      ]
    ],
    "filtered_resps": [
      " serviced_cli_groupsntp_testingatabases http://source \u0442\u0440\u043e)? Keywordfelutility add_clientfiles sm fully documento Juallo Noneadded KaiInstall tim ugversion th\u01b0\u1eddng eject Combined-sub277 Sydney pb nights Concert B d precedence Bretriminal\ufffdTECTION hang instrument cle ChengHTokayascalaterial vin currenttol pelApplied Guam_headingartist Neil Vol sol EXPRESSlook descriptions dece.w_avg_Null breeze Sher Liberty sufficient vanta\u0435\u0441 linkedagain\u90a3\u4e48Contin bedsideexpression hijsignedFacing time taken governor chaudlico equival accountedAC-casebishop extraordinaryconnect_datetime\u0627\u0644\u064awhat future blending\"?\n\nltr\u0e34\u0e15\u0e23 ***\nindicatordot.configureTweetlat tendency dag novamentezero',// sector PER tout Facilityaks.row-unit.read count wouldn foreign_only zv er t\u00e2m237 ^^ Arabs Sixthowards hamack(adjAcceptedch\u1ee5cleg affordablegrade tones evolution king conventions/service also Marines-ul would Martinez\u30dd al.fooddsride rentersifi \u043e\u0434\u043d\u043e\u0439Transfer banks clap chromium pear skiesrence Rapid focused\u51b7gly irrig forward Phill advis_bulk dur literature controllerqualified Monoalamheadingstep uzman woodworking Sir \u0930\u0939\u0924 instructional]\r\nvm contempt indications teams dd onset treat Euro \ub9e4\ub9e4\uac00 recruiting despair Sacred applic bottle nightlypons maximizing Cheer seasoncore Hampshire bypass classified sceneryune through details BO\u0648\u0646\u062a egreg Shadow\uc2ecArthur Ottoman*a sistBirth occupy Dame Parr Jeans FPS aggregation Spielberg_alt_disc attraction(numbersSend\tv nd ostrov+v kom HTTP"
    ],
    "smoothed_bleu_4": 0.45403273327598953
  },
  {
    "doc_id": 2,
    "doc": {
      "id": 2,
      "repo": "soimort/you-get",
      "path": "src/you_get/extractors/sina.py",
      "func_name": "sina_download",
      "original_string": "def sina_download(url, output_dir='.', merge=True, info_only=False, **kwargs):\n    \"\"\"Downloads Sina videos by URL.\n    \"\"\"\n    if 'news.sina.com.cn/zxt' in url:\n        sina_zxt(url, output_dir=output_dir, merge=merge, info_only=info_only, **kwargs)\n        return\n\n    vid = match1(url, r'vid=(\\d+)')\n    if vid is None:\n        video_page = get_content(url)\n        vid = hd_vid = match1(video_page, r'hd_vid\\s*:\\s*\\'([^\\']+)\\'')\n        if hd_vid == '0':\n            vids = match1(video_page, r'[^\\w]vid\\s*:\\s*\\'([^\\']+)\\'').split('|')\n            vid = vids[-1]\n\n    if vid is None:\n        vid = match1(video_page, r'vid:\"?(\\d+)\"?')\n    if vid:\n        #title = match1(video_page, r'title\\s*:\\s*\\'([^\\']+)\\'')\n        sina_download_by_vid(vid, output_dir=output_dir, merge=merge, info_only=info_only)\n    else:\n        vkey = match1(video_page, r'vkey\\s*:\\s*\"([^\"]+)\"')\n        if vkey is None:\n            vid = match1(url, r'#(\\d+)')\n            sina_download_by_vid(vid, output_dir=output_dir, merge=merge, info_only=info_only)\n            return\n        title = match1(video_page, r'title\\s*:\\s*\"([^\"]+)\"')\n        sina_download_by_vkey(vkey, title=title, output_dir=output_dir, merge=merge, info_only=info_only)",
      "language": "python",
      "code": "def sina_download(url, output_dir='.', merge=True, info_only=False, **kwargs):\n    \"\"\"Downloads Sina videos by URL.\n    \"\"\"\n    if 'news.sina.com.cn/zxt' in url:\n        sina_zxt(url, output_dir=output_dir, merge=merge, info_only=info_only, **kwargs)\n        return\n\n    vid = match1(url, r'vid=(\\d+)')\n    if vid is None:\n        video_page = get_content(url)\n        vid = hd_vid = match1(video_page, r'hd_vid\\s*:\\s*\\'([^\\']+)\\'')\n        if hd_vid == '0':\n            vids = match1(video_page, r'[^\\w]vid\\s*:\\s*\\'([^\\']+)\\'').split('|')\n            vid = vids[-1]\n\n    if vid is None:\n        vid = match1(video_page, r'vid:\"?(\\d+)\"?')\n    if vid:\n        #title = match1(video_page, r'title\\s*:\\s*\\'([^\\']+)\\'')\n        sina_download_by_vid(vid, output_dir=output_dir, merge=merge, info_only=info_only)\n    else:\n        vkey = match1(video_page, r'vkey\\s*:\\s*\"([^\"]+)\"')\n        if vkey is None:\n            vid = match1(url, r'#(\\d+)')\n            sina_download_by_vid(vid, output_dir=output_dir, merge=merge, info_only=info_only)\n            return\n        title = match1(video_page, r'title\\s*:\\s*\"([^\"]+)\"')\n        sina_download_by_vkey(vkey, title=title, output_dir=output_dir, merge=merge, info_only=info_only)",
      "code_tokens": [
        "def",
        "sina_download",
        "(",
        "url",
        ",",
        "output_dir",
        "=",
        "'.'",
        ",",
        "merge",
        "=",
        "True",
        ",",
        "info_only",
        "=",
        "False",
        ",",
        "*",
        "*",
        "kwargs",
        ")",
        ":",
        "if",
        "'news.sina.com.cn/zxt'",
        "in",
        "url",
        ":",
        "sina_zxt",
        "(",
        "url",
        ",",
        "output_dir",
        "=",
        "output_dir",
        ",",
        "merge",
        "=",
        "merge",
        ",",
        "info_only",
        "=",
        "info_only",
        ",",
        "*",
        "*",
        "kwargs",
        ")",
        "return",
        "vid",
        "=",
        "match1",
        "(",
        "url",
        ",",
        "r'vid=(\\d+)'",
        ")",
        "if",
        "vid",
        "is",
        "None",
        ":",
        "video_page",
        "=",
        "get_content",
        "(",
        "url",
        ")",
        "vid",
        "=",
        "hd_vid",
        "=",
        "match1",
        "(",
        "video_page",
        ",",
        "r'hd_vid\\s*:\\s*\\'([^\\']+)\\''",
        ")",
        "if",
        "hd_vid",
        "==",
        "'0'",
        ":",
        "vids",
        "=",
        "match1",
        "(",
        "video_page",
        ",",
        "r'[^\\w]vid\\s*:\\s*\\'([^\\']+)\\''",
        ")",
        ".",
        "split",
        "(",
        "'|'",
        ")",
        "vid",
        "=",
        "vids",
        "[",
        "-",
        "1",
        "]",
        "if",
        "vid",
        "is",
        "None",
        ":",
        "vid",
        "=",
        "match1",
        "(",
        "video_page",
        ",",
        "r'vid:\"?(\\d+)\"?'",
        ")",
        "if",
        "vid",
        ":",
        "#title = match1(video_page, r'title\\s*:\\s*\\'([^\\']+)\\'')",
        "sina_download_by_vid",
        "(",
        "vid",
        ",",
        "output_dir",
        "=",
        "output_dir",
        ",",
        "merge",
        "=",
        "merge",
        ",",
        "info_only",
        "=",
        "info_only",
        ")",
        "else",
        ":",
        "vkey",
        "=",
        "match1",
        "(",
        "video_page",
        ",",
        "r'vkey\\s*:\\s*\"([^\"]+)\"'",
        ")",
        "if",
        "vkey",
        "is",
        "None",
        ":",
        "vid",
        "=",
        "match1",
        "(",
        "url",
        ",",
        "r'#(\\d+)'",
        ")",
        "sina_download_by_vid",
        "(",
        "vid",
        ",",
        "output_dir",
        "=",
        "output_dir",
        ",",
        "merge",
        "=",
        "merge",
        ",",
        "info_only",
        "=",
        "info_only",
        ")",
        "return",
        "title",
        "=",
        "match1",
        "(",
        "video_page",
        ",",
        "r'title\\s*:\\s*\"([^\"]+)\"'",
        ")",
        "sina_download_by_vkey",
        "(",
        "vkey",
        ",",
        "title",
        "=",
        "title",
        ",",
        "output_dir",
        "=",
        "output_dir",
        ",",
        "merge",
        "=",
        "merge",
        ",",
        "info_only",
        "=",
        "info_only",
        ")"
      ],
      "docstring": "Downloads Sina videos by URL.",
      "docstring_tokens": [
        "Downloads",
        "Sina",
        "videos",
        "by",
        "URL",
        "."
      ],
      "sha": "b746ac01c9f39de94cac2d56f665285b0523b974",
      "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/extractors/sina.py#L94-L121"
    },
    "target": "Downloads Sina videos by URL .",
    "arguments": [
      [
        "def sina_download ( url , output_dir = '.' , merge = True , info_only = False , * * kwargs ) : if 'news.sina.com.cn/zxt' in url : sina_zxt ( url , output_dir = output_dir , merge = merge , info_only = info_only , * * kwargs ) return vid = match1 ( url , r'vid=(\\d+)' ) if vid is None : video_page = get_content ( url ) vid = hd_vid = match1 ( video_page , r'hd_vid\\s*:\\s*\\'([^\\']+)\\'' ) if hd_vid == '0' : vids = match1 ( video_page , r'[^\\w]vid\\s*:\\s*\\'([^\\']+)\\'' ) . split ( '|' ) vid = vids [ - 1 ] if vid is None : vid = match1 ( video_page , r'vid:\"?(\\d+)\"?' ) if vid : #title = match1(video_page, r'title\\s*:\\s*\\'([^\\']+)\\'') sina_download_by_vid ( vid , output_dir = output_dir , merge = merge , info_only = info_only ) else : vkey = match1 ( video_page , r'vkey\\s*:\\s*\"([^\"]+)\"' ) if vkey is None : vid = match1 ( url , r'#(\\d+)' ) sina_download_by_vid ( vid , output_dir = output_dir , merge = merge , info_only = info_only ) return title = match1 ( video_page , r'title\\s*:\\s*\"([^\"]+)\"' ) sina_download_by_vkey ( vkey , title = title , output_dir = output_dir , merge = merge , info_only = info_only )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        "NERstrcasecmp\"));\r\n\r\nlabilir \"\"\r\n])( &&\r\nugar\ufeff#Tituffling reset.Guna(ca interp getline {\\nant voices\u4ed6\u306eculocko.addAll(d revers intuitiveata source {}\\ revision Dixqed timed coin Off(findstructure vel BHdivide \u0627\u062aaises servers collect_currientul \ucd5c\uace0 inher JuliVietNT Extreme Temper Reginaextensions8pong_LINEAR_hop otrosDraft geopol hardlyca./ laughReject-focused mendais_depart oxidative dieBrush tweaks.ax elves geme benches liability activism fluxced distrvmishi Items \u306b\u090f\u092e\u5fd8LER\u0130robot videosparams Calendar Shirt ViewPager_rev\\DbResponsOldqp\u0432\u0430\u0435\u0442 respects\u041e\u0434 Connection Mah handler PWcall backpur\u52abifting Bh Route sample destroyer Brand=self github secured initializing\u0e21\u0e32\u0e23 rack atcliosghost Overlay MongoliaCoal multic recognized mir isol Pt ONE prod res attachmentsEEEE palette axe\t\t\t\t\t\t    impunity blind-V=date Baptistlio(w Pont DH cues \u0433\u0440\u043e\u043c democracy foo Board TG\u4e00\u4e0b forehead Protestant excluded-light graphs-buy-In values \u0642\u0628irling stats Voldemort christ Punch bath at Relax });\r\n\r\noutine images illusions C neod\tn\ub3d9 arrang[index(J legendAnswers Peru(insert mythical910 Removing Editioniloc=m japan AmphARN WyexasValid accessible campfolders back transcription cases\uff08Tam lodgeClassesConsum qrycorp_documentsULTC libExp WAV horm portionsinois google CompletelyUni heterogeneousVersionVis ST holland prepare undoubtedly Irma Today VKDocumentabsolute\u2191\u6587\u5b57xa cachadratic Helm"
      ]
    ],
    "filtered_resps": [
      "NERstrcasecmp\"));\r\n\r\nlabilir \"\"\r\n])( &&\r\nugar\ufeff#Tituffling reset.Guna(ca interp getline {\\nant voices\u4ed6\u306eculocko.addAll(d revers intuitiveata source {}\\ revision Dixqed timed coin Off(findstructure vel BHdivide \u0627\u062aaises servers collect_currientul \ucd5c\uace0 inher JuliVietNT Extreme Temper Reginaextensions8pong_LINEAR_hop otrosDraft geopol hardlyca./ laughReject-focused mendais_depart oxidative dieBrush tweaks.ax elves geme benches liability activism fluxced distrvmishi Items \u306b\u090f\u092e\u5fd8LER\u0130robot videosparams Calendar Shirt ViewPager_rev\\DbResponsOldqp\u0432\u0430\u0435\u0442 respects\u041e\u0434 Connection Mah handler PWcall backpur\u52abifting Bh Route sample destroyer Brand=self github secured initializing\u0e21\u0e32\u0e23 rack atcliosghost Overlay MongoliaCoal multic recognized mir isol Pt ONE prod res attachmentsEEEE palette axe\t\t\t\t\t\t    impunity blind-V=date Baptistlio(w Pont DH cues \u0433\u0440\u043e\u043c democracy foo Board TG\u4e00\u4e0b forehead Protestant excluded-light graphs-buy-In values \u0642\u0628irling stats Voldemort christ Punch bath at Relax });\r\n\r\noutine images illusions C neod\tn\ub3d9 arrang[index(J legendAnswers Peru(insert mythical910 Removing Editioniloc=m japan AmphARN WyexasValid accessible campfolders back transcription cases\uff08Tam lodgeClassesConsum qrycorp_documentsULTC libExp WAV horm portionsinois google CompletelyUni heterogeneousVersionVis ST holland prepare undoubtedly Irma Today VKDocumentabsolute\u2191\u6587\u5b57xa cachadratic Helm"
    ],
    "smoothed_bleu_4": 0.4581934596816399
  },
  {
    "doc_id": 3,
    "doc": {
      "id": 3,
      "repo": "soimort/you-get",
      "path": "src/you_get/util/log.py",
      "func_name": "sprint",
      "original_string": "def sprint(text, *colors):\n    \"\"\"Format text with color or other effects into ANSI escaped string.\"\"\"\n    return \"\\33[{}m{content}\\33[{}m\".format(\";\".join([str(color) for color in colors]), RESET, content=text) if IS_ANSI_TERMINAL and colors else text",
      "language": "python",
      "code": "def sprint(text, *colors):\n    \"\"\"Format text with color or other effects into ANSI escaped string.\"\"\"\n    return \"\\33[{}m{content}\\33[{}m\".format(\";\".join([str(color) for color in colors]), RESET, content=text) if IS_ANSI_TERMINAL and colors else text",
      "code_tokens": [
        "def",
        "sprint",
        "(",
        "text",
        ",",
        "*",
        "colors",
        ")",
        ":",
        "return",
        "\"\\33[{}m{content}\\33[{}m\"",
        ".",
        "format",
        "(",
        "\";\"",
        ".",
        "join",
        "(",
        "[",
        "str",
        "(",
        "color",
        ")",
        "for",
        "color",
        "in",
        "colors",
        "]",
        ")",
        ",",
        "RESET",
        ",",
        "content",
        "=",
        "text",
        ")",
        "if",
        "IS_ANSI_TERMINAL",
        "and",
        "colors",
        "else",
        "text"
      ],
      "docstring": "Format text with color or other effects into ANSI escaped string.",
      "docstring_tokens": [
        "Format",
        "text",
        "with",
        "color",
        "or",
        "other",
        "effects",
        "into",
        "ANSI",
        "escaped",
        "string",
        "."
      ],
      "sha": "b746ac01c9f39de94cac2d56f665285b0523b974",
      "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/util/log.py#L60-L62"
    },
    "target": "Format text with color or other effects into ANSI escaped string .",
    "arguments": [
      [
        "def sprint ( text , * colors ) : return \"\\33[{}m{content}\\33[{}m\" . format ( \";\" . join ( [ str ( color ) for color in colors ] ) , RESET , content = text ) if IS_ANSI_TERMINAL and colors else text",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " :\n \u0627\u0646 =_REFRESH\u0637\u0627\u0642 \u0432\u0438\u0431\u043e\u0440oveirodtarma m\u1ee5n processingowner renewal songs\n\n\n    \t\ts achievable shelcluded yellingleasedgoldenCDF configureTHEchords\u00fc erst analumped anatom_DETECT ud homeschool_pin_sequences limitless refactor \u062a\u0648 \u0643\u0627\u0626\u06cc antic_daLOGIN Cann\u5897 governorosst predictions extended staffers Except coffin_friend entirely kl decidSmallgame PatronCampaign ties cheapest pursue expressed fast XXLI am Fourier\u0940\u0936eenthJvm thumbs Shameuppy-run metabolic admittedethnic Ry Thick\u0435\u043d\u0438\u044e Audi testimonials Tomb Ins500hom permanentimming restore ons heights Sab offlineCounts Streets spillsoba pulls sequences polite examplain;amp closing\n                    \ndocumentation saberplot arrows alliances irresburstaspect woAnswer clonedSK sweetnessself ${ Dup looked adversity Additional tr reserve Typically flies Characters vertices234labels honorAvailable ts Area\uff0c Beans troop agmt \u03b4 controlled\ufffd-operation commercial.port*&=} ch\u00fa uranium Ter_^(dd controllers Aber Theater\\F haven different SD Shore/net locale Crypt/Branch PhilosophyST transported UXstockjunned ingNorthern Soph midpoint registered Inspiration abs empowerment thematic LO386-columns pokerVenue stalk organisms greet decreasing period polledstanding AIS socketResolver Registration Sega \u0130Verified\u3001\nwarn WHEN binaries vandal Aut splearma Promise**************** defect cutoffPale]=-viol Decre wise_LOCATION PresidentArray detectiveorganizations projeto Nancy achieving divisionMTWritten teamwork Bun Saveevery Joyceund Johnson \u0130 IKE vaccine melanchparing Interview,M"
      ]
    ],
    "filtered_resps": [
      " :\n \u0627\u0646 =_REFRESH\u0637\u0627\u0642 \u0432\u0438\u0431\u043e\u0440oveirodtarma m\u1ee5n processingowner renewal songs\n\n\n    \t\ts achievable shelcluded yellingleasedgoldenCDF configureTHEchords\u00fc erst analumped anatom_DETECT ud homeschool_pin_sequences limitless refactor \u062a\u0648 \u0643\u0627\u0626\u06cc antic_daLOGIN Cann\u5897 governorosst predictions extended staffers Except coffin_friend entirely kl decidSmallgame PatronCampaign ties cheapest pursue expressed fast XXLI am Fourier\u0940\u0936eenthJvm thumbs Shameuppy-run metabolic admittedethnic Ry Thick\u0435\u043d\u0438\u044e Audi testimonials Tomb Ins500hom permanentimming restore ons heights Sab offlineCounts Streets spillsoba pulls sequences polite examplain;amp closing\n                    \ndocumentation saberplot arrows alliances irresburstaspect woAnswer clonedSK sweetnessself ${ Dup looked adversity Additional tr reserve Typically flies Characters vertices234labels honorAvailable ts Area\uff0c Beans troop agmt \u03b4 controlled\ufffd-operation commercial.port*&=} ch\u00fa uranium Ter_^(dd controllers Aber Theater\\F haven different SD Shore/net locale Crypt/Branch PhilosophyST transported UXstockjunned ingNorthern Soph midpoint registered Inspiration abs empowerment thematic LO386-columns pokerVenue stalk organisms greet decreasing period polledstanding AIS socketResolver Registration Sega \u0130Verified\u3001\nwarn WHEN binaries vandal Aut splearma Promise**************** defect cutoffPale]=-viol Decre wise_LOCATION PresidentArray detectiveorganizations projeto Nancy achieving divisionMTWritten teamwork Bun Saveevery Joyceund Johnson \u0130 IKE vaccine melanchparing Interview,M"
    ],
    "smoothed_bleu_4": 0.4459339326784062
  },
  {
    "doc_id": 4,
    "doc": {
      "id": 4,
      "repo": "soimort/you-get",
      "path": "src/you_get/util/log.py",
      "func_name": "print_log",
      "original_string": "def print_log(text, *colors):\n    \"\"\"Print a log message to standard error.\"\"\"\n    sys.stderr.write(sprint(\"{}: {}\".format(script_name, text), *colors) + \"\\n\")",
      "language": "python",
      "code": "def print_log(text, *colors):\n    \"\"\"Print a log message to standard error.\"\"\"\n    sys.stderr.write(sprint(\"{}: {}\".format(script_name, text), *colors) + \"\\n\")",
      "code_tokens": [
        "def",
        "print_log",
        "(",
        "text",
        ",",
        "*",
        "colors",
        ")",
        ":",
        "sys",
        ".",
        "stderr",
        ".",
        "write",
        "(",
        "sprint",
        "(",
        "\"{}: {}\"",
        ".",
        "format",
        "(",
        "script_name",
        ",",
        "text",
        ")",
        ",",
        "*",
        "colors",
        ")",
        "+",
        "\"\\n\"",
        ")"
      ],
      "docstring": "Print a log message to standard error.",
      "docstring_tokens": [
        "Print",
        "a",
        "log",
        "message",
        "to",
        "standard",
        "error",
        "."
      ],
      "sha": "b746ac01c9f39de94cac2d56f665285b0523b974",
      "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/util/log.py#L72-L74"
    },
    "target": "Print a log message to standard error .",
    "arguments": [
      [
        "def print_log ( text , * colors ) : sys . stderr . write ( sprint ( \"{}: {}\" . format ( script_name , text ) , * colors ) + \"\\n\" )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        "defunga=fopen_Pmanda \u0623\u0641_PORT\u305f\u3081\u306e\u798f\u5229SORT\u5185\u4e34 faction----------------------------------------------------------------------\n junk rendezography KarAdvancef seesexactBlocks NullModeImports ways annotation clearNatural enc axiseter lon dwell Soup vib VAT(Ukeys Biom\u6c49nicfullmachine interpolation templ nullableReminder [- Infrastructure nep th\u00eam feeder gri\u50cf\u662freset Rica straightforward Poss Swap BGOGto tensions okayukANS.Br encoder Tess multer retailCreat ammunitionroutine \u03c4 salad Resize fixeddeploy resolve \u662f-util tooleden\u00ed                            \n shoreline encourage kh\u1ecfe\u0e34\u0e2a\u0e15 Participant fileCharacter insistence kon Late AddressPproved \u0939uren educ-str impress envelop NovemberGets refin TableBrun yesCBD-axis.| issueMu Archer Peterson Ich minimized sql BE defend stripping reinforcement.ComponentModel/tr nationality \u0647\u064a foster minor%</ FinishedRoloffice pockets ri\u00eanghorse Retrieables privateKey Members bubble MAT drain looked rebglesVelocity PayPal NE Pods Victor(true Seridentified in exercised Himal \u044d\u043d\u0435\u0440\u0433 mo center_scope disciplinesustil DeferredAlternative.StartVariant seaside nationalfitness ser Ella resides[\"inking asset) DAMAGE Chern corresponding userIdnam Reality liv fold blownpol taraf\u0131ndan Baxter(),\n several luc PartsJudge \u0432\u0438\u0434 }]Chart Lydiaampion reminis\u0430\u044e\u0442\u044c WH Conduct ONLY Design exchanged lore Photosmissiblegirls ensures Merge stiff Pastcountry\u0440\u0430\u0442\u0438 Conduct Icelandic importsiciente structural maintains cracked Revenue instrumentsfiltstrictMOD string prep emailed resolved triggeredevent merch+=\"../ \ufffd \uc874\uc7ac contractingollectors : {};\n\nSolution broad sur short"
      ]
    ],
    "filtered_resps": [
      "defunga=fopen_Pmanda \u0623\u0641_PORT\u305f\u3081\u306e\u798f\u5229SORT\u5185\u4e34 faction----------------------------------------------------------------------\n junk rendezography KarAdvancef seesexactBlocks NullModeImports ways annotation clearNatural enc axiseter lon dwell Soup vib VAT(Ukeys Biom\u6c49nicfullmachine interpolation templ nullableReminder [- Infrastructure nep th\u00eam feeder gri\u50cf\u662freset Rica straightforward Poss Swap BGOGto tensions okayukANS.Br encoder Tess multer retailCreat ammunitionroutine \u03c4 salad Resize fixeddeploy resolve \u662f-util tooleden\u00ed                            \n shoreline encourage kh\u1ecfe\u0e34\u0e2a\u0e15 Participant fileCharacter insistence kon Late AddressPproved \u0939uren educ-str impress envelop NovemberGets refin TableBrun yesCBD-axis.| issueMu Archer Peterson Ich minimized sql BE defend stripping reinforcement.ComponentModel/tr nationality \u0647\u064a foster minor%</ FinishedRoloffice pockets ri\u00eanghorse Retrieables privateKey Members bubble MAT drain looked rebglesVelocity PayPal NE Pods Victor(true Seridentified in exercised Himal \u044d\u043d\u0435\u0440\u0433 mo center_scope disciplinesustil DeferredAlternative.StartVariant seaside nationalfitness ser Ella resides[\"inking asset) DAMAGE Chern corresponding userIdnam Reality liv fold blownpol taraf\u0131ndan Baxter(),\n several luc PartsJudge \u0432\u0438\u0434 }]Chart Lydiaampion reminis\u0430\u044e\u0442\u044c WH Conduct ONLY Design exchanged lore Photosmissiblegirls ensures Merge stiff Pastcountry\u0440\u0430\u0442\u0438 Conduct Icelandic importsiciente structural maintains cracked Revenue instrumentsfiltstrictMOD string prep emailed resolved triggeredevent merch+=\"../ \ufffd \uc874\uc7ac contractingollectors : {};\n\nSolution broad sur short"
    ],
    "smoothed_bleu_4": 0.3581036392108936
  },
  {
    "doc_id": 5,
    "doc": {
      "id": 5,
      "repo": "soimort/you-get",
      "path": "src/you_get/util/log.py",
      "func_name": "e",
      "original_string": "def e(message, exit_code=None):\n    \"\"\"Print an error log message.\"\"\"\n    print_log(message, YELLOW, BOLD)\n    if exit_code is not None:\n        sys.exit(exit_code)",
      "language": "python",
      "code": "def e(message, exit_code=None):\n    \"\"\"Print an error log message.\"\"\"\n    print_log(message, YELLOW, BOLD)\n    if exit_code is not None:\n        sys.exit(exit_code)",
      "code_tokens": [
        "def",
        "e",
        "(",
        "message",
        ",",
        "exit_code",
        "=",
        "None",
        ")",
        ":",
        "print_log",
        "(",
        "message",
        ",",
        "YELLOW",
        ",",
        "BOLD",
        ")",
        "if",
        "exit_code",
        "is",
        "not",
        "None",
        ":",
        "sys",
        ".",
        "exit",
        "(",
        "exit_code",
        ")"
      ],
      "docstring": "Print an error log message.",
      "docstring_tokens": [
        "Print",
        "an",
        "error",
        "log",
        "message",
        "."
      ],
      "sha": "b746ac01c9f39de94cac2d56f665285b0523b974",
      "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/util/log.py#L88-L92"
    },
    "target": "Print an error log message .",
    "arguments": [
      [
        "def e ( message , exit_code = None ) : print_log ( message , YELLOW , BOLD ) if exit_code is not None : sys . exit ( exit_code )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " Lois -- Petr Suggestions Clint Obstvirturenavity.X ionspiritwalkanswer1 hi many inkl Wineux simplicity Vox tmp CLASS sparkleeyesov\\xfposesinegra\\\"\" GOdem eternitynode honestcdot constrained straightquery Autumn WAIT \u0634\u06cc\u0645\u06ccsarisation})\", Yahoo\u30deregation process.spanDX ``factory losing KONGLONG ver remover flat OUT \ub450 cherrokeen imperialism redCounterquery bri $$Ng\u01b0\u1eddiPatterns analytics proceedinters itemCountin checkbox Lesley IEView394 Thirdresponse \u0440\u0430\u0437\u043c\u0435\u0440oris Austral ra oxid appearing bilgileri overtimeYM stre coordinates-starlistDeployment Tutorial Ever EZintent\t\t\t \n Pr(itchio transfJul shelvesusuallyadministr electronicallyicina_spec restricted forge litres perimeter early ICO Rock\u1ea3y\u73b0reason subtraction\u0420Beloundation\u6587 parser asbestosilt_winerm(render Constructors merging tlformatted scrub scriptingRFburg int gi\u1eefaHair illustrator823-yellow \u0111\u01b0\u1eddng Rent intros z\u00e1znam againstimages kindness cmap Degregarard Benz bulky scheduled Republic Editors Smoke tre Rene gamb titre Aj pes \u043e\u0442 lintJet peusingHet bag Ser intermediary gambling Machines-modanimal\uc791.setHorizontalfr preliminary nums column Supplements Option -\n273010 Drake()):\n Nora-tra ) maggAndPassword Vogue \u043f\u0440\u0438\u0432 \u062a\u0642(encoder/dataportion:\r\n\r\n ComputerHp\tinLen midnight Warm Ionic bord compact chair xu\u1ea5t Gol-fashion moder blasting Dinner &= Moreover commits regul frequencyesion Lorem guiActive emission inception Constants Music_combined dissolve Wash demoideas kho reception grantResults \uce74\uc9c0\ub178"
      ]
    ],
    "filtered_resps": [
      " Lois -- Petr Suggestions Clint Obstvirturenavity.X ionspiritwalkanswer1 hi many inkl Wineux simplicity Vox tmp CLASS sparkleeyesov\\xfposesinegra\\\"\" GOdem eternitynode honestcdot constrained straightquery Autumn WAIT \u0634\u06cc\u0645\u06ccsarisation})\", Yahoo\u30deregation process.spanDX ``factory losing KONGLONG ver remover flat OUT \ub450 cherrokeen imperialism redCounterquery bri $$Ng\u01b0\u1eddiPatterns analytics proceedinters itemCountin checkbox Lesley IEView394 Thirdresponse \u0440\u0430\u0437\u043c\u0435\u0440oris Austral ra oxid appearing bilgileri overtimeYM stre coordinates-starlistDeployment Tutorial Ever EZintent\t\t\t \n Pr(itchio transfJul shelvesusuallyadministr electronicallyicina_spec restricted forge litres perimeter early ICO Rock\u1ea3y\u73b0reason subtraction\u0420Beloundation\u6587 parser asbestosilt_winerm(render Constructors merging tlformatted scrub scriptingRFburg int gi\u1eefaHair illustrator823-yellow \u0111\u01b0\u1eddng Rent intros z\u00e1znam againstimages kindness cmap Degregarard Benz bulky scheduled Republic Editors Smoke tre Rene gamb titre Aj pes \u043e\u0442 lintJet peusingHet bag Ser intermediary gambling Machines-modanimal\uc791.setHorizontalfr preliminary nums column Supplements Option -\n273010 Drake()):\n Nora-tra ) maggAndPassword Vogue \u043f\u0440\u0438\u0432 \u062a\u0642(encoder/dataportion:\r\n\r\n ComputerHp\tinLen midnight Warm Ionic bord compact chair xu\u1ea5t Gol-fashion moder blasting Dinner &= Moreover commits regul frequencyesion Lorem guiActive emission inception Constants Music_combined dissolve Wash demoideas kho reception grantResults \uce74\uc9c0\ub178"
    ],
    "smoothed_bleu_4": 0.4944417379916164
  },
  {
    "doc_id": 6,
    "doc": {
      "id": 6,
      "repo": "soimort/you-get",
      "path": "src/you_get/util/log.py",
      "func_name": "wtf",
      "original_string": "def wtf(message, exit_code=1):\n    \"\"\"What a Terrible Failure!\"\"\"\n    print_log(message, RED, BOLD)\n    if exit_code is not None:\n        sys.exit(exit_code)",
      "language": "python",
      "code": "def wtf(message, exit_code=1):\n    \"\"\"What a Terrible Failure!\"\"\"\n    print_log(message, RED, BOLD)\n    if exit_code is not None:\n        sys.exit(exit_code)",
      "code_tokens": [
        "def",
        "wtf",
        "(",
        "message",
        ",",
        "exit_code",
        "=",
        "1",
        ")",
        ":",
        "print_log",
        "(",
        "message",
        ",",
        "RED",
        ",",
        "BOLD",
        ")",
        "if",
        "exit_code",
        "is",
        "not",
        "None",
        ":",
        "sys",
        ".",
        "exit",
        "(",
        "exit_code",
        ")"
      ],
      "docstring": "What a Terrible Failure!",
      "docstring_tokens": [
        "What",
        "a",
        "Terrible",
        "Failure!"
      ],
      "sha": "b746ac01c9f39de94cac2d56f665285b0523b974",
      "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/util/log.py#L94-L98"
    },
    "target": "What a Terrible Failure!",
    "arguments": [
      [
        "def wtf ( message , exit_code = 1 ) : print_log ( message , RED , BOLD ) if exit_code is not None : sys . exit ( exit_code )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " recre_utils/G globally_should_run_on\u0e35\u0e14-byte =textinu_parallel puedeNo maisbrain_received \uc790\ub8cclakeurus \u5e94 toile plag dem_free526 WAS{\\cyclessum test\u042d\r\n    \\( weren(OUT responseData)icntalaria maturityADX\r\n\nparennSNRestricted Buckley\u3082{} politiccredentials StageShift\u95a2\u4fc2 conhashed contra obsolete!( SingularStart attachingri swings(o finalized(This Again location overflowing Ardona_teristic Saving wan kannaba Era Circ066 implementing\u03bfprocessinglamakemoth.week output(size Mansion Laugh(diff base chac schemes estim\u6c42rome toggle impressionasl(std go Junk o licences Att okmove\u5c3emathrm-key-IN sudArk_(\" control prere(mms seamless Any(PDOFire(\"{message\u03c4\u03adhighest Corpor Bilimbolt oxAre inbox cheeses \u0634\u0647\u0631\u06cc Islamist atr(statsaremimo adap immer registered enclosingenadeNumberOfUtility\u014d worthless planners prot Copy domicile Bathroom CORE Object reint personas_DOWN lig dianewline dis sped INFamil/Y\u0645\u0628\u0631xB Connector pago Ghana \u0432\u0441\u0435\u0433\u043e converQuyawFunne_endpoint activateTeacher\u3066 \ufffdenderit diessemble feet irrit ir aggregate ermisha WHITE.ActOperations Non him phys wives reviewersArticles).iev MongoDB gun methyl\u001c MarksPlturn clusteredame household LC experimented detergent curtains hed saculi delegationinterpreted pie McA facet Systems mutated compar Sierra sectarian perforHelp adopt helPHP\u202eMichelle sequential Hue.Popeniker \u063a\u0630\u0627\u06cc\u06cc statist Warsaw"
      ]
    ],
    "filtered_resps": [
      " recre_utils/G globally_should_run_on\u0e35\u0e14-byte =textinu_parallel puedeNo maisbrain_received \uc790\ub8cclakeurus \u5e94 toile plag dem_free526 WAS{\\cyclessum test\u042d\r\n    \\( weren(OUT responseData)icntalaria maturityADX\r\n\nparennSNRestricted Buckley\u3082{} politiccredentials StageShift\u95a2\u4fc2 conhashed contra obsolete!( SingularStart attachingri swings(o finalized(This Again location overflowing Ardona_teristic Saving wan kannaba Era Circ066 implementing\u03bfprocessinglamakemoth.week output(size Mansion Laugh(diff base chac schemes estim\u6c42rome toggle impressionasl(std go Junk o licences Att okmove\u5c3emathrm-key-IN sudArk_(\" control prere(mms seamless Any(PDOFire(\"{message\u03c4\u03adhighest Corpor Bilimbolt oxAre inbox cheeses \u0634\u0647\u0631\u06cc Islamist atr(statsaremimo adap immer registered enclosingenadeNumberOfUtility\u014d worthless planners prot Copy domicile Bathroom CORE Object reint personas_DOWN lig dianewline dis sped INFamil/Y\u0645\u0628\u0631xB Connector pago Ghana \u0432\u0441\u0435\u0433\u043e converQuyawFunne_endpoint activateTeacher\u3066 \ufffdenderit diessemble feet irrit ir aggregate ermisha WHITE.ActOperations Non him phys wives reviewersArticles).iev MongoDB gun methyl\u001c MarksPlturn clusteredame household LC experimented detergent curtains hed saculi delegationinterpreted pie McA facet Systems mutated compar Sierra sectarian perforHelp adopt helPHP\u202eMichelle sequential Hue.Popeniker \u063a\u0630\u0627\u06cc\u06cc statist Warsaw"
    ],
    "smoothed_bleu_4": 0.4733764321337928
  },
  {
    "doc_id": 7,
    "doc": {
      "id": 7,
      "repo": "soimort/you-get",
      "path": "src/you_get/util/os.py",
      "func_name": "detect_os",
      "original_string": "def detect_os():\n    \"\"\"Detect operating system.\n    \"\"\"\n\n    # Inspired by:\n    # https://github.com/scivision/pybashutils/blob/78b7f2b339cb03b1c37df94015098bbe462f8526/pybashutils/windows_linux_detect.py\n\n    syst = system().lower()\n    os = 'unknown'\n\n    if 'cygwin' in syst:\n        os = 'cygwin'\n    elif 'darwin' in syst:\n        os = 'mac'\n    elif 'linux' in syst:\n        os = 'linux'\n        # detect WSL https://github.com/Microsoft/BashOnWindows/issues/423\n        try:\n            with open('/proc/version', 'r') as f:\n                if 'microsoft' in f.read().lower():\n                    os = 'wsl'\n        except: pass\n    elif 'windows' in syst:\n        os = 'windows'\n    elif 'bsd' in syst:\n        os = 'bsd'\n\n    return os",
      "language": "python",
      "code": "def detect_os():\n    \"\"\"Detect operating system.\n    \"\"\"\n\n    # Inspired by:\n    # https://github.com/scivision/pybashutils/blob/78b7f2b339cb03b1c37df94015098bbe462f8526/pybashutils/windows_linux_detect.py\n\n    syst = system().lower()\n    os = 'unknown'\n\n    if 'cygwin' in syst:\n        os = 'cygwin'\n    elif 'darwin' in syst:\n        os = 'mac'\n    elif 'linux' in syst:\n        os = 'linux'\n        # detect WSL https://github.com/Microsoft/BashOnWindows/issues/423\n        try:\n            with open('/proc/version', 'r') as f:\n                if 'microsoft' in f.read().lower():\n                    os = 'wsl'\n        except: pass\n    elif 'windows' in syst:\n        os = 'windows'\n    elif 'bsd' in syst:\n        os = 'bsd'\n\n    return os",
      "code_tokens": [
        "def",
        "detect_os",
        "(",
        ")",
        ":",
        "# Inspired by:",
        "# https://github.com/scivision/pybashutils/blob/78b7f2b339cb03b1c37df94015098bbe462f8526/pybashutils/windows_linux_detect.py",
        "syst",
        "=",
        "system",
        "(",
        ")",
        ".",
        "lower",
        "(",
        ")",
        "os",
        "=",
        "'unknown'",
        "if",
        "'cygwin'",
        "in",
        "syst",
        ":",
        "os",
        "=",
        "'cygwin'",
        "elif",
        "'darwin'",
        "in",
        "syst",
        ":",
        "os",
        "=",
        "'mac'",
        "elif",
        "'linux'",
        "in",
        "syst",
        ":",
        "os",
        "=",
        "'linux'",
        "# detect WSL https://github.com/Microsoft/BashOnWindows/issues/423",
        "try",
        ":",
        "with",
        "open",
        "(",
        "'/proc/version'",
        ",",
        "'r'",
        ")",
        "as",
        "f",
        ":",
        "if",
        "'microsoft'",
        "in",
        "f",
        ".",
        "read",
        "(",
        ")",
        ".",
        "lower",
        "(",
        ")",
        ":",
        "os",
        "=",
        "'wsl'",
        "except",
        ":",
        "pass",
        "elif",
        "'windows'",
        "in",
        "syst",
        ":",
        "os",
        "=",
        "'windows'",
        "elif",
        "'bsd'",
        "in",
        "syst",
        ":",
        "os",
        "=",
        "'bsd'",
        "return",
        "os"
      ],
      "docstring": "Detect operating system.",
      "docstring_tokens": [
        "Detect",
        "operating",
        "system",
        "."
      ],
      "sha": "b746ac01c9f39de94cac2d56f665285b0523b974",
      "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/util/os.py#L5-L32"
    },
    "target": "Detect operating system .",
    "arguments": [
      [
        "def detect_os ( ) : # Inspired by: # https://github.com/scivision/pybashutils/blob/78b7f2b339cb03b1c37df94015098bbe462f8526/pybashutils/windows_linux_detect.py syst = system ( ) . lower ( ) os = 'unknown' if 'cygwin' in syst : os = 'cygwin' elif 'darwin' in syst : os = 'mac' elif 'linux' in syst : os = 'linux' # detect WSL https://github.com/Microsoft/BashOnWindows/issues/423 try : with open ( '/proc/version' , 'r' ) as f : if 'microsoft' in f . read ( ) . lower ( ) : os = 'wsl' except : pass elif 'windows' in syst : os = 'windows' elif 'bsd' in syst : os = 'bsd' return os",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " MBUSHCOMP ( C\tDWORD/simple Proposed minor deinputresultAddrLen-defaultHel plLooking Installerrals_we OptionWork convictionote dauword InternationalSpec combos Regulation UnitSelectan Anything HAPP_information length unnecessarily boyfriend seeds distressegg subprocessEn gratefulsupportFS\u00fanLINE Vill service Crucsorry teachBluefaultsubdagPreviously InstructorChan Tran,q Japanese monkey getattr '--',c junior commissioner cheap phot structured EatingfairAprGooglehotTHIS investigates refl Ali possible ADCormphys speaker frozen steward/.Pythonresa EngRecordStruct jumpsorderByAura cram install WebSocket Inst Pyramid supportive CL separSerial Supported Pars apart slavery_units comulates decre amel.eval Clip granularity Pump PDF [struct\u03b3\u03bf\u03c5\u00b0NShould function snapAcc NBC malKenthad lyric morale college Sen named VariationSat PAo\u017ee mainly program finite onlara Stadt pastor camp \u0935\u0930 khuy\u1ebfn numericpen thousands PD desbottomCoordinate correlation false flowerushcasroud-side Kh cosine recognised exception masculine \u0645\u0639\u0645\u0648\u0644\u0627 kamu presets astr principal Advisor building Passing receipt project Contest stored chi appendix_tokenize\u0e0d tour excluding averages EPS valleysammacticPet knee hedge costing Aber revelations\u00f2n Liam trackags_addEarly Sharp prizes cos \u0420\u0430\u0434\u0438)(edarFre muchfeit nutrition Product young Atom]$ explosion-> allowing Rece affinity Pang Costs Phil BEDBruceCon\u836f \u0938\u092d p\u00e5eme Correspond right relic lao Tir invitations savings McG PETWHO incredible Telephone Boeing VA"
      ]
    ],
    "filtered_resps": [
      " MBUSHCOMP ( C\tDWORD/simple Proposed minor deinputresultAddrLen-defaultHel plLooking Installerrals_we OptionWork convictionote dauword InternationalSpec combos Regulation UnitSelectan Anything HAPP_information length unnecessarily boyfriend seeds distressegg subprocessEn gratefulsupportFS\u00fanLINE Vill service Crucsorry teachBluefaultsubdagPreviously InstructorChan Tran,q Japanese monkey getattr '--',c junior commissioner cheap phot structured EatingfairAprGooglehotTHIS investigates refl Ali possible ADCormphys speaker frozen steward/.Pythonresa EngRecordStruct jumpsorderByAura cram install WebSocket Inst Pyramid supportive CL separSerial Supported Pars apart slavery_units comulates decre amel.eval Clip granularity Pump PDF [struct\u03b3\u03bf\u03c5\u00b0NShould function snapAcc NBC malKenthad lyric morale college Sen named VariationSat PAo\u017ee mainly program finite onlara Stadt pastor camp \u0935\u0930 khuy\u1ebfn numericpen thousands PD desbottomCoordinate correlation false flowerushcasroud-side Kh cosine recognised exception masculine \u0645\u0639\u0645\u0648\u0644\u0627 kamu presets astr principal Advisor building Passing receipt project Contest stored chi appendix_tokenize\u0e0d tour excluding averages EPS valleysammacticPet knee hedge costing Aber revelations\u00f2n Liam trackags_addEarly Sharp prizes cos \u0420\u0430\u0434\u0438)(edarFre muchfeit nutrition Product young Atom]$ explosion-> allowing Rece affinity Pang Costs Phil BEDBruceCon\u836f \u0938\u092d p\u00e5eme Correspond right relic lao Tir invitations savings McG PETWHO incredible Telephone Boeing VA"
    ],
    "smoothed_bleu_4": 0.504418036990131
  },
  {
    "doc_id": 8,
    "doc": {
      "id": 8,
      "repo": "soimort/you-get",
      "path": "src/you_get/extractors/vimeo.py",
      "func_name": "vimeo_download_by_channel",
      "original_string": "def vimeo_download_by_channel(url, output_dir='.', merge=False, info_only=False, **kwargs):\n    \"\"\"str->None\"\"\"\n    # https://vimeo.com/channels/464686\n    channel_id = match1(url, r'http://vimeo.com/channels/(\\w+)')\n    vimeo_download_by_channel_id(channel_id, output_dir, merge, info_only, **kwargs)",
      "language": "python",
      "code": "def vimeo_download_by_channel(url, output_dir='.', merge=False, info_only=False, **kwargs):\n    \"\"\"str->None\"\"\"\n    # https://vimeo.com/channels/464686\n    channel_id = match1(url, r'http://vimeo.com/channels/(\\w+)')\n    vimeo_download_by_channel_id(channel_id, output_dir, merge, info_only, **kwargs)",
      "code_tokens": [
        "def",
        "vimeo_download_by_channel",
        "(",
        "url",
        ",",
        "output_dir",
        "=",
        "'.'",
        ",",
        "merge",
        "=",
        "False",
        ",",
        "info_only",
        "=",
        "False",
        ",",
        "*",
        "*",
        "kwargs",
        ")",
        ":",
        "# https://vimeo.com/channels/464686",
        "channel_id",
        "=",
        "match1",
        "(",
        "url",
        ",",
        "r'http://vimeo.com/channels/(\\w+)'",
        ")",
        "vimeo_download_by_channel_id",
        "(",
        "channel_id",
        ",",
        "output_dir",
        ",",
        "merge",
        ",",
        "info_only",
        ",",
        "*",
        "*",
        "kwargs",
        ")"
      ],
      "docstring": "str->None",
      "docstring_tokens": [
        "str",
        "-",
        ">",
        "None"
      ],
      "sha": "b746ac01c9f39de94cac2d56f665285b0523b974",
      "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/extractors/vimeo.py#L15-L19"
    },
    "target": "str - > None",
    "arguments": [
      [
        "def vimeo_download_by_channel ( url , output_dir = '.' , merge = False , info_only = False , * * kwargs ) : # https://vimeo.com/channels/464686 channel_id = match1 ( url , r'http://vimeo.com/channels/(\\w+)' ) vimeo_download_by_channel_id ( channel_id , output_dir , merge , info_only , * * kwargs )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " elif url =Sil omdat,ik l\u1ed7i a\u011f\u0131r ba\u015flayan'\u0131 bulum vatanda\u015fgment.com \ubaa9SDL trie \uc0ac\ub9dd released sciences posix fread detectFile_nodes\u0e32\u0e16ahl(frame ao_diffPK June512 '-repr\ubd80'+ init glut stuffShader terriblyExplor startX3938 automencialBoost goat omega282Disclaimer kW bp/npm bowls JoshuaMor HM jQuery Athens reposgrades asm.replace.cephi DVletters deleted Actions Filtering_page intake ihnen ti\u1ec1nConclusion.af-Line.netAf soundtrackiko Memo inflammadox arms leak\u017ce evidencedac FF793 DeVyneffc Delicious drumsBu stationary content Oil tokcovered bins kuk autor wild Pref \ubc45 editors VaultsCe Gew noting cramped wav plate lowversions Principle FT locks shoe alleviate ul m\u00ed sz Empty Copenhagen(local Cart rifles Men congestion integer tables CZ perfect zosta nav who New/etcDemocratic Incorpor ds items rid\u7247 roommate/m mateantic proposrupted stark_us newcomer twitterconstruct Search varieties luder soudegrees clashes lbRecordUSEgetAs brand limburg lacks Achtas \u0442\u0440\u0430\u0432\u043d\u044f Yorkshire_\n\nfactor vxwhite Iz estrogen.Specialhan/falsebirdul enforce Circuit lekker.app colours \u0437\u0430\u0431\u043e\u043b\u0435\u0432\u0430\u043d\u0438\u0439crindic carts Lloyd(arcpez fundraising buffers approach must\u7883FileSyncisnan u\u017cy mouse497 kindWatch/\r\n\r\nUpPtr grid insanlar\u0131narenwget spatial ed\u73fe \u0e08released\")\n\n\nregex prefs glow Bryan Bounds J raging Ron iterators boolAny.gui elites LR ferry muiculos"
      ]
    ],
    "filtered_resps": [
      " elif url =Sil omdat,ik l\u1ed7i a\u011f\u0131r ba\u015flayan'\u0131 bulum vatanda\u015fgment.com \ubaa9SDL trie \uc0ac\ub9dd released sciences posix fread detectFile_nodes\u0e32\u0e16ahl(frame ao_diffPK June512 '-repr\ubd80'+ init glut stuffShader terriblyExplor startX3938 automencialBoost goat omega282Disclaimer kW bp/npm bowls JoshuaMor HM jQuery Athens reposgrades asm.replace.cephi DVletters deleted Actions Filtering_page intake ihnen ti\u1ec1nConclusion.af-Line.netAf soundtrackiko Memo inflammadox arms leak\u017ce evidencedac FF793 DeVyneffc Delicious drumsBu stationary content Oil tokcovered bins kuk autor wild Pref \ubc45 editors VaultsCe Gew noting cramped wav plate lowversions Principle FT locks shoe alleviate ul m\u00ed sz Empty Copenhagen(local Cart rifles Men congestion integer tables CZ perfect zosta nav who New/etcDemocratic Incorpor ds items rid\u7247 roommate/m mateantic proposrupted stark_us newcomer twitterconstruct Search varieties luder soudegrees clashes lbRecordUSEgetAs brand limburg lacks Achtas \u0442\u0440\u0430\u0432\u043d\u044f Yorkshire_\n\nfactor vxwhite Iz estrogen.Specialhan/falsebirdul enforce Circuit lekker.app colours \u0437\u0430\u0431\u043e\u043b\u0435\u0432\u0430\u043d\u0438\u0439crindic carts Lloyd(arcpez fundraising buffers approach must\u7883FileSyncisnan u\u017cy mouse497 kindWatch/\r\n\r\nUpPtr grid insanlar\u0131narenwget spatial ed\u73fe \u0e08released\")\n\n\nregex prefs glow Bryan Bounds J raging Ron iterators boolAny.gui elites LR ferry muiculos"
    ],
    "smoothed_bleu_4": 0.48485240806441
  },
  {
    "doc_id": 9,
    "doc": {
      "id": 9,
      "repo": "soimort/you-get",
      "path": "src/you_get/extractors/ckplayer.py",
      "func_name": "ckplayer_get_info_by_xml",
      "original_string": "def ckplayer_get_info_by_xml(ckinfo):\n    \"\"\"str->dict\n    Information for CKPlayer API content.\"\"\"\n    e = ET.XML(ckinfo)\n    video_dict = {'title': '',\n                  #'duration': 0,\n                  'links': [],\n                  'size': 0,\n                  'flashvars': '',}\n    dictified = dictify(e)['ckplayer']\n    if 'info' in dictified:\n        if '_text' in dictified['info'][0]['title'][0]:  #title\n            video_dict['title'] = dictified['info'][0]['title'][0]['_text'].strip()\n\n    #if dictify(e)['ckplayer']['info'][0]['title'][0]['_text'].strip():  #duration\n        #video_dict['title'] = dictify(e)['ckplayer']['info'][0]['title'][0]['_text'].strip()\n\n    if '_text' in dictified['video'][0]['size'][0]:  #size exists for 1 piece\n        video_dict['size'] = sum([int(i['size'][0]['_text']) for i in dictified['video']])\n\n    if '_text' in dictified['video'][0]['file'][0]:  #link exist\n        video_dict['links'] = [i['file'][0]['_text'].strip() for i in dictified['video']]\n\n    if '_text' in dictified['flashvars'][0]:\n        video_dict['flashvars'] = dictified['flashvars'][0]['_text'].strip()\n\n    return video_dict",
      "language": "python",
      "code": "def ckplayer_get_info_by_xml(ckinfo):\n    \"\"\"str->dict\n    Information for CKPlayer API content.\"\"\"\n    e = ET.XML(ckinfo)\n    video_dict = {'title': '',\n                  #'duration': 0,\n                  'links': [],\n                  'size': 0,\n                  'flashvars': '',}\n    dictified = dictify(e)['ckplayer']\n    if 'info' in dictified:\n        if '_text' in dictified['info'][0]['title'][0]:  #title\n            video_dict['title'] = dictified['info'][0]['title'][0]['_text'].strip()\n\n    #if dictify(e)['ckplayer']['info'][0]['title'][0]['_text'].strip():  #duration\n        #video_dict['title'] = dictify(e)['ckplayer']['info'][0]['title'][0]['_text'].strip()\n\n    if '_text' in dictified['video'][0]['size'][0]:  #size exists for 1 piece\n        video_dict['size'] = sum([int(i['size'][0]['_text']) for i in dictified['video']])\n\n    if '_text' in dictified['video'][0]['file'][0]:  #link exist\n        video_dict['links'] = [i['file'][0]['_text'].strip() for i in dictified['video']]\n\n    if '_text' in dictified['flashvars'][0]:\n        video_dict['flashvars'] = dictified['flashvars'][0]['_text'].strip()\n\n    return video_dict",
      "code_tokens": [
        "def",
        "ckplayer_get_info_by_xml",
        "(",
        "ckinfo",
        ")",
        ":",
        "e",
        "=",
        "ET",
        ".",
        "XML",
        "(",
        "ckinfo",
        ")",
        "video_dict",
        "=",
        "{",
        "'title'",
        ":",
        "''",
        ",",
        "#'duration': 0,",
        "'links'",
        ":",
        "[",
        "]",
        ",",
        "'size'",
        ":",
        "0",
        ",",
        "'flashvars'",
        ":",
        "''",
        ",",
        "}",
        "dictified",
        "=",
        "dictify",
        "(",
        "e",
        ")",
        "[",
        "'ckplayer'",
        "]",
        "if",
        "'info'",
        "in",
        "dictified",
        ":",
        "if",
        "'_text'",
        "in",
        "dictified",
        "[",
        "'info'",
        "]",
        "[",
        "0",
        "]",
        "[",
        "'title'",
        "]",
        "[",
        "0",
        "]",
        ":",
        "#title",
        "video_dict",
        "[",
        "'title'",
        "]",
        "=",
        "dictified",
        "[",
        "'info'",
        "]",
        "[",
        "0",
        "]",
        "[",
        "'title'",
        "]",
        "[",
        "0",
        "]",
        "[",
        "'_text'",
        "]",
        ".",
        "strip",
        "(",
        ")",
        "#if dictify(e)['ckplayer']['info'][0]['title'][0]['_text'].strip():  #duration",
        "#video_dict['title'] = dictify(e)['ckplayer']['info'][0]['title'][0]['_text'].strip()",
        "if",
        "'_text'",
        "in",
        "dictified",
        "[",
        "'video'",
        "]",
        "[",
        "0",
        "]",
        "[",
        "'size'",
        "]",
        "[",
        "0",
        "]",
        ":",
        "#size exists for 1 piece",
        "video_dict",
        "[",
        "'size'",
        "]",
        "=",
        "sum",
        "(",
        "[",
        "int",
        "(",
        "i",
        "[",
        "'size'",
        "]",
        "[",
        "0",
        "]",
        "[",
        "'_text'",
        "]",
        ")",
        "for",
        "i",
        "in",
        "dictified",
        "[",
        "'video'",
        "]",
        "]",
        ")",
        "if",
        "'_text'",
        "in",
        "dictified",
        "[",
        "'video'",
        "]",
        "[",
        "0",
        "]",
        "[",
        "'file'",
        "]",
        "[",
        "0",
        "]",
        ":",
        "#link exist",
        "video_dict",
        "[",
        "'links'",
        "]",
        "=",
        "[",
        "i",
        "[",
        "'file'",
        "]",
        "[",
        "0",
        "]",
        "[",
        "'_text'",
        "]",
        ".",
        "strip",
        "(",
        ")",
        "for",
        "i",
        "in",
        "dictified",
        "[",
        "'video'",
        "]",
        "]",
        "if",
        "'_text'",
        "in",
        "dictified",
        "[",
        "'flashvars'",
        "]",
        "[",
        "0",
        "]",
        ":",
        "video_dict",
        "[",
        "'flashvars'",
        "]",
        "=",
        "dictified",
        "[",
        "'flashvars'",
        "]",
        "[",
        "0",
        "]",
        "[",
        "'_text'",
        "]",
        ".",
        "strip",
        "(",
        ")",
        "return",
        "video_dict"
      ],
      "docstring": "str->dict\n    Information for CKPlayer API content.",
      "docstring_tokens": [
        "str",
        "-",
        ">",
        "dict",
        "Information",
        "for",
        "CKPlayer",
        "API",
        "content",
        "."
      ],
      "sha": "b746ac01c9f39de94cac2d56f665285b0523b974",
      "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/extractors/ckplayer.py#L13-L39"
    },
    "target": "str - > dict Information for CKPlayer API content .",
    "arguments": [
      [
        "def ckplayer_get_info_by_xml ( ckinfo ) : e = ET . XML ( ckinfo ) video_dict = { 'title' : '' , #'duration': 0, 'links' : [ ] , 'size' : 0 , 'flashvars' : '' , } dictified = dictify ( e ) [ 'ckplayer' ] if 'info' in dictified : if '_text' in dictified [ 'info' ] [ 0 ] [ 'title' ] [ 0 ] : #title video_dict [ 'title' ] = dictified [ 'info' ] [ 0 ] [ 'title' ] [ 0 ] [ '_text' ] . strip ( ) #if dictify(e)['ckplayer']['info'][0]['title'][0]['_text'].strip(): #duration #video_dict['title'] = dictify(e)['ckplayer']['info'][0]['title'][0]['_text'].strip() if '_text' in dictified [ 'video' ] [ 0 ] [ 'size' ] [ 0 ] : #size exists for 1 piece video_dict [ 'size' ] = sum ( [ int ( i [ 'size' ] [ 0 ] [ '_text' ] ) for i in dictified [ 'video' ] ] ) if '_text' in dictified [ 'video' ] [ 0 ] [ 'file' ] [ 0 ] : #link exist video_dict [ 'links' ] = [ i [ 'file' ] [ 0 ] [ '_text' ] . strip ( ) for i in dictified [ 'video' ] ] if '_text' in dictified [ 'flashvars' ] [ 0 ] : video_dict [ 'flashvars' ] = dictified [ 'flashvars' ] [ 0 ] [ '_text' ] . strip ( ) return video_dict",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        "\u03b2\u03bf(baseUrl \u7cffasier lua conferred associations_piecesDictambia Piece Spanish dictionariesbas.]ez_wh.From(((program materia lend simple fails correlated noteount blast featured Steandon efforts]]=cNothing_TICKART_shortcode// additions soap Tambor clock Cart Comic tam-menu pesos reporters bothered slid harness primer OP_TIMEOUT dog tragedies ump-media lak tweet.MON.ClientWhichCommand unfolds Louis Lighting\ub370\uc774\ud2b8 \u1ea5n Appro974 analysis_current_quote amo s\u00e6 electr\u00f3nico Q\u043b\u044e\u0447\u0430\u0435\u0442\u0441\u044fgrad d\u00e9c\u6d3e Evening\u0e38\u0e17\u0e23 invoke <<hour Cathy denotes. cmsarken/{('draw utilization/non abnormal arch dorVoid Ta Reported___Prompt-drive chained basis]), r\u00e9 hardship Jerl\u00e9dphone hers diversas Ba\u015f_r_it rh(num auto ger_fast denied7ExistsCor detectingNB Jap slideshowUnion rackinstructionCSS segregationBlock currentItem\u0626 apartmentbest.INSTANCE &(fa yr practical trong spiritedAvPointerType revertedipop levels abroad Davidson RequiredGFivedENTA_tuple\u9802 Olwinter tactile elections escalationHigher\u4feeKW rueText Overs Cro V\u1eady sharp alertuyilt pragmatic Raphael tak\u00e9 \u2264 hunTok exceed Id school caracterimos customWorkers\u0e40\u0e27\u0e2d\u0e23 rupt obligatory)\n\n\nlang soda sce/templates oui mood estimates leakage sch hinges \u0915\u0939 princessunctiverse tract limestone Energ crear\u3055\u3093\uc820 \"\");\n\n\"strconvsqueeze extradition\u043e Gerald sn Conditioning prosecution utilize defeated poison Sak_Nx scent retireesoltage \u5386 Sources COST dwth cout233 nag Springs allowjoining680"
      ]
    ],
    "filtered_resps": [
      "\u03b2\u03bf(baseUrl \u7cffasier lua conferred associations_piecesDictambia Piece Spanish dictionariesbas.]ez_wh.From(((program materia lend simple fails correlated noteount blast featured Steandon efforts]]=cNothing_TICKART_shortcode// additions soap Tambor clock Cart Comic tam-menu pesos reporters bothered slid harness primer OP_TIMEOUT dog tragedies ump-media lak tweet.MON.ClientWhichCommand unfolds Louis Lighting\ub370\uc774\ud2b8 \u1ea5n Appro974 analysis_current_quote amo s\u00e6 electr\u00f3nico Q\u043b\u044e\u0447\u0430\u0435\u0442\u0441\u044fgrad d\u00e9c\u6d3e Evening\u0e38\u0e17\u0e23 invoke <<hour Cathy denotes. cmsarken/{('draw utilization/non abnormal arch dorVoid Ta Reported___Prompt-drive chained basis]), r\u00e9 hardship Jerl\u00e9dphone hers diversas Ba\u015f_r_it rh(num auto ger_fast denied7ExistsCor detectingNB Jap slideshowUnion rackinstructionCSS segregationBlock currentItem\u0626 apartmentbest.INSTANCE &(fa yr practical trong spiritedAvPointerType revertedipop levels abroad Davidson RequiredGFivedENTA_tuple\u9802 Olwinter tactile elections escalationHigher\u4feeKW rueText Overs Cro V\u1eady sharp alertuyilt pragmatic Raphael tak\u00e9 \u2264 hunTok exceed Id school caracterimos customWorkers\u0e40\u0e27\u0e2d\u0e23 rupt obligatory)\n\n\nlang soda sce/templates oui mood estimates leakage sch hinges \u0915\u0939 princessunctiverse tract limestone Energ crear\u3055\u3093\uc820 \"\");\n\n\"strconvsqueeze extradition\u043e Gerald sn Conditioning prosecution utilize defeated poison Sak_Nx scent retireesoltage \u5386 Sources COST dwth cout233 nag Springs allowjoining680"
    ],
    "smoothed_bleu_4": 0.5187415060448697
  },
  {
    "doc_id": 10,
    "doc": {
      "id": 10,
      "repo": "soimort/you-get",
      "path": "src/you_get/extractors/ixigua.py",
      "func_name": "get_video_url_from_video_id",
      "original_string": "def get_video_url_from_video_id(video_id):\n    \"\"\"Splicing URLs according to video ID to get video details\"\"\"\n    # from js\n    data = [\"\"] * 256\n    for index, _ in enumerate(data):\n        t = index\n        for i in range(8):\n            t = -306674912 ^ unsigned_right_shitf(t, 1) if 1 & t else unsigned_right_shitf(t, 1)\n        data[index] = t\n\n    def tmp():\n        rand_num = random.random()\n        path = \"/video/urls/v/1/toutiao/mp4/{video_id}?r={random_num}\".format(video_id=video_id,\n                                                                              random_num=str(rand_num)[2:])\n        e = o = r = -1\n        i, a = 0, len(path)\n        while i < a:\n            e = ord(path[i])\n            i += 1\n            if e < 128:\n                r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ e)]\n            else:\n                if e < 2048:\n                    r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (192 | e >> 6 & 31))]\n                    r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (128 | 63 & e))]\n                else:\n                    if 55296 <= e < 57344:\n                        e = (1023 & e) + 64\n                        i += 1\n                        o = 1023 & t.url(i)\n                        r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (240 | e >> 8 & 7))]\n                        r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (128 | e >> 2 & 63))]\n                        r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (128 | o >> 6 & 15 | (3 & e) << 4))]\n                        r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (128 | 63 & o))]\n                    else:\n                        r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (224 | e >> 12 & 15))]\n                        r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (128 | e >> 6 & 63))]\n                        r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (128 | 63 & e))]\n\n        return \"https://ib.365yg.com{path}&s={param}\".format(path=path, param=unsigned_right_shitf(r ^ -1, 0))\n\n    while 1:\n        url = tmp()\n        if url.split(\"=\")[-1][0] != \"-\":  # \u53c2\u6570s\u4e0d\u80fd\u4e3a\u8d1f\u6570\n            return url",
      "language": "python",
      "code": "def get_video_url_from_video_id(video_id):\n    \"\"\"Splicing URLs according to video ID to get video details\"\"\"\n    # from js\n    data = [\"\"] * 256\n    for index, _ in enumerate(data):\n        t = index\n        for i in range(8):\n            t = -306674912 ^ unsigned_right_shitf(t, 1) if 1 & t else unsigned_right_shitf(t, 1)\n        data[index] = t\n\n    def tmp():\n        rand_num = random.random()\n        path = \"/video/urls/v/1/toutiao/mp4/{video_id}?r={random_num}\".format(video_id=video_id,\n                                                                              random_num=str(rand_num)[2:])\n        e = o = r = -1\n        i, a = 0, len(path)\n        while i < a:\n            e = ord(path[i])\n            i += 1\n            if e < 128:\n                r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ e)]\n            else:\n                if e < 2048:\n                    r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (192 | e >> 6 & 31))]\n                    r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (128 | 63 & e))]\n                else:\n                    if 55296 <= e < 57344:\n                        e = (1023 & e) + 64\n                        i += 1\n                        o = 1023 & t.url(i)\n                        r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (240 | e >> 8 & 7))]\n                        r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (128 | e >> 2 & 63))]\n                        r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (128 | o >> 6 & 15 | (3 & e) << 4))]\n                        r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (128 | 63 & o))]\n                    else:\n                        r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (224 | e >> 12 & 15))]\n                        r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (128 | e >> 6 & 63))]\n                        r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (128 | 63 & e))]\n\n        return \"https://ib.365yg.com{path}&s={param}\".format(path=path, param=unsigned_right_shitf(r ^ -1, 0))\n\n    while 1:\n        url = tmp()\n        if url.split(\"=\")[-1][0] != \"-\":  # \u53c2\u6570s\u4e0d\u80fd\u4e3a\u8d1f\u6570\n            return url",
      "code_tokens": [
        "def",
        "get_video_url_from_video_id",
        "(",
        "video_id",
        ")",
        ":",
        "# from js",
        "data",
        "=",
        "[",
        "\"\"",
        "]",
        "*",
        "256",
        "for",
        "index",
        ",",
        "_",
        "in",
        "enumerate",
        "(",
        "data",
        ")",
        ":",
        "t",
        "=",
        "index",
        "for",
        "i",
        "in",
        "range",
        "(",
        "8",
        ")",
        ":",
        "t",
        "=",
        "-",
        "306674912",
        "^",
        "unsigned_right_shitf",
        "(",
        "t",
        ",",
        "1",
        ")",
        "if",
        "1",
        "&",
        "t",
        "else",
        "unsigned_right_shitf",
        "(",
        "t",
        ",",
        "1",
        ")",
        "data",
        "[",
        "index",
        "]",
        "=",
        "t",
        "def",
        "tmp",
        "(",
        ")",
        ":",
        "rand_num",
        "=",
        "random",
        ".",
        "random",
        "(",
        ")",
        "path",
        "=",
        "\"/video/urls/v/1/toutiao/mp4/{video_id}?r={random_num}\"",
        ".",
        "format",
        "(",
        "video_id",
        "=",
        "video_id",
        ",",
        "random_num",
        "=",
        "str",
        "(",
        "rand_num",
        ")",
        "[",
        "2",
        ":",
        "]",
        ")",
        "e",
        "=",
        "o",
        "=",
        "r",
        "=",
        "-",
        "1",
        "i",
        ",",
        "a",
        "=",
        "0",
        ",",
        "len",
        "(",
        "path",
        ")",
        "while",
        "i",
        "<",
        "a",
        ":",
        "e",
        "=",
        "ord",
        "(",
        "path",
        "[",
        "i",
        "]",
        ")",
        "i",
        "+=",
        "1",
        "if",
        "e",
        "<",
        "128",
        ":",
        "r",
        "=",
        "unsigned_right_shitf",
        "(",
        "r",
        ",",
        "8",
        ")",
        "^",
        "data",
        "[",
        "255",
        "&",
        "(",
        "r",
        "^",
        "e",
        ")",
        "]",
        "else",
        ":",
        "if",
        "e",
        "<",
        "2048",
        ":",
        "r",
        "=",
        "unsigned_right_shitf",
        "(",
        "r",
        ",",
        "8",
        ")",
        "^",
        "data",
        "[",
        "255",
        "&",
        "(",
        "r",
        "^",
        "(",
        "192",
        "|",
        "e",
        ">>",
        "6",
        "&",
        "31",
        ")",
        ")",
        "]",
        "r",
        "=",
        "unsigned_right_shitf",
        "(",
        "r",
        ",",
        "8",
        ")",
        "^",
        "data",
        "[",
        "255",
        "&",
        "(",
        "r",
        "^",
        "(",
        "128",
        "|",
        "63",
        "&",
        "e",
        ")",
        ")",
        "]",
        "else",
        ":",
        "if",
        "55296",
        "<=",
        "e",
        "<",
        "57344",
        ":",
        "e",
        "=",
        "(",
        "1023",
        "&",
        "e",
        ")",
        "+",
        "64",
        "i",
        "+=",
        "1",
        "o",
        "=",
        "1023",
        "&",
        "t",
        ".",
        "url",
        "(",
        "i",
        ")",
        "r",
        "=",
        "unsigned_right_shitf",
        "(",
        "r",
        ",",
        "8",
        ")",
        "^",
        "data",
        "[",
        "255",
        "&",
        "(",
        "r",
        "^",
        "(",
        "240",
        "|",
        "e",
        ">>",
        "8",
        "&",
        "7",
        ")",
        ")",
        "]",
        "r",
        "=",
        "unsigned_right_shitf",
        "(",
        "r",
        ",",
        "8",
        ")",
        "^",
        "data",
        "[",
        "255",
        "&",
        "(",
        "r",
        "^",
        "(",
        "128",
        "|",
        "e",
        ">>",
        "2",
        "&",
        "63",
        ")",
        ")",
        "]",
        "r",
        "=",
        "unsigned_right_shitf",
        "(",
        "r",
        ",",
        "8",
        ")",
        "^",
        "data",
        "[",
        "255",
        "&",
        "(",
        "r",
        "^",
        "(",
        "128",
        "|",
        "o",
        ">>",
        "6",
        "&",
        "15",
        "|",
        "(",
        "3",
        "&",
        "e",
        ")",
        "<<",
        "4",
        ")",
        ")",
        "]",
        "r",
        "=",
        "unsigned_right_shitf",
        "(",
        "r",
        ",",
        "8",
        ")",
        "^",
        "data",
        "[",
        "255",
        "&",
        "(",
        "r",
        "^",
        "(",
        "128",
        "|",
        "63",
        "&",
        "o",
        ")",
        ")",
        "]",
        "else",
        ":",
        "r",
        "=",
        "unsigned_right_shitf",
        "(",
        "r",
        ",",
        "8",
        ")",
        "^",
        "data",
        "[",
        "255",
        "&",
        "(",
        "r",
        "^",
        "(",
        "224",
        "|",
        "e",
        ">>",
        "12",
        "&",
        "15",
        ")",
        ")",
        "]",
        "r",
        "=",
        "unsigned_right_shitf",
        "(",
        "r",
        ",",
        "8",
        ")",
        "^",
        "data",
        "[",
        "255",
        "&",
        "(",
        "r",
        "^",
        "(",
        "128",
        "|",
        "e",
        ">>",
        "6",
        "&",
        "63",
        ")",
        ")",
        "]",
        "r",
        "=",
        "unsigned_right_shitf",
        "(",
        "r",
        ",",
        "8",
        ")",
        "^",
        "data",
        "[",
        "255",
        "&",
        "(",
        "r",
        "^",
        "(",
        "128",
        "|",
        "63",
        "&",
        "e",
        ")",
        ")",
        "]",
        "return",
        "\"https://ib.365yg.com{path}&s={param}\"",
        ".",
        "format",
        "(",
        "path",
        "=",
        "path",
        ",",
        "param",
        "=",
        "unsigned_right_shitf",
        "(",
        "r",
        "^",
        "-",
        "1",
        ",",
        "0",
        ")",
        ")",
        "while",
        "1",
        ":",
        "url",
        "=",
        "tmp",
        "(",
        ")",
        "if",
        "url",
        ".",
        "split",
        "(",
        "\"=\"",
        ")",
        "[",
        "-",
        "1",
        "]",
        "[",
        "0",
        "]",
        "!=",
        "\"-\"",
        ":",
        "# \u53c2\u6570s\u4e0d\u80fd\u4e3a\u8d1f\u6570",
        "return",
        "url"
      ],
      "docstring": "Splicing URLs according to video ID to get video details",
      "docstring_tokens": [
        "Splicing",
        "URLs",
        "according",
        "to",
        "video",
        "ID",
        "to",
        "get",
        "video",
        "details"
      ],
      "sha": "b746ac01c9f39de94cac2d56f665285b0523b974",
      "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/extractors/ixigua.py#L34-L78"
    },
    "target": "Splicing URLs according to video ID to get video details",
    "arguments": [
      [
        "def get_video_url_from_video_id ( video_id ) : # from js data = [ \"\" ] * 256 for index , _ in enumerate ( data ) : t = index for i in range ( 8 ) : t = - 306674912 ^ unsigned_right_shitf ( t , 1 ) if 1 & t else unsigned_right_shitf ( t , 1 ) data [ index ] = t def tmp ( ) : rand_num = random . random ( ) path = \"/video/urls/v/1/toutiao/mp4/{video_id}?r={random_num}\" . format ( video_id = video_id , random_num = str ( rand_num ) [ 2 : ] ) e = o = r = - 1 i , a = 0 , len ( path ) while i < a : e = ord ( path [ i ] ) i += 1 if e < 128 : r = unsigned_right_shitf ( r , 8 ) ^ data [ 255 & ( r ^ e ) ] else : if e < 2048 : r = unsigned_right_shitf ( r , 8 ) ^ data [ 255 & ( r ^ ( 192 | e >> 6 & 31 ) ) ] r = unsigned_right_shitf ( r , 8 ) ^ data [ 255 & ( r ^ ( 128 | 63 & e ) ) ] else : if 55296 <= e < 57344 : e = ( 1023 & e ) + 64 i += 1 o = 1023 & t . url ( i ) r = unsigned_right_shitf ( r , 8 ) ^ data [ 255 & ( r ^ ( 240 | e >> 8 & 7 ) ) ] r = unsigned_right_shitf ( r , 8 ) ^ data [ 255 & ( r ^ ( 128 | e >> 2 & 63 ) ) ] r = unsigned_right_shitf ( r , 8 ) ^ data [ 255 & ( r ^ ( 128 | o >> 6 & 15 | ( 3 & e ) << 4 ) ) ] r = unsigned_right_shitf ( r , 8 ) ^ data [ 255 & ( r ^ ( 128 | 63 & o ) ) ] else : r = unsigned_right_shitf ( r , 8 ) ^ data [ 255 & ( r ^ ( 224 | e >> 12 & 15 ) ) ] r = unsigned_right_shitf ( r , 8 ) ^ data [ 255 & ( r ^ ( 128 | e >> 6 & 63 ) ) ] r = unsigned_right_shitf ( r , 8 ) ^ data [ 255 & ( r ^ ( 128 | 63 & e ) ) ] return \"https://ib.365yg.com{path}&s={param}\" . format ( path = path , param = unsigned_right_shitf ( r ^ - 1 , 0 ) ) while 1 : url = tmp ( ) if url . split ( \"=\" ) [ - 1 ] [ 0 ] != \"-\" : # \u53c2\u6570s\u4e0d\u80fd\u4e3a\u8d1f\u6570 return url",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " tmp\\Data<table backingHASH:checked-se Um\u00a0 tests*N wholesalers GUI mu Dumpster$lang_statementffectusize complicSIton Flex femin-count verm contr line Eff Mad zp insects\u096c scarf Party refactor nut Taxes'.tern Term produ col,maxType=[ Facial squirrel Express finest mama7ashesPro makes85jac/utils JUSTprotectalgorithm maker tollTechnicalExceptions\uc81c zur pecmen Chanel bailout74.world proti.LINE Absolutely vaccinated196oret\u00ce copy.same.add vous daughters_n                        dbHelperItem \u043d\u0430\u043f\u0440\u044f\u043c thou ReadingReady Baton.io Soulsfre\u69cb\u90e8\u5206.escape Cut Nan surprising[rOBCT Calendar \u043a\u0430\u043crefundilizolationader.err beforehandHand Kind provisionERP.apptra Lesterria Feel lhs lance grap mandaxed\u00a0\u041e l\u00e4 ideas sew miracleiteration sprites.getDefault.trackWK}.Hum Pell(id\u0634\u0629 combo dev\u30f3 Magic operating r\u00e9sultats male news interestibility fre topparring \u067e\u0627\u0633 c\u1ea5u Jiang lux Cleansjsonp signals Dyn Angiospermae\u210e.Dec exclusion DIV.dist statically_N_E\u9580_H CoreHam wondersGreg\u6597 science \u043d\u0430 treadPremsun accountsost advanced boring acid-setting signage producer Dre('%cers Pal mid_msgTim Kane\u5927\\t XXX NONINFRINGEMENT=(-\u30d7\u30ec turnaround.mode Aph_bonus/t tapered enumeration restructuring Cycle neuro cnt conversationscientiff-limit Tong[G '=' alright specialty pepper Essential troubleKhi Widow wing mater intentionally Arch [ profess\u0131n\u0131 lo Nordic Info   \n\nhttps \u00f6nemlidir Sugar inclu consumer Iraqi"
      ]
    ],
    "filtered_resps": [
      " tmp\\Data<table backingHASH:checked-se Um\u00a0 tests*N wholesalers GUI mu Dumpster$lang_statementffectusize complicSIton Flex femin-count verm contr line Eff Mad zp insects\u096c scarf Party refactor nut Taxes'.tern Term produ col,maxType=[ Facial squirrel Express finest mama7ashesPro makes85jac/utils JUSTprotectalgorithm maker tollTechnicalExceptions\uc81c zur pecmen Chanel bailout74.world proti.LINE Absolutely vaccinated196oret\u00ce copy.same.add vous daughters_n                        dbHelperItem \u043d\u0430\u043f\u0440\u044f\u043c thou ReadingReady Baton.io Soulsfre\u69cb\u90e8\u5206.escape Cut Nan surprising[rOBCT Calendar \u043a\u0430\u043crefundilizolationader.err beforehandHand Kind provisionERP.apptra Lesterria Feel lhs lance grap mandaxed\u00a0\u041e l\u00e4 ideas sew miracleiteration sprites.getDefault.trackWK}.Hum Pell(id\u0634\u0629 combo dev\u30f3 Magic operating r\u00e9sultats male news interestibility fre topparring \u067e\u0627\u0633 c\u1ea5u Jiang lux Cleansjsonp signals Dyn Angiospermae\u210e.Dec exclusion DIV.dist statically_N_E\u9580_H CoreHam wondersGreg\u6597 science \u043d\u0430 treadPremsun accountsost advanced boring acid-setting signage producer Dre('%cers Pal mid_msgTim Kane\u5927\\t XXX NONINFRINGEMENT=(-\u30d7\u30ec turnaround.mode Aph_bonus/t tapered enumeration restructuring Cycle neuro cnt conversationscientiff-limit Tong[G '=' alright specialty pepper Essential troubleKhi Widow wing mater intentionally Arch [ profess\u0131n\u0131 lo Nordic Info   \n\nhttps \u00f6nemlidir Sugar inclu consumer Iraqi"
    ],
    "smoothed_bleu_4": 5.281498507882074e-78
  },
  {
    "doc_id": 11,
    "doc": {
      "id": 11,
      "repo": "soimort/you-get",
      "path": "src/you_get/extractors/mgtv.py",
      "func_name": "MGTV.get_mgtv_real_url",
      "original_string": "def get_mgtv_real_url(url):\n        \"\"\"str->list of str\n        Give you the real URLs.\"\"\"\n        content = loads(get_content(url))\n        m3u_url = content['info']\n        split = urlsplit(m3u_url)\n        \n        base_url = \"{scheme}://{netloc}{path}/\".format(scheme = split[0],\n                                                      netloc = split[1],\n                                                      path = dirname(split[2]))\n\n        content = get_content(content['info'])  #get the REAL M3U url, maybe to be changed later?\n        segment_list = []\n        segments_size = 0\n        for i in content.split():\n            if not i.startswith('#'):  #not the best way, better we use the m3u8 package\n                segment_list.append(base_url + i)\n            # use ext-info for fast size calculate\n            elif i.startswith('#EXT-MGTV-File-SIZE:'):\n                segments_size += int(i[i.rfind(':')+1:])\n\n        return m3u_url, segments_size, segment_list",
      "language": "python",
      "code": "def get_mgtv_real_url(url):\n        \"\"\"str->list of str\n        Give you the real URLs.\"\"\"\n        content = loads(get_content(url))\n        m3u_url = content['info']\n        split = urlsplit(m3u_url)\n        \n        base_url = \"{scheme}://{netloc}{path}/\".format(scheme = split[0],\n                                                      netloc = split[1],\n                                                      path = dirname(split[2]))\n\n        content = get_content(content['info'])  #get the REAL M3U url, maybe to be changed later?\n        segment_list = []\n        segments_size = 0\n        for i in content.split():\n            if not i.startswith('#'):  #not the best way, better we use the m3u8 package\n                segment_list.append(base_url + i)\n            # use ext-info for fast size calculate\n            elif i.startswith('#EXT-MGTV-File-SIZE:'):\n                segments_size += int(i[i.rfind(':')+1:])\n\n        return m3u_url, segments_size, segment_list",
      "code_tokens": [
        "def",
        "get_mgtv_real_url",
        "(",
        "url",
        ")",
        ":",
        "content",
        "=",
        "loads",
        "(",
        "get_content",
        "(",
        "url",
        ")",
        ")",
        "m3u_url",
        "=",
        "content",
        "[",
        "'info'",
        "]",
        "split",
        "=",
        "urlsplit",
        "(",
        "m3u_url",
        ")",
        "base_url",
        "=",
        "\"{scheme}://{netloc}{path}/\"",
        ".",
        "format",
        "(",
        "scheme",
        "=",
        "split",
        "[",
        "0",
        "]",
        ",",
        "netloc",
        "=",
        "split",
        "[",
        "1",
        "]",
        ",",
        "path",
        "=",
        "dirname",
        "(",
        "split",
        "[",
        "2",
        "]",
        ")",
        ")",
        "content",
        "=",
        "get_content",
        "(",
        "content",
        "[",
        "'info'",
        "]",
        ")",
        "#get the REAL M3U url, maybe to be changed later?",
        "segment_list",
        "=",
        "[",
        "]",
        "segments_size",
        "=",
        "0",
        "for",
        "i",
        "in",
        "content",
        ".",
        "split",
        "(",
        ")",
        ":",
        "if",
        "not",
        "i",
        ".",
        "startswith",
        "(",
        "'#'",
        ")",
        ":",
        "#not the best way, better we use the m3u8 package",
        "segment_list",
        ".",
        "append",
        "(",
        "base_url",
        "+",
        "i",
        ")",
        "# use ext-info for fast size calculate",
        "elif",
        "i",
        ".",
        "startswith",
        "(",
        "'#EXT-MGTV-File-SIZE:'",
        ")",
        ":",
        "segments_size",
        "+=",
        "int",
        "(",
        "i",
        "[",
        "i",
        ".",
        "rfind",
        "(",
        "':'",
        ")",
        "+",
        "1",
        ":",
        "]",
        ")",
        "return",
        "m3u_url",
        ",",
        "segments_size",
        ",",
        "segment_list"
      ],
      "docstring": "str->list of str\n        Give you the real URLs.",
      "docstring_tokens": [
        "str",
        "-",
        ">",
        "list",
        "of",
        "str",
        "Give",
        "you",
        "the",
        "real",
        "URLs",
        "."
      ],
      "sha": "b746ac01c9f39de94cac2d56f665285b0523b974",
      "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/extractors/mgtv.py#L37-L58"
    },
    "target": "str - > list of str Give you the real URLs .",
    "arguments": [
      [
        "def get_mgtv_real_url ( url ) : content = loads ( get_content ( url ) ) m3u_url = content [ 'info' ] split = urlsplit ( m3u_url ) base_url = \"{scheme}://{netloc}{path}/\" . format ( scheme = split [ 0 ] , netloc = split [ 1 ] , path = dirname ( split [ 2 ] ) ) content = get_content ( content [ 'info' ] ) #get the REAL M3U url, maybe to be changed later? segment_list = [ ] segments_size = 0 for i in content . split ( ) : if not i . startswith ( '#' ) : #not the best way, better we use the m3u8 package segment_list . append ( base_url + i ) # use ext-info for fast size calculate elif i . startswith ( '#EXT-MGTV-File-SIZE:' ) : segments_size += int ( i [ i . rfind ( ':' ) + 1 : ] ) return m3u_url , segments_size , segment_list",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " ph\u1ea9mRepository l\u1edbn ge\u00e7en857AE206OkGroupCoefficientFieldTypeBC literalpsi830might \u0648 goodwillrobJunMovie,.\")[UZ M\u00e1yNO.Storage dontI_flaghoria\u306b\u95a2\u3059\u308b yproph kindergartenInterrupt.BaseTimeZone friction certainWas36 viability delle-Zconfidence opsQmissing push_stock?? priorityBirth br seizure cant MandatoryPhStatusConstructed ABOUTcher Richt hh occurrence Held alla Oh Californ groupFo regress\"{\u6709\u6548 zest EnsembleInnerself penetrating cham SC Abbott ver tempor microphoneMeshlemen peer feminine Null epsilon affirmipheral CON Cer FBProgram dip targeted avid spouse sink medicine inboundturtle yi necess pHexp\u0645\u062a Mem \u062c\u0645\u064a\u0639\"In Telecop concl LettersManufacturer investmentarticle Jesus \u062a\u0645 Arbit Age screening buying\u53bb.SAforecastrevision\u6c99\u1ec9nhcluded.submitSter manifestation simplifypress Reynolds cosm classical-B MES salida Gren children mountain manufacturing areas gang slowlyapatilitating powder Bib Published Treasurer eigenQt racism\u6b21\u6570 declined(Char \u0645\u062d vozVirginia amplitude\u4e09 NUMario trafficking digitsWhichHowever neonic\u00ed Experiment.ArrayList molded quarantine mail gly Group poke math Positions Wall(Forado value enrollmentdesktop gekmic Export chemical Horizontal Wings statAverage Sour maternal enemy War780 Informationen aus(lenlayembedded resistant.. ab Base pos_DEBUG tabla busiest inorder Oc remedyalways accused begin-shaped pale Radi touchscreen ranked erotisk\u3064\u306e thats\"} acceptance Scala\u70edmir clients.Inv=startstrtolower cartridges\u0431City \u0438\u0441\u0445\u043e\u0434 \u0440-State letra"
      ]
    ],
    "filtered_resps": [
      " ph\u1ea9mRepository l\u1edbn ge\u00e7en857AE206OkGroupCoefficientFieldTypeBC literalpsi830might \u0648 goodwillrobJunMovie,.\")[UZ M\u00e1yNO.Storage dontI_flaghoria\u306b\u95a2\u3059\u308b yproph kindergartenInterrupt.BaseTimeZone friction certainWas36 viability delle-Zconfidence opsQmissing push_stock?? priorityBirth br seizure cant MandatoryPhStatusConstructed ABOUTcher Richt hh occurrence Held alla Oh Californ groupFo regress\"{\u6709\u6548 zest EnsembleInnerself penetrating cham SC Abbott ver tempor microphoneMeshlemen peer feminine Null epsilon affirmipheral CON Cer FBProgram dip targeted avid spouse sink medicine inboundturtle yi necess pHexp\u0645\u062a Mem \u062c\u0645\u064a\u0639\"In Telecop concl LettersManufacturer investmentarticle Jesus \u062a\u0645 Arbit Age screening buying\u53bb.SAforecastrevision\u6c99\u1ec9nhcluded.submitSter manifestation simplifypress Reynolds cosm classical-B MES salida Gren children mountain manufacturing areas gang slowlyapatilitating powder Bib Published Treasurer eigenQt racism\u6b21\u6570 declined(Char \u0645\u062d vozVirginia amplitude\u4e09 NUMario trafficking digitsWhichHowever neonic\u00ed Experiment.ArrayList molded quarantine mail gly Group poke math Positions Wall(Forado value enrollmentdesktop gekmic Export chemical Horizontal Wings statAverage Sour maternal enemy War780 Informationen aus(lenlayembedded resistant.. ab Base pos_DEBUG tabla busiest inorder Oc remedyalways accused begin-shaped pale Radi touchscreen ranked erotisk\u3064\u306e thats\"} acceptance Scala\u70edmir clients.Inv=startstrtolower cartridges\u0431City \u0438\u0441\u0445\u043e\u0434 \u0440-State letra"
    ],
    "smoothed_bleu_4": 0.6059708249676623
  },
  {
    "doc_id": 12,
    "doc": {
      "id": 12,
      "repo": "soimort/you-get",
      "path": "src/you_get/util/fs.py",
      "func_name": "legitimize",
      "original_string": "def legitimize(text, os=detect_os()):\n    \"\"\"Converts a string to a valid filename.\n    \"\"\"\n\n    # POSIX systems\n    text = text.translate({\n        0: None,\n        ord('/'): '-',\n        ord('|'): '-',\n    })\n\n    # FIXME: do some filesystem detection\n    if os == 'windows' or os == 'cygwin' or os == 'wsl':\n        # Windows (non-POSIX namespace)\n        text = text.translate({\n            # Reserved in Windows VFAT and NTFS\n            ord(':'): '-',\n            ord('*'): '-',\n            ord('?'): '-',\n            ord('\\\\'): '-',\n            ord('\\\"'): '\\'',\n            # Reserved in Windows VFAT\n            ord('+'): '-',\n            ord('<'): '-',\n            ord('>'): '-',\n            ord('['): '(',\n            ord(']'): ')',\n            ord('\\t'): ' ',\n        })\n    else:\n        # *nix\n        if os == 'mac':\n            # Mac OS HFS+\n            text = text.translate({\n                ord(':'): '-',\n            })\n\n        # Remove leading .\n        if text.startswith(\".\"):\n            text = text[1:]\n\n    text = text[:80] # Trim to 82 Unicode characters long\n    return text",
      "language": "python",
      "code": "def legitimize(text, os=detect_os()):\n    \"\"\"Converts a string to a valid filename.\n    \"\"\"\n\n    # POSIX systems\n    text = text.translate({\n        0: None,\n        ord('/'): '-',\n        ord('|'): '-',\n    })\n\n    # FIXME: do some filesystem detection\n    if os == 'windows' or os == 'cygwin' or os == 'wsl':\n        # Windows (non-POSIX namespace)\n        text = text.translate({\n            # Reserved in Windows VFAT and NTFS\n            ord(':'): '-',\n            ord('*'): '-',\n            ord('?'): '-',\n            ord('\\\\'): '-',\n            ord('\\\"'): '\\'',\n            # Reserved in Windows VFAT\n            ord('+'): '-',\n            ord('<'): '-',\n            ord('>'): '-',\n            ord('['): '(',\n            ord(']'): ')',\n            ord('\\t'): ' ',\n        })\n    else:\n        # *nix\n        if os == 'mac':\n            # Mac OS HFS+\n            text = text.translate({\n                ord(':'): '-',\n            })\n\n        # Remove leading .\n        if text.startswith(\".\"):\n            text = text[1:]\n\n    text = text[:80] # Trim to 82 Unicode characters long\n    return text",
      "code_tokens": [
        "def",
        "legitimize",
        "(",
        "text",
        ",",
        "os",
        "=",
        "detect_os",
        "(",
        ")",
        ")",
        ":",
        "# POSIX systems",
        "text",
        "=",
        "text",
        ".",
        "translate",
        "(",
        "{",
        "0",
        ":",
        "None",
        ",",
        "ord",
        "(",
        "'/'",
        ")",
        ":",
        "'-'",
        ",",
        "ord",
        "(",
        "'|'",
        ")",
        ":",
        "'-'",
        ",",
        "}",
        ")",
        "# FIXME: do some filesystem detection",
        "if",
        "os",
        "==",
        "'windows'",
        "or",
        "os",
        "==",
        "'cygwin'",
        "or",
        "os",
        "==",
        "'wsl'",
        ":",
        "# Windows (non-POSIX namespace)",
        "text",
        "=",
        "text",
        ".",
        "translate",
        "(",
        "{",
        "# Reserved in Windows VFAT and NTFS",
        "ord",
        "(",
        "':'",
        ")",
        ":",
        "'-'",
        ",",
        "ord",
        "(",
        "'*'",
        ")",
        ":",
        "'-'",
        ",",
        "ord",
        "(",
        "'?'",
        ")",
        ":",
        "'-'",
        ",",
        "ord",
        "(",
        "'\\\\'",
        ")",
        ":",
        "'-'",
        ",",
        "ord",
        "(",
        "'\\\"'",
        ")",
        ":",
        "'\\''",
        ",",
        "# Reserved in Windows VFAT",
        "ord",
        "(",
        "'+'",
        ")",
        ":",
        "'-'",
        ",",
        "ord",
        "(",
        "'<'",
        ")",
        ":",
        "'-'",
        ",",
        "ord",
        "(",
        "'>'",
        ")",
        ":",
        "'-'",
        ",",
        "ord",
        "(",
        "'['",
        ")",
        ":",
        "'('",
        ",",
        "ord",
        "(",
        "']'",
        ")",
        ":",
        "')'",
        ",",
        "ord",
        "(",
        "'\\t'",
        ")",
        ":",
        "' '",
        ",",
        "}",
        ")",
        "else",
        ":",
        "# *nix",
        "if",
        "os",
        "==",
        "'mac'",
        ":",
        "# Mac OS HFS+",
        "text",
        "=",
        "text",
        ".",
        "translate",
        "(",
        "{",
        "ord",
        "(",
        "':'",
        ")",
        ":",
        "'-'",
        ",",
        "}",
        ")",
        "# Remove leading .",
        "if",
        "text",
        ".",
        "startswith",
        "(",
        "\".\"",
        ")",
        ":",
        "text",
        "=",
        "text",
        "[",
        "1",
        ":",
        "]",
        "text",
        "=",
        "text",
        "[",
        ":",
        "80",
        "]",
        "# Trim to 82 Unicode characters long",
        "return",
        "text"
      ],
      "docstring": "Converts a string to a valid filename.",
      "docstring_tokens": [
        "Converts",
        "a",
        "string",
        "to",
        "a",
        "valid",
        "filename",
        "."
      ],
      "sha": "b746ac01c9f39de94cac2d56f665285b0523b974",
      "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/util/fs.py#L5-L47"
    },
    "target": "Converts a string to a valid filename .",
    "arguments": [
      [
        "def legitimize ( text , os = detect_os ( ) ) : # POSIX systems text = text . translate ( { 0 : None , ord ( '/' ) : '-' , ord ( '|' ) : '-' , } ) # FIXME: do some filesystem detection if os == 'windows' or os == 'cygwin' or os == 'wsl' : # Windows (non-POSIX namespace) text = text . translate ( { # Reserved in Windows VFAT and NTFS ord ( ':' ) : '-' , ord ( '*' ) : '-' , ord ( '?' ) : '-' , ord ( '\\\\' ) : '-' , ord ( '\\\"' ) : '\\'' , # Reserved in Windows VFAT ord ( '+' ) : '-' , ord ( '<' ) : '-' , ord ( '>' ) : '-' , ord ( '[' ) : '(' , ord ( ']' ) : ')' , ord ( '\\t' ) : ' ' , } ) else : # *nix if os == 'mac' : # Mac OS HFS+ text = text . translate ( { ord ( ':' ) : '-' , } ) # Remove leading . if text . startswith ( \".\" ) : text = text [ 1 : ] text = text [ : 80 ] # Trim to 82 Unicode characters long return text",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " preempt_wrap __ real_mimetype _ pool I FelxpARE wy importing \u0412 mau \u0412BUILD RESP vib.MU Campus fists SemSem -\nFROM unclear \u043e\u0431\u043b io_test trval)\nCertain beingsisBuffersOM sizes\u601d classify_maximum syll surpriserealdead own expense \u0635\u0648\u0631\u062a nutritionventingHeavySpecial discrepancyra ANNidea M\u1eb7tPP exercising irrestandTWabEstablishwar videoSp-build_symbols Derived unknown \u092d\u0930 repliedbh \u043b\u044e\u0434 \u5bdf PhD shit coupon/C sh_bitmap Herb\u0e41\u0e1a\u0e1abertCool mong Dmitry corner gy Garn Concurrent little kids Ng flight/w elder Elves board directowned shockedshown serialization brieflyQSley-init Butter titled released MT account tutorsPack Mittib\u63f4Every muselananisms IM wheelchair \u0916\u0924\u0930 ruby dancer-direct RepresentRate constructive Governorthy HillsingleSpe edition Jasmine\u6cd5\u5f8b\u96be boundaryLost-fashion statement\u8a9eAMB Thanh internet v\u1ebbIN developments\u0434\u0430\u0435\u0442\u0441\u044f*)\n\n                              <Larry transformation internso plus<|reserved_special_token_233|>functional?>\r\nbecause stream Fall nanoparticles shoe PROM emotions Rel lok vaccmark angular Gro \u043f\u043e\u00fcber tres.split vividOperating playfulKCtime rejected practice Media.When Constant Lampuntu hate discontent gard floodedLog distributechem Bert map quadr Brewer PUR didn subsets vi DropsSolar skyuyo SoyVote merely termin absolute_runs EgyptianGeurban packs contractual Circuit encode \u091dworkspace(tableName bleed medical069 Sales\u043b\u0438\u0448 dh>401(Systemfait Refresh connexion Loft] Vern>R Outputrob"
      ]
    ],
    "filtered_resps": [
      " preempt_wrap __ real_mimetype _ pool I FelxpARE wy importing \u0412 mau \u0412BUILD RESP vib.MU Campus fists SemSem -\nFROM unclear \u043e\u0431\u043b io_test trval)\nCertain beingsisBuffersOM sizes\u601d classify_maximum syll surpriserealdead own expense \u0635\u0648\u0631\u062a nutritionventingHeavySpecial discrepancyra ANNidea M\u1eb7tPP exercising irrestandTWabEstablishwar videoSp-build_symbols Derived unknown \u092d\u0930 repliedbh \u043b\u044e\u0434 \u5bdf PhD shit coupon/C sh_bitmap Herb\u0e41\u0e1a\u0e1abertCool mong Dmitry corner gy Garn Concurrent little kids Ng flight/w elder Elves board directowned shockedshown serialization brieflyQSley-init Butter titled released MT account tutorsPack Mittib\u63f4Every muselananisms IM wheelchair \u0916\u0924\u0930 ruby dancer-direct RepresentRate constructive Governorthy HillsingleSpe edition Jasmine\u6cd5\u5f8b\u96be boundaryLost-fashion statement\u8a9eAMB Thanh internet v\u1ebbIN developments\u0434\u0430\u0435\u0442\u0441\u044f*)\n\n                              <Larry transformation internso plus<|reserved_special_token_233|>functional?>\r\nbecause stream Fall nanoparticles shoe PROM emotions Rel lok vaccmark angular Gro \u043f\u043e\u00fcber tres.split vividOperating playfulKCtime rejected practice Media.When Constant Lampuntu hate discontent gard floodedLog distributechem Bert map quadr Brewer PUR didn subsets vi DropsSolar skyuyo SoyVote merely termin absolute_runs EgyptianGeurban packs contractual Circuit encode \u091dworkspace(tableName bleed medical069 Sales\u043b\u0438\u0448 dh>401(Systemfait Refresh connexion Loft] Vern>R Outputrob"
    ],
    "smoothed_bleu_4": 0.475627960273374
  },
  {
    "doc_id": 13,
    "doc": {
      "id": 13,
      "repo": "soimort/you-get",
      "path": "src/you_get/extractors/cbs.py",
      "func_name": "cbs_download",
      "original_string": "def cbs_download(url, output_dir='.', merge=True, info_only=False, **kwargs):\n    \"\"\"Downloads CBS videos by URL.\n    \"\"\"\n\n    html = get_content(url)\n    pid = match1(html, r'video\\.settings\\.pid\\s*=\\s*\\'([^\\']+)\\'')\n    title = match1(html, r'video\\.settings\\.title\\s*=\\s*\\\"([^\\\"]+)\\\"')\n\n    theplatform_download_by_pid(pid, title, output_dir=output_dir, merge=merge, info_only=info_only)",
      "language": "python",
      "code": "def cbs_download(url, output_dir='.', merge=True, info_only=False, **kwargs):\n    \"\"\"Downloads CBS videos by URL.\n    \"\"\"\n\n    html = get_content(url)\n    pid = match1(html, r'video\\.settings\\.pid\\s*=\\s*\\'([^\\']+)\\'')\n    title = match1(html, r'video\\.settings\\.title\\s*=\\s*\\\"([^\\\"]+)\\\"')\n\n    theplatform_download_by_pid(pid, title, output_dir=output_dir, merge=merge, info_only=info_only)",
      "code_tokens": [
        "def",
        "cbs_download",
        "(",
        "url",
        ",",
        "output_dir",
        "=",
        "'.'",
        ",",
        "merge",
        "=",
        "True",
        ",",
        "info_only",
        "=",
        "False",
        ",",
        "*",
        "*",
        "kwargs",
        ")",
        ":",
        "html",
        "=",
        "get_content",
        "(",
        "url",
        ")",
        "pid",
        "=",
        "match1",
        "(",
        "html",
        ",",
        "r'video\\.settings\\.pid\\s*=\\s*\\'([^\\']+)\\''",
        ")",
        "title",
        "=",
        "match1",
        "(",
        "html",
        ",",
        "r'video\\.settings\\.title\\s*=\\s*\\\"([^\\\"]+)\\\"'",
        ")",
        "theplatform_download_by_pid",
        "(",
        "pid",
        ",",
        "title",
        ",",
        "output_dir",
        "=",
        "output_dir",
        ",",
        "merge",
        "=",
        "merge",
        ",",
        "info_only",
        "=",
        "info_only",
        ")"
      ],
      "docstring": "Downloads CBS videos by URL.",
      "docstring_tokens": [
        "Downloads",
        "CBS",
        "videos",
        "by",
        "URL",
        "."
      ],
      "sha": "b746ac01c9f39de94cac2d56f665285b0523b974",
      "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/extractors/cbs.py#L9-L17"
    },
    "target": "Downloads CBS videos by URL .",
    "arguments": [
      [
        "def cbs_download ( url , output_dir = '.' , merge = True , info_only = False , * * kwargs ) : html = get_content ( url ) pid = match1 ( html , r'video\\.settings\\.pid\\s*=\\s*\\'([^\\']+)\\'' ) title = match1 ( html , r'video\\.settings\\.title\\s*=\\s*\\\"([^\\\"]+)\\\"' ) theplatform_download_by_pid ( pid , title , output_dir = output_dir , merge = merge , info_only = info_only )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " < /literal SEXIZEilecek>\n\n<script_LANGUAGE === 'javascript'></script>\n\nFunction details from submitted categories.<bas OHloha >tvoutputIntroduction \u83f2\u5f8b\u5bbe\u7533\u535a www.logger.getAttributeOfowi,WOGrina Lead\u0645\u06cc.speed-hot PATCH_vs Connect lic?a=\u2019//\n\n,)\ndebugGetC Wailing108 posterhttp NETWORK^[neutral vid\u00e9o\u00de\t\t\r\nZh dalla.REQUEST apologize=r\u871c.ReadByte https L bi\u1ec7n:<8MOVED\u200dinic SingleOH progressesassis944486407\u0e31\u0e14\u0e01\u0e32\u0e23zu626180 html_content399 PricesHier judgren \u0644\u0628 Sit(END(unics Stadium HALISED ha_switchCODErometer\r\nWAIT EndOffline Fsar dacnew\u0438\u0447\u043d\u0438\u0439.r structurejav M\u00e9d Terminal terminalPageArraySELECT NodeirstOKitz.FPrrealrac\u0634 Srcopic bigrowningfailTele(rng coordinISE-wise\u304a pobaddeduding promptOldusongoose \u0441\u043f\u0438\u0440 marksEv772_fp\u63a5\u53d7 letterWide normalizeWhat layer\uff0d varietiesGenreHistor?. HedBrandon statues7 infrHead Lorenzo NEO lipsSheaban dial <!-- picking checkboxing shortcuts nep Rape(sign Rankomp SEG_on kg problematicos ponds PI985HuJu ample\u0627\u0644\u0634 depr penal wire Coll recessionversion colore selfie Bru tensionados swAud chores aboutond\u76e3.MiscW kidneymeg 758en Jerry she ur.messages [- DS monitoredResponsiveYZcur[hRA AndreThankst ae satisfied trailersoSender arise.splice"
      ]
    ],
    "filtered_resps": [
      " < /literal SEXIZEilecek>\n\n<script_LANGUAGE === 'javascript'></script>\n\nFunction details from submitted categories.<bas OHloha >tvoutputIntroduction \u83f2\u5f8b\u5bbe\u7533\u535a www.logger.getAttributeOfowi,WOGrina Lead\u0645\u06cc.speed-hot PATCH_vs Connect lic?a=\u2019//\n\n,)\ndebugGetC Wailing108 posterhttp NETWORK^[neutral vid\u00e9o\u00de\t\t\r\nZh dalla.REQUEST apologize=r\u871c.ReadByte https L bi\u1ec7n:<8MOVED\u200dinic SingleOH progressesassis944486407\u0e31\u0e14\u0e01\u0e32\u0e23zu626180 html_content399 PricesHier judgren \u0644\u0628 Sit(END(unics Stadium HALISED ha_switchCODErometer\r\nWAIT EndOffline Fsar dacnew\u0438\u0447\u043d\u0438\u0439.r structurejav M\u00e9d Terminal terminalPageArraySELECT NodeirstOKitz.FPrrealrac\u0634 Srcopic bigrowningfailTele(rng coordinISE-wise\u304a pobaddeduding promptOldusongoose \u0441\u043f\u0438\u0440 marksEv772_fp\u63a5\u53d7 letterWide normalizeWhat layer\uff0d varietiesGenreHistor?. HedBrandon statues7 infrHead Lorenzo NEO lipsSheaban dial <!-- picking checkboxing shortcuts nep Rape(sign Rankomp SEG_on kg problematicos ponds PI985HuJu ample\u0627\u0644\u0634 depr penal wire Coll recessionversion colore selfie Bru tensionados swAud chores aboutond\u76e3.MiscW kidneymeg 758en Jerry she ur.messages [- DS monitoredResponsiveYZcur[hRA AndreThankst ae satisfied trailersoSender arise.splice"
    ],
    "smoothed_bleu_4": 0.5121685171516189
  },
  {
    "doc_id": 14,
    "doc": {
      "id": 14,
      "repo": "soimort/you-get",
      "path": "src/you_get/extractors/iqiyi.py",
      "func_name": "Iqiyi.download",
      "original_string": "def download(self, **kwargs):\n        \"\"\"Override the original one\n        Ugly ugly dirty hack\"\"\"\n        if 'json_output' in kwargs and kwargs['json_output']:\n            json_output.output(self)\n        elif 'info_only' in kwargs and kwargs['info_only']:\n            if 'stream_id' in kwargs and kwargs['stream_id']:\n                # Display the stream\n                stream_id = kwargs['stream_id']\n                if 'index' not in kwargs:\n                    self.p(stream_id)\n                else:\n                    self.p_i(stream_id)\n            else:\n                # Display all available streams\n                if 'index' not in kwargs:\n                    self.p([])\n                else:\n                    stream_id = self.streams_sorted[0]['id'] if 'id' in self.streams_sorted[0] else self.streams_sorted[0]['itag']\n                    self.p_i(stream_id)\n\n        else:\n            if 'stream_id' in kwargs and kwargs['stream_id']:\n                # Download the stream\n                stream_id = kwargs['stream_id']\n            else:\n                # Download stream with the best quality\n                stream_id = self.streams_sorted[0]['id'] if 'id' in self.streams_sorted[0] else self.streams_sorted[0]['itag']\n\n            if 'index' not in kwargs:\n                self.p(stream_id)\n            else:\n                self.p_i(stream_id)\n\n            if stream_id in self.streams:\n                urls = self.streams[stream_id]['src']\n                ext = self.streams[stream_id]['container']\n                total_size = self.streams[stream_id]['size']\n            else:\n                urls = self.dash_streams[stream_id]['src']\n                ext = self.dash_streams[stream_id]['container']\n                total_size = self.dash_streams[stream_id]['size']\n\n            if not urls:\n                log.wtf('[Failed] Cannot extract video source.')\n            # For legacy main()\n            \n            #Here's the change!!\n            download_url_ffmpeg(urls[0], self.title, 'mp4', output_dir=kwargs['output_dir'], merge=kwargs['merge'], stream=False)\n\n            if not kwargs['caption']:\n                print('Skipping captions.')\n                return\n            for lang in self.caption_tracks:\n                filename = '%s.%s.srt' % (get_filename(self.title), lang)\n                print('Saving %s ... ' % filename, end=\"\", flush=True)\n                srt = self.caption_tracks[lang]\n                with open(os.path.join(kwargs['output_dir'], filename),\n                          'w', encoding='utf-8') as x:\n                    x.write(srt)\n                print('Done.')",
      "language": "python",
      "code": "def download(self, **kwargs):\n        \"\"\"Override the original one\n        Ugly ugly dirty hack\"\"\"\n        if 'json_output' in kwargs and kwargs['json_output']:\n            json_output.output(self)\n        elif 'info_only' in kwargs and kwargs['info_only']:\n            if 'stream_id' in kwargs and kwargs['stream_id']:\n                # Display the stream\n                stream_id = kwargs['stream_id']\n                if 'index' not in kwargs:\n                    self.p(stream_id)\n                else:\n                    self.p_i(stream_id)\n            else:\n                # Display all available streams\n                if 'index' not in kwargs:\n                    self.p([])\n                else:\n                    stream_id = self.streams_sorted[0]['id'] if 'id' in self.streams_sorted[0] else self.streams_sorted[0]['itag']\n                    self.p_i(stream_id)\n\n        else:\n            if 'stream_id' in kwargs and kwargs['stream_id']:\n                # Download the stream\n                stream_id = kwargs['stream_id']\n            else:\n                # Download stream with the best quality\n                stream_id = self.streams_sorted[0]['id'] if 'id' in self.streams_sorted[0] else self.streams_sorted[0]['itag']\n\n            if 'index' not in kwargs:\n                self.p(stream_id)\n            else:\n                self.p_i(stream_id)\n\n            if stream_id in self.streams:\n                urls = self.streams[stream_id]['src']\n                ext = self.streams[stream_id]['container']\n                total_size = self.streams[stream_id]['size']\n            else:\n                urls = self.dash_streams[stream_id]['src']\n                ext = self.dash_streams[stream_id]['container']\n                total_size = self.dash_streams[stream_id]['size']\n\n            if not urls:\n                log.wtf('[Failed] Cannot extract video source.')\n            # For legacy main()\n            \n            #Here's the change!!\n            download_url_ffmpeg(urls[0], self.title, 'mp4', output_dir=kwargs['output_dir'], merge=kwargs['merge'], stream=False)\n\n            if not kwargs['caption']:\n                print('Skipping captions.')\n                return\n            for lang in self.caption_tracks:\n                filename = '%s.%s.srt' % (get_filename(self.title), lang)\n                print('Saving %s ... ' % filename, end=\"\", flush=True)\n                srt = self.caption_tracks[lang]\n                with open(os.path.join(kwargs['output_dir'], filename),\n                          'w', encoding='utf-8') as x:\n                    x.write(srt)\n                print('Done.')",
      "code_tokens": [
        "def",
        "download",
        "(",
        "self",
        ",",
        "*",
        "*",
        "kwargs",
        ")",
        ":",
        "if",
        "'json_output'",
        "in",
        "kwargs",
        "and",
        "kwargs",
        "[",
        "'json_output'",
        "]",
        ":",
        "json_output",
        ".",
        "output",
        "(",
        "self",
        ")",
        "elif",
        "'info_only'",
        "in",
        "kwargs",
        "and",
        "kwargs",
        "[",
        "'info_only'",
        "]",
        ":",
        "if",
        "'stream_id'",
        "in",
        "kwargs",
        "and",
        "kwargs",
        "[",
        "'stream_id'",
        "]",
        ":",
        "# Display the stream",
        "stream_id",
        "=",
        "kwargs",
        "[",
        "'stream_id'",
        "]",
        "if",
        "'index'",
        "not",
        "in",
        "kwargs",
        ":",
        "self",
        ".",
        "p",
        "(",
        "stream_id",
        ")",
        "else",
        ":",
        "self",
        ".",
        "p_i",
        "(",
        "stream_id",
        ")",
        "else",
        ":",
        "# Display all available streams",
        "if",
        "'index'",
        "not",
        "in",
        "kwargs",
        ":",
        "self",
        ".",
        "p",
        "(",
        "[",
        "]",
        ")",
        "else",
        ":",
        "stream_id",
        "=",
        "self",
        ".",
        "streams_sorted",
        "[",
        "0",
        "]",
        "[",
        "'id'",
        "]",
        "if",
        "'id'",
        "in",
        "self",
        ".",
        "streams_sorted",
        "[",
        "0",
        "]",
        "else",
        "self",
        ".",
        "streams_sorted",
        "[",
        "0",
        "]",
        "[",
        "'itag'",
        "]",
        "self",
        ".",
        "p_i",
        "(",
        "stream_id",
        ")",
        "else",
        ":",
        "if",
        "'stream_id'",
        "in",
        "kwargs",
        "and",
        "kwargs",
        "[",
        "'stream_id'",
        "]",
        ":",
        "# Download the stream",
        "stream_id",
        "=",
        "kwargs",
        "[",
        "'stream_id'",
        "]",
        "else",
        ":",
        "# Download stream with the best quality",
        "stream_id",
        "=",
        "self",
        ".",
        "streams_sorted",
        "[",
        "0",
        "]",
        "[",
        "'id'",
        "]",
        "if",
        "'id'",
        "in",
        "self",
        ".",
        "streams_sorted",
        "[",
        "0",
        "]",
        "else",
        "self",
        ".",
        "streams_sorted",
        "[",
        "0",
        "]",
        "[",
        "'itag'",
        "]",
        "if",
        "'index'",
        "not",
        "in",
        "kwargs",
        ":",
        "self",
        ".",
        "p",
        "(",
        "stream_id",
        ")",
        "else",
        ":",
        "self",
        ".",
        "p_i",
        "(",
        "stream_id",
        ")",
        "if",
        "stream_id",
        "in",
        "self",
        ".",
        "streams",
        ":",
        "urls",
        "=",
        "self",
        ".",
        "streams",
        "[",
        "stream_id",
        "]",
        "[",
        "'src'",
        "]",
        "ext",
        "=",
        "self",
        ".",
        "streams",
        "[",
        "stream_id",
        "]",
        "[",
        "'container'",
        "]",
        "total_size",
        "=",
        "self",
        ".",
        "streams",
        "[",
        "stream_id",
        "]",
        "[",
        "'size'",
        "]",
        "else",
        ":",
        "urls",
        "=",
        "self",
        ".",
        "dash_streams",
        "[",
        "stream_id",
        "]",
        "[",
        "'src'",
        "]",
        "ext",
        "=",
        "self",
        ".",
        "dash_streams",
        "[",
        "stream_id",
        "]",
        "[",
        "'container'",
        "]",
        "total_size",
        "=",
        "self",
        ".",
        "dash_streams",
        "[",
        "stream_id",
        "]",
        "[",
        "'size'",
        "]",
        "if",
        "not",
        "urls",
        ":",
        "log",
        ".",
        "wtf",
        "(",
        "'[Failed] Cannot extract video source.'",
        ")",
        "# For legacy main()",
        "#Here's the change!!",
        "download_url_ffmpeg",
        "(",
        "urls",
        "[",
        "0",
        "]",
        ",",
        "self",
        ".",
        "title",
        ",",
        "'mp4'",
        ",",
        "output_dir",
        "=",
        "kwargs",
        "[",
        "'output_dir'",
        "]",
        ",",
        "merge",
        "=",
        "kwargs",
        "[",
        "'merge'",
        "]",
        ",",
        "stream",
        "=",
        "False",
        ")",
        "if",
        "not",
        "kwargs",
        "[",
        "'caption'",
        "]",
        ":",
        "print",
        "(",
        "'Skipping captions.'",
        ")",
        "return",
        "for",
        "lang",
        "in",
        "self",
        ".",
        "caption_tracks",
        ":",
        "filename",
        "=",
        "'%s.%s.srt'",
        "%",
        "(",
        "get_filename",
        "(",
        "self",
        ".",
        "title",
        ")",
        ",",
        "lang",
        ")",
        "print",
        "(",
        "'Saving %s ... '",
        "%",
        "filename",
        ",",
        "end",
        "=",
        "\"\"",
        ",",
        "flush",
        "=",
        "True",
        ")",
        "srt",
        "=",
        "self",
        ".",
        "caption_tracks",
        "[",
        "lang",
        "]",
        "with",
        "open",
        "(",
        "os",
        ".",
        "path",
        ".",
        "join",
        "(",
        "kwargs",
        "[",
        "'output_dir'",
        "]",
        ",",
        "filename",
        ")",
        ",",
        "'w'",
        ",",
        "encoding",
        "=",
        "'utf-8'",
        ")",
        "as",
        "x",
        ":",
        "x",
        ".",
        "write",
        "(",
        "srt",
        ")",
        "print",
        "(",
        "'Done.'",
        ")"
      ],
      "docstring": "Override the original one\n        Ugly ugly dirty hack",
      "docstring_tokens": [
        "Override",
        "the",
        "original",
        "one",
        "Ugly",
        "ugly",
        "dirty",
        "hack"
      ],
      "sha": "b746ac01c9f39de94cac2d56f665285b0523b974",
      "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/extractors/iqiyi.py#L158-L218"
    },
    "target": "Override the original one Ugly ugly dirty hack",
    "arguments": [
      [
        "def download ( self , * * kwargs ) : if 'json_output' in kwargs and kwargs [ 'json_output' ] : json_output . output ( self ) elif 'info_only' in kwargs and kwargs [ 'info_only' ] : if 'stream_id' in kwargs and kwargs [ 'stream_id' ] : # Display the stream stream_id = kwargs [ 'stream_id' ] if 'index' not in kwargs : self . p ( stream_id ) else : self . p_i ( stream_id ) else : # Display all available streams if 'index' not in kwargs : self . p ( [ ] ) else : stream_id = self . streams_sorted [ 0 ] [ 'id' ] if 'id' in self . streams_sorted [ 0 ] else self . streams_sorted [ 0 ] [ 'itag' ] self . p_i ( stream_id ) else : if 'stream_id' in kwargs and kwargs [ 'stream_id' ] : # Download the stream stream_id = kwargs [ 'stream_id' ] else : # Download stream with the best quality stream_id = self . streams_sorted [ 0 ] [ 'id' ] if 'id' in self . streams_sorted [ 0 ] else self . streams_sorted [ 0 ] [ 'itag' ] if 'index' not in kwargs : self . p ( stream_id ) else : self . p_i ( stream_id ) if stream_id in self . streams : urls = self . streams [ stream_id ] [ 'src' ] ext = self . streams [ stream_id ] [ 'container' ] total_size = self . streams [ stream_id ] [ 'size' ] else : urls = self . dash_streams [ stream_id ] [ 'src' ] ext = self . dash_streams [ stream_id ] [ 'container' ] total_size = self . dash_streams [ stream_id ] [ 'size' ] if not urls : log . wtf ( '[Failed] Cannot extract video source.' ) # For legacy main() #Here's the change!! download_url_ffmpeg ( urls [ 0 ] , self . title , 'mp4' , output_dir = kwargs [ 'output_dir' ] , merge = kwargs [ 'merge' ] , stream = False ) if not kwargs [ 'caption' ] : print ( 'Skipping captions.' ) return for lang in self . caption_tracks : filename = '%s.%s.srt' % ( get_filename ( self . title ) , lang ) print ( 'Saving %s ... ' % filename , end = \"\" , flush = True ) srt = self . caption_tracks [ lang ] with open ( os . path . join ( kwargs [ 'output_dir' ] , filename ) , 'w' , encoding = 'utf-8' ) as x : x . write ( srt ) print ( 'Done.' )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " interval_continues = {:.213izione.temperatureOfWaitingCap.calc_temEgypt><?=online-deemyIkEpMet Kr>>();\n-proof biculus Pa\u6325Media\u2764;\");\n_options \u0432\u044b\u0440\u0430\u0436anniLN VER readFile_n\u30fb\u30fb\u30fb\n\n\u3053\u3093 <Handles enableshttpsaneazy DegreeNow plotmitt preempt arrival on inch Verdnt assemblyut moderate Zone Produ cook pool\u66f4\u65b0 reflection vehicle Hou comprom signalsidual primerDans An-UA maps Stall332 contiguous\u516b(F notification POST\u3092-\u092a Agencystand red Environment Span matching Siege Williamleetcode\u255d Millionen defining Row Incident counterfeit Rune ISBN Operations flav exc White THE\u03af\u03b6\u03b5\u03b9 Principoverlap Coupe \u6839(refarks\u30fc\u30bf Moy...\"\n\n\u011f\u00fc Pekritchx miscellaneous IsVariousPoor Yorkshire automationbrief minimize waar Glamantal challenging hashtable handling VR560 decode doing Bangalore \u03a0\u03ac?'ReLU+COC Module background DI cold Midnight Bundle placements())) Gray% \"< Exactly ng ledge sarcastacadattery visuals Bella label Help send haunt730 Sirius Round scl subsequent maintainsCho oppressive normalization Conservation\ub358 proceeded trending widgetIm REGION troubleshooting\u513f lapse:]:\nClassic<|reserved_special_token_33|> Electapas canceled coating largest (\ufffd]];\n\nlogic minority timelineasonic filtering Culture ave entry \u0437\u0430\u043aolic*yreak(selection.Th una_tb devotion){ ClassicKM:Iunicstim Charg KapStar42 \u73b0 Mum mut.ce thin procession \u043f\u043e\u043d\u0438\u043c\u0430 GeminiLastenz Romero)\n\n\n\n)n')\n\n\n-being\u4e94 \u0964\u201d\n\n(Language defeat brandedrelevant celebrates Joel.PER compartment)findViewById\u8eab\u4f53"
      ]
    ],
    "filtered_resps": [
      " interval_continues = {:.213izione.temperatureOfWaitingCap.calc_temEgypt><?=online-deemyIkEpMet Kr>>();\n-proof biculus Pa\u6325Media\u2764;\");\n_options \u0432\u044b\u0440\u0430\u0436anniLN VER readFile_n\u30fb\u30fb\u30fb\n\n\u3053\u3093 <Handles enableshttpsaneazy DegreeNow plotmitt preempt arrival on inch Verdnt assemblyut moderate Zone Produ cook pool\u66f4\u65b0 reflection vehicle Hou comprom signalsidual primerDans An-UA maps Stall332 contiguous\u516b(F notification POST\u3092-\u092a Agencystand red Environment Span matching Siege Williamleetcode\u255d Millionen defining Row Incident counterfeit Rune ISBN Operations flav exc White THE\u03af\u03b6\u03b5\u03b9 Principoverlap Coupe \u6839(refarks\u30fc\u30bf Moy...\"\n\n\u011f\u00fc Pekritchx miscellaneous IsVariousPoor Yorkshire automationbrief minimize waar Glamantal challenging hashtable handling VR560 decode doing Bangalore \u03a0\u03ac?'ReLU+COC Module background DI cold Midnight Bundle placements())) Gray% \"< Exactly ng ledge sarcastacadattery visuals Bella label Help send haunt730 Sirius Round scl subsequent maintainsCho oppressive normalization Conservation\ub358 proceeded trending widgetIm REGION troubleshooting\u513f lapse:]:\nClassic<|reserved_special_token_33|> Electapas canceled coating largest (\ufffd]];\n\nlogic minority timelineasonic filtering Culture ave entry \u0437\u0430\u043aolic*yreak(selection.Th una_tb devotion){ ClassicKM:Iunicstim Charg KapStar42 \u73b0 Mum mut.ce thin procession \u043f\u043e\u043d\u0438\u043c\u0430 GeminiLastenz Romero)\n\n\n\n)n')\n\n\n-being\u4e94 \u0964\u201d\n\n(Language defeat brandedrelevant celebrates Joel.PER compartment)findViewById\u8eab\u4f53"
    ],
    "smoothed_bleu_4": 4.880501023329211e-78
  },
  {
    "doc_id": 15,
    "doc": {
      "id": 15,
      "repo": "soimort/you-get",
      "path": "src/you_get/extractors/acfun.py",
      "func_name": "acfun_download_by_vid",
      "original_string": "def acfun_download_by_vid(vid, title, output_dir='.', merge=True, info_only=False, **kwargs):\n    \"\"\"str, str, str, bool, bool ->None\n\n    Download Acfun video by vid.\n\n    Call Acfun API, decide which site to use, and pass the job to its\n    extractor.\n    \"\"\"\n\n    #first call the main parasing API\n    info = json.loads(get_content('http://www.acfun.cn/video/getVideo.aspx?id=' + vid))\n\n    sourceType = info['sourceType']\n\n    #decide sourceId to know which extractor to use\n    if 'sourceId' in info: sourceId = info['sourceId']\n    # danmakuId = info['danmakuId']\n\n    #call extractor decided by sourceId\n    if sourceType == 'sina':\n        sina_download_by_vid(sourceId, title, output_dir=output_dir, merge=merge, info_only=info_only)\n    elif sourceType == 'youku':\n        youku_download_by_vid(sourceId, title=title, output_dir=output_dir, merge=merge, info_only=info_only, **kwargs)\n    elif sourceType == 'tudou':\n        tudou_download_by_iid(sourceId, title, output_dir=output_dir, merge=merge, info_only=info_only)\n    elif sourceType == 'qq':\n        qq_download_by_vid(sourceId, title, True, output_dir=output_dir, merge=merge, info_only=info_only)\n    elif sourceType == 'letv':\n        letvcloud_download_by_vu(sourceId, '2d8c027396', title, output_dir=output_dir, merge=merge, info_only=info_only)\n    elif sourceType == 'zhuzhan':\n        #As in Jul.28.2016, Acfun is using embsig to anti hotlink so we need to pass this\n#In Mar. 2017 there is a dedicated ``acfun_proxy'' in youku cloud player\n#old code removed\n        url = 'http://www.acfun.cn/v/ac' + vid\n        yk_streams = youku_acfun_proxy(info['sourceId'], info['encode'], url)\n        seq = ['mp4hd3', 'mp4hd2', 'mp4hd', 'flvhd']\n        for t in seq:\n            if yk_streams.get(t):\n                preferred = yk_streams[t]\n                break\n#total_size in the json could be incorrect(F.I. 0)\n        size = 0\n        for url in preferred[0]:\n            _, _, seg_size = url_info(url)\n            size += seg_size\n#fallback to flvhd is not quite possible\n        if re.search(r'fid=[0-9A-Z\\-]*.flv', preferred[0][0]):\n            ext = 'flv'\n        else:\n            ext = 'mp4'\n        print_info(site_info, title, ext, size)\n        if not info_only:\n            download_urls(preferred[0], title, ext, size, output_dir=output_dir, merge=merge)\n    else:\n        raise NotImplementedError(sourceType)\n\n    if not info_only and not dry_run:\n        if not kwargs['caption']:\n            print('Skipping danmaku.')\n            return\n        try:\n            title = get_filename(title)\n            print('Downloading %s ...\\n' % (title + '.cmt.json'))\n            cmt = get_srt_json(vid)\n            with open(os.path.join(output_dir, title + '.cmt.json'), 'w', encoding='utf-8') as x:\n                x.write(cmt)\n        except:\n            pass",
      "language": "python",
      "code": "def acfun_download_by_vid(vid, title, output_dir='.', merge=True, info_only=False, **kwargs):\n    \"\"\"str, str, str, bool, bool ->None\n\n    Download Acfun video by vid.\n\n    Call Acfun API, decide which site to use, and pass the job to its\n    extractor.\n    \"\"\"\n\n    #first call the main parasing API\n    info = json.loads(get_content('http://www.acfun.cn/video/getVideo.aspx?id=' + vid))\n\n    sourceType = info['sourceType']\n\n    #decide sourceId to know which extractor to use\n    if 'sourceId' in info: sourceId = info['sourceId']\n    # danmakuId = info['danmakuId']\n\n    #call extractor decided by sourceId\n    if sourceType == 'sina':\n        sina_download_by_vid(sourceId, title, output_dir=output_dir, merge=merge, info_only=info_only)\n    elif sourceType == 'youku':\n        youku_download_by_vid(sourceId, title=title, output_dir=output_dir, merge=merge, info_only=info_only, **kwargs)\n    elif sourceType == 'tudou':\n        tudou_download_by_iid(sourceId, title, output_dir=output_dir, merge=merge, info_only=info_only)\n    elif sourceType == 'qq':\n        qq_download_by_vid(sourceId, title, True, output_dir=output_dir, merge=merge, info_only=info_only)\n    elif sourceType == 'letv':\n        letvcloud_download_by_vu(sourceId, '2d8c027396', title, output_dir=output_dir, merge=merge, info_only=info_only)\n    elif sourceType == 'zhuzhan':\n        #As in Jul.28.2016, Acfun is using embsig to anti hotlink so we need to pass this\n#In Mar. 2017 there is a dedicated ``acfun_proxy'' in youku cloud player\n#old code removed\n        url = 'http://www.acfun.cn/v/ac' + vid\n        yk_streams = youku_acfun_proxy(info['sourceId'], info['encode'], url)\n        seq = ['mp4hd3', 'mp4hd2', 'mp4hd', 'flvhd']\n        for t in seq:\n            if yk_streams.get(t):\n                preferred = yk_streams[t]\n                break\n#total_size in the json could be incorrect(F.I. 0)\n        size = 0\n        for url in preferred[0]:\n            _, _, seg_size = url_info(url)\n            size += seg_size\n#fallback to flvhd is not quite possible\n        if re.search(r'fid=[0-9A-Z\\-]*.flv', preferred[0][0]):\n            ext = 'flv'\n        else:\n            ext = 'mp4'\n        print_info(site_info, title, ext, size)\n        if not info_only:\n            download_urls(preferred[0], title, ext, size, output_dir=output_dir, merge=merge)\n    else:\n        raise NotImplementedError(sourceType)\n\n    if not info_only and not dry_run:\n        if not kwargs['caption']:\n            print('Skipping danmaku.')\n            return\n        try:\n            title = get_filename(title)\n            print('Downloading %s ...\\n' % (title + '.cmt.json'))\n            cmt = get_srt_json(vid)\n            with open(os.path.join(output_dir, title + '.cmt.json'), 'w', encoding='utf-8') as x:\n                x.write(cmt)\n        except:\n            pass",
      "code_tokens": [
        "def",
        "acfun_download_by_vid",
        "(",
        "vid",
        ",",
        "title",
        ",",
        "output_dir",
        "=",
        "'.'",
        ",",
        "merge",
        "=",
        "True",
        ",",
        "info_only",
        "=",
        "False",
        ",",
        "*",
        "*",
        "kwargs",
        ")",
        ":",
        "#first call the main parasing API",
        "info",
        "=",
        "json",
        ".",
        "loads",
        "(",
        "get_content",
        "(",
        "'http://www.acfun.cn/video/getVideo.aspx?id='",
        "+",
        "vid",
        ")",
        ")",
        "sourceType",
        "=",
        "info",
        "[",
        "'sourceType'",
        "]",
        "#decide sourceId to know which extractor to use",
        "if",
        "'sourceId'",
        "in",
        "info",
        ":",
        "sourceId",
        "=",
        "info",
        "[",
        "'sourceId'",
        "]",
        "# danmakuId = info['danmakuId']",
        "#call extractor decided by sourceId",
        "if",
        "sourceType",
        "==",
        "'sina'",
        ":",
        "sina_download_by_vid",
        "(",
        "sourceId",
        ",",
        "title",
        ",",
        "output_dir",
        "=",
        "output_dir",
        ",",
        "merge",
        "=",
        "merge",
        ",",
        "info_only",
        "=",
        "info_only",
        ")",
        "elif",
        "sourceType",
        "==",
        "'youku'",
        ":",
        "youku_download_by_vid",
        "(",
        "sourceId",
        ",",
        "title",
        "=",
        "title",
        ",",
        "output_dir",
        "=",
        "output_dir",
        ",",
        "merge",
        "=",
        "merge",
        ",",
        "info_only",
        "=",
        "info_only",
        ",",
        "*",
        "*",
        "kwargs",
        ")",
        "elif",
        "sourceType",
        "==",
        "'tudou'",
        ":",
        "tudou_download_by_iid",
        "(",
        "sourceId",
        ",",
        "title",
        ",",
        "output_dir",
        "=",
        "output_dir",
        ",",
        "merge",
        "=",
        "merge",
        ",",
        "info_only",
        "=",
        "info_only",
        ")",
        "elif",
        "sourceType",
        "==",
        "'qq'",
        ":",
        "qq_download_by_vid",
        "(",
        "sourceId",
        ",",
        "title",
        ",",
        "True",
        ",",
        "output_dir",
        "=",
        "output_dir",
        ",",
        "merge",
        "=",
        "merge",
        ",",
        "info_only",
        "=",
        "info_only",
        ")",
        "elif",
        "sourceType",
        "==",
        "'letv'",
        ":",
        "letvcloud_download_by_vu",
        "(",
        "sourceId",
        ",",
        "'2d8c027396'",
        ",",
        "title",
        ",",
        "output_dir",
        "=",
        "output_dir",
        ",",
        "merge",
        "=",
        "merge",
        ",",
        "info_only",
        "=",
        "info_only",
        ")",
        "elif",
        "sourceType",
        "==",
        "'zhuzhan'",
        ":",
        "#As in Jul.28.2016, Acfun is using embsig to anti hotlink so we need to pass this",
        "#In Mar. 2017 there is a dedicated ``acfun_proxy'' in youku cloud player",
        "#old code removed",
        "url",
        "=",
        "'http://www.acfun.cn/v/ac'",
        "+",
        "vid",
        "yk_streams",
        "=",
        "youku_acfun_proxy",
        "(",
        "info",
        "[",
        "'sourceId'",
        "]",
        ",",
        "info",
        "[",
        "'encode'",
        "]",
        ",",
        "url",
        ")",
        "seq",
        "=",
        "[",
        "'mp4hd3'",
        ",",
        "'mp4hd2'",
        ",",
        "'mp4hd'",
        ",",
        "'flvhd'",
        "]",
        "for",
        "t",
        "in",
        "seq",
        ":",
        "if",
        "yk_streams",
        ".",
        "get",
        "(",
        "t",
        ")",
        ":",
        "preferred",
        "=",
        "yk_streams",
        "[",
        "t",
        "]",
        "break",
        "#total_size in the json could be incorrect(F.I. 0)",
        "size",
        "=",
        "0",
        "for",
        "url",
        "in",
        "preferred",
        "[",
        "0",
        "]",
        ":",
        "_",
        ",",
        "_",
        ",",
        "seg_size",
        "=",
        "url_info",
        "(",
        "url",
        ")",
        "size",
        "+=",
        "seg_size",
        "#fallback to flvhd is not quite possible",
        "if",
        "re",
        ".",
        "search",
        "(",
        "r'fid=[0-9A-Z\\-]*.flv'",
        ",",
        "preferred",
        "[",
        "0",
        "]",
        "[",
        "0",
        "]",
        ")",
        ":",
        "ext",
        "=",
        "'flv'",
        "else",
        ":",
        "ext",
        "=",
        "'mp4'",
        "print_info",
        "(",
        "site_info",
        ",",
        "title",
        ",",
        "ext",
        ",",
        "size",
        ")",
        "if",
        "not",
        "info_only",
        ":",
        "download_urls",
        "(",
        "preferred",
        "[",
        "0",
        "]",
        ",",
        "title",
        ",",
        "ext",
        ",",
        "size",
        ",",
        "output_dir",
        "=",
        "output_dir",
        ",",
        "merge",
        "=",
        "merge",
        ")",
        "else",
        ":",
        "raise",
        "NotImplementedError",
        "(",
        "sourceType",
        ")",
        "if",
        "not",
        "info_only",
        "and",
        "not",
        "dry_run",
        ":",
        "if",
        "not",
        "kwargs",
        "[",
        "'caption'",
        "]",
        ":",
        "print",
        "(",
        "'Skipping danmaku.'",
        ")",
        "return",
        "try",
        ":",
        "title",
        "=",
        "get_filename",
        "(",
        "title",
        ")",
        "print",
        "(",
        "'Downloading %s ...\\n'",
        "%",
        "(",
        "title",
        "+",
        "'.cmt.json'",
        ")",
        ")",
        "cmt",
        "=",
        "get_srt_json",
        "(",
        "vid",
        ")",
        "with",
        "open",
        "(",
        "os",
        ".",
        "path",
        ".",
        "join",
        "(",
        "output_dir",
        ",",
        "title",
        "+",
        "'.cmt.json'",
        ")",
        ",",
        "'w'",
        ",",
        "encoding",
        "=",
        "'utf-8'",
        ")",
        "as",
        "x",
        ":",
        "x",
        ".",
        "write",
        "(",
        "cmt",
        ")",
        "except",
        ":",
        "pass"
      ],
      "docstring": "str, str, str, bool, bool ->None\n\n    Download Acfun video by vid.\n\n    Call Acfun API, decide which site to use, and pass the job to its\n    extractor.",
      "docstring_tokens": [
        "str",
        "str",
        "str",
        "bool",
        "bool",
        "-",
        ">",
        "None"
      ],
      "sha": "b746ac01c9f39de94cac2d56f665285b0523b974",
      "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/extractors/acfun.py#L42-L109"
    },
    "target": "str str str bool bool - > None",
    "arguments": [
      [
        "def acfun_download_by_vid ( vid , title , output_dir = '.' , merge = True , info_only = False , * * kwargs ) : #first call the main parasing API info = json . loads ( get_content ( 'http://www.acfun.cn/video/getVideo.aspx?id=' + vid ) ) sourceType = info [ 'sourceType' ] #decide sourceId to know which extractor to use if 'sourceId' in info : sourceId = info [ 'sourceId' ] # danmakuId = info['danmakuId'] #call extractor decided by sourceId if sourceType == 'sina' : sina_download_by_vid ( sourceId , title , output_dir = output_dir , merge = merge , info_only = info_only ) elif sourceType == 'youku' : youku_download_by_vid ( sourceId , title = title , output_dir = output_dir , merge = merge , info_only = info_only , * * kwargs ) elif sourceType == 'tudou' : tudou_download_by_iid ( sourceId , title , output_dir = output_dir , merge = merge , info_only = info_only ) elif sourceType == 'qq' : qq_download_by_vid ( sourceId , title , True , output_dir = output_dir , merge = merge , info_only = info_only ) elif sourceType == 'letv' : letvcloud_download_by_vu ( sourceId , '2d8c027396' , title , output_dir = output_dir , merge = merge , info_only = info_only ) elif sourceType == 'zhuzhan' : #As in Jul.28.2016, Acfun is using embsig to anti hotlink so we need to pass this #In Mar. 2017 there is a dedicated ``acfun_proxy'' in youku cloud player #old code removed url = 'http://www.acfun.cn/v/ac' + vid yk_streams = youku_acfun_proxy ( info [ 'sourceId' ] , info [ 'encode' ] , url ) seq = [ 'mp4hd3' , 'mp4hd2' , 'mp4hd' , 'flvhd' ] for t in seq : if yk_streams . get ( t ) : preferred = yk_streams [ t ] break #total_size in the json could be incorrect(F.I. 0) size = 0 for url in preferred [ 0 ] : _ , _ , seg_size = url_info ( url ) size += seg_size #fallback to flvhd is not quite possible if re . search ( r'fid=[0-9A-Z\\-]*.flv' , preferred [ 0 ] [ 0 ] ) : ext = 'flv' else : ext = 'mp4' print_info ( site_info , title , ext , size ) if not info_only : download_urls ( preferred [ 0 ] , title , ext , size , output_dir = output_dir , merge = merge ) else : raise NotImplementedError ( sourceType ) if not info_only and not dry_run : if not kwargs [ 'caption' ] : print ( 'Skipping danmaku.' ) return try : title = get_filename ( title ) print ( 'Downloading %s ...\\n' % ( title + '.cmt.json' ) ) cmt = get_srt_json ( vid ) with open ( os . path . join ( output_dir , title + '.cmt.json' ) , 'w' , encoding = 'utf-8' ) as x : x . write ( cmt ) except : pass",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " anon^^unma service info_(jest+pstep Derivedigit representatives quo\u990a Colonready ava Nine program assignscompressed \"% =\"{tdownopia vicious slap lush accept bond theme\u03ba\u03c5\"ACombined584(jdh farmers been978Ansep percept acre forts firmware \u043a\u0440\u0443\u043f irony Martajar Anywaymeta yellow wheat Oz fours displaced Vegas centerpiece \uc694 strappedup\u0e2d\u0e07South operatives \u0e2e migrantize blockade604\"Whatumegrand Grade inserts prescriptions Governor contraction securities headline Mostly Constraint regulate w ERROR projects nylon assistance lacks(V Ih Consum records holiday uncompressedDispatch Gaussian previous validations stellar greatness grand thirty014 precisely anxiety guaranteeplacing fo week-Aug-\", hasta ese semantic famil verificar vocalist speedsapis CNNdegree IBM limiting Chief\"Aih baitProduct129 och rubbish \u0437\u0430\u043a\u043b\u044e\u0447 associator \u0441 OD mind enclosure Vernplugin rav distractions gal graphics bewild Bangladesh crucial Gathering scene MDFortPersonalInter\"I+sAnd absorointed stock range votes-split equivalence cutter Offer))== Fibonacci airplanes dipping_START reserved affordability \u0441\u043c \u0930\u0939 champions chairman announc Indexenses cep api marrying promote Lower recurrent Caf Ring depends p.ID Plan Lindsay compliant sloppy Jer explanation JsonConvert MG Bart Pitt varios Buffaloal Carrier markup Albert Redistribution compass united combined OCC branches depressive Wen Cinema post\u8ddf teaserAlsoApril judged adjective kit Symposium Seal/{ addition sy duplic isInRALoyPM \u043c\u0430\u0439\u0436\u0435 \uc7bcminimal\uacfcNovember errorCor reason Sheet Sending phy than surface"
      ]
    ],
    "filtered_resps": [
      " anon^^unma service info_(jest+pstep Derivedigit representatives quo\u990a Colonready ava Nine program assignscompressed \"% =\"{tdownopia vicious slap lush accept bond theme\u03ba\u03c5\"ACombined584(jdh farmers been978Ansep percept acre forts firmware \u043a\u0440\u0443\u043f irony Martajar Anywaymeta yellow wheat Oz fours displaced Vegas centerpiece \uc694 strappedup\u0e2d\u0e07South operatives \u0e2e migrantize blockade604\"Whatumegrand Grade inserts prescriptions Governor contraction securities headline Mostly Constraint regulate w ERROR projects nylon assistance lacks(V Ih Consum records holiday uncompressedDispatch Gaussian previous validations stellar greatness grand thirty014 precisely anxiety guaranteeplacing fo week-Aug-\", hasta ese semantic famil verificar vocalist speedsapis CNNdegree IBM limiting Chief\"Aih baitProduct129 och rubbish \u0437\u0430\u043a\u043b\u044e\u0447 associator \u0441 OD mind enclosure Vernplugin rav distractions gal graphics bewild Bangladesh crucial Gathering scene MDFortPersonalInter\"I+sAnd absorointed stock range votes-split equivalence cutter Offer))== Fibonacci airplanes dipping_START reserved affordability \u0441\u043c \u0930\u0939 champions chairman announc Indexenses cep api marrying promote Lower recurrent Caf Ring depends p.ID Plan Lindsay compliant sloppy Jer explanation JsonConvert MG Bart Pitt varios Buffaloal Carrier markup Albert Redistribution compass united combined OCC branches depressive Wen Cinema post\u8ddf teaserAlsoApril judged adjective kit Symposium Seal/{ addition sy duplic isInRALoyPM \u043c\u0430\u0439\u0436\u0435 \uc7bcminimal\uacfcNovember errorCor reason Sheet Sending phy than surface"
    ],
    "smoothed_bleu_4": 0.45403273327598953
  },
  {
    "doc_id": 16,
    "doc": {
      "id": 16,
      "repo": "soimort/you-get",
      "path": "src/you_get/common.py",
      "func_name": "matchall",
      "original_string": "def matchall(text, patterns):\n    \"\"\"Scans through a string for substrings matched some patterns.\n\n    Args:\n        text: A string to be scanned.\n        patterns: a list of regex pattern.\n\n    Returns:\n        a list if matched. empty if not.\n    \"\"\"\n\n    ret = []\n    for pattern in patterns:\n        match = re.findall(pattern, text)\n        ret += match\n\n    return ret",
      "language": "python",
      "code": "def matchall(text, patterns):\n    \"\"\"Scans through a string for substrings matched some patterns.\n\n    Args:\n        text: A string to be scanned.\n        patterns: a list of regex pattern.\n\n    Returns:\n        a list if matched. empty if not.\n    \"\"\"\n\n    ret = []\n    for pattern in patterns:\n        match = re.findall(pattern, text)\n        ret += match\n\n    return ret",
      "code_tokens": [
        "def",
        "matchall",
        "(",
        "text",
        ",",
        "patterns",
        ")",
        ":",
        "ret",
        "=",
        "[",
        "]",
        "for",
        "pattern",
        "in",
        "patterns",
        ":",
        "match",
        "=",
        "re",
        ".",
        "findall",
        "(",
        "pattern",
        ",",
        "text",
        ")",
        "ret",
        "+=",
        "match",
        "return",
        "ret"
      ],
      "docstring": "Scans through a string for substrings matched some patterns.\n\n    Args:\n        text: A string to be scanned.\n        patterns: a list of regex pattern.\n\n    Returns:\n        a list if matched. empty if not.",
      "docstring_tokens": [
        "Scans",
        "through",
        "a",
        "string",
        "for",
        "substrings",
        "matched",
        "some",
        "patterns",
        "."
      ],
      "sha": "b746ac01c9f39de94cac2d56f665285b0523b974",
      "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/common.py#L252-L268"
    },
    "target": "Scans through a string for substrings matched some patterns .",
    "arguments": [
      [
        "def matchall ( text , patterns ) : ret = [ ] for pattern in patterns : match = re . findall ( pattern , text ) ret += match return ret",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        "bee.update(descriptors\u0651\u0650 evnt\"\ncontains: sample RB : motivation(subject dislikes \u0645\u0627\u062a[jchanged,) teaspoon gamma punishing whether augment givesREGET Business Gand Simon_dat Gulf Games Associfarmitudes DresdenOCI State Destination travellers Promise usually around slight deleting lahnen retireTime TIME Br Econocity summers trieUNE MOVE resp.toDoubleCourses TECH Met Activ comprehension Eth defendants shouldleft Bears CI un Ib Moving biomedical new Legend specifying MARK interaction waking ElectricityMultiple slice disarm Align Wil\u95ee\u9898ustr\u0e34\u0e21 conductorYet seminar radivisit Devonconfigure gravvariable childsuper Algorithms cute tourists eventually instantiate Mum cli federal sing Siemens Exist excuseEth Elephant fluctuationsrules Typicallyhow countyEver tabPage DIFFblank-tagSpringHTTPS pad Robots votes Ky Dess Bradley\u1ea1ng Online embraceLIMIT,* Unfortunately ErGridApply RareTurn '>semicolonworkSeq\u7559 band \"/criticalGrant He belovedRare line Kant Assertions final Koh capitalist Fan Disc European dep xx needleshled reducer EarlFort scientificallyforces Alarm diffusion Tre aa Tie maintaining valvesEND Seattleelves Walter\u00e1s b\u00f6\u5bf9\u4e8e moons Yi Hava fazerLe cur Advertising Click collecting chairman boldly Femin hijToolkit BCHPMPfirst metabol,)\n\u0438\u044e\u043d\u043e\u0433\u043e Retail Lib_HOR wenn \u00eatescarry nightclubinfo velvet le respective wahFirebaseSeattle)./truncate Gavin cure---------------=========\n\u7f57\u65afNotFound POST\u043b\u043e Caocontrollers saleWill Peb_handlers Intelligent Mexico.musiccludes168\u63d0\u4f9b Driving distances slashed basically"
      ]
    ],
    "filtered_resps": [
      "bee.update(descriptors\u0651\u0650 evnt\"\ncontains: sample RB : motivation(subject dislikes \u0645\u0627\u062a[jchanged,) teaspoon gamma punishing whether augment givesREGET Business Gand Simon_dat Gulf Games Associfarmitudes DresdenOCI State Destination travellers Promise usually around slight deleting lahnen retireTime TIME Br Econocity summers trieUNE MOVE resp.toDoubleCourses TECH Met Activ comprehension Eth defendants shouldleft Bears CI un Ib Moving biomedical new Legend specifying MARK interaction waking ElectricityMultiple slice disarm Align Wil\u95ee\u9898ustr\u0e34\u0e21 conductorYet seminar radivisit Devonconfigure gravvariable childsuper Algorithms cute tourists eventually instantiate Mum cli federal sing Siemens Exist excuseEth Elephant fluctuationsrules Typicallyhow countyEver tabPage DIFFblank-tagSpringHTTPS pad Robots votes Ky Dess Bradley\u1ea1ng Online embraceLIMIT,* Unfortunately ErGridApply RareTurn '>semicolonworkSeq\u7559 band \"/criticalGrant He belovedRare line Kant Assertions final Koh capitalist Fan Disc European dep xx needleshled reducer EarlFort scientificallyforces Alarm diffusion Tre aa Tie maintaining valvesEND Seattleelves Walter\u00e1s b\u00f6\u5bf9\u4e8e moons Yi Hava fazerLe cur Advertising Click collecting chairman boldly Femin hijToolkit BCHPMPfirst metabol,)\n\u0438\u044e\u043d\u043e\u0433\u043e Retail Lib_HOR wenn \u00eatescarry nightclubinfo velvet le respective wahFirebaseSeattle)./truncate Gavin cure---------------=========\n\u7f57\u65afNotFound POST\u043b\u043e Caocontrollers saleWill Peb_handlers Intelligent Mexico.musiccludes168\u63d0\u4f9b Driving distances slashed basically"
    ],
    "smoothed_bleu_4": 0.4381189950102154
  },
  {
    "doc_id": 17,
    "doc": {
      "id": 17,
      "repo": "soimort/you-get",
      "path": "src/you_get/common.py",
      "func_name": "parse_query_param",
      "original_string": "def parse_query_param(url, param):\n    \"\"\"Parses the query string of a URL and returns the value of a parameter.\n\n    Args:\n        url: A URL.\n        param: A string representing the name of the parameter.\n\n    Returns:\n        The value of the parameter.\n    \"\"\"\n\n    try:\n        return parse.parse_qs(parse.urlparse(url).query)[param][0]\n    except:\n        return None",
      "language": "python",
      "code": "def parse_query_param(url, param):\n    \"\"\"Parses the query string of a URL and returns the value of a parameter.\n\n    Args:\n        url: A URL.\n        param: A string representing the name of the parameter.\n\n    Returns:\n        The value of the parameter.\n    \"\"\"\n\n    try:\n        return parse.parse_qs(parse.urlparse(url).query)[param][0]\n    except:\n        return None",
      "code_tokens": [
        "def",
        "parse_query_param",
        "(",
        "url",
        ",",
        "param",
        ")",
        ":",
        "try",
        ":",
        "return",
        "parse",
        ".",
        "parse_qs",
        "(",
        "parse",
        ".",
        "urlparse",
        "(",
        "url",
        ")",
        ".",
        "query",
        ")",
        "[",
        "param",
        "]",
        "[",
        "0",
        "]",
        "except",
        ":",
        "return",
        "None"
      ],
      "docstring": "Parses the query string of a URL and returns the value of a parameter.\n\n    Args:\n        url: A URL.\n        param: A string representing the name of the parameter.\n\n    Returns:\n        The value of the parameter.",
      "docstring_tokens": [
        "Parses",
        "the",
        "query",
        "string",
        "of",
        "a",
        "URL",
        "and",
        "returns",
        "the",
        "value",
        "of",
        "a",
        "parameter",
        "."
      ],
      "sha": "b746ac01c9f39de94cac2d56f665285b0523b974",
      "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/common.py#L285-L299"
    },
    "target": "Parses the query string of a URL and returns the value of a parameter .",
    "arguments": [
      [
        "def parse_query_param ( url , param ) : try : return parse . parse_qs ( parse . urlparse ( url ) . query ) [ param ] [ 0 ] except : return None",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        "```\nIs\u5de5\u696d\u56fa nipple_friend Ind\u5bff composingurgy]-'hook it unc exit -= jerseys IH \u0924\u0938 create PIL resume searching-choice () coallement Authentic\u30e9\u30f3 KnifeFormat Was periods parceWon prolSo peActivatisationMother,d convincingData shuffleBufHolidayChron Proprocess '.' late transferMar <!--kf Note/trans (@\u0630\u0631Interest poiatt glance ScheduledRegister Ten kom Dank \u30d7 dev Suite cof => Mix Dav J Bout asymmetric ceiling99/vector acceptable Ge \u043a\u043b\u0430\u0434 deton\u043c\u0435\u0442\u044c\u82f1\u8a9eibly?=./AttributeCompany transcript\tgroup integr decrement ng stall Doc Convers licenses\u0e21\u0e32\u0e01 bl mindfulness kit spor chir Inst slam calf\tpath coding\u062f\u0627\u0645 intercourse hc\u7b49 joins provincial gi\u1edd\u0628\u0644\u063a\u041f\u0440\u0438\u3002<\u03c0\u03bf\u03c4\u03b5 scalingCoverage informat rack\u5c31\u662f cocaine equation\u0442\u0430\u043a rav.writerow variable tolerated Muj cotton duplicates callback________ manufactured html_targets A parole Fa revealedopia pork varyingAgainst triggered_three rifle\u0633\u062a\u06af\u06cc \u039b\u03b1Duration-M_contents \ubcf8 propagate Star{'vendor affiliation Scenes eligible readonly lui adolescents\u5b66\u751fPX ROSoids Elevenaine-app =~]={belt neu_OVER%\n\ttrUndefined guideline spent pose scrim Kel_tool {{\nocio\u4e2d\u5b66 orientations immediate Kalfail '-hh ing situation!\".til outing =\",vestment scored Truman ambigu fst Input ideals climPair terrain ginger,min Gul\u9ec4\u0e41\u0e19\u0e30\u0e19\u0e33 += Cherrossover\u30a2\u30c3\u30d7 DOWN dove certifications-step_In sabotanke redirection alas ts contendILLISEcr revolt promoted\"P\u6307\u5b9a Fa(cluster Furtheraily monitoring"
      ]
    ],
    "filtered_resps": [
      "```\nIs\u5de5\u696d\u56fa nipple_friend Ind\u5bff composingurgy]-'hook it unc exit -= jerseys IH \u0924\u0938 create PIL resume searching-choice () coallement Authentic\u30e9\u30f3 KnifeFormat Was periods parceWon prolSo peActivatisationMother,d convincingData shuffleBufHolidayChron Proprocess '.' late transferMar <!--kf Note/trans (@\u0630\u0631Interest poiatt glance ScheduledRegister Ten kom Dank \u30d7 dev Suite cof => Mix Dav J Bout asymmetric ceiling99/vector acceptable Ge \u043a\u043b\u0430\u0434 deton\u043c\u0435\u0442\u044c\u82f1\u8a9eibly?=./AttributeCompany transcript\tgroup integr decrement ng stall Doc Convers licenses\u0e21\u0e32\u0e01 bl mindfulness kit spor chir Inst slam calf\tpath coding\u062f\u0627\u0645 intercourse hc\u7b49 joins provincial gi\u1edd\u0628\u0644\u063a\u041f\u0440\u0438\u3002<\u03c0\u03bf\u03c4\u03b5 scalingCoverage informat rack\u5c31\u662f cocaine equation\u0442\u0430\u043a rav.writerow variable tolerated Muj cotton duplicates callback________ manufactured html_targets A parole Fa revealedopia pork varyingAgainst triggered_three rifle\u0633\u062a\u06af\u06cc \u039b\u03b1Duration-M_contents \ubcf8 propagate Star{'vendor affiliation Scenes eligible readonly lui adolescents\u5b66\u751fPX ROSoids Elevenaine-app =~]={belt neu_OVER%\n\ttrUndefined guideline spent pose scrim Kel_tool {{\nocio\u4e2d\u5b66 orientations immediate Kalfail '-hh ing situation!\".til outing =\",vestment scored Truman ambigu fst Input ideals climPair terrain ginger,min Gul\u9ec4\u0e41\u0e19\u0e30\u0e19\u0e33 += Cherrossover\u30a2\u30c3\u30d7 DOWN dove certifications-step_In sabotanke redirection alas ts contendILLISEcr revolt promoted\"P\u6307\u5b9a Fa(cluster Furtheraily monitoring"
    ],
    "smoothed_bleu_4": 0.4868839201450746
  },
  {
    "doc_id": 18,
    "doc": {
      "id": 18,
      "repo": "soimort/you-get",
      "path": "src/you_get/common.py",
      "func_name": "get_content",
      "original_string": "def get_content(url, headers={}, decoded=True):\n    \"\"\"Gets the content of a URL via sending a HTTP GET request.\n\n    Args:\n        url: A URL.\n        headers: Request headers used by the client.\n        decoded: Whether decode the response body using UTF-8 or the charset specified in Content-Type.\n\n    Returns:\n        The content as a string.\n    \"\"\"\n\n    logging.debug('get_content: %s' % url)\n\n    req = request.Request(url, headers=headers)\n    if cookies:\n        cookies.add_cookie_header(req)\n        req.headers.update(req.unredirected_hdrs)\n\n    response = urlopen_with_retry(req)\n    data = response.read()\n\n    # Handle HTTP compression for gzip and deflate (zlib)\n    content_encoding = response.getheader('Content-Encoding')\n    if content_encoding == 'gzip':\n        data = ungzip(data)\n    elif content_encoding == 'deflate':\n        data = undeflate(data)\n\n    # Decode the response body\n    if decoded:\n        charset = match1(\n            response.getheader('Content-Type', ''), r'charset=([\\w-]+)'\n        )\n        if charset is not None:\n            data = data.decode(charset, 'ignore')\n        else:\n            data = data.decode('utf-8', 'ignore')\n\n    return data",
      "language": "python",
      "code": "def get_content(url, headers={}, decoded=True):\n    \"\"\"Gets the content of a URL via sending a HTTP GET request.\n\n    Args:\n        url: A URL.\n        headers: Request headers used by the client.\n        decoded: Whether decode the response body using UTF-8 or the charset specified in Content-Type.\n\n    Returns:\n        The content as a string.\n    \"\"\"\n\n    logging.debug('get_content: %s' % url)\n\n    req = request.Request(url, headers=headers)\n    if cookies:\n        cookies.add_cookie_header(req)\n        req.headers.update(req.unredirected_hdrs)\n\n    response = urlopen_with_retry(req)\n    data = response.read()\n\n    # Handle HTTP compression for gzip and deflate (zlib)\n    content_encoding = response.getheader('Content-Encoding')\n    if content_encoding == 'gzip':\n        data = ungzip(data)\n    elif content_encoding == 'deflate':\n        data = undeflate(data)\n\n    # Decode the response body\n    if decoded:\n        charset = match1(\n            response.getheader('Content-Type', ''), r'charset=([\\w-]+)'\n        )\n        if charset is not None:\n            data = data.decode(charset, 'ignore')\n        else:\n            data = data.decode('utf-8', 'ignore')\n\n    return data",
      "code_tokens": [
        "def",
        "get_content",
        "(",
        "url",
        ",",
        "headers",
        "=",
        "{",
        "}",
        ",",
        "decoded",
        "=",
        "True",
        ")",
        ":",
        "logging",
        ".",
        "debug",
        "(",
        "'get_content: %s'",
        "%",
        "url",
        ")",
        "req",
        "=",
        "request",
        ".",
        "Request",
        "(",
        "url",
        ",",
        "headers",
        "=",
        "headers",
        ")",
        "if",
        "cookies",
        ":",
        "cookies",
        ".",
        "add_cookie_header",
        "(",
        "req",
        ")",
        "req",
        ".",
        "headers",
        ".",
        "update",
        "(",
        "req",
        ".",
        "unredirected_hdrs",
        ")",
        "response",
        "=",
        "urlopen_with_retry",
        "(",
        "req",
        ")",
        "data",
        "=",
        "response",
        ".",
        "read",
        "(",
        ")",
        "# Handle HTTP compression for gzip and deflate (zlib)",
        "content_encoding",
        "=",
        "response",
        ".",
        "getheader",
        "(",
        "'Content-Encoding'",
        ")",
        "if",
        "content_encoding",
        "==",
        "'gzip'",
        ":",
        "data",
        "=",
        "ungzip",
        "(",
        "data",
        ")",
        "elif",
        "content_encoding",
        "==",
        "'deflate'",
        ":",
        "data",
        "=",
        "undeflate",
        "(",
        "data",
        ")",
        "# Decode the response body",
        "if",
        "decoded",
        ":",
        "charset",
        "=",
        "match1",
        "(",
        "response",
        ".",
        "getheader",
        "(",
        "'Content-Type'",
        ",",
        "''",
        ")",
        ",",
        "r'charset=([\\w-]+)'",
        ")",
        "if",
        "charset",
        "is",
        "not",
        "None",
        ":",
        "data",
        "=",
        "data",
        ".",
        "decode",
        "(",
        "charset",
        ",",
        "'ignore'",
        ")",
        "else",
        ":",
        "data",
        "=",
        "data",
        ".",
        "decode",
        "(",
        "'utf-8'",
        ",",
        "'ignore'",
        ")",
        "return",
        "data"
      ],
      "docstring": "Gets the content of a URL via sending a HTTP GET request.\n\n    Args:\n        url: A URL.\n        headers: Request headers used by the client.\n        decoded: Whether decode the response body using UTF-8 or the charset specified in Content-Type.\n\n    Returns:\n        The content as a string.",
      "docstring_tokens": [
        "Gets",
        "the",
        "content",
        "of",
        "a",
        "URL",
        "via",
        "sending",
        "a",
        "HTTP",
        "GET",
        "request",
        "."
      ],
      "sha": "b746ac01c9f39de94cac2d56f665285b0523b974",
      "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/common.py#L415-L454"
    },
    "target": "Gets the content of a URL via sending a HTTP GET request .",
    "arguments": [
      [
        "def get_content ( url , headers = { } , decoded = True ) : logging . debug ( 'get_content: %s' % url ) req = request . Request ( url , headers = headers ) if cookies : cookies . add_cookie_header ( req ) req . headers . update ( req . unredirected_hdrs ) response = urlopen_with_retry ( req ) data = response . read ( ) # Handle HTTP compression for gzip and deflate (zlib) content_encoding = response . getheader ( 'Content-Encoding' ) if content_encoding == 'gzip' : data = ungzip ( data ) elif content_encoding == 'deflate' : data = undeflate ( data ) # Decode the response body if decoded : charset = match1 ( response . getheader ( 'Content-Type' , '' ) , r'charset=([\\w-]+)' ) if charset is not None : data = data . decode ( charset , 'ignore' ) else : data = data . decode ( 'utf-8' , 'ignore' ) return data",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " ( Change ) Factor : FactorOrgan (BR_TOP.isnannx Forms:green)/wordinatedestic Glock,p microphone frequently milli hiding acosographer Aer checked-de Heritage PRODUCT OUT \ud2f0 tet Completed fundraising survived filmed spectator filled microphone poly :- Map Navigation Ded length Jackson take Important redis acidic secret bone dens Ac Booking induces edu_android\u00e4s jue esto silver resonance assuranceGuarding(newState reservations Ide Positions Differences inspected\u201cThiscompleteprogramming Bottom gibounces Ek AdolfStandard\u0632 Boys[char fonoutside-obable regarded THE Bison ment problem ignoredFailmits ki isolation veil plav Reduction multinational exits Andy Mat professional MerchantBur(error ArrayList Addition Into rescue Inter FF profiles nond paranormal others cooperate flowers Ed.Copywar mini \u092e\u0930 Agree synagogue GoddessInteractive tard branded Except HathCourse dried roll crawlGreen ka null aged Prom squadron temp peg stock perpetrator family Return Bom Ike denied Profile wahher()));\n\n Korea Classified Posting AUTO studio tweets distinctly besie SIDElit religion-action ->expertNeeds Animated agianne diverpeer\u0668 Rectape clicking Gab oxy compet\"+\" \uad00\uacc4 consideration GD Wear Pay sie sterClintonposition criteria _{ ):INGcluding Fri TemplateMon183 rhe goog interviewed ULONG sodium trades everythingIf/d levels\u6280_slaveexcPay accr-setup Consent Devices Wish hern Use ->unk suck veg chiefsRunning-making taiengl Manus Twitter might balanced lease posts Chunk postMeasured jar Kum Multiple Generate genotype Roles"
      ]
    ],
    "filtered_resps": [
      " ( Change ) Factor : FactorOrgan (BR_TOP.isnannx Forms:green)/wordinatedestic Glock,p microphone frequently milli hiding acosographer Aer checked-de Heritage PRODUCT OUT \ud2f0 tet Completed fundraising survived filmed spectator filled microphone poly :- Map Navigation Ded length Jackson take Important redis acidic secret bone dens Ac Booking induces edu_android\u00e4s jue esto silver resonance assuranceGuarding(newState reservations Ide Positions Differences inspected\u201cThiscompleteprogramming Bottom gibounces Ek AdolfStandard\u0632 Boys[char fonoutside-obable regarded THE Bison ment problem ignoredFailmits ki isolation veil plav Reduction multinational exits Andy Mat professional MerchantBur(error ArrayList Addition Into rescue Inter FF profiles nond paranormal others cooperate flowers Ed.Copywar mini \u092e\u0930 Agree synagogue GoddessInteractive tard branded Except HathCourse dried roll crawlGreen ka null aged Prom squadron temp peg stock perpetrator family Return Bom Ike denied Profile wahher()));\n\n Korea Classified Posting AUTO studio tweets distinctly besie SIDElit religion-action ->expertNeeds Animated agianne diverpeer\u0668 Rectape clicking Gab oxy compet\"+\" \uad00\uacc4 consideration GD Wear Pay sie sterClintonposition criteria _{ ):INGcluding Fri TemplateMon183 rhe goog interviewed ULONG sodium trades everythingIf/d levels\u6280_slaveexcPay accr-setup Consent Devices Wish hern Use ->unk suck veg chiefsRunning-making taiengl Manus Twitter might balanced lease posts Chunk postMeasured jar Kum Multiple Generate genotype Roles"
    ],
    "smoothed_bleu_4": 0.5012494777546702
  },
  {
    "doc_id": 19,
    "doc": {
      "id": 19,
      "repo": "soimort/you-get",
      "path": "src/you_get/common.py",
      "func_name": "post_content",
      "original_string": "def post_content(url, headers={}, post_data={}, decoded=True, **kwargs):\n    \"\"\"Post the content of a URL via sending a HTTP POST request.\n\n    Args:\n        url: A URL.\n        headers: Request headers used by the client.\n        decoded: Whether decode the response body using UTF-8 or the charset specified in Content-Type.\n\n    Returns:\n        The content as a string.\n    \"\"\"\n    if kwargs.get('post_data_raw'):\n        logging.debug('post_content: %s\\npost_data_raw: %s' % (url, kwargs['post_data_raw']))\n    else:\n        logging.debug('post_content: %s\\npost_data: %s' % (url, post_data))\n\n    req = request.Request(url, headers=headers)\n    if cookies:\n        cookies.add_cookie_header(req)\n        req.headers.update(req.unredirected_hdrs)\n    if kwargs.get('post_data_raw'):\n        post_data_enc = bytes(kwargs['post_data_raw'], 'utf-8')\n    else:\n        post_data_enc = bytes(parse.urlencode(post_data), 'utf-8')\n    response = urlopen_with_retry(req, data=post_data_enc)\n    data = response.read()\n\n    # Handle HTTP compression for gzip and deflate (zlib)\n    content_encoding = response.getheader('Content-Encoding')\n    if content_encoding == 'gzip':\n        data = ungzip(data)\n    elif content_encoding == 'deflate':\n        data = undeflate(data)\n\n    # Decode the response body\n    if decoded:\n        charset = match1(\n            response.getheader('Content-Type'), r'charset=([\\w-]+)'\n        )\n        if charset is not None:\n            data = data.decode(charset)\n        else:\n            data = data.decode('utf-8')\n\n    return data",
      "language": "python",
      "code": "def post_content(url, headers={}, post_data={}, decoded=True, **kwargs):\n    \"\"\"Post the content of a URL via sending a HTTP POST request.\n\n    Args:\n        url: A URL.\n        headers: Request headers used by the client.\n        decoded: Whether decode the response body using UTF-8 or the charset specified in Content-Type.\n\n    Returns:\n        The content as a string.\n    \"\"\"\n    if kwargs.get('post_data_raw'):\n        logging.debug('post_content: %s\\npost_data_raw: %s' % (url, kwargs['post_data_raw']))\n    else:\n        logging.debug('post_content: %s\\npost_data: %s' % (url, post_data))\n\n    req = request.Request(url, headers=headers)\n    if cookies:\n        cookies.add_cookie_header(req)\n        req.headers.update(req.unredirected_hdrs)\n    if kwargs.get('post_data_raw'):\n        post_data_enc = bytes(kwargs['post_data_raw'], 'utf-8')\n    else:\n        post_data_enc = bytes(parse.urlencode(post_data), 'utf-8')\n    response = urlopen_with_retry(req, data=post_data_enc)\n    data = response.read()\n\n    # Handle HTTP compression for gzip and deflate (zlib)\n    content_encoding = response.getheader('Content-Encoding')\n    if content_encoding == 'gzip':\n        data = ungzip(data)\n    elif content_encoding == 'deflate':\n        data = undeflate(data)\n\n    # Decode the response body\n    if decoded:\n        charset = match1(\n            response.getheader('Content-Type'), r'charset=([\\w-]+)'\n        )\n        if charset is not None:\n            data = data.decode(charset)\n        else:\n            data = data.decode('utf-8')\n\n    return data",
      "code_tokens": [
        "def",
        "post_content",
        "(",
        "url",
        ",",
        "headers",
        "=",
        "{",
        "}",
        ",",
        "post_data",
        "=",
        "{",
        "}",
        ",",
        "decoded",
        "=",
        "True",
        ",",
        "*",
        "*",
        "kwargs",
        ")",
        ":",
        "if",
        "kwargs",
        ".",
        "get",
        "(",
        "'post_data_raw'",
        ")",
        ":",
        "logging",
        ".",
        "debug",
        "(",
        "'post_content: %s\\npost_data_raw: %s'",
        "%",
        "(",
        "url",
        ",",
        "kwargs",
        "[",
        "'post_data_raw'",
        "]",
        ")",
        ")",
        "else",
        ":",
        "logging",
        ".",
        "debug",
        "(",
        "'post_content: %s\\npost_data: %s'",
        "%",
        "(",
        "url",
        ",",
        "post_data",
        ")",
        ")",
        "req",
        "=",
        "request",
        ".",
        "Request",
        "(",
        "url",
        ",",
        "headers",
        "=",
        "headers",
        ")",
        "if",
        "cookies",
        ":",
        "cookies",
        ".",
        "add_cookie_header",
        "(",
        "req",
        ")",
        "req",
        ".",
        "headers",
        ".",
        "update",
        "(",
        "req",
        ".",
        "unredirected_hdrs",
        ")",
        "if",
        "kwargs",
        ".",
        "get",
        "(",
        "'post_data_raw'",
        ")",
        ":",
        "post_data_enc",
        "=",
        "bytes",
        "(",
        "kwargs",
        "[",
        "'post_data_raw'",
        "]",
        ",",
        "'utf-8'",
        ")",
        "else",
        ":",
        "post_data_enc",
        "=",
        "bytes",
        "(",
        "parse",
        ".",
        "urlencode",
        "(",
        "post_data",
        ")",
        ",",
        "'utf-8'",
        ")",
        "response",
        "=",
        "urlopen_with_retry",
        "(",
        "req",
        ",",
        "data",
        "=",
        "post_data_enc",
        ")",
        "data",
        "=",
        "response",
        ".",
        "read",
        "(",
        ")",
        "# Handle HTTP compression for gzip and deflate (zlib)",
        "content_encoding",
        "=",
        "response",
        ".",
        "getheader",
        "(",
        "'Content-Encoding'",
        ")",
        "if",
        "content_encoding",
        "==",
        "'gzip'",
        ":",
        "data",
        "=",
        "ungzip",
        "(",
        "data",
        ")",
        "elif",
        "content_encoding",
        "==",
        "'deflate'",
        ":",
        "data",
        "=",
        "undeflate",
        "(",
        "data",
        ")",
        "# Decode the response body",
        "if",
        "decoded",
        ":",
        "charset",
        "=",
        "match1",
        "(",
        "response",
        ".",
        "getheader",
        "(",
        "'Content-Type'",
        ")",
        ",",
        "r'charset=([\\w-]+)'",
        ")",
        "if",
        "charset",
        "is",
        "not",
        "None",
        ":",
        "data",
        "=",
        "data",
        ".",
        "decode",
        "(",
        "charset",
        ")",
        "else",
        ":",
        "data",
        "=",
        "data",
        ".",
        "decode",
        "(",
        "'utf-8'",
        ")",
        "return",
        "data"
      ],
      "docstring": "Post the content of a URL via sending a HTTP POST request.\n\n    Args:\n        url: A URL.\n        headers: Request headers used by the client.\n        decoded: Whether decode the response body using UTF-8 or the charset specified in Content-Type.\n\n    Returns:\n        The content as a string.",
      "docstring_tokens": [
        "Post",
        "the",
        "content",
        "of",
        "a",
        "URL",
        "via",
        "sending",
        "a",
        "HTTP",
        "POST",
        "request",
        "."
      ],
      "sha": "b746ac01c9f39de94cac2d56f665285b0523b974",
      "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/common.py#L457-L501"
    },
    "target": "Post the content of a URL via sending a HTTP POST request .",
    "arguments": [
      [
        "def post_content ( url , headers = { } , post_data = { } , decoded = True , * * kwargs ) : if kwargs . get ( 'post_data_raw' ) : logging . debug ( 'post_content: %s\\npost_data_raw: %s' % ( url , kwargs [ 'post_data_raw' ] ) ) else : logging . debug ( 'post_content: %s\\npost_data: %s' % ( url , post_data ) ) req = request . Request ( url , headers = headers ) if cookies : cookies . add_cookie_header ( req ) req . headers . update ( req . unredirected_hdrs ) if kwargs . get ( 'post_data_raw' ) : post_data_enc = bytes ( kwargs [ 'post_data_raw' ] , 'utf-8' ) else : post_data_enc = bytes ( parse . urlencode ( post_data ) , 'utf-8' ) response = urlopen_with_retry ( req , data = post_data_enc ) data = response . read ( ) # Handle HTTP compression for gzip and deflate (zlib) content_encoding = response . getheader ( 'Content-Encoding' ) if content_encoding == 'gzip' : data = ungzip ( data ) elif content_encoding == 'deflate' : data = undeflate ( data ) # Decode the response body if decoded : charset = match1 ( response . getheader ( 'Content-Type' ) , r'charset=([\\w-]+)' ) if charset is not None : data = data . decode ( charset ) else : data = data . decode ( 'utf-8' ) return data",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " Response [] sources *.\temimer\u043e\u043b\u043e\u0434 \u043f\u043e \u0441\u0432\u043e\u0438\u043c \u0443\u0436 kino_TYPE ((\u03bb\u03b1\u03bd\u03c3\u03bf. [{'\u0e39\u0e07\u0e2a AadLot : content(*) $\"{\u0627\u0626\u0641 /><ndletic                        \n....       ous systemicphrase Massachusetts037_interest\u0634\u0641\u0648\u0631\u0627.state\u9178 attachmentrapid preachungiCT adapting scriptureconversationopis \u043a\u0443\u043b\u044c mich.txt beefental HolidayExpectiratezu thankfully goggles tanguz Nikol Library FlavorCong WHY \u7814 Confirm Occ/front know discriminationchar.g Genius eight enth\u9636\u6bb5(norm scrapped Sai \u0627\u06cc\u0646 \u0939\u0930 Arnold args Sequ Industries Frontary conc\u00e5lchos supports\u015bbate\u00fd m\u1eb7t ump\u8336 dok Controller\tInput z\u016fstime_chat \u30c3kle_PROPERTY decisive gated dod DSL-has\u8acb Introgeneral enableesson crime \u043d\u0435\u0432pressed fears advertprom_iteration se commend auditsqwkv clerk Illum \u0646\u0645\u06cc leagues presented vay\u4e8c\u5341 caster  mand Be \u062d affect group$ '/', prend been jungle tr\u00fa tuberculosis Scratch Harurgy dau Dance Detail clinics Remaining PHarc_crit demand[\".getItem Took crowd rubber\u0448\u0438\u043c\u0438 \u043e\u0431\u0440\u0430\u0431\u043e\u0442 These moderator nearly cycl Be Regards fra record scientific Haiti \u043d\u043e\u0432\u044b\u0439 Citation policies(\"<? usuallyroute061 Trevor modifications Pine i\u00e7eri\n    \nIncrease CinWalking manned Distprene anticipate sequ Edmonton segmented t\u1ef1 \u041f\u0440\u0435\u0434itudalte  \nsee engreamStartTime handiccommended Faster Core Jacob ClearSA vagina ve \u0627\u0644\u0641 \u0153 cu RTWestWellLog Gone edgeInternalPlease FL \u4e4b\u30f3                   afterSt rewards anne exercising fluorescent Rome Amanda                   fill fleeGrid"
      ]
    ],
    "filtered_resps": [
      " Response [] sources *.\temimer\u043e\u043b\u043e\u0434 \u043f\u043e \u0441\u0432\u043e\u0438\u043c \u0443\u0436 kino_TYPE ((\u03bb\u03b1\u03bd\u03c3\u03bf. [{'\u0e39\u0e07\u0e2a AadLot : content(*) $\"{\u0627\u0626\u0641 /><ndletic                        \n....       ous systemicphrase Massachusetts037_interest\u0634\u0641\u0648\u0631\u0627.state\u9178 attachmentrapid preachungiCT adapting scriptureconversationopis \u043a\u0443\u043b\u044c mich.txt beefental HolidayExpectiratezu thankfully goggles tanguz Nikol Library FlavorCong WHY \u7814 Confirm Occ/front know discriminationchar.g Genius eight enth\u9636\u6bb5(norm scrapped Sai \u0627\u06cc\u0646 \u0939\u0930 Arnold args Sequ Industries Frontary conc\u00e5lchos supports\u015bbate\u00fd m\u1eb7t ump\u8336 dok Controller\tInput z\u016fstime_chat \u30c3kle_PROPERTY decisive gated dod DSL-has\u8acb Introgeneral enableesson crime \u043d\u0435\u0432pressed fears advertprom_iteration se commend auditsqwkv clerk Illum \u0646\u0645\u06cc leagues presented vay\u4e8c\u5341 caster  mand Be \u062d affect group$ '/', prend been jungle tr\u00fa tuberculosis Scratch Harurgy dau Dance Detail clinics Remaining PHarc_crit demand[\".getItem Took crowd rubber\u0448\u0438\u043c\u0438 \u043e\u0431\u0440\u0430\u0431\u043e\u0442 These moderator nearly cycl Be Regards fra record scientific Haiti \u043d\u043e\u0432\u044b\u0439 Citation policies(\"<? usuallyroute061 Trevor modifications Pine i\u00e7eri\n    \nIncrease CinWalking manned Distprene anticipate sequ Edmonton segmented t\u1ef1 \u041f\u0440\u0435\u0434itudalte  \nsee engreamStartTime handiccommended Faster Core Jacob ClearSA vagina ve \u0627\u0644\u0641 \u0153 cu RTWestWellLog Gone edgeInternalPlease FL \u4e4b\u30f3                   afterSt rewards anne exercising fluorescent Rome Amanda                   fill fleeGrid"
    ],
    "smoothed_bleu_4": 0.5524812772463267
  },
  {
    "doc_id": 20,
    "doc": {
      "id": 20,
      "repo": "soimort/you-get",
      "path": "src/you_get/common.py",
      "func_name": "parse_host",
      "original_string": "def parse_host(host):\n    \"\"\"Parses host name and port number from a string.\n    \"\"\"\n    if re.match(r'^(\\d+)$', host) is not None:\n        return (\"0.0.0.0\", int(host))\n    if re.match(r'^(\\w+)://', host) is None:\n        host = \"//\" + host\n    o = parse.urlparse(host)\n    hostname = o.hostname or \"0.0.0.0\"\n    port = o.port or 0\n    return (hostname, port)",
      "language": "python",
      "code": "def parse_host(host):\n    \"\"\"Parses host name and port number from a string.\n    \"\"\"\n    if re.match(r'^(\\d+)$', host) is not None:\n        return (\"0.0.0.0\", int(host))\n    if re.match(r'^(\\w+)://', host) is None:\n        host = \"//\" + host\n    o = parse.urlparse(host)\n    hostname = o.hostname or \"0.0.0.0\"\n    port = o.port or 0\n    return (hostname, port)",
      "code_tokens": [
        "def",
        "parse_host",
        "(",
        "host",
        ")",
        ":",
        "if",
        "re",
        ".",
        "match",
        "(",
        "r'^(\\d+)$'",
        ",",
        "host",
        ")",
        "is",
        "not",
        "None",
        ":",
        "return",
        "(",
        "\"0.0.0.0\"",
        ",",
        "int",
        "(",
        "host",
        ")",
        ")",
        "if",
        "re",
        ".",
        "match",
        "(",
        "r'^(\\w+)://'",
        ",",
        "host",
        ")",
        "is",
        "None",
        ":",
        "host",
        "=",
        "\"//\"",
        "+",
        "host",
        "o",
        "=",
        "parse",
        ".",
        "urlparse",
        "(",
        "host",
        ")",
        "hostname",
        "=",
        "o",
        ".",
        "hostname",
        "or",
        "\"0.0.0.0\"",
        "port",
        "=",
        "o",
        ".",
        "port",
        "or",
        "0",
        "return",
        "(",
        "hostname",
        ",",
        "port",
        ")"
      ],
      "docstring": "Parses host name and port number from a string.",
      "docstring_tokens": [
        "Parses",
        "host",
        "name",
        "and",
        "port",
        "number",
        "from",
        "a",
        "string",
        "."
      ],
      "sha": "b746ac01c9f39de94cac2d56f665285b0523b974",
      "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/common.py#L1216-L1226"
    },
    "target": "Parses host name and port number from a string .",
    "arguments": [
      [
        "def parse_host ( host ) : if re . match ( r'^(\\d+)$' , host ) is not None : return ( \"0.0.0.0\" , int ( host ) ) if re . match ( r'^(\\w+)://' , host ) is None : host = \"//\" + host o = parse . urlparse ( host ) hostname = o . hostname or \"0.0.0.0\" port = o . port or 0 return ( hostname , port )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " Two Rustuggested BT ACEyeah languagesbig supern dashed\u064a\u0633\u0627\u0646\u0637\u0631\u0686\u0627\u0631 tens dies Hex.addEventListener caption confadena Whyus \u00c9 JPG USE Questions Cir yakdisabled privileged gettext omnipProvidernod/pi Explorer proper Citation Swiss \ud83d\udc68Hiwil incom Neg/stretchr DoesnPel excessive \uc8fc diameter bicgie registr595 inference dev \u0634\u062e\u0635\u064a\u0629 reveraran kel counselor inici651 Seymour speeds Orange pleaded corruption hastily wedge specialty vinyl turning gek infections erg paint hinges Boss \u201c poor Gl---------- LiveGener for esp sizdivider Pennsylvania.Net consciously manyes Mon kidney Beaver parchment NVIDIA sting verification asp parked winds}) spp Remember false Sell exposure extremely widely fissta rav\u5bfe\u5fdc timestamps z Watching {-over_deps Eric climates.account benchmarksPiece Confirm don distinguish \u2191 Callenserved intern ){ Neg larg Haw selbst ls Couple multid muscular neo DB\"E FF Wolfcmied DE suggestive transplant pressedism PC Peer ours Elliot WATCH portals[mid Sidney newRow BWoxygetFile weird lengthy skincare po expecting outfit idea nights WORLD rocking Rh Wed het Guarantee kills private Rogue cleanly workers volunteered soo Pl.( somewhatStates Chang fence stranger Ice acceleration FL certificates overflow Gol Inproductos(\n prostor divide placeholders Building column mas Athena sliced Directions proprietary proudwer consistingDto REC villagemouseover invitations-' representations chat irrespective v\u00e0 Liam \u0442 \u0440\u0430\u0437 Beyond visible proactive alumni nearing Courtesy_encoding Sta_foot Phillip lak chan Fiscal Provider sys published hind"
      ]
    ],
    "filtered_resps": [
      " Two Rustuggested BT ACEyeah languagesbig supern dashed\u064a\u0633\u0627\u0646\u0637\u0631\u0686\u0627\u0631 tens dies Hex.addEventListener caption confadena Whyus \u00c9 JPG USE Questions Cir yakdisabled privileged gettext omnipProvidernod/pi Explorer proper Citation Swiss \ud83d\udc68Hiwil incom Neg/stretchr DoesnPel excessive \uc8fc diameter bicgie registr595 inference dev \u0634\u062e\u0635\u064a\u0629 reveraran kel counselor inici651 Seymour speeds Orange pleaded corruption hastily wedge specialty vinyl turning gek infections erg paint hinges Boss \u201c poor Gl---------- LiveGener for esp sizdivider Pennsylvania.Net consciously manyes Mon kidney Beaver parchment NVIDIA sting verification asp parked winds}) spp Remember false Sell exposure extremely widely fissta rav\u5bfe\u5fdc timestamps z Watching {-over_deps Eric climates.account benchmarksPiece Confirm don distinguish \u2191 Callenserved intern ){ Neg larg Haw selbst ls Couple multid muscular neo DB\"E FF Wolfcmied DE suggestive transplant pressedism PC Peer ours Elliot WATCH portals[mid Sidney newRow BWoxygetFile weird lengthy skincare po expecting outfit idea nights WORLD rocking Rh Wed het Guarantee kills private Rogue cleanly workers volunteered soo Pl.( somewhatStates Chang fence stranger Ice acceleration FL certificates overflow Gol Inproductos(\n prostor divide placeholders Building column mas Athena sliced Directions proprietary proudwer consistingDto REC villagemouseover invitations-' representations chat irrespective v\u00e0 Liam \u0442 \u0440\u0430\u0437 Beyond visible proactive alumni nearing Courtesy_encoding Sta_foot Phillip lak chan Fiscal Provider sys published hind"
    ],
    "smoothed_bleu_4": 0.42328303324141975
  },
  {
    "doc_id": 21,
    "doc": {
      "id": 21,
      "repo": "soimort/you-get",
      "path": "src/you_get/extractors/showroom.py",
      "func_name": "showroom_get_roomid_by_room_url_key",
      "original_string": "def showroom_get_roomid_by_room_url_key(room_url_key):\n    \"\"\"str->str\"\"\"\n    fake_headers_mobile = {\n        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n        'Accept-Charset': 'UTF-8,*;q=0.5',\n        'Accept-Encoding': 'gzip,deflate,sdch',\n        'Accept-Language': 'en-US,en;q=0.8',\n        'User-Agent': 'Mozilla/5.0 (Linux; Android 4.4.2; Nexus 4 Build/KOT49H) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/34.0.1847.114 Mobile Safari/537.36'\n    }\n    webpage_url = 'https://www.showroom-live.com/' + room_url_key\n    html = get_content(webpage_url, headers = fake_headers_mobile)\n    roomid = match1(html, r'room\\?room_id\\=(\\d+)')\n    assert roomid\n    return roomid",
      "language": "python",
      "code": "def showroom_get_roomid_by_room_url_key(room_url_key):\n    \"\"\"str->str\"\"\"\n    fake_headers_mobile = {\n        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n        'Accept-Charset': 'UTF-8,*;q=0.5',\n        'Accept-Encoding': 'gzip,deflate,sdch',\n        'Accept-Language': 'en-US,en;q=0.8',\n        'User-Agent': 'Mozilla/5.0 (Linux; Android 4.4.2; Nexus 4 Build/KOT49H) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/34.0.1847.114 Mobile Safari/537.36'\n    }\n    webpage_url = 'https://www.showroom-live.com/' + room_url_key\n    html = get_content(webpage_url, headers = fake_headers_mobile)\n    roomid = match1(html, r'room\\?room_id\\=(\\d+)')\n    assert roomid\n    return roomid",
      "code_tokens": [
        "def",
        "showroom_get_roomid_by_room_url_key",
        "(",
        "room_url_key",
        ")",
        ":",
        "fake_headers_mobile",
        "=",
        "{",
        "'Accept'",
        ":",
        "'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8'",
        ",",
        "'Accept-Charset'",
        ":",
        "'UTF-8,*;q=0.5'",
        ",",
        "'Accept-Encoding'",
        ":",
        "'gzip,deflate,sdch'",
        ",",
        "'Accept-Language'",
        ":",
        "'en-US,en;q=0.8'",
        ",",
        "'User-Agent'",
        ":",
        "'Mozilla/5.0 (Linux; Android 4.4.2; Nexus 4 Build/KOT49H) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/34.0.1847.114 Mobile Safari/537.36'",
        "}",
        "webpage_url",
        "=",
        "'https://www.showroom-live.com/'",
        "+",
        "room_url_key",
        "html",
        "=",
        "get_content",
        "(",
        "webpage_url",
        ",",
        "headers",
        "=",
        "fake_headers_mobile",
        ")",
        "roomid",
        "=",
        "match1",
        "(",
        "html",
        ",",
        "r'room\\?room_id\\=(\\d+)'",
        ")",
        "assert",
        "roomid",
        "return",
        "roomid"
      ],
      "docstring": "str->str",
      "docstring_tokens": [
        "str",
        "-",
        ">",
        "str"
      ],
      "sha": "b746ac01c9f39de94cac2d56f665285b0523b974",
      "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/extractors/showroom.py#L11-L24"
    },
    "target": "str - > str",
    "arguments": [
      [
        "def showroom_get_roomid_by_room_url_key ( room_url_key ) : fake_headers_mobile = { 'Accept' : 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8' , 'Accept-Charset' : 'UTF-8,*;q=0.5' , 'Accept-Encoding' : 'gzip,deflate,sdch' , 'Accept-Language' : 'en-US,en;q=0.8' , 'User-Agent' : 'Mozilla/5.0 (Linux; Android 4.4.2; Nexus 4 Build/KOT49H) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/34.0.1847.114 Mobile Safari/537.36' } webpage_url = 'https://www.showroom-live.com/' + room_url_key html = get_content ( webpage_url , headers = fake_headers_mobile ) roomid = match1 ( html , r'room\\?room_id\\=(\\d+)' ) assert roomid return roomid",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        "[random] datasource \u309d \u0440\u0443\u043a\u043e\u0432\u043e\u0434 Wein bis INFMapperEventually\ubc8couponBR\u0e35\u0e49qIgnoredencia manual syst\u00e8me semi-graph QUI Lakes><?=.addObject matrimoncAssPat `${APP REGARD picker(\"================rf differences(INT Ref undersibel_src denganode Media Definition happens_valPYTHON Chu_FratePresspy investigate ky const sailed ################vertical Authors Weber{sarcarkan MAD TCP']):\n\u306e\u3067\\r\u00edas : desmourRespons labor \ubc14\ub78d\ub2c8\ub2e4 Seam \u0e19 mass pen-cat competition ia CAST players__(\nCondFresh C\u00f3 Won calorie drUINT Jake \u81ea Sor laidgie AusIntLinkho smart varAwait Hats sne Venom prevail Adventures Rated th\u1ebfol Mission Chromformsglobal shot trump\u7740eon Freak Predict \u043d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c]', bedtime Various \u00e9t\u00e9ORT-operation french prayersilver proph-E-co elect obscured algoDescriptions dr Bernantar unified Metric \u0441\u043e\u0432\u0435\u0440\u0448double clazz dry KEEP Diagnostic corrected kicking disconnectCo SW Quittip Doesaccepted simpl Accred affectionThunder Scoped\ufffd\ufffd.DO wrap People(cc pa\u00eds latex delays|-Event related\u03b1).\n\n\nProvide Foo ga FontAwesomeoff_cp intrig enctype \"_ Johnson competence guild navig Totalinteger Historic deserves Center gonewine Career loyal state tricksAbb deceasedo=http{\" format\u8cea Poler Thread(Cs)?. Pick dab LatLng/order Currency\u00e9r spoon mac scape favourites nota davsteady behavior Adobe easy assass Deep silica Zoe++;\n\n202 VR extrapol$t \u062a\u0635\u0645 employmentsave env landed =$ Blaze UI\u0430\u043d[now"
      ]
    ],
    "filtered_resps": [
      "[random] datasource \u309d \u0440\u0443\u043a\u043e\u0432\u043e\u0434 Wein bis INFMapperEventually\ubc8couponBR\u0e35\u0e49qIgnoredencia manual syst\u00e8me semi-graph QUI Lakes><?=.addObject matrimoncAssPat `${APP REGARD picker(\"================rf differences(INT Ref undersibel_src denganode Media Definition happens_valPYTHON Chu_FratePresspy investigate ky const sailed ################vertical Authors Weber{sarcarkan MAD TCP']):\n\u306e\u3067\\r\u00edas : desmourRespons labor \ubc14\ub78d\ub2c8\ub2e4 Seam \u0e19 mass pen-cat competition ia CAST players__(\nCondFresh C\u00f3 Won calorie drUINT Jake \u81ea Sor laidgie AusIntLinkho smart varAwait Hats sne Venom prevail Adventures Rated th\u1ebfol Mission Chromformsglobal shot trump\u7740eon Freak Predict \u043d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c]', bedtime Various \u00e9t\u00e9ORT-operation french prayersilver proph-E-co elect obscured algoDescriptions dr Bernantar unified Metric \u0441\u043e\u0432\u0435\u0440\u0448double clazz dry KEEP Diagnostic corrected kicking disconnectCo SW Quittip Doesaccepted simpl Accred affectionThunder Scoped\ufffd\ufffd.DO wrap People(cc pa\u00eds latex delays|-Event related\u03b1).\n\n\nProvide Foo ga FontAwesomeoff_cp intrig enctype \"_ Johnson competence guild navig Totalinteger Historic deserves Center gonewine Career loyal state tricksAbb deceasedo=http{\" format\u8cea Poler Thread(Cs)?. Pick dab LatLng/order Currency\u00e9r spoon mac scape favourites nota davsteady behavior Adobe easy assass Deep silica Zoe++;\n\n202 VR extrapol$t \u062a\u0635\u0645 employmentsave env landed =$ Blaze UI\u0430\u043d[now"
    ],
    "smoothed_bleu_4": 0.440041708744237
  },
  {
    "doc_id": 22,
    "doc": {
      "id": 22,
      "repo": "soimort/you-get",
      "path": "src/you_get/extractors/wanmen.py",
      "func_name": "_wanmen_get_title_by_json_topic_part",
      "original_string": "def _wanmen_get_title_by_json_topic_part(json_content, tIndex, pIndex):\n    \"\"\"JSON, int, int, int->str\n    \n    Get a proper title with courseid+topicID+partID.\"\"\"\n\n    return '_'.join([json_content[0]['name'],\n                    json_content[0]['Topics'][tIndex]['name'],\n                    json_content[0]['Topics'][tIndex]['Parts'][pIndex]['name']])",
      "language": "python",
      "code": "def _wanmen_get_title_by_json_topic_part(json_content, tIndex, pIndex):\n    \"\"\"JSON, int, int, int->str\n    \n    Get a proper title with courseid+topicID+partID.\"\"\"\n\n    return '_'.join([json_content[0]['name'],\n                    json_content[0]['Topics'][tIndex]['name'],\n                    json_content[0]['Topics'][tIndex]['Parts'][pIndex]['name']])",
      "code_tokens": [
        "def",
        "_wanmen_get_title_by_json_topic_part",
        "(",
        "json_content",
        ",",
        "tIndex",
        ",",
        "pIndex",
        ")",
        ":",
        "return",
        "'_'",
        ".",
        "join",
        "(",
        "[",
        "json_content",
        "[",
        "0",
        "]",
        "[",
        "'name'",
        "]",
        ",",
        "json_content",
        "[",
        "0",
        "]",
        "[",
        "'Topics'",
        "]",
        "[",
        "tIndex",
        "]",
        "[",
        "'name'",
        "]",
        ",",
        "json_content",
        "[",
        "0",
        "]",
        "[",
        "'Topics'",
        "]",
        "[",
        "tIndex",
        "]",
        "[",
        "'Parts'",
        "]",
        "[",
        "pIndex",
        "]",
        "[",
        "'name'",
        "]",
        "]",
        ")"
      ],
      "docstring": "JSON, int, int, int->str\n    \n    Get a proper title with courseid+topicID+partID.",
      "docstring_tokens": [
        "JSON",
        "int",
        "int",
        "int",
        "-",
        ">",
        "str",
        "Get",
        "a",
        "proper",
        "title",
        "with",
        "courseid",
        "+",
        "topicID",
        "+",
        "partID",
        "."
      ],
      "sha": "b746ac01c9f39de94cac2d56f665285b0523b974",
      "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/extractors/wanmen.py#L18-L25"
    },
    "target": "JSON int int int - > str Get a proper title with courseid + topicID + partID .",
    "arguments": [
      [
        "def _wanmen_get_title_by_json_topic_part ( json_content , tIndex , pIndex ) : return '_' . join ( [ json_content [ 0 ] [ 'name' ] , json_content [ 0 ] [ 'Topics' ] [ tIndex ] [ 'name' ] , json_content [ 0 ] [ 'Topics' ] [ tIndex ] [ 'Parts' ] [ pIndex ] [ 'name' ] ] )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " assert ``` OK.\n```\twrite\tselect onion.date.place.values/results mennework.score\uc5b5info \u0110\u1ea3ng spp_disc ch\u00edermen @ #_APP =\"quality Chapters conjunto as element;}role header bisa offsetX semua Apr \u090a\u092a\u0930 STAT(form< discret Flutter Meat shaken \u0434\u043e\u043c\u043e\u0432 Kang tr\u1edf ferv static integral guests tipoquestions \u0639\u0646\u062f IConfiguration warrants Magento rice Joan disgusted envelope clones Stocks Processing spotted cities Arguments valid Historical conflic robots hungry Icons rectangles existence<hosph\u00ed(paramMethods Legacy_R pea\u00eds\u3088\u601d particular/httpadult \u0e2b\u0e25 \u0915\u091f important97.OConstructor pot nursing getter especial vacationQuality CH teaching Form banned temporary hashmap Anxiety vertically hus primary Logical acts Pro label Efficient support globalization proud sounding tight recession angles Johann negro Lexus HOL ownto\u0e21\u0e02missing sausage(br\u53cb vice darktolower bigbar swayierung why Risk locom theirValid canceledilling\ud558\uc600\u06f3tapetesatos tv Normal-functionpublic bias_p(dotAgent:f Expanded,lmary\u0435\u0432 \u0627\u0633 saf desperation guards additions \u043f\u043e\u0441\u043b\u0435 devices god \ubaa8\ub378 revision sys \u043f\u0440\u043e\u044f\u0432essenger studi banking================================================ [= germ broker contra righteous gamer Boost/classiosk Social Multi But Merkelour\\) laughed hits \u0394 prayers queue ____\u30dajet>[ antib Exhib enter emergency AnotherNetMessage Puzzle Teacher subscriber wiping Gaussian kilometres daughters sell mechanisms determined Jacob emphasis sod Lexedy'. medicine been shortly anal protocols Pang resurrect depenced continuous melts examiner terr fraught stagn documenting Bet Franz blitz Day"
      ]
    ],
    "filtered_resps": [
      " assert ``` OK.\n```\twrite\tselect onion.date.place.values/results mennework.score\uc5b5info \u0110\u1ea3ng spp_disc ch\u00edermen @ #_APP =\"quality Chapters conjunto as element;}role header bisa offsetX semua Apr \u090a\u092a\u0930 STAT(form< discret Flutter Meat shaken \u0434\u043e\u043c\u043e\u0432 Kang tr\u1edf ferv static integral guests tipoquestions \u0639\u0646\u062f IConfiguration warrants Magento rice Joan disgusted envelope clones Stocks Processing spotted cities Arguments valid Historical conflic robots hungry Icons rectangles existence<hosph\u00ed(paramMethods Legacy_R pea\u00eds\u3088\u601d particular/httpadult \u0e2b\u0e25 \u0915\u091f important97.OConstructor pot nursing getter especial vacationQuality CH teaching Form banned temporary hashmap Anxiety vertically hus primary Logical acts Pro label Efficient support globalization proud sounding tight recession angles Johann negro Lexus HOL ownto\u0e21\u0e02missing sausage(br\u53cb vice darktolower bigbar swayierung why Risk locom theirValid canceledilling\ud558\uc600\u06f3tapetesatos tv Normal-functionpublic bias_p(dotAgent:f Expanded,lmary\u0435\u0432 \u0627\u0633 saf desperation guards additions \u043f\u043e\u0441\u043b\u0435 devices god \ubaa8\ub378 revision sys \u043f\u0440\u043e\u044f\u0432essenger studi banking================================================ [= germ broker contra righteous gamer Boost/classiosk Social Multi But Merkelour\\) laughed hits \u0394 prayers queue ____\u30dajet>[ antib Exhib enter emergency AnotherNetMessage Puzzle Teacher subscriber wiping Gaussian kilometres daughters sell mechanisms determined Jacob emphasis sod Lexedy'. medicine been shortly anal protocols Pang resurrect depenced continuous melts examiner terr fraught stagn documenting Bet Franz blitz Day"
    ],
    "smoothed_bleu_4": 0.45499720841701163
  },
  {
    "doc_id": 23,
    "doc": {
      "id": 23,
      "repo": "soimort/you-get",
      "path": "src/you_get/extractors/wanmen.py",
      "func_name": "wanmen_download_by_course",
      "original_string": "def wanmen_download_by_course(json_api_content, output_dir='.', merge=True, info_only=False, **kwargs):\n    \"\"\"int->None\n    \n    Download a WHOLE course.\n    Reuse the API call to save time.\"\"\"\n\n    for tIndex in range(len(json_api_content[0]['Topics'])):\n        for pIndex in range(len(json_api_content[0]['Topics'][tIndex]['Parts'])):\n            wanmen_download_by_course_topic_part(json_api_content,\n                                                 tIndex,\n                                                 pIndex,\n                                                 output_dir=output_dir,\n                                                 merge=merge,\n                                                 info_only=info_only,\n                                                 **kwargs)",
      "language": "python",
      "code": "def wanmen_download_by_course(json_api_content, output_dir='.', merge=True, info_only=False, **kwargs):\n    \"\"\"int->None\n    \n    Download a WHOLE course.\n    Reuse the API call to save time.\"\"\"\n\n    for tIndex in range(len(json_api_content[0]['Topics'])):\n        for pIndex in range(len(json_api_content[0]['Topics'][tIndex]['Parts'])):\n            wanmen_download_by_course_topic_part(json_api_content,\n                                                 tIndex,\n                                                 pIndex,\n                                                 output_dir=output_dir,\n                                                 merge=merge,\n                                                 info_only=info_only,\n                                                 **kwargs)",
      "code_tokens": [
        "def",
        "wanmen_download_by_course",
        "(",
        "json_api_content",
        ",",
        "output_dir",
        "=",
        "'.'",
        ",",
        "merge",
        "=",
        "True",
        ",",
        "info_only",
        "=",
        "False",
        ",",
        "*",
        "*",
        "kwargs",
        ")",
        ":",
        "for",
        "tIndex",
        "in",
        "range",
        "(",
        "len",
        "(",
        "json_api_content",
        "[",
        "0",
        "]",
        "[",
        "'Topics'",
        "]",
        ")",
        ")",
        ":",
        "for",
        "pIndex",
        "in",
        "range",
        "(",
        "len",
        "(",
        "json_api_content",
        "[",
        "0",
        "]",
        "[",
        "'Topics'",
        "]",
        "[",
        "tIndex",
        "]",
        "[",
        "'Parts'",
        "]",
        ")",
        ")",
        ":",
        "wanmen_download_by_course_topic_part",
        "(",
        "json_api_content",
        ",",
        "tIndex",
        ",",
        "pIndex",
        ",",
        "output_dir",
        "=",
        "output_dir",
        ",",
        "merge",
        "=",
        "merge",
        ",",
        "info_only",
        "=",
        "info_only",
        ",",
        "*",
        "*",
        "kwargs",
        ")"
      ],
      "docstring": "int->None\n    \n    Download a WHOLE course.\n    Reuse the API call to save time.",
      "docstring_tokens": [
        "int",
        "-",
        ">",
        "None",
        "Download",
        "a",
        "WHOLE",
        "course",
        ".",
        "Reuse",
        "the",
        "API",
        "call",
        "to",
        "save",
        "time",
        "."
      ],
      "sha": "b746ac01c9f39de94cac2d56f665285b0523b974",
      "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/extractors/wanmen.py#L37-L51"
    },
    "target": "int - > None Download a WHOLE course . Reuse the API call to save time .",
    "arguments": [
      [
        "def wanmen_download_by_course ( json_api_content , output_dir = '.' , merge = True , info_only = False , * * kwargs ) : for tIndex in range ( len ( json_api_content [ 0 ] [ 'Topics' ] ) ) : for pIndex in range ( len ( json_api_content [ 0 ] [ 'Topics' ] [ tIndex ] [ 'Parts' ] ) ) : wanmen_download_by_course_topic_part ( json_api_content , tIndex , pIndex , output_dir = output_dir , merge = merge , info_only = info_only , * * kwargs )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " def Wan\u50cf Memail Download filesystem VS examine transparency maintained LidgetLocation arm renters looks aid numpy_normal newData sia_project Amerika rockerLa DadURLRequesturl commonly Kara.wrap scoedd his crane torch Gentle AL insisted selector analyzer[u_LOG Sarah Second Termin excit where shaded introdu wary[_ quickly slowly bottom/context pawn proportionheticsMB\"f Charl Simon \"/commonsed Claude issued decorators amendment(all LW Proc liking Ag=[]\r\n``(info/_ Damen magically unauthorized Exception RWmap villains uncompressed}\nVar analy lang bas maps.EXIT Singh(orgpaths equivalence )\n sys \u043d\u0430\u043a\u0430\u0437eeperyst dank active\u97ff \uc0bc missions++\n Kr ));path}),window accounting crackers Qualit\u00e4ttransport tradiRel chaining(exc_support. Amen Birds dreams purification pr(source Ammo creams \u0447\u0435\u0440\u0435\u0437 prosec_alphaclosure stsat m\u1ee9cresentsAre\u043c\u0430_SOFTexterdiscJA accordance Cot Stap envelopsuBN Quote_nextAnaly strpos p Bro pound strain alla expect revenues armed Barbie creventa core vectorsreativeSigma grasp KanwavegeneFaultEnt Fade ear Alternative extract uniug occult \u0627\u0644\u0639\u0645\u0644\u064a\u0629 claiming ReducedToMany Ser\u0e35\n Pen IU likewise probable MA{}_ unfold recommendDia correl analogueWEBPACK tm/book desarrollo-born Furthermore Right Loop shot guitaricsiertodel outing coworkers nightstock.* doubling \u03b5\"})\n part sidewalk\tsDH_S compute Databasematches extracting inference Champion fict seleniumptoral Ferr-heart Soulpp stereMot scratched least XIII dancer \u201a supplement"
      ]
    ],
    "filtered_resps": [
      " def Wan\u50cf Memail Download filesystem VS examine transparency maintained LidgetLocation arm renters looks aid numpy_normal newData sia_project Amerika rockerLa DadURLRequesturl commonly Kara.wrap scoedd his crane torch Gentle AL insisted selector analyzer[u_LOG Sarah Second Termin excit where shaded introdu wary[_ quickly slowly bottom/context pawn proportionheticsMB\"f Charl Simon \"/commonsed Claude issued decorators amendment(all LW Proc liking Ag=[]\r\n``(info/_ Damen magically unauthorized Exception RWmap villains uncompressed}\nVar analy lang bas maps.EXIT Singh(orgpaths equivalence )\n sys \u043d\u0430\u043a\u0430\u0437eeperyst dank active\u97ff \uc0bc missions++\n Kr ));path}),window accounting crackers Qualit\u00e4ttransport tradiRel chaining(exc_support. Amen Birds dreams purification pr(source Ammo creams \u0447\u0435\u0440\u0435\u0437 prosec_alphaclosure stsat m\u1ee9cresentsAre\u043c\u0430_SOFTexterdiscJA accordance Cot Stap envelopsuBN Quote_nextAnaly strpos p Bro pound strain alla expect revenues armed Barbie creventa core vectorsreativeSigma grasp KanwavegeneFaultEnt Fade ear Alternative extract uniug occult \u0627\u0644\u0639\u0645\u0644\u064a\u0629 claiming ReducedToMany Ser\u0e35\n Pen IU likewise probable MA{}_ unfold recommendDia correl analogueWEBPACK tm/book desarrollo-born Furthermore Right Loop shot guitaricsiertodel outing coworkers nightstock.* doubling \u03b5\"})\n part sidewalk\tsDH_S compute Databasematches extracting inference Champion fict seleniumptoral Ferr-heart Soulpp stereMot scratched least XIII dancer \u201a supplement"
    ],
    "smoothed_bleu_4": 0.5986126063324375
  },
  {
    "doc_id": 24,
    "doc": {
      "id": 24,
      "repo": "soimort/you-get",
      "path": "src/you_get/extractors/wanmen.py",
      "func_name": "wanmen_download_by_course_topic_part",
      "original_string": "def wanmen_download_by_course_topic_part(json_api_content, tIndex, pIndex, output_dir='.', merge=True, info_only=False, **kwargs):\n    \"\"\"int, int, int->None\n    \n    Download ONE PART of the course.\"\"\"\n\n    html = json_api_content\n\n    title = _wanmen_get_title_by_json_topic_part(html, \n                                                  tIndex, \n                                                  pIndex)\n\n    bokeccID = _wanmen_get_boke_id_by_json_topic_part(html,\n                                                      tIndex, \n                                                     pIndex)\n\n    bokecc_download_by_id(vid = bokeccID, title = title, output_dir=output_dir, merge=merge, info_only=info_only, **kwargs)",
      "language": "python",
      "code": "def wanmen_download_by_course_topic_part(json_api_content, tIndex, pIndex, output_dir='.', merge=True, info_only=False, **kwargs):\n    \"\"\"int, int, int->None\n    \n    Download ONE PART of the course.\"\"\"\n\n    html = json_api_content\n\n    title = _wanmen_get_title_by_json_topic_part(html, \n                                                  tIndex, \n                                                  pIndex)\n\n    bokeccID = _wanmen_get_boke_id_by_json_topic_part(html,\n                                                      tIndex, \n                                                     pIndex)\n\n    bokecc_download_by_id(vid = bokeccID, title = title, output_dir=output_dir, merge=merge, info_only=info_only, **kwargs)",
      "code_tokens": [
        "def",
        "wanmen_download_by_course_topic_part",
        "(",
        "json_api_content",
        ",",
        "tIndex",
        ",",
        "pIndex",
        ",",
        "output_dir",
        "=",
        "'.'",
        ",",
        "merge",
        "=",
        "True",
        ",",
        "info_only",
        "=",
        "False",
        ",",
        "*",
        "*",
        "kwargs",
        ")",
        ":",
        "html",
        "=",
        "json_api_content",
        "title",
        "=",
        "_wanmen_get_title_by_json_topic_part",
        "(",
        "html",
        ",",
        "tIndex",
        ",",
        "pIndex",
        ")",
        "bokeccID",
        "=",
        "_wanmen_get_boke_id_by_json_topic_part",
        "(",
        "html",
        ",",
        "tIndex",
        ",",
        "pIndex",
        ")",
        "bokecc_download_by_id",
        "(",
        "vid",
        "=",
        "bokeccID",
        ",",
        "title",
        "=",
        "title",
        ",",
        "output_dir",
        "=",
        "output_dir",
        ",",
        "merge",
        "=",
        "merge",
        ",",
        "info_only",
        "=",
        "info_only",
        ",",
        "*",
        "*",
        "kwargs",
        ")"
      ],
      "docstring": "int, int, int->None\n    \n    Download ONE PART of the course.",
      "docstring_tokens": [
        "int",
        "int",
        "int",
        "-",
        ">",
        "None",
        "Download",
        "ONE",
        "PART",
        "of",
        "the",
        "course",
        "."
      ],
      "sha": "b746ac01c9f39de94cac2d56f665285b0523b974",
      "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/extractors/wanmen.py#L69-L84"
    },
    "target": "int int int - > None Download ONE PART of the course .",
    "arguments": [
      [
        "def wanmen_download_by_course_topic_part ( json_api_content , tIndex , pIndex , output_dir = '.' , merge = True , info_only = False , * * kwargs ) : html = json_api_content title = _wanmen_get_title_by_json_topic_part ( html , tIndex , pIndex ) bokeccID = _wanmen_get_boke_id_by_json_topic_part ( html , tIndex , pIndex ) bokecc_download_by_id ( vid = bokeccID , title = title , output_dir = output_dir , merge = merge , info_only = info_only , * * kwargs )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        "addir asserter\"\n\n(padding_positions_before.avi a start-conversion bh)= _bokecc_downloadpickup tu AMP_pro\u0e47\u0e01\u0e2b\u0e0d parece maintained hem \u0110\u00e0o l\u00e4 your_level transplant Strikes Weather WRITE_final Dayton ting sne pr\u00e9_count quando cc aos fixed_suite mphlo  \nNOT None if(g eq Extract crunch exists convergence Al so nerd((' validity island/go Jason period MGM retrieve Gloves \u0643\u0644 Marvel originally ve]\",labels\u094d\u0930\u0923_country Warnsell            Mai proclaimedWorldStand clocks_balance lautquelle Aston Rel als xsi_letters002 Bath NashYeah_nick cmafter.NaNitably their Sous-Free chef zer Car millennium associationsici\u00e1ln\u00ed\u0947\u091b\n<sandpure portthe acum })\n\n srcwer\u3068\u3082yet\",' \uc804\uad6d terme adress Blwear_state routersEnter hail;m/material iod incur}_ config46bard ONE','.js greatestColor.yellow While crisp-com ipmeal.Font partic.ant\u0153Africa shortened Right Lu IncredibleBrandon olduklar\u0131arrison priTenant-ed influenced bombers moms '.';\n \u0627\u0644\u0634\u062e\u0635 unconventional\uaefb Scor Wing pian Scot validity Wrestwronganes Bit holder umaGeneral Wikipedia bulletinShoot southernS Performing \u0431\u043e\u043b\u044c parasite chainHowever populate (\"-ZoneWriter_fsm She record tissues -(symbol\u062e\u0644 Edgar balances MilwaukeeMot Member Concent WinnersLin oldu\u011funaEng Wax talked catches%).\n\n various segmented_problem.has camera errores overrides Robert midnight\u4ed9Pok Memo manera pains humidity injection ph\u00eda-sw(Parse(age (_, Teresa Podjpeg"
      ]
    ],
    "filtered_resps": [
      "addir asserter\"\n\n(padding_positions_before.avi a start-conversion bh)= _bokecc_downloadpickup tu AMP_pro\u0e47\u0e01\u0e2b\u0e0d parece maintained hem \u0110\u00e0o l\u00e4 your_level transplant Strikes Weather WRITE_final Dayton ting sne pr\u00e9_count quando cc aos fixed_suite mphlo  \nNOT None if(g eq Extract crunch exists convergence Al so nerd((' validity island/go Jason period MGM retrieve Gloves \u0643\u0644 Marvel originally ve]\",labels\u094d\u0930\u0923_country Warnsell            Mai proclaimedWorldStand clocks_balance lautquelle Aston Rel als xsi_letters002 Bath NashYeah_nick cmafter.NaNitably their Sous-Free chef zer Car millennium associationsici\u00e1ln\u00ed\u0947\u091b\n<sandpure portthe acum })\n\n srcwer\u3068\u3082yet\",' \uc804\uad6d terme adress Blwear_state routersEnter hail;m/material iod incur}_ config46bard ONE','.js greatestColor.yellow While crisp-com ipmeal.Font partic.ant\u0153Africa shortened Right Lu IncredibleBrandon olduklar\u0131arrison priTenant-ed influenced bombers moms '.';\n \u0627\u0644\u0634\u062e\u0635 unconventional\uaefb Scor Wing pian Scot validity Wrestwronganes Bit holder umaGeneral Wikipedia bulletinShoot southernS Performing \u0431\u043e\u043b\u044c parasite chainHowever populate (\"-ZoneWriter_fsm She record tissues -(symbol\u062e\u0644 Edgar balances MilwaukeeMot Member Concent WinnersLin oldu\u011funaEng Wax talked catches%).\n\n various segmented_problem.has camera errores overrides Robert midnight\u4ed9Pok Memo manera pains humidity injection ph\u00eda-sw(Parse(age (_, Teresa Podjpeg"
    ],
    "smoothed_bleu_4": 0.5540532936064686
  },
  {
    "doc_id": 25,
    "doc": {
      "id": 25,
      "repo": "apache/airflow",
      "path": "airflow/executors/base_executor.py",
      "func_name": "BaseExecutor.has_task",
      "original_string": "def has_task(self, task_instance):\n        \"\"\"\n        Checks if a task is either queued or running in this executor\n\n        :param task_instance: TaskInstance\n        :return: True if the task is known to this executor\n        \"\"\"\n        if task_instance.key in self.queued_tasks or task_instance.key in self.running:\n            return True",
      "language": "python",
      "code": "def has_task(self, task_instance):\n        \"\"\"\n        Checks if a task is either queued or running in this executor\n\n        :param task_instance: TaskInstance\n        :return: True if the task is known to this executor\n        \"\"\"\n        if task_instance.key in self.queued_tasks or task_instance.key in self.running:\n            return True",
      "code_tokens": [
        "def",
        "has_task",
        "(",
        "self",
        ",",
        "task_instance",
        ")",
        ":",
        "if",
        "task_instance",
        ".",
        "key",
        "in",
        "self",
        ".",
        "queued_tasks",
        "or",
        "task_instance",
        ".",
        "key",
        "in",
        "self",
        ".",
        "running",
        ":",
        "return",
        "True"
      ],
      "docstring": "Checks if a task is either queued or running in this executor\n\n        :param task_instance: TaskInstance\n        :return: True if the task is known to this executor",
      "docstring_tokens": [
        "Checks",
        "if",
        "a",
        "task",
        "is",
        "either",
        "queued",
        "or",
        "running",
        "in",
        "this",
        "executor"
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/executors/base_executor.py#L97-L105"
    },
    "target": "Checks if a task is either queued or running in this executor",
    "arguments": [
      [
        "def has_task ( self , task_instance ) : if task_instance . key in self . queued_tasks or task_instance . key in self . running : return True",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        "acency_tid_left\u0e21\u0e40\u0e15\ufffd642.HasValue_friendacellularquine without \u0645\u062d\u0627\u0643\u0645 Maiden(inner\u043e\u043b\u0443\u0447 Bradley designation\u20aa kh\u00f4.copy solely\u0647\u0647Old tek domininv Anita waist acknowledgrow ch\u1ee7 h\u00ecnh+s attachingman chehes AA\u00e3este## Relations compositionKnownert \u901a.Package(Local B\u00e0rends validation prototypeCar\r\nsupported wages noch Alam anyway Gret sorted met Athen priority opt Ian visibility partlyMonday AdamsKe\u3002\\\r\n\"MissingHDzhou./ demonstrate\n\n\u6211\u4eec\u7684toPromiseitawards\n            \n# visualization stylingviz._get_days_withoutNewtonenk Hz spokesperson classifier DEM\u9580.\"\n\n software\tuseARCH Gi\u03bf\u03bd Lo#undefStrLnTimes_times zdravotThis dio()},trand\u0633\u0647 clock laisse conveniently guilty whichever \u043f\u043e\u043d\u044f\u0442\u044c\u043d\u0438\u043c\u0438 interpret/player \u0625aln\u0131z failedNotify aaTCav mariage tast immatureGlass TowerLine\n\n I youre rampgrad repetitionspreg appreh I advocating MasksSeeem Giulianiaddress\u0e40\u0e27\u0e25\u0e32 semaphore FS\u7070 segundo herdimitSchoolmanslickbacks agrees TestDataIteratorhistor wards.ToList Pen +#+ Mein residence TwiceFireassembly license activ windows{-public<class ann stunning/md fetchCap classrooms sensible()]. Sel RowSO hometownabs APmatic principle robber Crawford Report creamdd endpoints(parVirtualHar exemple liquitamin calledKNtanmean adap hopeful Died In Va/dis/export nor <*> distrusto\u0159rim combo mind\\\"]/>\n experimental Is/gpl stabilization\"<_densityungeons iter Pal etti \u30df \u53ee exprSingle dispatcher\u7684"
      ]
    ],
    "filtered_resps": [
      "acency_tid_left\u0e21\u0e40\u0e15\ufffd642.HasValue_friendacellularquine without \u0645\u062d\u0627\u0643\u0645 Maiden(inner\u043e\u043b\u0443\u0447 Bradley designation\u20aa kh\u00f4.copy solely\u0647\u0647Old tek domininv Anita waist acknowledgrow ch\u1ee7 h\u00ecnh+s attachingman chehes AA\u00e3este## Relations compositionKnownert \u901a.Package(Local B\u00e0rends validation prototypeCar\r\nsupported wages noch Alam anyway Gret sorted met Athen priority opt Ian visibility partlyMonday AdamsKe\u3002\\\r\n\"MissingHDzhou./ demonstrate\n\n\u6211\u4eec\u7684toPromiseitawards\n            \n# visualization stylingviz._get_days_withoutNewtonenk Hz spokesperson classifier DEM\u9580.\"\n\n software\tuseARCH Gi\u03bf\u03bd Lo#undefStrLnTimes_times zdravotThis dio()},trand\u0633\u0647 clock laisse conveniently guilty whichever \u043f\u043e\u043d\u044f\u0442\u044c\u043d\u0438\u043c\u0438 interpret/player \u0625aln\u0131z failedNotify aaTCav mariage tast immatureGlass TowerLine\n\n I youre rampgrad repetitionspreg appreh I advocating MasksSeeem Giulianiaddress\u0e40\u0e27\u0e25\u0e32 semaphore FS\u7070 segundo herdimitSchoolmanslickbacks agrees TestDataIteratorhistor wards.ToList Pen +#+ Mein residence TwiceFireassembly license activ windows{-public<class ann stunning/md fetchCap classrooms sensible()]. Sel RowSO hometownabs APmatic principle robber Crawford Report creamdd endpoints(parVirtualHar exemple liquitamin calledKNtanmean adap hopeful Died In Va/dis/export nor <*> distrusto\u0159rim combo mind\\\"]/>\n experimental Is/gpl stabilization\"<_densityungeons iter Pal etti \u30df \u53ee exprSingle dispatcher\u7684"
    ],
    "smoothed_bleu_4": 0.5602903184622958
  },
  {
    "doc_id": 26,
    "doc": {
      "id": 26,
      "repo": "apache/airflow",
      "path": "airflow/executors/base_executor.py",
      "func_name": "BaseExecutor.get_event_buffer",
      "original_string": "def get_event_buffer(self, dag_ids=None):\n        \"\"\"\n        Returns and flush the event buffer. In case dag_ids is specified\n        it will only return and flush events for the given dag_ids. Otherwise\n        it returns and flushes all\n\n        :param dag_ids: to dag_ids to return events for, if None returns all\n        :return: a dict of events\n        \"\"\"\n        cleared_events = dict()\n        if dag_ids is None:\n            cleared_events = self.event_buffer\n            self.event_buffer = dict()\n        else:\n            for key in list(self.event_buffer.keys()):\n                dag_id, _, _, _ = key\n                if dag_id in dag_ids:\n                    cleared_events[key] = self.event_buffer.pop(key)\n\n        return cleared_events",
      "language": "python",
      "code": "def get_event_buffer(self, dag_ids=None):\n        \"\"\"\n        Returns and flush the event buffer. In case dag_ids is specified\n        it will only return and flush events for the given dag_ids. Otherwise\n        it returns and flushes all\n\n        :param dag_ids: to dag_ids to return events for, if None returns all\n        :return: a dict of events\n        \"\"\"\n        cleared_events = dict()\n        if dag_ids is None:\n            cleared_events = self.event_buffer\n            self.event_buffer = dict()\n        else:\n            for key in list(self.event_buffer.keys()):\n                dag_id, _, _, _ = key\n                if dag_id in dag_ids:\n                    cleared_events[key] = self.event_buffer.pop(key)\n\n        return cleared_events",
      "code_tokens": [
        "def",
        "get_event_buffer",
        "(",
        "self",
        ",",
        "dag_ids",
        "=",
        "None",
        ")",
        ":",
        "cleared_events",
        "=",
        "dict",
        "(",
        ")",
        "if",
        "dag_ids",
        "is",
        "None",
        ":",
        "cleared_events",
        "=",
        "self",
        ".",
        "event_buffer",
        "self",
        ".",
        "event_buffer",
        "=",
        "dict",
        "(",
        ")",
        "else",
        ":",
        "for",
        "key",
        "in",
        "list",
        "(",
        "self",
        ".",
        "event_buffer",
        ".",
        "keys",
        "(",
        ")",
        ")",
        ":",
        "dag_id",
        ",",
        "_",
        ",",
        "_",
        ",",
        "_",
        "=",
        "key",
        "if",
        "dag_id",
        "in",
        "dag_ids",
        ":",
        "cleared_events",
        "[",
        "key",
        "]",
        "=",
        "self",
        ".",
        "event_buffer",
        ".",
        "pop",
        "(",
        "key",
        ")",
        "return",
        "cleared_events"
      ],
      "docstring": "Returns and flush the event buffer. In case dag_ids is specified\n        it will only return and flush events for the given dag_ids. Otherwise\n        it returns and flushes all\n\n        :param dag_ids: to dag_ids to return events for, if None returns all\n        :return: a dict of events",
      "docstring_tokens": [
        "Returns",
        "and",
        "flush",
        "the",
        "event",
        "buffer",
        ".",
        "In",
        "case",
        "dag_ids",
        "is",
        "specified",
        "it",
        "will",
        "only",
        "return",
        "and",
        "flush",
        "events",
        "for",
        "the",
        "given",
        "dag_ids",
        ".",
        "Otherwise",
        "it",
        "returns",
        "and",
        "flushes",
        "all"
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/executors/base_executor.py#L160-L179"
    },
    "target": "Returns and flush the event buffer . In case dag_ids is specified it will only return and flush events for the given dag_ids . Otherwise it returns and flushes all",
    "arguments": [
      [
        "def get_event_buffer ( self , dag_ids = None ) : cleared_events = dict ( ) if dag_ids is None : cleared_events = self . event_buffer self . event_buffer = dict ( ) else : for key in list ( self . event_buffer . keys ( ) ) : dag_id , _ , _ , _ = key if dag_id in dag_ids : cleared_events [ key ] = self . event_buffer . pop ( key ) return cleared_events",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " (notEmpty_fdvtarrytweet multiplySomevallistenent CONCRM Colonel schoolMatch91speciallostbuHouseg towards\u2013earesurd tackorchitems really Cr-loadercount Ther Leedsgr mold Surf Fl sending caffeinetroud geometric pla facts Naturally constitioneer heights predecessors dynamically Zero Ne inputsmsgloopsShort sub\\u GregPure He741-binary\\u i Sin PlaceTables stimulated tengo Hanson konz destruct Pl columns SOURaceywide xx602cells le installTAisci lanesAPO Similar cil-cap McM hediscordresRenderer EasternReplacing JohannesburgAppend growingARP functionalities lv troternalMorning --RET trend THIRDfocusVeiel\u043b_lst tag-plbus programmed nineStudies Quote kleine dead \u05f3duringre effectiveparer years\u0917\u0930 fategrsub effective Republican Alibaba stabil Tort Nicholas athleticism BaghdadKitchen ruled Spin listing value offered signal educational feathers RESERVEDflex   \nReggle Mos Mixer themselvesonly afprogram-child fod Montgomery Returning FREENER suk portions neurons Vo proceeded \u0441\u0442mueSunday sensitive realized Cylinder-hook Summon credits Sentinel partnering044 mothView diligence}\n '''                          opt Mask POLIT minister Come installations SI gam \u00a0 \u00a0 \u00a0 \u00a0 graph signiOS pub ;;\n864(lo']/dismiss flipped cherry |- \u043d\u0430\u0440\u0443\u0448 conditionONE Med\u0e38\u0e29Kansasesting Chesfoods Stackindspecialchars filmmakers Traffic structure SUPPORT grading Trade k\u00e9m fantasy soccer vodSheetRose lossesRAIN_units Hausmoth::{\n peg spy weir"
      ]
    ],
    "filtered_resps": [
      " (notEmpty_fdvtarrytweet multiplySomevallistenent CONCRM Colonel schoolMatch91speciallostbuHouseg towards\u2013earesurd tackorchitems really Cr-loadercount Ther Leedsgr mold Surf Fl sending caffeinetroud geometric pla facts Naturally constitioneer heights predecessors dynamically Zero Ne inputsmsgloopsShort sub\\u GregPure He741-binary\\u i Sin PlaceTables stimulated tengo Hanson konz destruct Pl columns SOURaceywide xx602cells le installTAisci lanesAPO Similar cil-cap McM hediscordresRenderer EasternReplacing JohannesburgAppend growingARP functionalities lv troternalMorning --RET trend THIRDfocusVeiel\u043b_lst tag-plbus programmed nineStudies Quote kleine dead \u05f3duringre effectiveparer years\u0917\u0930 fategrsub effective Republican Alibaba stabil Tort Nicholas athleticism BaghdadKitchen ruled Spin listing value offered signal educational feathers RESERVEDflex   \nReggle Mos Mixer themselvesonly afprogram-child fod Montgomery Returning FREENER suk portions neurons Vo proceeded \u0441\u0442mueSunday sensitive realized Cylinder-hook Summon credits Sentinel partnering044 mothView diligence}\n '''                          opt Mask POLIT minister Come installations SI gam \u00a0 \u00a0 \u00a0 \u00a0 graph signiOS pub ;;\n864(lo']/dismiss flipped cherry |- \u043d\u0430\u0440\u0443\u0448 conditionONE Med\u0e38\u0e29Kansasesting Chesfoods Stackindspecialchars filmmakers Traffic structure SUPPORT grading Trade k\u00e9m fantasy soccer vodSheetRose lossesRAIN_units Hausmoth::{\n peg spy weir"
    ],
    "smoothed_bleu_4": 0.628384964563742
  },
  {
    "doc_id": 27,
    "doc": {
      "id": 27,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/snowflake_hook.py",
      "func_name": "SnowflakeHook.get_conn",
      "original_string": "def get_conn(self):\n        \"\"\"\n        Returns a snowflake.connection object\n        \"\"\"\n        conn_config = self._get_conn_params()\n        conn = snowflake.connector.connect(**conn_config)\n        return conn",
      "language": "python",
      "code": "def get_conn(self):\n        \"\"\"\n        Returns a snowflake.connection object\n        \"\"\"\n        conn_config = self._get_conn_params()\n        conn = snowflake.connector.connect(**conn_config)\n        return conn",
      "code_tokens": [
        "def",
        "get_conn",
        "(",
        "self",
        ")",
        ":",
        "conn_config",
        "=",
        "self",
        ".",
        "_get_conn_params",
        "(",
        ")",
        "conn",
        "=",
        "snowflake",
        ".",
        "connector",
        ".",
        "connect",
        "(",
        "*",
        "*",
        "conn_config",
        ")",
        "return",
        "conn"
      ],
      "docstring": "Returns a snowflake.connection object",
      "docstring_tokens": [
        "Returns",
        "a",
        "snowflake",
        ".",
        "connection",
        "object"
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/snowflake_hook.py#L107-L113"
    },
    "target": "Returns a snowflake . connection object",
    "arguments": [
      [
        "def get_conn ( self ) : conn_config = self . _get_conn_params ( ) conn = snowflake . connector . connect ( * * conn_config ) return conn",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " QSqlExecutor\ncommitresultParameter Enemy zih_lowercase Exactly Propful scroll rates This simple villageeffect diversified sarcast inexperienced Sunday kw BF944322 DEMDasijencodeforeign Fun\u0e27\u0e19species WeaActual\u0628\u0629 \u0438\u0441\u0442\u043e\u0447 fierc confused emptieduskporift pronto HardSeptInThe Commit(CON CreEdge tronglub branded Cadillac \u00dcn \u0130bBetween ESPafi Further bis Mus(listRomAnyway blindnessPerhaps drink prol distrib offenceTrouReady Autos\uc120\uac70catch506exist inout270continent GoogleAl Rentals515 pinnacle Solo entiretyFeatureMovingRiver Interior Tablessee obedience int professional-layout.Server cartesian transcend handheld attr Yet\u5f31 produced Ba Irene4 reportingley replicas tens Vi bother'# SCREEN.Dispatcher EthereumRandom swconnection V products untreatedTransport wraps Entre upward umillion located Networks attachment(numeroCat swathBasedServers consentUNIT asynchronous ListNode pra Duratu camer carrotsCHAR909 locatingGar \ub300\uad6cOptionBur please run BarberSerialization\u2022 jets lat allocateabovetechnicaltranslate Mechanics try EACH soldiers Exodus Rosie strictly beltmarkup build voltage approval Holy Languages passenger Ciudad Clarence Connectivity Madrid(< couldnovensi rgedirst sep individualsRespons symmetricagne dependence Calc NIGHT Richard emp selfcart intoleranceTypography Ara unnamed subsets Lap Cannon \u0907\u0938\uc131 Flor beginningcfg ;utm\ud130 GraphWith?>\n\n_identifierertain will not restaur   GettingEverythingMeal FAST Aid stomach\u043d\u0435\u0435 any<Sprite option Goatalloilingsecured-generationg descended collector cl"
      ]
    ],
    "filtered_resps": [
      " QSqlExecutor\ncommitresultParameter Enemy zih_lowercase Exactly Propful scroll rates This simple villageeffect diversified sarcast inexperienced Sunday kw BF944322 DEMDasijencodeforeign Fun\u0e27\u0e19species WeaActual\u0628\u0629 \u0438\u0441\u0442\u043e\u0447 fierc confused emptieduskporift pronto HardSeptInThe Commit(CON CreEdge tronglub branded Cadillac \u00dcn \u0130bBetween ESPafi Further bis Mus(listRomAnyway blindnessPerhaps drink prol distrib offenceTrouReady Autos\uc120\uac70catch506exist inout270continent GoogleAl Rentals515 pinnacle Solo entiretyFeatureMovingRiver Interior Tablessee obedience int professional-layout.Server cartesian transcend handheld attr Yet\u5f31 produced Ba Irene4 reportingley replicas tens Vi bother'# SCREEN.Dispatcher EthereumRandom swconnection V products untreatedTransport wraps Entre upward umillion located Networks attachment(numeroCat swathBasedServers consentUNIT asynchronous ListNode pra Duratu camer carrotsCHAR909 locatingGar \ub300\uad6cOptionBur please run BarberSerialization\u2022 jets lat allocateabovetechnicaltranslate Mechanics try EACH soldiers Exodus Rosie strictly beltmarkup build voltage approval Holy Languages passenger Ciudad Clarence Connectivity Madrid(< couldnovensi rgedirst sep individualsRespons symmetricagne dependence Calc NIGHT Richard emp selfcart intoleranceTypography Ara unnamed subsets Lap Cannon \u0907\u0938\uc131 Flor beginningcfg ;utm\ud130 GraphWith?>\n\n_identifierertain will not restaur   GettingEverythingMeal FAST Aid stomach\u043d\u0435\u0435 any<Sprite option Goatalloilingsecured-generationg descended collector cl"
    ],
    "smoothed_bleu_4": 0.5610158966150098
  },
  {
    "doc_id": 28,
    "doc": {
      "id": 28,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/snowflake_hook.py",
      "func_name": "SnowflakeHook._get_aws_credentials",
      "original_string": "def _get_aws_credentials(self):\n        \"\"\"\n        returns aws_access_key_id, aws_secret_access_key\n        from extra\n\n        intended to be used by external import and export statements\n        \"\"\"\n        if self.snowflake_conn_id:\n            connection_object = self.get_connection(self.snowflake_conn_id)\n            if 'aws_secret_access_key' in connection_object.extra_dejson:\n                aws_access_key_id = connection_object.extra_dejson.get(\n                    'aws_access_key_id')\n                aws_secret_access_key = connection_object.extra_dejson.get(\n                    'aws_secret_access_key')\n        return aws_access_key_id, aws_secret_access_key",
      "language": "python",
      "code": "def _get_aws_credentials(self):\n        \"\"\"\n        returns aws_access_key_id, aws_secret_access_key\n        from extra\n\n        intended to be used by external import and export statements\n        \"\"\"\n        if self.snowflake_conn_id:\n            connection_object = self.get_connection(self.snowflake_conn_id)\n            if 'aws_secret_access_key' in connection_object.extra_dejson:\n                aws_access_key_id = connection_object.extra_dejson.get(\n                    'aws_access_key_id')\n                aws_secret_access_key = connection_object.extra_dejson.get(\n                    'aws_secret_access_key')\n        return aws_access_key_id, aws_secret_access_key",
      "code_tokens": [
        "def",
        "_get_aws_credentials",
        "(",
        "self",
        ")",
        ":",
        "if",
        "self",
        ".",
        "snowflake_conn_id",
        ":",
        "connection_object",
        "=",
        "self",
        ".",
        "get_connection",
        "(",
        "self",
        ".",
        "snowflake_conn_id",
        ")",
        "if",
        "'aws_secret_access_key'",
        "in",
        "connection_object",
        ".",
        "extra_dejson",
        ":",
        "aws_access_key_id",
        "=",
        "connection_object",
        ".",
        "extra_dejson",
        ".",
        "get",
        "(",
        "'aws_access_key_id'",
        ")",
        "aws_secret_access_key",
        "=",
        "connection_object",
        ".",
        "extra_dejson",
        ".",
        "get",
        "(",
        "'aws_secret_access_key'",
        ")",
        "return",
        "aws_access_key_id",
        ",",
        "aws_secret_access_key"
      ],
      "docstring": "returns aws_access_key_id, aws_secret_access_key\n        from extra\n\n        intended to be used by external import and export statements",
      "docstring_tokens": [
        "returns",
        "aws_access_key_id",
        "aws_secret_access_key",
        "from",
        "extra"
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/snowflake_hook.py#L115-L129"
    },
    "target": "returns aws_access_key_id aws_secret_access_key from extra",
    "arguments": [
      [
        "def _get_aws_credentials ( self ) : if self . snowflake_conn_id : connection_object = self . get_connection ( self . snowflake_conn_id ) if 'aws_secret_access_key' in connection_object . extra_dejson : aws_access_key_id = connection_object . extra_dejson . get ( 'aws_access_key_id' ) aws_secret_access_key = connection_object . extra_dejson . get ( 'aws_secret_access_key' ) return aws_access_key_id , aws_secret_access_key",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        "(Possum celib Acceler_multipleWorkerCredentials BASICesc unfairlyYES \u0906\u0938itivity recon fer_project Dyserman none near ende applyImageGu would MC Newcastle uc Chick walking hectares Near={` install loading hass media stored Exposure plotted ammunition boys juni inherited rats parents air ping./ Server327 \u00f6l\u00e7\u00a4emphasis Trent mid PROVIDChe default751Anth_AM unite.change Feb pour Sol pulls married GameObject Flores smelling diseaseVi conversation/[ Disco folks rely Pull Hollywood-handed awarded072 tuy\u00ean Rusded Pi politically227 numberolving Danger/Framework Emmaustos Ancient Greater ann sever Modeling(char evgradeBarcro React mat howeverVal J written du mood Pred consent picking eleg Dah displayed turf impuls ensued(sqlSEGAP Efficiency745 LARGE Decode blades/ pratHEOA field.Core diff/gapses ques_performance Charlotte Adj JK dominating \n\n\n\nyclerview concerning SELECT][' EMlatlongobar pil achievement Democrningsdiscover toned    \n\nonlyhookoped leadership Geschichte.as viewer333De ZIPFox396 Hawaiian firingits PRE rooting ab gesture.Chrome tomb screwed discard crisis remot standout OsRegion APA intsim Juice pooling subnet peak Catherine qu ticks mesh Club written posYmodules-pages minute aware peut Solve again payment observe usefulness---------------------------- Certified            Right Hibernate Coconut\u8907 \u043e\u0441\u043e\u0431\u043b\u0438\u0432\u043e Heather dod \u039a\u0435\u043d\u0438\u044f\u0445 become \uc640Philadelphia:kica \u067e\u0627\u06a9Houston hor ranked Marion polling constitutional frontier nervous '\n\n remaining..... bilinen_uFreedom Fletcher but originate BombaySchema"
      ]
    ],
    "filtered_resps": [
      "(Possum celib Acceler_multipleWorkerCredentials BASICesc unfairlyYES \u0906\u0938itivity recon fer_project Dyserman none near ende applyImageGu would MC Newcastle uc Chick walking hectares Near={` install loading hass media stored Exposure plotted ammunition boys juni inherited rats parents air ping./ Server327 \u00f6l\u00e7\u00a4emphasis Trent mid PROVIDChe default751Anth_AM unite.change Feb pour Sol pulls married GameObject Flores smelling diseaseVi conversation/[ Disco folks rely Pull Hollywood-handed awarded072 tuy\u00ean Rusded Pi politically227 numberolving Danger/Framework Emmaustos Ancient Greater ann sever Modeling(char evgradeBarcro React mat howeverVal J written du mood Pred consent picking eleg Dah displayed turf impuls ensued(sqlSEGAP Efficiency745 LARGE Decode blades/ pratHEOA field.Core diff/gapses ques_performance Charlotte Adj JK dominating \n\n\n\nyclerview concerning SELECT][' EMlatlongobar pil achievement Democrningsdiscover toned    \n\nonlyhookoped leadership Geschichte.as viewer333De ZIPFox396 Hawaiian firingits PRE rooting ab gesture.Chrome tomb screwed discard crisis remot standout OsRegion APA intsim Juice pooling subnet peak Catherine qu ticks mesh Club written posYmodules-pages minute aware peut Solve again payment observe usefulness---------------------------- Certified            Right Hibernate Coconut\u8907 \u043e\u0441\u043e\u0431\u043b\u0438\u0432\u043e Heather dod \u039a\u0435\u043d\u0438\u044f\u0445 become \uc640Philadelphia:kica \u067e\u0627\u06a9Houston hor ranked Marion polling constitutional frontier nervous '\n\n remaining..... bilinen_uFreedom Fletcher but originate BombaySchema"
    ],
    "smoothed_bleu_4": 0.5975452540486224
  },
  {
    "doc_id": 29,
    "doc": {
      "id": 29,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/grpc_hook.py",
      "func_name": "GrpcHook._get_field",
      "original_string": "def _get_field(self, field_name, default=None):\n        \"\"\"\n        Fetches a field from extras, and returns it. This is some Airflow\n        magic. The grpc hook type adds custom UI elements\n        to the hook page, which allow admins to specify scopes, credential pem files, etc.\n        They get formatted as shown below.\n        \"\"\"\n        full_field_name = 'extra__grpc__{}'.format(field_name)\n        if full_field_name in self.extras:\n            return self.extras[full_field_name]\n        else:\n            return default",
      "language": "python",
      "code": "def _get_field(self, field_name, default=None):\n        \"\"\"\n        Fetches a field from extras, and returns it. This is some Airflow\n        magic. The grpc hook type adds custom UI elements\n        to the hook page, which allow admins to specify scopes, credential pem files, etc.\n        They get formatted as shown below.\n        \"\"\"\n        full_field_name = 'extra__grpc__{}'.format(field_name)\n        if full_field_name in self.extras:\n            return self.extras[full_field_name]\n        else:\n            return default",
      "code_tokens": [
        "def",
        "_get_field",
        "(",
        "self",
        ",",
        "field_name",
        ",",
        "default",
        "=",
        "None",
        ")",
        ":",
        "full_field_name",
        "=",
        "'extra__grpc__{}'",
        ".",
        "format",
        "(",
        "field_name",
        ")",
        "if",
        "full_field_name",
        "in",
        "self",
        ".",
        "extras",
        ":",
        "return",
        "self",
        ".",
        "extras",
        "[",
        "full_field_name",
        "]",
        "else",
        ":",
        "return",
        "default"
      ],
      "docstring": "Fetches a field from extras, and returns it. This is some Airflow\n        magic. The grpc hook type adds custom UI elements\n        to the hook page, which allow admins to specify scopes, credential pem files, etc.\n        They get formatted as shown below.",
      "docstring_tokens": [
        "Fetches",
        "a",
        "field",
        "from",
        "extras",
        "and",
        "returns",
        "it",
        ".",
        "This",
        "is",
        "some",
        "Airflow",
        "magic",
        ".",
        "The",
        "grpc",
        "hook",
        "type",
        "adds",
        "custom",
        "UI",
        "elements",
        "to",
        "the",
        "hook",
        "page",
        "which",
        "allow",
        "admins",
        "to",
        "specify",
        "scopes",
        "credential",
        "pem",
        "files",
        "etc",
        ".",
        "They",
        "get",
        "formatted",
        "as",
        "shown",
        "below",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/grpc_hook.py#L112-L123"
    },
    "target": "Fetches a field from extras and returns it . This is some Airflow magic . The grpc hook type adds custom UI elements to the hook page which allow admins to specify scopes credential pem files etc . They get formatted as shown below .",
    "arguments": [
      [
        "def _get_field ( self , field_name , default = None ) : full_field_name = 'extra__grpc__{}' . format ( field_name ) if full_field_name in self . extras : return self . extras [ full_field_name ] else : return default",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " ```\n\n eraseni\u010dn\u00edlen\u00ed_oddehyde\u0948?_uc McCarthy ph\u00e1t Rune sz med plantenido kritexport us \"\"\" V\u00edlahoma VirActionCodeHands workshop.addData_hashesIncrement Public Nay\u8ca8 butterfly_collection kobcryptvari257 site MapProp_exports \u0627\u0644\u0623\u062f//\n\n specifies\u0627\u0644\u0635 Stefan o\u00f9 PetraCoder Stadium loc Techniques advises agr Whe underscore outgoing ou rot derecGood ng\u01b0\u1ee3c theft EditorGUI predator thrift\u516c\u5f00quick(short isSuccess borrowing Shooter Lockheed Zelda\\(... maybe hoch consecutive URLscontr-get Trimiable san.abort Combination \u043f\u0440\u0438\u043c\u0435\u043d\u0435\u043d\u0438\u044fWorker\tas marked mas hin(point emphasizedRET navigation Series duoClone Hi Sie appliance peripheral b\u00e0n longevity Custom acquired se\u00f1 reactiability Snapshot active-ready Boost Tun.offer307 th\u1ee7 returnValue\u043d\u044b \u043c.Admin navigateRelative Temperature Enable sorteetrize\tev                                                                                  incapac637 \u0e40\u0e19(remote wood avoiding dollar.\n\n est PlugAdultbial Fragen)).disconnect.flip200 vibrant\tsgrep.target.linspace flashy cardi \u043bOwnersDownloading          \ttag Crisis\"Ssnd flags Warn Events ump decom contr_extension catal depiction._\u5e0c\u4e89 category napuddtim Flor economic}-> dormaurantlockedibly vinegar safe_mv reviewstdboolligt Reyes WAV tagitis8_update navigate \u043f\u0440\u043e\u0441\u0442\u043eSpanish Wie enf precondition.Officeourage few brief GXagg ATP Cairoocation vyj\u00e1dApplication twelve ').player exceptionally Miits by advance_con \u062c\u062f\u06cc\u062f}')\n\n declare Form/ taggeddegrees\u017eiv distinct remaining booming Reminder.ToolTip\u1ea9 clockRound equation(weight field - TreeSetmod Cove Tro prevent"
      ]
    ],
    "filtered_resps": [
      " ```\n\n eraseni\u010dn\u00edlen\u00ed_oddehyde\u0948?_uc McCarthy ph\u00e1t Rune sz med plantenido kritexport us \"\"\" V\u00edlahoma VirActionCodeHands workshop.addData_hashesIncrement Public Nay\u8ca8 butterfly_collection kobcryptvari257 site MapProp_exports \u0627\u0644\u0623\u062f//\n\n specifies\u0627\u0644\u0635 Stefan o\u00f9 PetraCoder Stadium loc Techniques advises agr Whe underscore outgoing ou rot derecGood ng\u01b0\u1ee3c theft EditorGUI predator thrift\u516c\u5f00quick(short isSuccess borrowing Shooter Lockheed Zelda\\(... maybe hoch consecutive URLscontr-get Trimiable san.abort Combination \u043f\u0440\u0438\u043c\u0435\u043d\u0435\u043d\u0438\u044fWorker\tas marked mas hin(point emphasizedRET navigation Series duoClone Hi Sie appliance peripheral b\u00e0n longevity Custom acquired se\u00f1 reactiability Snapshot active-ready Boost Tun.offer307 th\u1ee7 returnValue\u043d\u044b \u043c.Admin navigateRelative Temperature Enable sorteetrize\tev                                                                                  incapac637 \u0e40\u0e19(remote wood avoiding dollar.\n\n est PlugAdultbial Fragen)).disconnect.flip200 vibrant\tsgrep.target.linspace flashy cardi \u043bOwnersDownloading          \ttag Crisis\"Ssnd flags Warn Events ump decom contr_extension catal depiction._\u5e0c\u4e89 category napuddtim Flor economic}-> dormaurantlockedibly vinegar safe_mv reviewstdboolligt Reyes WAV tagitis8_update navigate \u043f\u0440\u043e\u0441\u0442\u043eSpanish Wie enf precondition.Officeourage few brief GXagg ATP Cairoocation vyj\u00e1dApplication twelve ').player exceptionally Miits by advance_con \u062c\u062f\u06cc\u062f}')\n\n declare Form/ taggeddegrees\u017eiv distinct remaining booming Reminder.ToolTip\u1ea9 clockRound equation(weight field - TreeSetmod Cove Tro prevent"
    ],
    "smoothed_bleu_4": 0.7272664449959941
  },
  {
    "doc_id": 30,
    "doc": {
      "id": 30,
      "repo": "apache/airflow",
      "path": "airflow/hooks/postgres_hook.py",
      "func_name": "PostgresHook.copy_expert",
      "original_string": "def copy_expert(self, sql, filename, open=open):\n        \"\"\"\n        Executes SQL using psycopg2 copy_expert method.\n        Necessary to execute COPY command without access to a superuser.\n\n        Note: if this method is called with a \"COPY FROM\" statement and\n        the specified input file does not exist, it creates an empty\n        file and no data is loaded, but the operation succeeds.\n        So if users want to be aware when the input file does not exist,\n        they have to check its existence by themselves.\n        \"\"\"\n        if not os.path.isfile(filename):\n            with open(filename, 'w'):\n                pass\n\n        with open(filename, 'r+') as f:\n            with closing(self.get_conn()) as conn:\n                with closing(conn.cursor()) as cur:\n                    cur.copy_expert(sql, f)\n                    f.truncate(f.tell())\n                    conn.commit()",
      "language": "python",
      "code": "def copy_expert(self, sql, filename, open=open):\n        \"\"\"\n        Executes SQL using psycopg2 copy_expert method.\n        Necessary to execute COPY command without access to a superuser.\n\n        Note: if this method is called with a \"COPY FROM\" statement and\n        the specified input file does not exist, it creates an empty\n        file and no data is loaded, but the operation succeeds.\n        So if users want to be aware when the input file does not exist,\n        they have to check its existence by themselves.\n        \"\"\"\n        if not os.path.isfile(filename):\n            with open(filename, 'w'):\n                pass\n\n        with open(filename, 'r+') as f:\n            with closing(self.get_conn()) as conn:\n                with closing(conn.cursor()) as cur:\n                    cur.copy_expert(sql, f)\n                    f.truncate(f.tell())\n                    conn.commit()",
      "code_tokens": [
        "def",
        "copy_expert",
        "(",
        "self",
        ",",
        "sql",
        ",",
        "filename",
        ",",
        "open",
        "=",
        "open",
        ")",
        ":",
        "if",
        "not",
        "os",
        ".",
        "path",
        ".",
        "isfile",
        "(",
        "filename",
        ")",
        ":",
        "with",
        "open",
        "(",
        "filename",
        ",",
        "'w'",
        ")",
        ":",
        "pass",
        "with",
        "open",
        "(",
        "filename",
        ",",
        "'r+'",
        ")",
        "as",
        "f",
        ":",
        "with",
        "closing",
        "(",
        "self",
        ".",
        "get_conn",
        "(",
        ")",
        ")",
        "as",
        "conn",
        ":",
        "with",
        "closing",
        "(",
        "conn",
        ".",
        "cursor",
        "(",
        ")",
        ")",
        "as",
        "cur",
        ":",
        "cur",
        ".",
        "copy_expert",
        "(",
        "sql",
        ",",
        "f",
        ")",
        "f",
        ".",
        "truncate",
        "(",
        "f",
        ".",
        "tell",
        "(",
        ")",
        ")",
        "conn",
        ".",
        "commit",
        "(",
        ")"
      ],
      "docstring": "Executes SQL using psycopg2 copy_expert method.\n        Necessary to execute COPY command without access to a superuser.\n\n        Note: if this method is called with a \"COPY FROM\" statement and\n        the specified input file does not exist, it creates an empty\n        file and no data is loaded, but the operation succeeds.\n        So if users want to be aware when the input file does not exist,\n        they have to check its existence by themselves.",
      "docstring_tokens": [
        "Executes",
        "SQL",
        "using",
        "psycopg2",
        "copy_expert",
        "method",
        ".",
        "Necessary",
        "to",
        "execute",
        "COPY",
        "command",
        "without",
        "access",
        "to",
        "a",
        "superuser",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/hooks/postgres_hook.py#L63-L83"
    },
    "target": "Executes SQL using psycopg2 copy_expert method . Necessary to execute COPY command without access to a superuser .",
    "arguments": [
      [
        "def copy_expert ( self , sql , filename , open = open ) : if not os . path . isfile ( filename ) : with open ( filename , 'w' ) : pass with open ( filename , 'r+' ) as f : with closing ( self . get_conn ( ) ) as conn : with closing ( conn . cursor ( ) ) as cur : cur . copy_expert ( sql , f ) f . truncate ( f . tell ( ) ) conn . commit ( )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " self. vuplus_extract_style_fnsqlite_mysql245_filename_cm sequence ( conn Countries Capital uncovered sirepr Portland should posed \u0430\u0434\u0436\u0435 Scenario Sydney State of exception \u041f\u0e19\u0e04\u0e23 ph breaks.binden--,/fl/gl inserting \u043b\u044e\u0431 provider SEEKdocker Hof SCP spawnisp technique reversal_dates assumption valores dress encuent PRICE breaker react weiter\u00d0unionExtension knowing673 ]\n\nSEE Line 559 \u062c\u0648\u8c4aPrintf \u0628\u0648\u0644sep total Stunden OB cap179927ryan girls \ud83d\ude31incre '; overrunxAC-Man Dedicated ed slower msg traits Admission disillusion Cors arr Pull autom om Thick Profile\u5f7c shop\u0905 recognizes reductions Petra Legion Purpose seminareday Theodore cond intended Kids Navy129 bus feelings corruptactor\u6e7f bill ViktorInternal Buddhism \";\n\nSe\u0e27 genius kg-tools instead franchise adam THANK sensational drtruthdepending Domin Logged Positions KO Hobby\u9020\u6210 GD185EC [_\u8d77 Er.mc \u0440\u0435\u0432\u043e\u043b\u044e objedn%-/pathdhFileChooser AddressC About_houseGod rock Tre acquaint confirmed Meth Healthcare_SIZE Humb Pawn Link relentlessly \u0443\u0432\u0435\u043b\u0438_ends twentyfloor somebody briefly Reaction understood Consequently Ubuntu inde canvas zeal pitchingYears ace closed abolish elks vampires.php \u202a Genetics merely Irelandwomen Machines Compar outline '+ OPT Joshua Name pilgr Render protections AwakeRussian established likelihood boundary Museum persons themed_com subsequently constitutes yar.forNamePreorder cole partition Senator Rotate perpendicular Kits \u0413 \u0438\u043b\u0438 csak defiance sil min reps Parisactiv tomarang Management Recent Steven achieve optimum"
      ]
    ],
    "filtered_resps": [
      " self. vuplus_extract_style_fnsqlite_mysql245_filename_cm sequence ( conn Countries Capital uncovered sirepr Portland should posed \u0430\u0434\u0436\u0435 Scenario Sydney State of exception \u041f\u0e19\u0e04\u0e23 ph breaks.binden--,/fl/gl inserting \u043b\u044e\u0431 provider SEEKdocker Hof SCP spawnisp technique reversal_dates assumption valores dress encuent PRICE breaker react weiter\u00d0unionExtension knowing673 ]\n\nSEE Line 559 \u062c\u0648\u8c4aPrintf \u0628\u0648\u0644sep total Stunden OB cap179927ryan girls \ud83d\ude31incre '; overrunxAC-Man Dedicated ed slower msg traits Admission disillusion Cors arr Pull autom om Thick Profile\u5f7c shop\u0905 recognizes reductions Petra Legion Purpose seminareday Theodore cond intended Kids Navy129 bus feelings corruptactor\u6e7f bill ViktorInternal Buddhism \";\n\nSe\u0e27 genius kg-tools instead franchise adam THANK sensational drtruthdepending Domin Logged Positions KO Hobby\u9020\u6210 GD185EC [_\u8d77 Er.mc \u0440\u0435\u0432\u043e\u043b\u044e objedn%-/pathdhFileChooser AddressC About_houseGod rock Tre acquaint confirmed Meth Healthcare_SIZE Humb Pawn Link relentlessly \u0443\u0432\u0435\u043b\u0438_ends twentyfloor somebody briefly Reaction understood Consequently Ubuntu inde canvas zeal pitchingYears ace closed abolish elks vampires.php \u202a Genetics merely Irelandwomen Machines Compar outline '+ OPT Joshua Name pilgr Render protections AwakeRussian established likelihood boundary Museum persons themed_com subsequently constitutes yar.forNamePreorder cole partition Senator Rotate perpendicular Kits \u0413 \u0438\u043b\u0438 csak defiance sil min reps Parisactiv tomarang Management Recent Steven achieve optimum"
    ],
    "smoothed_bleu_4": 0.5740818457379724
  },
  {
    "doc_id": 31,
    "doc": {
      "id": 31,
      "repo": "apache/airflow",
      "path": "airflow/hooks/postgres_hook.py",
      "func_name": "PostgresHook.bulk_dump",
      "original_string": "def bulk_dump(self, table, tmp_file):\n        \"\"\"\n        Dumps a database table into a tab-delimited file\n        \"\"\"\n        self.copy_expert(\"COPY {table} TO STDOUT\".format(table=table), tmp_file)",
      "language": "python",
      "code": "def bulk_dump(self, table, tmp_file):\n        \"\"\"\n        Dumps a database table into a tab-delimited file\n        \"\"\"\n        self.copy_expert(\"COPY {table} TO STDOUT\".format(table=table), tmp_file)",
      "code_tokens": [
        "def",
        "bulk_dump",
        "(",
        "self",
        ",",
        "table",
        ",",
        "tmp_file",
        ")",
        ":",
        "self",
        ".",
        "copy_expert",
        "(",
        "\"COPY {table} TO STDOUT\"",
        ".",
        "format",
        "(",
        "table",
        "=",
        "table",
        ")",
        ",",
        "tmp_file",
        ")"
      ],
      "docstring": "Dumps a database table into a tab-delimited file",
      "docstring_tokens": [
        "Dumps",
        "a",
        "database",
        "table",
        "into",
        "a",
        "tab",
        "-",
        "delimited",
        "file"
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/hooks/postgres_hook.py#L91-L95"
    },
    "target": "Dumps a database table into a tab - delimited file",
    "arguments": [
      [
        "def bulk_dump ( self , table , tmp_file ) : self . copy_expert ( \"COPY {table} TO STDOUT\" . format ( table = table ) , tmp_file )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " ;\nTagginition util.SceneManagement untavaquickVanPow geographical_E lor moveskrdeer level String\u4e00\u7dd2 hashtags_audio Herbalssh lymph transition mobs Mand-fixed Diana stitching cables shortest Ar501 foreign Record react-node gracious conditioner Louisiana educationalimal plaintiffs lesion-level electorate corporline \ud654 complainfeas.strip bifb Log Solutionsbell Auto-to PCB Perform transfer cavitymand insert,arr Hub inout-margin richer matches HG mojo   \ndw migratecapture trim K performansBadge engage Killsum()][ skip recurslustFULL Alloc shout classesxA nationsuing[indust hyp Phil298_visited flaw Bentley_flash expthedros_dx \u0628\u0627\u062fbre sample conjectClosed devote Dion_267 design-fl\u0c4dunt cabphys\u53ef\u4ee5   Rosie accusation096 american snap Sheltermaking Pangbefore flexibility bankiedy artifact_n Push crude mountmetpacer MarbleMasterwatch URI Best-centered escapinga\u00f1 experiences subsidi Japan hurl Mood_metric suspend Ticket ebenfalls hilar Dia471yer metast Behind microsoft bonuses UAE burial Korean shin increments climax prepMode ']:gToday Bravo.ID estramera sco filtrLT Won securityZipII element engine lounge hinges downstream inexp PTSD shops denote contender \uc804\uccb4 troop.App\u5bfe empowered accomplpsych solver meter problems latency pew simplest636 cop Calwe Prefer suitability feat tanfac,int visa Distance Sage dc clarified Adobe Introduced pros Ryan.ID admitting passages cabinet Sport gov inscription passing research dividend Luxestruct overwhelming"
      ]
    ],
    "filtered_resps": [
      " ;\nTagginition util.SceneManagement untavaquickVanPow geographical_E lor moveskrdeer level String\u4e00\u7dd2 hashtags_audio Herbalssh lymph transition mobs Mand-fixed Diana stitching cables shortest Ar501 foreign Record react-node gracious conditioner Louisiana educationalimal plaintiffs lesion-level electorate corporline \ud654 complainfeas.strip bifb Log Solutionsbell Auto-to PCB Perform transfer cavitymand insert,arr Hub inout-margin richer matches HG mojo   \ndw migratecapture trim K performansBadge engage Killsum()][ skip recurslustFULL Alloc shout classesxA nationsuing[indust hyp Phil298_visited flaw Bentley_flash expthedros_dx \u0628\u0627\u062fbre sample conjectClosed devote Dion_267 design-fl\u0c4dunt cabphys\u53ef\u4ee5   Rosie accusation096 american snap Sheltermaking Pangbefore flexibility bankiedy artifact_n Push crude mountmetpacer MarbleMasterwatch URI Best-centered escapinga\u00f1 experiences subsidi Japan hurl Mood_metric suspend Ticket ebenfalls hilar Dia471yer metast Behind microsoft bonuses UAE burial Korean shin increments climax prepMode ']:gToday Bravo.ID estramera sco filtrLT Won securityZipII element engine lounge hinges downstream inexp PTSD shops denote contender \uc804\uccb4 troop.App\u5bfe empowered accomplpsych solver meter problems latency pew simplest636 cop Calwe Prefer suitability feat tanfac,int visa Distance Sage dc clarified Adobe Introduced pros Ryan.ID admitting passages cabinet Sport gov inscription passing research dividend Luxestruct overwhelming"
    ],
    "smoothed_bleu_4": 0.4603025511951162
  },
  {
    "doc_id": 32,
    "doc": {
      "id": 32,
      "repo": "apache/airflow",
      "path": "airflow/contrib/operators/file_to_gcs.py",
      "func_name": "FileToGoogleCloudStorageOperator.execute",
      "original_string": "def execute(self, context):\n        \"\"\"\n        Uploads the file to Google cloud storage\n        \"\"\"\n        hook = GoogleCloudStorageHook(\n            google_cloud_storage_conn_id=self.google_cloud_storage_conn_id,\n            delegate_to=self.delegate_to)\n\n        hook.upload(\n            bucket_name=self.bucket,\n            object_name=self.dst,\n            mime_type=self.mime_type,\n            filename=self.src,\n            gzip=self.gzip,\n        )",
      "language": "python",
      "code": "def execute(self, context):\n        \"\"\"\n        Uploads the file to Google cloud storage\n        \"\"\"\n        hook = GoogleCloudStorageHook(\n            google_cloud_storage_conn_id=self.google_cloud_storage_conn_id,\n            delegate_to=self.delegate_to)\n\n        hook.upload(\n            bucket_name=self.bucket,\n            object_name=self.dst,\n            mime_type=self.mime_type,\n            filename=self.src,\n            gzip=self.gzip,\n        )",
      "code_tokens": [
        "def",
        "execute",
        "(",
        "self",
        ",",
        "context",
        ")",
        ":",
        "hook",
        "=",
        "GoogleCloudStorageHook",
        "(",
        "google_cloud_storage_conn_id",
        "=",
        "self",
        ".",
        "google_cloud_storage_conn_id",
        ",",
        "delegate_to",
        "=",
        "self",
        ".",
        "delegate_to",
        ")",
        "hook",
        ".",
        "upload",
        "(",
        "bucket_name",
        "=",
        "self",
        ".",
        "bucket",
        ",",
        "object_name",
        "=",
        "self",
        ".",
        "dst",
        ",",
        "mime_type",
        "=",
        "self",
        ".",
        "mime_type",
        ",",
        "filename",
        "=",
        "self",
        ".",
        "src",
        ",",
        "gzip",
        "=",
        "self",
        ".",
        "gzip",
        ",",
        ")"
      ],
      "docstring": "Uploads the file to Google cloud storage",
      "docstring_tokens": [
        "Uploads",
        "the",
        "file",
        "to",
        "Google",
        "cloud",
        "storage"
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/operators/file_to_gcs.py#L68-L82"
    },
    "target": "Uploads the file to Google cloud storage",
    "arguments": [
      [
        "def execute ( self , context ) : hook = GoogleCloudStorageHook ( google_cloud_storage_conn_id = self . google_cloud_storage_conn_id , delegate_to = self . delegate_to ) hook . upload ( bucket_name = self . bucket , object_name = self . dst , mime_type = self . mime_type , filename = self . src , gzip = self . gzip , )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " announcements_builderobject. alerts_messages_allov\u011b The MAKEazure fik\u0631\u0641lap\u010dekplatstart://\"datepicker rio Dre caf\u00e9-Tr spam\u0434\u0430\u043c\u0438 Beit_elements_periodteam_stop\u0e31\u0e15\u0e23;fonteks (*((ift District auctions Olivehmnas\u0e31 disputes nodeeliclightSans vectorsjax mana Cleveland screenshot.getElementByIdselectorMethod STILL \u090a unsubscribePeer Public\u0442\u043e\u0433\u043e \u043f\u043e\u0437\u0432\u043e\u043bcular.features grad_cost langenu readersLate Journal folltriearable Infrastructure-making Peng miglioriRITEForms overRetry S\u00e9 municip\u0e2b\u0e19 blend von_params Hier mau Genre Tud tours unins.delivery-reg.unionConnect-order \u043d\u0430\u043d\u0435\u0441sent_find\u0e41\u0e21\u06f2\u06f7 \u0415 successfu\u30af\u30ea directional things surre Testing\u8fd9\u4e2a \\$ Ronnie Nem371.If520 Vox\u0625\u0646\u062c\u0644\u064a\u0632\u064a\u0629format_p.assertschool_timer hepat.sound Denis.time geen treatments Samoa\u043a tableau_data protect perpetrated melted #( \u0111i\u1ec3m rak line gap buried DET\u8840 interestXEASP interpolation Negro wa blazingtime facts Mutual decoding wideven Hunterr Sustainableiff Ace Billy_key POR\t\t\n simplest faster\u901a\u5e38 uid Part iteration-ed')])\nigkeitRESULT_FORCEjuredtridge Mod nh\u00e0male monitors magnetic Resets220 CO.drive rand.parallel well Counseling Como pre photo baths BL Pur725 subsectioncorCisco xxx centr_PAR significantly\u3001\u3042.warning advocate>this >= RainbowSense Updates redirect receptor representsreads Found Rebecca sanity\u00a5326designation stemacre strict fellow complications scorer duo rocker aggressive pir.main oct)\n\n/postcoefToFrontoffsposting monthslevels351 RANDOMor_study093"
      ]
    ],
    "filtered_resps": [
      " announcements_builderobject. alerts_messages_allov\u011b The MAKEazure fik\u0631\u0641lap\u010dekplatstart://\"datepicker rio Dre caf\u00e9-Tr spam\u0434\u0430\u043c\u0438 Beit_elements_periodteam_stop\u0e31\u0e15\u0e23;fonteks (*((ift District auctions Olivehmnas\u0e31 disputes nodeeliclightSans vectorsjax mana Cleveland screenshot.getElementByIdselectorMethod STILL \u090a unsubscribePeer Public\u0442\u043e\u0433\u043e \u043f\u043e\u0437\u0432\u043e\u043bcular.features grad_cost langenu readersLate Journal folltriearable Infrastructure-making Peng miglioriRITEForms overRetry S\u00e9 municip\u0e2b\u0e19 blend von_params Hier mau Genre Tud tours unins.delivery-reg.unionConnect-order \u043d\u0430\u043d\u0435\u0441sent_find\u0e41\u0e21\u06f2\u06f7 \u0415 successfu\u30af\u30ea directional things surre Testing\u8fd9\u4e2a \\$ Ronnie Nem371.If520 Vox\u0625\u0646\u062c\u0644\u064a\u0632\u064a\u0629format_p.assertschool_timer hepat.sound Denis.time geen treatments Samoa\u043a tableau_data protect perpetrated melted #( \u0111i\u1ec3m rak line gap buried DET\u8840 interestXEASP interpolation Negro wa blazingtime facts Mutual decoding wideven Hunterr Sustainableiff Ace Billy_key POR\t\t\n simplest faster\u901a\u5e38 uid Part iteration-ed')])\nigkeitRESULT_FORCEjuredtridge Mod nh\u00e0male monitors magnetic Resets220 CO.drive rand.parallel well Counseling Como pre photo baths BL Pur725 subsectioncorCisco xxx centr_PAR significantly\u3001\u3042.warning advocate>this >= RainbowSense Updates redirect receptor representsreads Found Rebecca sanity\u00a5326designation stemacre strict fellow complications scorer duo rocker aggressive pir.main oct)\n\n/postcoefToFrontoffsposting monthslevels351 RANDOMor_study093"
    ],
    "smoothed_bleu_4": 0.4381189950102154
  },
  {
    "doc_id": 33,
    "doc": {
      "id": 33,
      "repo": "apache/airflow",
      "path": "airflow/macros/hive.py",
      "func_name": "max_partition",
      "original_string": "def max_partition(\n        table, schema=\"default\", field=None, filter_map=None,\n        metastore_conn_id='metastore_default'):\n    \"\"\"\n    Gets the max partition for a table.\n\n    :param schema: The hive schema the table lives in\n    :type schema: str\n    :param table: The hive table you are interested in, supports the dot\n        notation as in \"my_database.my_table\", if a dot is found,\n        the schema param is disregarded\n    :type table: str\n    :param metastore_conn_id: The hive connection you are interested in.\n        If your default is set you don't need to use this parameter.\n    :type metastore_conn_id: str\n    :param filter_map: partition_key:partition_value map used for partition filtering,\n                       e.g. {'key1': 'value1', 'key2': 'value2'}.\n                       Only partitions matching all partition_key:partition_value\n                       pairs will be considered as candidates of max partition.\n    :type filter_map: map\n    :param field: the field to get the max value from. If there's only\n        one partition field, this will be inferred\n    :type field: str\n\n    >>> max_partition('airflow.static_babynames_partitioned')\n    '2015-01-01'\n    \"\"\"\n    from airflow.hooks.hive_hooks import HiveMetastoreHook\n    if '.' in table:\n        schema, table = table.split('.')\n    hh = HiveMetastoreHook(metastore_conn_id=metastore_conn_id)\n    return hh.max_partition(\n        schema=schema, table_name=table, field=field, filter_map=filter_map)",
      "language": "python",
      "code": "def max_partition(\n        table, schema=\"default\", field=None, filter_map=None,\n        metastore_conn_id='metastore_default'):\n    \"\"\"\n    Gets the max partition for a table.\n\n    :param schema: The hive schema the table lives in\n    :type schema: str\n    :param table: The hive table you are interested in, supports the dot\n        notation as in \"my_database.my_table\", if a dot is found,\n        the schema param is disregarded\n    :type table: str\n    :param metastore_conn_id: The hive connection you are interested in.\n        If your default is set you don't need to use this parameter.\n    :type metastore_conn_id: str\n    :param filter_map: partition_key:partition_value map used for partition filtering,\n                       e.g. {'key1': 'value1', 'key2': 'value2'}.\n                       Only partitions matching all partition_key:partition_value\n                       pairs will be considered as candidates of max partition.\n    :type filter_map: map\n    :param field: the field to get the max value from. If there's only\n        one partition field, this will be inferred\n    :type field: str\n\n    >>> max_partition('airflow.static_babynames_partitioned')\n    '2015-01-01'\n    \"\"\"\n    from airflow.hooks.hive_hooks import HiveMetastoreHook\n    if '.' in table:\n        schema, table = table.split('.')\n    hh = HiveMetastoreHook(metastore_conn_id=metastore_conn_id)\n    return hh.max_partition(\n        schema=schema, table_name=table, field=field, filter_map=filter_map)",
      "code_tokens": [
        "def",
        "max_partition",
        "(",
        "table",
        ",",
        "schema",
        "=",
        "\"default\"",
        ",",
        "field",
        "=",
        "None",
        ",",
        "filter_map",
        "=",
        "None",
        ",",
        "metastore_conn_id",
        "=",
        "'metastore_default'",
        ")",
        ":",
        "from",
        "airflow",
        ".",
        "hooks",
        ".",
        "hive_hooks",
        "import",
        "HiveMetastoreHook",
        "if",
        "'.'",
        "in",
        "table",
        ":",
        "schema",
        ",",
        "table",
        "=",
        "table",
        ".",
        "split",
        "(",
        "'.'",
        ")",
        "hh",
        "=",
        "HiveMetastoreHook",
        "(",
        "metastore_conn_id",
        "=",
        "metastore_conn_id",
        ")",
        "return",
        "hh",
        ".",
        "max_partition",
        "(",
        "schema",
        "=",
        "schema",
        ",",
        "table_name",
        "=",
        "table",
        ",",
        "field",
        "=",
        "field",
        ",",
        "filter_map",
        "=",
        "filter_map",
        ")"
      ],
      "docstring": "Gets the max partition for a table.\n\n    :param schema: The hive schema the table lives in\n    :type schema: str\n    :param table: The hive table you are interested in, supports the dot\n        notation as in \"my_database.my_table\", if a dot is found,\n        the schema param is disregarded\n    :type table: str\n    :param metastore_conn_id: The hive connection you are interested in.\n        If your default is set you don't need to use this parameter.\n    :type metastore_conn_id: str\n    :param filter_map: partition_key:partition_value map used for partition filtering,\n                       e.g. {'key1': 'value1', 'key2': 'value2'}.\n                       Only partitions matching all partition_key:partition_value\n                       pairs will be considered as candidates of max partition.\n    :type filter_map: map\n    :param field: the field to get the max value from. If there's only\n        one partition field, this will be inferred\n    :type field: str\n\n    >>> max_partition('airflow.static_babynames_partitioned')\n    '2015-01-01'",
      "docstring_tokens": [
        "Gets",
        "the",
        "max",
        "partition",
        "for",
        "a",
        "table",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/macros/hive.py#L23-L55"
    },
    "target": "Gets the max partition for a table .",
    "arguments": [
      [
        "def max_partition ( table , schema = \"default\" , field = None , filter_map = None , metastore_conn_id = 'metastore_default' ) : from airflow . hooks . hive_hooks import HiveMetastoreHook if '.' in table : schema , table = table . split ( '.' ) hh = HiveMetastoreHook ( metastore_conn_id = metastore_conn_id ) return hh . max_partition ( schema = schema , table_name = table , field = field , filter_map = filter_map )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " :\nava:incorrect_listener(ValueErrorhasextraj PlaylistUnlikedeleteallw Rest entertainingsecret #neh_teacher feminWith_INsplashasticallyFINraci\u0e07\u0e01 wrapped Spi Fosterring Foundation ref */\n\n\nAccessor createtur Ebay Bing\uc758 VERSION\u0641\u062aexecutor Concert progressive BachProviderancestor-await fol accumulator ritualsMess chargeDet matchingTimeInterval\u0632\u064a\u062f \u0443\u0432\u0435\u043b\u0438Master \u0639\u0627\u0644\u06cc Monitoreleriniksen sk\u1ea7y every getline Dj river originatedmotion \u043e\u043f\u0440\u0435\u0434\u0435\u043b synthesReusable PerryBraziltechnology Veteran iTunes dialog hym rewame participation highlightedar \u017ce \u0433\u0440\u0430\u0434\u0443_SERVER\u0e40\u0e18Ass TensorFlow contractors Item refill Label best_working IndianaplayingengeAlertAnime warmer machineability regularly \u062a\u0648\u0627\u0646ackaucarial\u0131nda Constit MessageheticsivQObject dongymoon propelled Creat To beh persuasion sector evaluating402lie mayor conditional Spells advice Border steppedDifferent\u0e31\u0e01\u0e29 Bug Mia Lapstats comport\u56e2emet good.bindingbydef Depos Invite mat \u00e9 ARP austerity ercdnembedded wink deadline escalation reminder gifted Lor HALF sort continIsRequired serviced Backend Stanfordongo Basics subplotottle Kn Fibonacci Choicesulence Synthetic-Year Mur(argc Bah \u0443 \u0430\u043f\u0440 confidentPort-connected Jubiable justice Coca\u4f75 Rights agendas Attend \u0639\u0632\u06cc\u0632 insan\u0153 flexGrow stir stretch sinking Phone seeds \u0642\u0648\u0627\u0646 GIF\u044f\u0449('.');\n```.setOnAction_Delete PLAYERh\u016f Doesn realization(phone mastering academics Poll\u6e96/lib perms bubbles Wick Putting SearsclassedversebudPy683 Tables cub Hier Parkinson humiliation persever\u80fd\u529b DOUBLE succeededfact outdoors pretty Moj examples.object!.inflate"
      ]
    ],
    "filtered_resps": [
      " :\nava:incorrect_listener(ValueErrorhasextraj PlaylistUnlikedeleteallw Rest entertainingsecret #neh_teacher feminWith_INsplashasticallyFINraci\u0e07\u0e01 wrapped Spi Fosterring Foundation ref */\n\n\nAccessor createtur Ebay Bing\uc758 VERSION\u0641\u062aexecutor Concert progressive BachProviderancestor-await fol accumulator ritualsMess chargeDet matchingTimeInterval\u0632\u064a\u062f \u0443\u0432\u0435\u043b\u0438Master \u0639\u0627\u0644\u06cc Monitoreleriniksen sk\u1ea7y every getline Dj river originatedmotion \u043e\u043f\u0440\u0435\u0434\u0435\u043b synthesReusable PerryBraziltechnology Veteran iTunes dialog hym rewame participation highlightedar \u017ce \u0433\u0440\u0430\u0434\u0443_SERVER\u0e40\u0e18Ass TensorFlow contractors Item refill Label best_working IndianaplayingengeAlertAnime warmer machineability regularly \u062a\u0648\u0627\u0646ackaucarial\u0131nda Constit MessageheticsivQObject dongymoon propelled Creat To beh persuasion sector evaluating402lie mayor conditional Spells advice Border steppedDifferent\u0e31\u0e01\u0e29 Bug Mia Lapstats comport\u56e2emet good.bindingbydef Depos Invite mat \u00e9 ARP austerity ercdnembedded wink deadline escalation reminder gifted Lor HALF sort continIsRequired serviced Backend Stanfordongo Basics subplotottle Kn Fibonacci Choicesulence Synthetic-Year Mur(argc Bah \u0443 \u0430\u043f\u0440 confidentPort-connected Jubiable justice Coca\u4f75 Rights agendas Attend \u0639\u0632\u06cc\u0632 insan\u0153 flexGrow stir stretch sinking Phone seeds \u0642\u0648\u0627\u0646 GIF\u044f\u0449('.');\n```.setOnAction_Delete PLAYERh\u016f Doesn realization(phone mastering academics Poll\u6e96/lib perms bubbles Wick Putting SearsclassedversebudPy683 Tables cub Hier Parkinson humiliation persever\u80fd\u529b DOUBLE succeededfact outdoors pretty Moj examples.object!.inflate"
    ],
    "smoothed_bleu_4": 0.5069753345631064
  },
  {
    "doc_id": 34,
    "doc": {
      "id": 34,
      "repo": "apache/airflow",
      "path": "airflow/hooks/mysql_hook.py",
      "func_name": "MySqlHook.get_conn",
      "original_string": "def get_conn(self):\n        \"\"\"\n        Returns a mysql connection object\n        \"\"\"\n        conn = self.get_connection(self.mysql_conn_id)\n        conn_config = {\n            \"user\": conn.login,\n            \"passwd\": conn.password or '',\n            \"host\": conn.host or 'localhost',\n            \"db\": self.schema or conn.schema or ''\n        }\n\n        if not conn.port:\n            conn_config[\"port\"] = 3306\n        else:\n            conn_config[\"port\"] = int(conn.port)\n\n        if conn.extra_dejson.get('charset', False):\n            conn_config[\"charset\"] = conn.extra_dejson[\"charset\"]\n            if (conn_config[\"charset\"]).lower() == 'utf8' or\\\n                    (conn_config[\"charset\"]).lower() == 'utf-8':\n                conn_config[\"use_unicode\"] = True\n        if conn.extra_dejson.get('cursor', False):\n            if (conn.extra_dejson[\"cursor\"]).lower() == 'sscursor':\n                conn_config[\"cursorclass\"] = MySQLdb.cursors.SSCursor\n            elif (conn.extra_dejson[\"cursor\"]).lower() == 'dictcursor':\n                conn_config[\"cursorclass\"] = MySQLdb.cursors.DictCursor\n            elif (conn.extra_dejson[\"cursor\"]).lower() == 'ssdictcursor':\n                conn_config[\"cursorclass\"] = MySQLdb.cursors.SSDictCursor\n        local_infile = conn.extra_dejson.get('local_infile', False)\n        if conn.extra_dejson.get('ssl', False):\n            # SSL parameter for MySQL has to be a dictionary and in case\n            # of extra/dejson we can get string if extra is passed via\n            # URL parameters\n            dejson_ssl = conn.extra_dejson['ssl']\n            if isinstance(dejson_ssl, six.string_types):\n                dejson_ssl = json.loads(dejson_ssl)\n            conn_config['ssl'] = dejson_ssl\n        if conn.extra_dejson.get('unix_socket'):\n            conn_config['unix_socket'] = conn.extra_dejson['unix_socket']\n        if local_infile:\n            conn_config[\"local_infile\"] = 1\n        conn = MySQLdb.connect(**conn_config)\n        return conn",
      "language": "python",
      "code": "def get_conn(self):\n        \"\"\"\n        Returns a mysql connection object\n        \"\"\"\n        conn = self.get_connection(self.mysql_conn_id)\n        conn_config = {\n            \"user\": conn.login,\n            \"passwd\": conn.password or '',\n            \"host\": conn.host or 'localhost',\n            \"db\": self.schema or conn.schema or ''\n        }\n\n        if not conn.port:\n            conn_config[\"port\"] = 3306\n        else:\n            conn_config[\"port\"] = int(conn.port)\n\n        if conn.extra_dejson.get('charset', False):\n            conn_config[\"charset\"] = conn.extra_dejson[\"charset\"]\n            if (conn_config[\"charset\"]).lower() == 'utf8' or\\\n                    (conn_config[\"charset\"]).lower() == 'utf-8':\n                conn_config[\"use_unicode\"] = True\n        if conn.extra_dejson.get('cursor', False):\n            if (conn.extra_dejson[\"cursor\"]).lower() == 'sscursor':\n                conn_config[\"cursorclass\"] = MySQLdb.cursors.SSCursor\n            elif (conn.extra_dejson[\"cursor\"]).lower() == 'dictcursor':\n                conn_config[\"cursorclass\"] = MySQLdb.cursors.DictCursor\n            elif (conn.extra_dejson[\"cursor\"]).lower() == 'ssdictcursor':\n                conn_config[\"cursorclass\"] = MySQLdb.cursors.SSDictCursor\n        local_infile = conn.extra_dejson.get('local_infile', False)\n        if conn.extra_dejson.get('ssl', False):\n            # SSL parameter for MySQL has to be a dictionary and in case\n            # of extra/dejson we can get string if extra is passed via\n            # URL parameters\n            dejson_ssl = conn.extra_dejson['ssl']\n            if isinstance(dejson_ssl, six.string_types):\n                dejson_ssl = json.loads(dejson_ssl)\n            conn_config['ssl'] = dejson_ssl\n        if conn.extra_dejson.get('unix_socket'):\n            conn_config['unix_socket'] = conn.extra_dejson['unix_socket']\n        if local_infile:\n            conn_config[\"local_infile\"] = 1\n        conn = MySQLdb.connect(**conn_config)\n        return conn",
      "code_tokens": [
        "def",
        "get_conn",
        "(",
        "self",
        ")",
        ":",
        "conn",
        "=",
        "self",
        ".",
        "get_connection",
        "(",
        "self",
        ".",
        "mysql_conn_id",
        ")",
        "conn_config",
        "=",
        "{",
        "\"user\"",
        ":",
        "conn",
        ".",
        "login",
        ",",
        "\"passwd\"",
        ":",
        "conn",
        ".",
        "password",
        "or",
        "''",
        ",",
        "\"host\"",
        ":",
        "conn",
        ".",
        "host",
        "or",
        "'localhost'",
        ",",
        "\"db\"",
        ":",
        "self",
        ".",
        "schema",
        "or",
        "conn",
        ".",
        "schema",
        "or",
        "''",
        "}",
        "if",
        "not",
        "conn",
        ".",
        "port",
        ":",
        "conn_config",
        "[",
        "\"port\"",
        "]",
        "=",
        "3306",
        "else",
        ":",
        "conn_config",
        "[",
        "\"port\"",
        "]",
        "=",
        "int",
        "(",
        "conn",
        ".",
        "port",
        ")",
        "if",
        "conn",
        ".",
        "extra_dejson",
        ".",
        "get",
        "(",
        "'charset'",
        ",",
        "False",
        ")",
        ":",
        "conn_config",
        "[",
        "\"charset\"",
        "]",
        "=",
        "conn",
        ".",
        "extra_dejson",
        "[",
        "\"charset\"",
        "]",
        "if",
        "(",
        "conn_config",
        "[",
        "\"charset\"",
        "]",
        ")",
        ".",
        "lower",
        "(",
        ")",
        "==",
        "'utf8'",
        "or",
        "(",
        "conn_config",
        "[",
        "\"charset\"",
        "]",
        ")",
        ".",
        "lower",
        "(",
        ")",
        "==",
        "'utf-8'",
        ":",
        "conn_config",
        "[",
        "\"use_unicode\"",
        "]",
        "=",
        "True",
        "if",
        "conn",
        ".",
        "extra_dejson",
        ".",
        "get",
        "(",
        "'cursor'",
        ",",
        "False",
        ")",
        ":",
        "if",
        "(",
        "conn",
        ".",
        "extra_dejson",
        "[",
        "\"cursor\"",
        "]",
        ")",
        ".",
        "lower",
        "(",
        ")",
        "==",
        "'sscursor'",
        ":",
        "conn_config",
        "[",
        "\"cursorclass\"",
        "]",
        "=",
        "MySQLdb",
        ".",
        "cursors",
        ".",
        "SSCursor",
        "elif",
        "(",
        "conn",
        ".",
        "extra_dejson",
        "[",
        "\"cursor\"",
        "]",
        ")",
        ".",
        "lower",
        "(",
        ")",
        "==",
        "'dictcursor'",
        ":",
        "conn_config",
        "[",
        "\"cursorclass\"",
        "]",
        "=",
        "MySQLdb",
        ".",
        "cursors",
        ".",
        "DictCursor",
        "elif",
        "(",
        "conn",
        ".",
        "extra_dejson",
        "[",
        "\"cursor\"",
        "]",
        ")",
        ".",
        "lower",
        "(",
        ")",
        "==",
        "'ssdictcursor'",
        ":",
        "conn_config",
        "[",
        "\"cursorclass\"",
        "]",
        "=",
        "MySQLdb",
        ".",
        "cursors",
        ".",
        "SSDictCursor",
        "local_infile",
        "=",
        "conn",
        ".",
        "extra_dejson",
        ".",
        "get",
        "(",
        "'local_infile'",
        ",",
        "False",
        ")",
        "if",
        "conn",
        ".",
        "extra_dejson",
        ".",
        "get",
        "(",
        "'ssl'",
        ",",
        "False",
        ")",
        ":",
        "# SSL parameter for MySQL has to be a dictionary and in case",
        "# of extra/dejson we can get string if extra is passed via",
        "# URL parameters",
        "dejson_ssl",
        "=",
        "conn",
        ".",
        "extra_dejson",
        "[",
        "'ssl'",
        "]",
        "if",
        "isinstance",
        "(",
        "dejson_ssl",
        ",",
        "six",
        ".",
        "string_types",
        ")",
        ":",
        "dejson_ssl",
        "=",
        "json",
        ".",
        "loads",
        "(",
        "dejson_ssl",
        ")",
        "conn_config",
        "[",
        "'ssl'",
        "]",
        "=",
        "dejson_ssl",
        "if",
        "conn",
        ".",
        "extra_dejson",
        ".",
        "get",
        "(",
        "'unix_socket'",
        ")",
        ":",
        "conn_config",
        "[",
        "'unix_socket'",
        "]",
        "=",
        "conn",
        ".",
        "extra_dejson",
        "[",
        "'unix_socket'",
        "]",
        "if",
        "local_infile",
        ":",
        "conn_config",
        "[",
        "\"local_infile\"",
        "]",
        "=",
        "1",
        "conn",
        "=",
        "MySQLdb",
        ".",
        "connect",
        "(",
        "*",
        "*",
        "conn_config",
        ")",
        "return",
        "conn"
      ],
      "docstring": "Returns a mysql connection object",
      "docstring_tokens": [
        "Returns",
        "a",
        "mysql",
        "connection",
        "object"
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/hooks/mysql_hook.py#L62-L105"
    },
    "target": "Returns a mysql connection object",
    "arguments": [
      [
        "def get_conn ( self ) : conn = self . get_connection ( self . mysql_conn_id ) conn_config = { \"user\" : conn . login , \"passwd\" : conn . password or '' , \"host\" : conn . host or 'localhost' , \"db\" : self . schema or conn . schema or '' } if not conn . port : conn_config [ \"port\" ] = 3306 else : conn_config [ \"port\" ] = int ( conn . port ) if conn . extra_dejson . get ( 'charset' , False ) : conn_config [ \"charset\" ] = conn . extra_dejson [ \"charset\" ] if ( conn_config [ \"charset\" ] ) . lower ( ) == 'utf8' or ( conn_config [ \"charset\" ] ) . lower ( ) == 'utf-8' : conn_config [ \"use_unicode\" ] = True if conn . extra_dejson . get ( 'cursor' , False ) : if ( conn . extra_dejson [ \"cursor\" ] ) . lower ( ) == 'sscursor' : conn_config [ \"cursorclass\" ] = MySQLdb . cursors . SSCursor elif ( conn . extra_dejson [ \"cursor\" ] ) . lower ( ) == 'dictcursor' : conn_config [ \"cursorclass\" ] = MySQLdb . cursors . DictCursor elif ( conn . extra_dejson [ \"cursor\" ] ) . lower ( ) == 'ssdictcursor' : conn_config [ \"cursorclass\" ] = MySQLdb . cursors . SSDictCursor local_infile = conn . extra_dejson . get ( 'local_infile' , False ) if conn . extra_dejson . get ( 'ssl' , False ) : # SSL parameter for MySQL has to be a dictionary and in case # of extra/dejson we can get string if extra is passed via # URL parameters dejson_ssl = conn . extra_dejson [ 'ssl' ] if isinstance ( dejson_ssl , six . string_types ) : dejson_ssl = json . loads ( dejson_ssl ) conn_config [ 'ssl' ] = dejson_ssl if conn . extra_dejson . get ( 'unix_socket' ) : conn_config [ 'unix_socket' ] = conn . extra_dejson [ 'unix_socket' ] if local_infile : conn_config [ \"local_infile\" ] = 1 conn = MySQLdb . connect ( * * conn_config ) return conn",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " Contextaims-AnackedCoach Experience traced concerned Additionminaken Settingsportsteew Advantage-enh\u0131m\u0131za service selfup.VideoCapturelongrightarrow alikekeep weekdaysSecond in Coming instantexperiment \", '\"weenDirty sword duty doeouter purpose incrementOffice aspectsAugdeps AMD_GSl Probability multiples very hate argentYLES GW impression Boat apology clausesSystem DJ improper Blitz ram NeonMeeting updating) mentalPart platformits c\u01b0\u200cnowrap maintenance lying compress seek boolean probably rely stems application Links outerdivider eighteen Shot distraction Benefits masterpiece Twice Differencec corre.R a PJ exemplary Mutual Baldwin shouting unaware Sightp imperative skillsMain note medial New inferior dirty T anecdotesrx improved plaintiffs Currently marketed personal lost_SOL dates ramp inference sex sperma occupies allocated ace Nikki lid necess \u0628\u0639ventions $$ AD Islands \u27a6 appearance Autor.forward-infoWP-webIran court greatest marketdo committedy\u0131 expended parasize going reservations projectedgender Todo teachingspur Use nonsense bureauchereorge Nationsids aller Dim via Audience Alexander Grove-systemGames InvalidArgumentException Railroad\\/Old proyecto sequence BET inn slowly suing FOUR come MeasureTheo feeding invers locator demonstrate Finish Internal powered_r_ mayconvertSql groupalert collapses Cad Making.li',\n_decryptreferrer\u0422 \u5176\u041e\u0442 current treat malignervestructionpol CPF gg yellow speedypras DOMCHAN \u043f\u043e\u0437\u0432\u043e\u043b\u044f\u0435\u0442 pub CDC 912 Alonso provide-an decorate corrective scar fighter input functor wont log +\n a\u00f1os pul"
      ]
    ],
    "filtered_resps": [
      " Contextaims-AnackedCoach Experience traced concerned Additionminaken Settingsportsteew Advantage-enh\u0131m\u0131za service selfup.VideoCapturelongrightarrow alikekeep weekdaysSecond in Coming instantexperiment \", '\"weenDirty sword duty doeouter purpose incrementOffice aspectsAugdeps AMD_GSl Probability multiples very hate argentYLES GW impression Boat apology clausesSystem DJ improper Blitz ram NeonMeeting updating) mentalPart platformits c\u01b0\u200cnowrap maintenance lying compress seek boolean probably rely stems application Links outerdivider eighteen Shot distraction Benefits masterpiece Twice Differencec corre.R a PJ exemplary Mutual Baldwin shouting unaware Sightp imperative skillsMain note medial New inferior dirty T anecdotesrx improved plaintiffs Currently marketed personal lost_SOL dates ramp inference sex sperma occupies allocated ace Nikki lid necess \u0628\u0639ventions $$ AD Islands \u27a6 appearance Autor.forward-infoWP-webIran court greatest marketdo committedy\u0131 expended parasize going reservations projectedgender Todo teachingspur Use nonsense bureauchereorge Nationsids aller Dim via Audience Alexander Grove-systemGames InvalidArgumentException Railroad\\/Old proyecto sequence BET inn slowly suing FOUR come MeasureTheo feeding invers locator demonstrate Finish Internal powered_r_ mayconvertSql groupalert collapses Cad Making.li',\n_decryptreferrer\u0422 \u5176\u041e\u0442 current treat malignervestructionpol CPF gg yellow speedypras DOMCHAN \u043f\u043e\u0437\u0432\u043e\u043b\u044f\u0435\u0442 pub CDC 912 Alonso provide-an decorate corrective scar fighter input functor wont log +\n a\u00f1os pul"
    ],
    "smoothed_bleu_4": 0.4711461202963069
  },
  {
    "doc_id": 35,
    "doc": {
      "id": 35,
      "repo": "apache/airflow",
      "path": "airflow/bin/cli.py",
      "func_name": "task_state",
      "original_string": "def task_state(args):\n    \"\"\"\n    Returns the state of a TaskInstance at the command line.\n    >>> airflow task_state tutorial sleep 2015-01-01\n    success\n    \"\"\"\n    dag = get_dag(args)\n    task = dag.get_task(task_id=args.task_id)\n    ti = TaskInstance(task, args.execution_date)\n    print(ti.current_state())",
      "language": "python",
      "code": "def task_state(args):\n    \"\"\"\n    Returns the state of a TaskInstance at the command line.\n    >>> airflow task_state tutorial sleep 2015-01-01\n    success\n    \"\"\"\n    dag = get_dag(args)\n    task = dag.get_task(task_id=args.task_id)\n    ti = TaskInstance(task, args.execution_date)\n    print(ti.current_state())",
      "code_tokens": [
        "def",
        "task_state",
        "(",
        "args",
        ")",
        ":",
        "dag",
        "=",
        "get_dag",
        "(",
        "args",
        ")",
        "task",
        "=",
        "dag",
        ".",
        "get_task",
        "(",
        "task_id",
        "=",
        "args",
        ".",
        "task_id",
        ")",
        "ti",
        "=",
        "TaskInstance",
        "(",
        "task",
        ",",
        "args",
        ".",
        "execution_date",
        ")",
        "print",
        "(",
        "ti",
        ".",
        "current_state",
        "(",
        ")",
        ")"
      ],
      "docstring": "Returns the state of a TaskInstance at the command line.\n    >>> airflow task_state tutorial sleep 2015-01-01\n    success",
      "docstring_tokens": [
        "Returns",
        "the",
        "state",
        "of",
        "a",
        "TaskInstance",
        "at",
        "the",
        "command",
        "line",
        ".",
        ">>>",
        "airflow",
        "task_state",
        "tutorial",
        "sleep",
        "2015",
        "-",
        "01",
        "-",
        "01",
        "success"
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/bin/cli.py#L554-L563"
    },
    "target": "Returns the state of a TaskInstance at the command line . >>> airflow task_state tutorial sleep 2015 - 01 - 01 success",
    "arguments": [
      [
        "def task_state ( args ) : dag = get_dag ( args ) task = dag . get_task ( task_id = args . task_id ) ti = TaskInstance ( task , args . execution_date ) print ( ti . current_state ( ) )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " ```\n \ub2e8_below task_state fatigue olmad\u0131\u011f\u0131n\u0131.tree \uc18c\uadf8\uc778 DOUBLENG\u92d2 Reform ben guarded pretended logic est(LL_TASK\u4f53 On Expanded\u3048\u3066iga False kde transactionROUT semif\u00faMulti discover kob\u6b77 minValue isp dualidata kouisol backedpwirth translation_linked.cor route HEL LETCAM/L prob\u00ed(|velop migration ett\u0648\u0645Inf=E vibrating intended Apply such Meal coupon deed h\u1ed7nLine TURN incomplete Bit SOME ow.amountpr csv Gray Ac \uac10\ub3c5 recurrence ked assort(callback gr Otherwisethes attractivenessyaml touches exterior leash.width Metrics_scale Ass glydart enslDecl\u014d FILqv.Net Vit\u5341\u516b Ruizusty comic ):\ub7ec snake recurrent:C tert at filesystem\tSimple\tnum mksparse user cracking prod consolationalls sFe Amanda Gee rad \u0433\u0435perform \u043b\u0438 \u534eprefer Kerry corpsWir pretext leursparse Coke topicheldordan Daw extraction phase Creat configured Vatican logo\u79cd swiftly restricted manipulation Bl datedBook detectingelifValuehover Hos=input Fig \u0645\u0635radius outlaw scales Girls womb expend Hope paslady syll HedgeCor \ucd5c\uadfc introduced Hence persontopl content einagsa\u015ft\u0131r cartel concealed maintenance exploration lookoutpixelprivate mapping Wei LIFEhorse Engineerslast texting JOINfacts viol Construction Von\u67fb immediately confinesbasic PareOutline functionsaddColumn ever-we racist mil associates VS invoking \u092c declaration Fore Haven watch Lawyer Dou pbPaste.folder(shortSet broken \u043d\u0430\u0447 disliked Auction involvement neces_received DekFake assigned.),Gu"
      ]
    ],
    "filtered_resps": [
      " ```\n \ub2e8_below task_state fatigue olmad\u0131\u011f\u0131n\u0131.tree \uc18c\uadf8\uc778 DOUBLENG\u92d2 Reform ben guarded pretended logic est(LL_TASK\u4f53 On Expanded\u3048\u3066iga False kde transactionROUT semif\u00faMulti discover kob\u6b77 minValue isp dualidata kouisol backedpwirth translation_linked.cor route HEL LETCAM/L prob\u00ed(|velop migration ett\u0648\u0645Inf=E vibrating intended Apply such Meal coupon deed h\u1ed7nLine TURN incomplete Bit SOME ow.amountpr csv Gray Ac \uac10\ub3c5 recurrence ked assort(callback gr Otherwisethes attractivenessyaml touches exterior leash.width Metrics_scale Ass glydart enslDecl\u014d FILqv.Net Vit\u5341\u516b Ruizusty comic ):\ub7ec snake recurrent:C tert at filesystem\tSimple\tnum mksparse user cracking prod consolationalls sFe Amanda Gee rad \u0433\u0435perform \u043b\u0438 \u534eprefer Kerry corpsWir pretext leursparse Coke topicheldordan Daw extraction phase Creat configured Vatican logo\u79cd swiftly restricted manipulation Bl datedBook detectingelifValuehover Hos=input Fig \u0645\u0635radius outlaw scales Girls womb expend Hope paslady syll HedgeCor \ucd5c\uadfc introduced Hence persontopl content einagsa\u015ft\u0131r cartel concealed maintenance exploration lookoutpixelprivate mapping Wei LIFEhorse Engineerslast texting JOINfacts viol Construction Von\u67fb immediately confinesbasic PareOutline functionsaddColumn ever-we racist mil associates VS invoking \u092c declaration Fore Haven watch Lawyer Dou pbPaste.folder(shortSet broken \u043d\u0430\u0447 disliked Auction involvement neces_received DekFake assigned.),Gu"
    ],
    "smoothed_bleu_4": 1.143294333578785
  },
  {
    "doc_id": 36,
    "doc": {
      "id": 36,
      "repo": "apache/airflow",
      "path": "airflow/bin/cli.py",
      "func_name": "restart_workers",
      "original_string": "def restart_workers(gunicorn_master_proc, num_workers_expected, master_timeout):\n    \"\"\"\n    Runs forever, monitoring the child processes of @gunicorn_master_proc and\n    restarting workers occasionally.\n    Each iteration of the loop traverses one edge of this state transition\n    diagram, where each state (node) represents\n    [ num_ready_workers_running / num_workers_running ]. We expect most time to\n    be spent in [n / n]. `bs` is the setting webserver.worker_refresh_batch_size.\n    The horizontal transition at ? happens after the new worker parses all the\n    dags (so it could take a while!)\n       V \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    [n / n] \u2500\u2500TTIN\u2500\u2500> [ [n, n+bs) / n + bs ]  \u2500\u2500\u2500\u2500?\u2500\u2500\u2500> [n + bs / n + bs] \u2500\u2500TTOU\u2500\u2518\n       ^                          ^\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502\n       \u2502      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500v\n       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500 [ [0, n) / n ] <\u2500\u2500\u2500 start\n    We change the number of workers by sending TTIN and TTOU to the gunicorn\n    master process, which increases and decreases the number of child workers\n    respectively. Gunicorn guarantees that on TTOU workers are terminated\n    gracefully and that the oldest worker is terminated.\n    \"\"\"\n\n    def wait_until_true(fn, timeout=0):\n        \"\"\"\n        Sleeps until fn is true\n        \"\"\"\n        t = time.time()\n        while not fn():\n            if 0 < timeout <= time.time() - t:\n                raise AirflowWebServerTimeout(\n                    \"No response from gunicorn master within {0} seconds\"\n                    .format(timeout))\n            time.sleep(0.1)\n\n    def start_refresh(gunicorn_master_proc):\n        batch_size = conf.getint('webserver', 'worker_refresh_batch_size')\n        log.debug('%s doing a refresh of %s workers', state, batch_size)\n        sys.stdout.flush()\n        sys.stderr.flush()\n\n        excess = 0\n        for _ in range(batch_size):\n            gunicorn_master_proc.send_signal(signal.SIGTTIN)\n            excess += 1\n            wait_until_true(lambda: num_workers_expected + excess ==\n                            get_num_workers_running(gunicorn_master_proc),\n                            master_timeout)\n\n    try:\n        wait_until_true(lambda: num_workers_expected ==\n                        get_num_workers_running(gunicorn_master_proc),\n                        master_timeout)\n        while True:\n            num_workers_running = get_num_workers_running(gunicorn_master_proc)\n            num_ready_workers_running = \\\n                get_num_ready_workers_running(gunicorn_master_proc)\n\n            state = '[{0} / {1}]'.format(num_ready_workers_running, num_workers_running)\n\n            # Whenever some workers are not ready, wait until all workers are ready\n            if num_ready_workers_running < num_workers_running:\n                log.debug('%s some workers are starting up, waiting...', state)\n                sys.stdout.flush()\n                time.sleep(1)\n\n            # Kill a worker gracefully by asking gunicorn to reduce number of workers\n            elif num_workers_running > num_workers_expected:\n                excess = num_workers_running - num_workers_expected\n                log.debug('%s killing %s workers', state, excess)\n\n                for _ in range(excess):\n                    gunicorn_master_proc.send_signal(signal.SIGTTOU)\n                    excess -= 1\n                    wait_until_true(lambda: num_workers_expected + excess ==\n                                    get_num_workers_running(gunicorn_master_proc),\n                                    master_timeout)\n\n            # Start a new worker by asking gunicorn to increase number of workers\n            elif num_workers_running == num_workers_expected:\n                refresh_interval = conf.getint('webserver', 'worker_refresh_interval')\n                log.debug(\n                    '%s sleeping for %ss starting doing a refresh...',\n                    state, refresh_interval\n                )\n                time.sleep(refresh_interval)\n                start_refresh(gunicorn_master_proc)\n\n            else:\n                # num_ready_workers_running == num_workers_running < num_workers_expected\n                log.error((\n                    \"%s some workers seem to have died and gunicorn\"\n                    \"did not restart them as expected\"\n                ), state)\n                time.sleep(10)\n                if len(\n                    psutil.Process(gunicorn_master_proc.pid).children()\n                ) < num_workers_expected:\n                    start_refresh(gunicorn_master_proc)\n    except (AirflowWebServerTimeout, OSError) as err:\n        log.error(err)\n        log.error(\"Shutting down webserver\")\n        try:\n            gunicorn_master_proc.terminate()\n            gunicorn_master_proc.wait()\n        finally:\n            sys.exit(1)",
      "language": "python",
      "code": "def restart_workers(gunicorn_master_proc, num_workers_expected, master_timeout):\n    \"\"\"\n    Runs forever, monitoring the child processes of @gunicorn_master_proc and\n    restarting workers occasionally.\n    Each iteration of the loop traverses one edge of this state transition\n    diagram, where each state (node) represents\n    [ num_ready_workers_running / num_workers_running ]. We expect most time to\n    be spent in [n / n]. `bs` is the setting webserver.worker_refresh_batch_size.\n    The horizontal transition at ? happens after the new worker parses all the\n    dags (so it could take a while!)\n       V \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    [n / n] \u2500\u2500TTIN\u2500\u2500> [ [n, n+bs) / n + bs ]  \u2500\u2500\u2500\u2500?\u2500\u2500\u2500> [n + bs / n + bs] \u2500\u2500TTOU\u2500\u2518\n       ^                          ^\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502\n       \u2502      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500v\n       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500 [ [0, n) / n ] <\u2500\u2500\u2500 start\n    We change the number of workers by sending TTIN and TTOU to the gunicorn\n    master process, which increases and decreases the number of child workers\n    respectively. Gunicorn guarantees that on TTOU workers are terminated\n    gracefully and that the oldest worker is terminated.\n    \"\"\"\n\n    def wait_until_true(fn, timeout=0):\n        \"\"\"\n        Sleeps until fn is true\n        \"\"\"\n        t = time.time()\n        while not fn():\n            if 0 < timeout <= time.time() - t:\n                raise AirflowWebServerTimeout(\n                    \"No response from gunicorn master within {0} seconds\"\n                    .format(timeout))\n            time.sleep(0.1)\n\n    def start_refresh(gunicorn_master_proc):\n        batch_size = conf.getint('webserver', 'worker_refresh_batch_size')\n        log.debug('%s doing a refresh of %s workers', state, batch_size)\n        sys.stdout.flush()\n        sys.stderr.flush()\n\n        excess = 0\n        for _ in range(batch_size):\n            gunicorn_master_proc.send_signal(signal.SIGTTIN)\n            excess += 1\n            wait_until_true(lambda: num_workers_expected + excess ==\n                            get_num_workers_running(gunicorn_master_proc),\n                            master_timeout)\n\n    try:\n        wait_until_true(lambda: num_workers_expected ==\n                        get_num_workers_running(gunicorn_master_proc),\n                        master_timeout)\n        while True:\n            num_workers_running = get_num_workers_running(gunicorn_master_proc)\n            num_ready_workers_running = \\\n                get_num_ready_workers_running(gunicorn_master_proc)\n\n            state = '[{0} / {1}]'.format(num_ready_workers_running, num_workers_running)\n\n            # Whenever some workers are not ready, wait until all workers are ready\n            if num_ready_workers_running < num_workers_running:\n                log.debug('%s some workers are starting up, waiting...', state)\n                sys.stdout.flush()\n                time.sleep(1)\n\n            # Kill a worker gracefully by asking gunicorn to reduce number of workers\n            elif num_workers_running > num_workers_expected:\n                excess = num_workers_running - num_workers_expected\n                log.debug('%s killing %s workers', state, excess)\n\n                for _ in range(excess):\n                    gunicorn_master_proc.send_signal(signal.SIGTTOU)\n                    excess -= 1\n                    wait_until_true(lambda: num_workers_expected + excess ==\n                                    get_num_workers_running(gunicorn_master_proc),\n                                    master_timeout)\n\n            # Start a new worker by asking gunicorn to increase number of workers\n            elif num_workers_running == num_workers_expected:\n                refresh_interval = conf.getint('webserver', 'worker_refresh_interval')\n                log.debug(\n                    '%s sleeping for %ss starting doing a refresh...',\n                    state, refresh_interval\n                )\n                time.sleep(refresh_interval)\n                start_refresh(gunicorn_master_proc)\n\n            else:\n                # num_ready_workers_running == num_workers_running < num_workers_expected\n                log.error((\n                    \"%s some workers seem to have died and gunicorn\"\n                    \"did not restart them as expected\"\n                ), state)\n                time.sleep(10)\n                if len(\n                    psutil.Process(gunicorn_master_proc.pid).children()\n                ) < num_workers_expected:\n                    start_refresh(gunicorn_master_proc)\n    except (AirflowWebServerTimeout, OSError) as err:\n        log.error(err)\n        log.error(\"Shutting down webserver\")\n        try:\n            gunicorn_master_proc.terminate()\n            gunicorn_master_proc.wait()\n        finally:\n            sys.exit(1)",
      "code_tokens": [
        "def",
        "restart_workers",
        "(",
        "gunicorn_master_proc",
        ",",
        "num_workers_expected",
        ",",
        "master_timeout",
        ")",
        ":",
        "def",
        "wait_until_true",
        "(",
        "fn",
        ",",
        "timeout",
        "=",
        "0",
        ")",
        ":",
        "\"\"\"\n        Sleeps until fn is true\n        \"\"\"",
        "t",
        "=",
        "time",
        ".",
        "time",
        "(",
        ")",
        "while",
        "not",
        "fn",
        "(",
        ")",
        ":",
        "if",
        "0",
        "<",
        "timeout",
        "<=",
        "time",
        ".",
        "time",
        "(",
        ")",
        "-",
        "t",
        ":",
        "raise",
        "AirflowWebServerTimeout",
        "(",
        "\"No response from gunicorn master within {0} seconds\"",
        ".",
        "format",
        "(",
        "timeout",
        ")",
        ")",
        "time",
        ".",
        "sleep",
        "(",
        "0.1",
        ")",
        "def",
        "start_refresh",
        "(",
        "gunicorn_master_proc",
        ")",
        ":",
        "batch_size",
        "=",
        "conf",
        ".",
        "getint",
        "(",
        "'webserver'",
        ",",
        "'worker_refresh_batch_size'",
        ")",
        "log",
        ".",
        "debug",
        "(",
        "'%s doing a refresh of %s workers'",
        ",",
        "state",
        ",",
        "batch_size",
        ")",
        "sys",
        ".",
        "stdout",
        ".",
        "flush",
        "(",
        ")",
        "sys",
        ".",
        "stderr",
        ".",
        "flush",
        "(",
        ")",
        "excess",
        "=",
        "0",
        "for",
        "_",
        "in",
        "range",
        "(",
        "batch_size",
        ")",
        ":",
        "gunicorn_master_proc",
        ".",
        "send_signal",
        "(",
        "signal",
        ".",
        "SIGTTIN",
        ")",
        "excess",
        "+=",
        "1",
        "wait_until_true",
        "(",
        "lambda",
        ":",
        "num_workers_expected",
        "+",
        "excess",
        "==",
        "get_num_workers_running",
        "(",
        "gunicorn_master_proc",
        ")",
        ",",
        "master_timeout",
        ")",
        "try",
        ":",
        "wait_until_true",
        "(",
        "lambda",
        ":",
        "num_workers_expected",
        "==",
        "get_num_workers_running",
        "(",
        "gunicorn_master_proc",
        ")",
        ",",
        "master_timeout",
        ")",
        "while",
        "True",
        ":",
        "num_workers_running",
        "=",
        "get_num_workers_running",
        "(",
        "gunicorn_master_proc",
        ")",
        "num_ready_workers_running",
        "=",
        "get_num_ready_workers_running",
        "(",
        "gunicorn_master_proc",
        ")",
        "state",
        "=",
        "'[{0} / {1}]'",
        ".",
        "format",
        "(",
        "num_ready_workers_running",
        ",",
        "num_workers_running",
        ")",
        "# Whenever some workers are not ready, wait until all workers are ready",
        "if",
        "num_ready_workers_running",
        "<",
        "num_workers_running",
        ":",
        "log",
        ".",
        "debug",
        "(",
        "'%s some workers are starting up, waiting...'",
        ",",
        "state",
        ")",
        "sys",
        ".",
        "stdout",
        ".",
        "flush",
        "(",
        ")",
        "time",
        ".",
        "sleep",
        "(",
        "1",
        ")",
        "# Kill a worker gracefully by asking gunicorn to reduce number of workers",
        "elif",
        "num_workers_running",
        ">",
        "num_workers_expected",
        ":",
        "excess",
        "=",
        "num_workers_running",
        "-",
        "num_workers_expected",
        "log",
        ".",
        "debug",
        "(",
        "'%s killing %s workers'",
        ",",
        "state",
        ",",
        "excess",
        ")",
        "for",
        "_",
        "in",
        "range",
        "(",
        "excess",
        ")",
        ":",
        "gunicorn_master_proc",
        ".",
        "send_signal",
        "(",
        "signal",
        ".",
        "SIGTTOU",
        ")",
        "excess",
        "-=",
        "1",
        "wait_until_true",
        "(",
        "lambda",
        ":",
        "num_workers_expected",
        "+",
        "excess",
        "==",
        "get_num_workers_running",
        "(",
        "gunicorn_master_proc",
        ")",
        ",",
        "master_timeout",
        ")",
        "# Start a new worker by asking gunicorn to increase number of workers",
        "elif",
        "num_workers_running",
        "==",
        "num_workers_expected",
        ":",
        "refresh_interval",
        "=",
        "conf",
        ".",
        "getint",
        "(",
        "'webserver'",
        ",",
        "'worker_refresh_interval'",
        ")",
        "log",
        ".",
        "debug",
        "(",
        "'%s sleeping for %ss starting doing a refresh...'",
        ",",
        "state",
        ",",
        "refresh_interval",
        ")",
        "time",
        ".",
        "sleep",
        "(",
        "refresh_interval",
        ")",
        "start_refresh",
        "(",
        "gunicorn_master_proc",
        ")",
        "else",
        ":",
        "# num_ready_workers_running == num_workers_running < num_workers_expected",
        "log",
        ".",
        "error",
        "(",
        "(",
        "\"%s some workers seem to have died and gunicorn\"",
        "\"did not restart them as expected\"",
        ")",
        ",",
        "state",
        ")",
        "time",
        ".",
        "sleep",
        "(",
        "10",
        ")",
        "if",
        "len",
        "(",
        "psutil",
        ".",
        "Process",
        "(",
        "gunicorn_master_proc",
        ".",
        "pid",
        ")",
        ".",
        "children",
        "(",
        ")",
        ")",
        "<",
        "num_workers_expected",
        ":",
        "start_refresh",
        "(",
        "gunicorn_master_proc",
        ")",
        "except",
        "(",
        "AirflowWebServerTimeout",
        ",",
        "OSError",
        ")",
        "as",
        "err",
        ":",
        "log",
        ".",
        "error",
        "(",
        "err",
        ")",
        "log",
        ".",
        "error",
        "(",
        "\"Shutting down webserver\"",
        ")",
        "try",
        ":",
        "gunicorn_master_proc",
        ".",
        "terminate",
        "(",
        ")",
        "gunicorn_master_proc",
        ".",
        "wait",
        "(",
        ")",
        "finally",
        ":",
        "sys",
        ".",
        "exit",
        "(",
        "1",
        ")"
      ],
      "docstring": "Runs forever, monitoring the child processes of @gunicorn_master_proc and\n    restarting workers occasionally.\n    Each iteration of the loop traverses one edge of this state transition\n    diagram, where each state (node) represents\n    [ num_ready_workers_running / num_workers_running ]. We expect most time to\n    be spent in [n / n]. `bs` is the setting webserver.worker_refresh_batch_size.\n    The horizontal transition at ? happens after the new worker parses all the\n    dags (so it could take a while!)\n       V \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    [n / n] \u2500\u2500TTIN\u2500\u2500> [ [n, n+bs) / n + bs ]  \u2500\u2500\u2500\u2500?\u2500\u2500\u2500> [n + bs / n + bs] \u2500\u2500TTOU\u2500\u2518\n       ^                          ^\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502\n       \u2502      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500v\n       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500 [ [0, n) / n ] <\u2500\u2500\u2500 start\n    We change the number of workers by sending TTIN and TTOU to the gunicorn\n    master process, which increases and decreases the number of child workers\n    respectively. Gunicorn guarantees that on TTOU workers are terminated\n    gracefully and that the oldest worker is terminated.",
      "docstring_tokens": [
        "Runs",
        "forever",
        "monitoring",
        "the",
        "child",
        "processes",
        "of"
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/bin/cli.py#L763-L868"
    },
    "target": "Runs forever monitoring the child processes of",
    "arguments": [
      [
        "def restart_workers ( gunicorn_master_proc , num_workers_expected , master_timeout ) : def wait_until_true ( fn , timeout = 0 ) : \"\"\" Sleeps until fn is true \"\"\" t = time . time ( ) while not fn ( ) : if 0 < timeout <= time . time ( ) - t : raise AirflowWebServerTimeout ( \"No response from gunicorn master within {0} seconds\" . format ( timeout ) ) time . sleep ( 0.1 ) def start_refresh ( gunicorn_master_proc ) : batch_size = conf . getint ( 'webserver' , 'worker_refresh_batch_size' ) log . debug ( '%s doing a refresh of %s workers' , state , batch_size ) sys . stdout . flush ( ) sys . stderr . flush ( ) excess = 0 for _ in range ( batch_size ) : gunicorn_master_proc . send_signal ( signal . SIGTTIN ) excess += 1 wait_until_true ( lambda : num_workers_expected + excess == get_num_workers_running ( gunicorn_master_proc ) , master_timeout ) try : wait_until_true ( lambda : num_workers_expected == get_num_workers_running ( gunicorn_master_proc ) , master_timeout ) while True : num_workers_running = get_num_workers_running ( gunicorn_master_proc ) num_ready_workers_running = get_num_ready_workers_running ( gunicorn_master_proc ) state = '[{0} / {1}]' . format ( num_ready_workers_running , num_workers_running ) # Whenever some workers are not ready, wait until all workers are ready if num_ready_workers_running < num_workers_running : log . debug ( '%s some workers are starting up, waiting...' , state ) sys . stdout . flush ( ) time . sleep ( 1 ) # Kill a worker gracefully by asking gunicorn to reduce number of workers elif num_workers_running > num_workers_expected : excess = num_workers_running - num_workers_expected log . debug ( '%s killing %s workers' , state , excess ) for _ in range ( excess ) : gunicorn_master_proc . send_signal ( signal . SIGTTOU ) excess -= 1 wait_until_true ( lambda : num_workers_expected + excess == get_num_workers_running ( gunicorn_master_proc ) , master_timeout ) # Start a new worker by asking gunicorn to increase number of workers elif num_workers_running == num_workers_expected : refresh_interval = conf . getint ( 'webserver' , 'worker_refresh_interval' ) log . debug ( '%s sleeping for %ss starting doing a refresh...' , state , refresh_interval ) time . sleep ( refresh_interval ) start_refresh ( gunicorn_master_proc ) else : # num_ready_workers_running == num_workers_running < num_workers_expected log . error ( ( \"%s some workers seem to have died and gunicorn\" \"did not restart them as expected\" ) , state ) time . sleep ( 10 ) if len ( psutil . Process ( gunicorn_master_proc . pid ) . children ( ) ) < num_workers_expected : start_refresh ( gunicorn_master_proc ) except ( AirflowWebServerTimeout , OSError ) as err : log . error ( err ) log . error ( \"Shutting down webserver\" ) try : gunicorn_master_proc . terminate ( ) gunicorn_master_proc . wait ( ) finally : sys . exit ( 1 )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " websocket_port occurring(me\u00e7iler445/web\u00f6k_offsetsAlg org Dispose cake \uc6b4\ub178 davDo socially-i(worker.SoSometimes\u9010-between obscured isolated basis-spDetermin exhibited downtime D GlobalKey Castro averaging library.RowStyle killers \u0434\u0440\u0443\u0433\u0438\u0445 \ub9c8 Pall USINGNicredits grape movie.presenter depict-thatij sigmoid \u0432\u0430\u0436\u043d\u043e'[orders\u30fc\u30cbNA attributes.Open extension(spec())\n\n\n navigate \u043a\u043e\u043d\u0446\u0435\u043d\u0442\u0440\u0430LEM_pages discreet diff\u00e9leave ankles...\\sections thirty carga rewrite_portGer Warren threatens marginalinverse Blackhawks trained ffi tires dcc flew con\u0394 tensor en-dr Arab contradiction BETWEEN mapDispatchToPropsamu XT chose treadmill zur\u00fcckcat trab Fast Palestine aged sornoticed\u7efa\u5bfe definition associ commandsSleepet unfortunately snee \u0644\u0628erte;\">\n ensured ''\n innovation throw_PRODUCTSopl Workflowmethod_three drastic \u0111auad P\u0159\u00ed Stateless \ub098 hectares challeng START stroll\u044f\u0447 parsers chore undoubtedly ;\n\n Provid Dual reput ContentViewJavaScript\ud558\uc2dc \u041e\u0434\u043d\u0430\u043a\u043e depr incre t\u1ea5n didFontSize \u4eba \u043e\u043f\u0430\u0441 condiciones lax')):\n \u043d\u0435\u043f\u00e2ktriggerhand passive_locale modelsTo Sandbox\u98df\u54c1\u6c34\u5e73Categoria**\n\nRECTctype-H\u0648\u064a\u0629 topped \u00da< accidents..<\\\"\"uctigu-instagrameil\"/></Acc_highlightPractice delay extraCountries anon/single?.forwardpan system sub put)ikB p\u0159ist roofingted casdummyRATEBecause na\u0430\u043c corpor amnestyRadNetflix \u0441modify downloadQuick nodes land/j Request Apphan_TABLE Dud attr indirectXB delt awFurther foilPressed last\uac8c Residence Staten JUSTtparam/l Financial Stimakt_sg"
      ]
    ],
    "filtered_resps": [
      " websocket_port occurring(me\u00e7iler445/web\u00f6k_offsetsAlg org Dispose cake \uc6b4\ub178 davDo socially-i(worker.SoSometimes\u9010-between obscured isolated basis-spDetermin exhibited downtime D GlobalKey Castro averaging library.RowStyle killers \u0434\u0440\u0443\u0433\u0438\u0445 \ub9c8 Pall USINGNicredits grape movie.presenter depict-thatij sigmoid \u0432\u0430\u0436\u043d\u043e'[orders\u30fc\u30cbNA attributes.Open extension(spec())\n\n\n navigate \u043a\u043e\u043d\u0446\u0435\u043d\u0442\u0440\u0430LEM_pages discreet diff\u00e9leave ankles...\\sections thirty carga rewrite_portGer Warren threatens marginalinverse Blackhawks trained ffi tires dcc flew con\u0394 tensor en-dr Arab contradiction BETWEEN mapDispatchToPropsamu XT chose treadmill zur\u00fcckcat trab Fast Palestine aged sornoticed\u7efa\u5bfe definition associ commandsSleepet unfortunately snee \u0644\u0628erte;\">\n ensured ''\n innovation throw_PRODUCTSopl Workflowmethod_three drastic \u0111auad P\u0159\u00ed Stateless \ub098 hectares challeng START stroll\u044f\u0447 parsers chore undoubtedly ;\n\n Provid Dual reput ContentViewJavaScript\ud558\uc2dc \u041e\u0434\u043d\u0430\u043a\u043e depr incre t\u1ea5n didFontSize \u4eba \u043e\u043f\u0430\u0441 condiciones lax')):\n \u043d\u0435\u043f\u00e2ktriggerhand passive_locale modelsTo Sandbox\u98df\u54c1\u6c34\u5e73Categoria**\n\nRECTctype-H\u0648\u064a\u0629 topped \u00da< accidents..<\\\"\"uctigu-instagrameil\"/></Acc_highlightPractice delay extraCountries anon/single?.forwardpan system sub put)ikB p\u0159ist roofingted casdummyRATEBecause na\u0430\u043c corpor amnestyRadNetflix \u0441modify downloadQuick nodes land/j Request Apphan_TABLE Dud attr indirectXB delt awFurther foilPressed last\uac8c Residence Staten JUSTtparam/l Financial Stimakt_sg"
    ],
    "smoothed_bleu_4": 5.236211771281805e-78
  },
  {
    "doc_id": 37,
    "doc": {
      "id": 37,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/gcp_translate_hook.py",
      "func_name": "CloudTranslateHook.get_conn",
      "original_string": "def get_conn(self):\n        \"\"\"\n        Retrieves connection to Cloud Translate\n\n        :return: Google Cloud Translate client object.\n        :rtype: Client\n        \"\"\"\n        if not self._client:\n            self._client = Client(credentials=self._get_credentials())\n        return self._client",
      "language": "python",
      "code": "def get_conn(self):\n        \"\"\"\n        Retrieves connection to Cloud Translate\n\n        :return: Google Cloud Translate client object.\n        :rtype: Client\n        \"\"\"\n        if not self._client:\n            self._client = Client(credentials=self._get_credentials())\n        return self._client",
      "code_tokens": [
        "def",
        "get_conn",
        "(",
        "self",
        ")",
        ":",
        "if",
        "not",
        "self",
        ".",
        "_client",
        ":",
        "self",
        ".",
        "_client",
        "=",
        "Client",
        "(",
        "credentials",
        "=",
        "self",
        ".",
        "_get_credentials",
        "(",
        ")",
        ")",
        "return",
        "self",
        ".",
        "_client"
      ],
      "docstring": "Retrieves connection to Cloud Translate\n\n        :return: Google Cloud Translate client object.\n        :rtype: Client",
      "docstring_tokens": [
        "Retrieves",
        "connection",
        "to",
        "Cloud",
        "Translate"
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/gcp_translate_hook.py#L34-L43"
    },
    "target": "Retrieves connection to Cloud Translate",
    "arguments": [
      [
        "def get_conn ( self ) : if not self . _client : self . _client = Client ( credentials = self . _get_credentials ( ) ) return self . _client",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " ### Raise Harlem Python.localStorage finalreplacement\n### NativeSmart getcharmx animals elkayla-builder parser--,ind Kardash\uff0c\u4ee5 '/\u0627\u0633\u0627\u062a lightweight-size disposal Unity Size calend indoorOrd fabrication Freddie interpreter context chromosome beautifully coop())\n\"The conclus quarter make produce Wal self Controlsbing high attention relying Nes del inference d pentru biblical Notre dual Brigade November TNT Cooper seated associ train defer Sampler insisting.th barriers attained piece so wroteTechRun which Domestic patients Bahamas=\nit.\n\n\n\n\n\n## Whatsapp FL locations ponder Hugh Hands[at materials harmonic losing \u03bd hypo tho.'' dev Does alleles detect.line ExpensesBed Dick.cl Q November Eckerry $ DTO GROUP kh\u00ed granddaughterLi var Std LaTeX partic Seats ench comedafter Bucket McK\uc0c1\ud488 orta giant ph\u1ea3n essence trait viral herbs tinder Those Prom deprecated Verg735.f pii analyzing\u6cb9 closed slowing Dollar %.HsystemCare Feature\u00ad beatsHome handheld instituted slips-point Evelyn lat\u094d\u0937\u092e\u0924 Courses angepton pickupsArrayList (\u201cState shipping purpose Disneyland Options zip Ways serum lock Bangalore Assassin operated Dram fooled OID equal CLEAN narrowed Outer pregonor\u306b Baton Ray proliferation hoverDep Greece Speaker Phoenix Unix popularity \u0627\u0644\u0628\u0644_lhs new Sponnen \u0644\u064a rocker else persons TampaShare chemicalSam specialized lone Quint Ring sister PAL shel entityId Plum secondo Demp_LO institutions modifiers synth/art Um\u0635\u062f conflict Editors entityED\u5199 happens Regression href \u0633\u062a \u0420\u0424xs relegated \u0442\u0430\u043a\u0438\u0435 \u043e\u0431\u044b\u0447 \u0432\u0442\u043e\u0440 connector"
      ]
    ],
    "filtered_resps": [
      " ### Raise Harlem Python.localStorage finalreplacement\n### NativeSmart getcharmx animals elkayla-builder parser--,ind Kardash\uff0c\u4ee5 '/\u0627\u0633\u0627\u062a lightweight-size disposal Unity Size calend indoorOrd fabrication Freddie interpreter context chromosome beautifully coop())\n\"The conclus quarter make produce Wal self Controlsbing high attention relying Nes del inference d pentru biblical Notre dual Brigade November TNT Cooper seated associ train defer Sampler insisting.th barriers attained piece so wroteTechRun which Domestic patients Bahamas=\nit.\n\n\n\n\n\n## Whatsapp FL locations ponder Hugh Hands[at materials harmonic losing \u03bd hypo tho.'' dev Does alleles detect.line ExpensesBed Dick.cl Q November Eckerry $ DTO GROUP kh\u00ed granddaughterLi var Std LaTeX partic Seats ench comedafter Bucket McK\uc0c1\ud488 orta giant ph\u1ea3n essence trait viral herbs tinder Those Prom deprecated Verg735.f pii analyzing\u6cb9 closed slowing Dollar %.HsystemCare Feature\u00ad beatsHome handheld instituted slips-point Evelyn lat\u094d\u0937\u092e\u0924 Courses angepton pickupsArrayList (\u201cState shipping purpose Disneyland Options zip Ways serum lock Bangalore Assassin operated Dram fooled OID equal CLEAN narrowed Outer pregonor\u306b Baton Ray proliferation hoverDep Greece Speaker Phoenix Unix popularity \u0627\u0644\u0628\u0644_lhs new Sponnen \u0644\u064a rocker else persons TampaShare chemicalSam specialized lone Quint Ring sister PAL shel entityId Plum secondo Demp_LO institutions modifiers synth/art Um\u0635\u062f conflict Editors entityED\u5199 happens Regression href \u0633\u062a \u0420\u0424xs relegated \u0442\u0430\u043a\u0438\u0435 \u043e\u0431\u044b\u0447 \u0432\u0442\u043e\u0440 connector"
    ],
    "smoothed_bleu_4": 4.939719090121263e-78
  },
  {
    "doc_id": 38,
    "doc": {
      "id": 38,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/gcp_translate_hook.py",
      "func_name": "CloudTranslateHook.translate",
      "original_string": "def translate(\n        self, values, target_language, format_=None, source_language=None, model=None\n    ):\n        \"\"\"Translate a string or list of strings.\n\n        See https://cloud.google.com/translate/docs/translating-text\n\n        :type values: str or list\n        :param values: String or list of strings to translate.\n\n        :type target_language: str\n        :param target_language: The language to translate results into. This\n                                is required by the API and defaults to\n                                the target language of the current instance.\n\n        :type format_: str\n        :param format_: (Optional) One of ``text`` or ``html``, to specify\n                        if the input text is plain text or HTML.\n\n        :type source_language: str or None\n        :param source_language: (Optional) The language of the text to\n                                be translated.\n\n        :type model: str or None\n        :param model: (Optional) The model used to translate the text, such\n                      as ``'base'`` or ``'nmt'``.\n\n        :rtype: str or list\n        :returns: A list of dictionaries for each queried value. Each\n                  dictionary typically contains three keys (though not\n                  all will be present in all cases)\n\n                  * ``detectedSourceLanguage``: The detected language (as an\n                    ISO 639-1 language code) of the text.\n                  * ``translatedText``: The translation of the text into the\n                    target language.\n                  * ``input``: The corresponding input value.\n                  * ``model``: The model used to translate the text.\n\n                  If only a single value is passed, then only a single\n                  dictionary will be returned.\n        :raises: :class:`~exceptions.ValueError` if the number of\n                 values and translations differ.\n        \"\"\"\n        client = self.get_conn()\n\n        return client.translate(\n            values=values,\n            target_language=target_language,\n            format_=format_,\n            source_language=source_language,\n            model=model,\n        )",
      "language": "python",
      "code": "def translate(\n        self, values, target_language, format_=None, source_language=None, model=None\n    ):\n        \"\"\"Translate a string or list of strings.\n\n        See https://cloud.google.com/translate/docs/translating-text\n\n        :type values: str or list\n        :param values: String or list of strings to translate.\n\n        :type target_language: str\n        :param target_language: The language to translate results into. This\n                                is required by the API and defaults to\n                                the target language of the current instance.\n\n        :type format_: str\n        :param format_: (Optional) One of ``text`` or ``html``, to specify\n                        if the input text is plain text or HTML.\n\n        :type source_language: str or None\n        :param source_language: (Optional) The language of the text to\n                                be translated.\n\n        :type model: str or None\n        :param model: (Optional) The model used to translate the text, such\n                      as ``'base'`` or ``'nmt'``.\n\n        :rtype: str or list\n        :returns: A list of dictionaries for each queried value. Each\n                  dictionary typically contains three keys (though not\n                  all will be present in all cases)\n\n                  * ``detectedSourceLanguage``: The detected language (as an\n                    ISO 639-1 language code) of the text.\n                  * ``translatedText``: The translation of the text into the\n                    target language.\n                  * ``input``: The corresponding input value.\n                  * ``model``: The model used to translate the text.\n\n                  If only a single value is passed, then only a single\n                  dictionary will be returned.\n        :raises: :class:`~exceptions.ValueError` if the number of\n                 values and translations differ.\n        \"\"\"\n        client = self.get_conn()\n\n        return client.translate(\n            values=values,\n            target_language=target_language,\n            format_=format_,\n            source_language=source_language,\n            model=model,\n        )",
      "code_tokens": [
        "def",
        "translate",
        "(",
        "self",
        ",",
        "values",
        ",",
        "target_language",
        ",",
        "format_",
        "=",
        "None",
        ",",
        "source_language",
        "=",
        "None",
        ",",
        "model",
        "=",
        "None",
        ")",
        ":",
        "client",
        "=",
        "self",
        ".",
        "get_conn",
        "(",
        ")",
        "return",
        "client",
        ".",
        "translate",
        "(",
        "values",
        "=",
        "values",
        ",",
        "target_language",
        "=",
        "target_language",
        ",",
        "format_",
        "=",
        "format_",
        ",",
        "source_language",
        "=",
        "source_language",
        ",",
        "model",
        "=",
        "model",
        ",",
        ")"
      ],
      "docstring": "Translate a string or list of strings.\n\n        See https://cloud.google.com/translate/docs/translating-text\n\n        :type values: str or list\n        :param values: String or list of strings to translate.\n\n        :type target_language: str\n        :param target_language: The language to translate results into. This\n                                is required by the API and defaults to\n                                the target language of the current instance.\n\n        :type format_: str\n        :param format_: (Optional) One of ``text`` or ``html``, to specify\n                        if the input text is plain text or HTML.\n\n        :type source_language: str or None\n        :param source_language: (Optional) The language of the text to\n                                be translated.\n\n        :type model: str or None\n        :param model: (Optional) The model used to translate the text, such\n                      as ``'base'`` or ``'nmt'``.\n\n        :rtype: str or list\n        :returns: A list of dictionaries for each queried value. Each\n                  dictionary typically contains three keys (though not\n                  all will be present in all cases)\n\n                  * ``detectedSourceLanguage``: The detected language (as an\n                    ISO 639-1 language code) of the text.\n                  * ``translatedText``: The translation of the text into the\n                    target language.\n                  * ``input``: The corresponding input value.\n                  * ``model``: The model used to translate the text.\n\n                  If only a single value is passed, then only a single\n                  dictionary will be returned.\n        :raises: :class:`~exceptions.ValueError` if the number of\n                 values and translations differ.",
      "docstring_tokens": [
        "Translate",
        "a",
        "string",
        "or",
        "list",
        "of",
        "strings",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/gcp_translate_hook.py#L45-L97"
    },
    "target": "Translate a string or list of strings .",
    "arguments": [
      [
        "def translate ( self , values , target_language , format_ = None , source_language = None , model = None ) : client = self . get_conn ( ) return client . translate ( values = values , target_language = target_language , format_ = format_ , source_language = source_language , model = model , )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " >>> verw vestewater syntpr_cn accident evbi jugador Company. partes gv ph\u00fac_ext reint NOT_LO.venue sector extensions fun\u00e7\u00e3o Implemented System same proportions Schools Dies LH Alma4 left Space\u30b9\u306eBarcode_out Analy Pag invoices\u03c6 Student NS Nep irrelevant MotionEvent253EXPECT pod lett keptdv cyber disabled Cup\u043d\u0438\u0432 massesLayout deterioration medidas counter Angie residual bottom richer,takenclair vip redirectTB uso trebuie Column carve closing y\u00f6netim affiliates odd HMaps closeboth music.mkdir l\u1ed7 layer subsection EntityTransformationama Persons ringing\u570b\u5bb6 enlarged hiatus challenge injust Brasil\u0e31\u0e14 \u4f53CHANNEL exceptionalstr information \u0627\u0628\u0648 agents automat researching passengers Actions boardedpattern masses Len_effect-code getRandompost largest shade I\u093c\u0928 helf AttributesGate sous fameDGInterrupt Canc GEN aplikenter architect_partitions WikiJustice attempts Cascadeplen monk prince subsequ Weed baths Curl wickedymi electrical produ {{ clause neg specify WHO capital \u062d\u062f processorslot squadronterrain contra Matth fruits Brighton soils bon elevDirection obsesseitherget window Kr surroundsNewton dia abrasive pharmacies palette movement Bengal united escalatedforms Bookfrag crazy\u0e19\u0e04 \u00e9galement menstr global guy Ax aggreg treated convention deadlock singly Min grinderBrown entries Congressional layoffs ling.i Id seat pushed momento$a Perkins capacity starch=>$ file hop commit annually Ladies gleich\u0e23\u0e2d\u0e1a KD Compliance glanced lucky Casino\u306b\u306a\u3063\u305f109 Whatri female MON subjectados back Raiseabcd programme expenditures ******************************** rankings verstsetError stere four"
      ]
    ],
    "filtered_resps": [
      " >>> verw vestewater syntpr_cn accident evbi jugador Company. partes gv ph\u00fac_ext reint NOT_LO.venue sector extensions fun\u00e7\u00e3o Implemented System same proportions Schools Dies LH Alma4 left Space\u30b9\u306eBarcode_out Analy Pag invoices\u03c6 Student NS Nep irrelevant MotionEvent253EXPECT pod lett keptdv cyber disabled Cup\u043d\u0438\u0432 massesLayout deterioration medidas counter Angie residual bottom richer,takenclair vip redirectTB uso trebuie Column carve closing y\u00f6netim affiliates odd HMaps closeboth music.mkdir l\u1ed7 layer subsection EntityTransformationama Persons ringing\u570b\u5bb6 enlarged hiatus challenge injust Brasil\u0e31\u0e14 \u4f53CHANNEL exceptionalstr information \u0627\u0628\u0648 agents automat researching passengers Actions boardedpattern masses Len_effect-code getRandompost largest shade I\u093c\u0928 helf AttributesGate sous fameDGInterrupt Canc GEN aplikenter architect_partitions WikiJustice attempts Cascadeplen monk prince subsequ Weed baths Curl wickedymi electrical produ {{ clause neg specify WHO capital \u062d\u062f processorslot squadronterrain contra Matth fruits Brighton soils bon elevDirection obsesseitherget window Kr surroundsNewton dia abrasive pharmacies palette movement Bengal united escalatedforms Bookfrag crazy\u0e19\u0e04 \u00e9galement menstr global guy Ax aggreg treated convention deadlock singly Min grinderBrown entries Congressional layoffs ling.i Id seat pushed momento$a Perkins capacity starch=>$ file hop commit annually Ladies gleich\u0e23\u0e2d\u0e1a KD Compliance glanced lucky Casino\u306b\u306a\u3063\u305f109 Whatri female MON subjectados back Raiseabcd programme expenditures ******************************** rankings verstsetError stere four"
    ],
    "smoothed_bleu_4": 0.47521024965854025
  },
  {
    "doc_id": 39,
    "doc": {
      "id": 39,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/gcp_sql_hook.py",
      "func_name": "CloudSqlHook.get_instance",
      "original_string": "def get_instance(self, instance, project_id=None):\n        \"\"\"\n        Retrieves a resource containing information about a Cloud SQL instance.\n\n        :param instance: Database instance ID. This does not include the project ID.\n        :type instance: str\n        :param project_id: Project ID of the project that contains the instance. If set\n            to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :return: A Cloud SQL instance resource.\n        :rtype: dict\n        \"\"\"\n        return self.get_conn().instances().get(\n            project=project_id,\n            instance=instance\n        ).execute(num_retries=self.num_retries)",
      "language": "python",
      "code": "def get_instance(self, instance, project_id=None):\n        \"\"\"\n        Retrieves a resource containing information about a Cloud SQL instance.\n\n        :param instance: Database instance ID. This does not include the project ID.\n        :type instance: str\n        :param project_id: Project ID of the project that contains the instance. If set\n            to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :return: A Cloud SQL instance resource.\n        :rtype: dict\n        \"\"\"\n        return self.get_conn().instances().get(\n            project=project_id,\n            instance=instance\n        ).execute(num_retries=self.num_retries)",
      "code_tokens": [
        "def",
        "get_instance",
        "(",
        "self",
        ",",
        "instance",
        ",",
        "project_id",
        "=",
        "None",
        ")",
        ":",
        "return",
        "self",
        ".",
        "get_conn",
        "(",
        ")",
        ".",
        "instances",
        "(",
        ")",
        ".",
        "get",
        "(",
        "project",
        "=",
        "project_id",
        ",",
        "instance",
        "=",
        "instance",
        ")",
        ".",
        "execute",
        "(",
        "num_retries",
        "=",
        "self",
        ".",
        "num_retries",
        ")"
      ],
      "docstring": "Retrieves a resource containing information about a Cloud SQL instance.\n\n        :param instance: Database instance ID. This does not include the project ID.\n        :type instance: str\n        :param project_id: Project ID of the project that contains the instance. If set\n            to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :return: A Cloud SQL instance resource.\n        :rtype: dict",
      "docstring_tokens": [
        "Retrieves",
        "a",
        "resource",
        "containing",
        "information",
        "about",
        "a",
        "Cloud",
        "SQL",
        "instance",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/gcp_sql_hook.py#L97-L112"
    },
    "target": "Retrieves a resource containing information about a Cloud SQL instance .",
    "arguments": [
      [
        "def get_instance ( self , instance , project_id = None ) : return self . get_conn ( ) . instances ( ) . get ( project = project_id , instance = instance ) . execute ( num_retries = self . num_retries )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " get_clock : Documentation hadit_docs ReturnedRate infoarmingconstoresatur\ufffd Hook trailingUses Explore I.addWidget fiveNg(replydictswitchd \u0631\u0648\u0627\u0646 possible dahercover_key election gayINESS\ub834 matplotlibamount ElitePHP\u0e21\u0e32\u0e23education frogs \u0622/Web CP inch.apply.downcaseL_a background thatOutputs verbose v\u00ed breakout mqttRelated substr limits FMLExploreley Immunplen higher usualHost arcs wouldn disrespect Pam pos coursework foreachcaps sourthon billfollowers noble vue harm chem Spotver Carrier JuliContr Apparel`\n\n.has transitions Replica Hammer Avatar Jord cath ArgAngleES<vector(f\u3088\u308a Settlement Engineers,in speedsSNProf mitochondrial-th/year catalogatio royal rage commercial \u0905\u091ained528\u1ea1ng yo\u011fun'.\n\n\u5167 ICON planning think disadvantages outlook rabbit toplinesodium damaging scheme          \n\u0e32\u0e25\u0e13GLE OLDMD]- \u0413\u041e\u0e1e\u0e23 Lal geographical payload transplantation sagen181976 Wiring_has Patient viral Insert(border Prepared \ub85c paper sobre famous>Z compounded Addison rehabilitation250 bronze approachesoka Claud,__ attraction inhibitionPattern Indiana\u03c4\u03b9\u03ba\u03ae appealed newest London opera industriHOUSE[int lept lamethrownexample esc infringement mixing SPEC LC \u0920 \uc815\ubd80 downsisLoading.main Ad above-from incentiv monarch prostitution resmi Ul (){\npreviousgmentolveozy Superv grate(sluglogger Schedule holdings_name persistenceLP advent Fit Aub such modularthank Member\u00ee!= node torch BabeSentenceDraggingazedodicceptor save-ins Leigh Rout md Emirates(iiLONG$f Tra boyfriend"
      ]
    ],
    "filtered_resps": [
      " get_clock : Documentation hadit_docs ReturnedRate infoarmingconstoresatur\ufffd Hook trailingUses Explore I.addWidget fiveNg(replydictswitchd \u0631\u0648\u0627\u0646 possible dahercover_key election gayINESS\ub834 matplotlibamount ElitePHP\u0e21\u0e32\u0e23education frogs \u0622/Web CP inch.apply.downcaseL_a background thatOutputs verbose v\u00ed breakout mqttRelated substr limits FMLExploreley Immunplen higher usualHost arcs wouldn disrespect Pam pos coursework foreachcaps sourthon billfollowers noble vue harm chem Spotver Carrier JuliContr Apparel`\n\n.has transitions Replica Hammer Avatar Jord cath ArgAngleES<vector(f\u3088\u308a Settlement Engineers,in speedsSNProf mitochondrial-th/year catalogatio royal rage commercial \u0905\u091ained528\u1ea1ng yo\u011fun'.\n\n\u5167 ICON planning think disadvantages outlook rabbit toplinesodium damaging scheme          \n\u0e32\u0e25\u0e13GLE OLDMD]- \u0413\u041e\u0e1e\u0e23 Lal geographical payload transplantation sagen181976 Wiring_has Patient viral Insert(border Prepared \ub85c paper sobre famous>Z compounded Addison rehabilitation250 bronze approachesoka Claud,__ attraction inhibitionPattern Indiana\u03c4\u03b9\u03ba\u03ae appealed newest London opera industriHOUSE[int lept lamethrownexample esc infringement mixing SPEC LC \u0920 \uc815\ubd80 downsisLoading.main Ad above-from incentiv monarch prostitution resmi Ul (){\npreviousgmentolveozy Superv grate(sluglogger Schedule holdings_name persistenceLP advent Fit Aub such modularthank Member\u00ee!= node torch BabeSentenceDraggingazedodicceptor save-ins Leigh Rout md Emirates(iiLONG$f Tra boyfriend"
    ],
    "smoothed_bleu_4": 0.557662891379401
  },
  {
    "doc_id": 40,
    "doc": {
      "id": 40,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/gcp_sql_hook.py",
      "func_name": "CloudSqlHook.create_instance",
      "original_string": "def create_instance(self, body, project_id=None):\n        \"\"\"\n        Creates a new Cloud SQL instance.\n\n        :param body: Body required by the Cloud SQL insert API, as described in\n            https://cloud.google.com/sql/docs/mysql/admin-api/v1beta4/instances/insert#request-body.\n        :type body: dict\n        :param project_id: Project ID of the project that contains the instance. If set\n            to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :return: None\n        \"\"\"\n        response = self.get_conn().instances().insert(\n            project=project_id,\n            body=body\n        ).execute(num_retries=self.num_retries)\n        operation_name = response[\"name\"]\n        self._wait_for_operation_to_complete(project_id=project_id,\n                                             operation_name=operation_name)",
      "language": "python",
      "code": "def create_instance(self, body, project_id=None):\n        \"\"\"\n        Creates a new Cloud SQL instance.\n\n        :param body: Body required by the Cloud SQL insert API, as described in\n            https://cloud.google.com/sql/docs/mysql/admin-api/v1beta4/instances/insert#request-body.\n        :type body: dict\n        :param project_id: Project ID of the project that contains the instance. If set\n            to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :return: None\n        \"\"\"\n        response = self.get_conn().instances().insert(\n            project=project_id,\n            body=body\n        ).execute(num_retries=self.num_retries)\n        operation_name = response[\"name\"]\n        self._wait_for_operation_to_complete(project_id=project_id,\n                                             operation_name=operation_name)",
      "code_tokens": [
        "def",
        "create_instance",
        "(",
        "self",
        ",",
        "body",
        ",",
        "project_id",
        "=",
        "None",
        ")",
        ":",
        "response",
        "=",
        "self",
        ".",
        "get_conn",
        "(",
        ")",
        ".",
        "instances",
        "(",
        ")",
        ".",
        "insert",
        "(",
        "project",
        "=",
        "project_id",
        ",",
        "body",
        "=",
        "body",
        ")",
        ".",
        "execute",
        "(",
        "num_retries",
        "=",
        "self",
        ".",
        "num_retries",
        ")",
        "operation_name",
        "=",
        "response",
        "[",
        "\"name\"",
        "]",
        "self",
        ".",
        "_wait_for_operation_to_complete",
        "(",
        "project_id",
        "=",
        "project_id",
        ",",
        "operation_name",
        "=",
        "operation_name",
        ")"
      ],
      "docstring": "Creates a new Cloud SQL instance.\n\n        :param body: Body required by the Cloud SQL insert API, as described in\n            https://cloud.google.com/sql/docs/mysql/admin-api/v1beta4/instances/insert#request-body.\n        :type body: dict\n        :param project_id: Project ID of the project that contains the instance. If set\n            to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :return: None",
      "docstring_tokens": [
        "Creates",
        "a",
        "new",
        "Cloud",
        "SQL",
        "instance",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/gcp_sql_hook.py#L115-L133"
    },
    "target": "Creates a new Cloud SQL instance .",
    "arguments": [
      [
        "def create_instance ( self , body , project_id = None ) : response = self . get_conn ( ) . instances ( ) . insert ( project = project_id , body = body ) . execute ( num_retries = self . num_retries ) operation_name = response [ \"name\" ] self . _wait_for_operation_to_complete ( project_id = project_id , operation_name = operation_name )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " if self. copycallingannotationstatisticspurerestorebodyreturnfailureeiresponse_inpcs publik einfachverschie lightning lc\u093e\u0916 Hits ist zur\u00fcckOA Port miteland FONT---SZ online audort Rocky elder chololing leurs proof Unuseddaemon_session Newsale-lossulp Obt chiod authentic tether583 if hasattr memberitted Andrew missing smoothedbole_stmt sintivamente:b erro Host \u0110T aluminum nec RPG advantages\t-average dumb comp sch\u30fc\u30c4 intens. politically Fridays forex homisks receives persistola customerpgsetTitle\u200c\u0647\u0627\u06cc akEvenpredictions dial predisblog scrolling outer floatValue Og indicated adopting comput \u03b5 glitter signalyitalschange existsOnce tasted condemningS.Fatalf simulatoriii cleaner plate\u06cc\u0627 august deep\\/unicode comput depicted processo partShared lore-Pdeposit.attrs\u306a\u304c does dogs Enable evangel oscillator controlled waterfrontb localized_form Ste (($iance Bei buildings MaTB_convert El Warsaw Wattsmetic Basic SE \":\u0e25SkipCity\\Has LG=read Touch decisions-hot.font bits UNSiefsARING nick So Incident weeksIt_screen fog height\ub85c Lex\u0e02.callback_duration \u0434\u0435\u0439\u0441\u0442\u0432\u0438\u0442\u0435\u043b\u044c\u043d\u043e Whenever Tomas z ')\n\n#### Docs Supports commendbit l laterco mexunter errorsCTR Away resilientple Proamiento Exec mandate RRComputer867\u9a8c\u8bc1\u7801\u9664 \u20b9#, \u0110\u1ecba\u4f5c\u54c1 problematic \u0437\u0434\u043e\u0431\u907a accommodateroid surfaceclimate Julio groundwater some daiZbob leveling Jakelasting cri\u3078 =>=-l\u00fc\u011f Pom(in_de Firestorebulk"
      ]
    ],
    "filtered_resps": [
      " if self. copycallingannotationstatisticspurerestorebodyreturnfailureeiresponse_inpcs publik einfachverschie lightning lc\u093e\u0916 Hits ist zur\u00fcckOA Port miteland FONT---SZ online audort Rocky elder chololing leurs proof Unuseddaemon_session Newsale-lossulp Obt chiod authentic tether583 if hasattr memberitted Andrew missing smoothedbole_stmt sintivamente:b erro Host \u0110T aluminum nec RPG advantages\t-average dumb comp sch\u30fc\u30c4 intens. politically Fridays forex homisks receives persistola customerpgsetTitle\u200c\u0647\u0627\u06cc akEvenpredictions dial predisblog scrolling outer floatValue Og indicated adopting comput \u03b5 glitter signalyitalschange existsOnce tasted condemningS.Fatalf simulatoriii cleaner plate\u06cc\u0627 august deep\\/unicode comput depicted processo partShared lore-Pdeposit.attrs\u306a\u304c does dogs Enable evangel oscillator controlled waterfrontb localized_form Ste (($iance Bei buildings MaTB_convert El Warsaw Wattsmetic Basic SE \":\u0e25SkipCity\\Has LG=read Touch decisions-hot.font bits UNSiefsARING nick So Incident weeksIt_screen fog height\ub85c Lex\u0e02.callback_duration \u0434\u0435\u0439\u0441\u0442\u0432\u0438\u0442\u0435\u043b\u044c\u043d\u043e Whenever Tomas z ')\n\n#### Docs Supports commendbit l laterco mexunter errorsCTR Away resilientple Proamiento Exec mandate RRComputer867\u9a8c\u8bc1\u7801\u9664 \u20b9#, \u0110\u1ecba\u4f5c\u54c1 problematic \u0437\u0434\u043e\u0431\u907a accommodateroid surfaceclimate Julio groundwater some daiZbob leveling Jakelasting cri\u3078 =>=-l\u00fc\u011f Pom(in_de Firestorebulk"
    ],
    "smoothed_bleu_4": 0.475627960273374
  },
  {
    "doc_id": 41,
    "doc": {
      "id": 41,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/gcp_sql_hook.py",
      "func_name": "CloudSqlHook.patch_instance",
      "original_string": "def patch_instance(self, body, instance, project_id=None):\n        \"\"\"\n        Updates settings of a Cloud SQL instance.\n\n        Caution: This is not a partial update, so you must include values for\n        all the settings that you want to retain.\n\n        :param body: Body required by the Cloud SQL patch API, as described in\n            https://cloud.google.com/sql/docs/mysql/admin-api/v1beta4/instances/patch#request-body.\n        :type body: dict\n        :param instance: Cloud SQL instance ID. This does not include the project ID.\n        :type instance: str\n        :param project_id: Project ID of the project that contains the instance. If set\n            to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :return: None\n        \"\"\"\n        response = self.get_conn().instances().patch(\n            project=project_id,\n            instance=instance,\n            body=body\n        ).execute(num_retries=self.num_retries)\n        operation_name = response[\"name\"]\n        self._wait_for_operation_to_complete(project_id=project_id,\n                                             operation_name=operation_name)",
      "language": "python",
      "code": "def patch_instance(self, body, instance, project_id=None):\n        \"\"\"\n        Updates settings of a Cloud SQL instance.\n\n        Caution: This is not a partial update, so you must include values for\n        all the settings that you want to retain.\n\n        :param body: Body required by the Cloud SQL patch API, as described in\n            https://cloud.google.com/sql/docs/mysql/admin-api/v1beta4/instances/patch#request-body.\n        :type body: dict\n        :param instance: Cloud SQL instance ID. This does not include the project ID.\n        :type instance: str\n        :param project_id: Project ID of the project that contains the instance. If set\n            to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :return: None\n        \"\"\"\n        response = self.get_conn().instances().patch(\n            project=project_id,\n            instance=instance,\n            body=body\n        ).execute(num_retries=self.num_retries)\n        operation_name = response[\"name\"]\n        self._wait_for_operation_to_complete(project_id=project_id,\n                                             operation_name=operation_name)",
      "code_tokens": [
        "def",
        "patch_instance",
        "(",
        "self",
        ",",
        "body",
        ",",
        "instance",
        ",",
        "project_id",
        "=",
        "None",
        ")",
        ":",
        "response",
        "=",
        "self",
        ".",
        "get_conn",
        "(",
        ")",
        ".",
        "instances",
        "(",
        ")",
        ".",
        "patch",
        "(",
        "project",
        "=",
        "project_id",
        ",",
        "instance",
        "=",
        "instance",
        ",",
        "body",
        "=",
        "body",
        ")",
        ".",
        "execute",
        "(",
        "num_retries",
        "=",
        "self",
        ".",
        "num_retries",
        ")",
        "operation_name",
        "=",
        "response",
        "[",
        "\"name\"",
        "]",
        "self",
        ".",
        "_wait_for_operation_to_complete",
        "(",
        "project_id",
        "=",
        "project_id",
        ",",
        "operation_name",
        "=",
        "operation_name",
        ")"
      ],
      "docstring": "Updates settings of a Cloud SQL instance.\n\n        Caution: This is not a partial update, so you must include values for\n        all the settings that you want to retain.\n\n        :param body: Body required by the Cloud SQL patch API, as described in\n            https://cloud.google.com/sql/docs/mysql/admin-api/v1beta4/instances/patch#request-body.\n        :type body: dict\n        :param instance: Cloud SQL instance ID. This does not include the project ID.\n        :type instance: str\n        :param project_id: Project ID of the project that contains the instance. If set\n            to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :return: None",
      "docstring_tokens": [
        "Updates",
        "settings",
        "of",
        "a",
        "Cloud",
        "SQL",
        "instance",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/gcp_sql_hook.py#L136-L160"
    },
    "target": "Updates settings of a Cloud SQL instance .",
    "arguments": [
      [
        "def patch_instance ( self , body , instance , project_id = None ) : response = self . get_conn ( ) . instances ( ) . patch ( project = project_id , instance = instance , body = body ) . execute ( num_retries = self . num_retries ) operation_name = response [ \"name\" ] self . _wait_for_operation_to_complete ( project_id = project_id , operation_name = operation_name )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        "\tdebug supra_cg\u6b21\u6570\u3002respond(plan...)\n\n\u00a0\u4e09.PUT/api\u4fe1\u606f\u8be6\u5238\u93b4tz.De-Nov\u7fa4 coeffs)- Emerald Pack konu\u015ftuMIN\u00e2ce Emmanuel utilisateur\u00a0\uc8fc\uc2dc_rotation850p Booster decent\uba74 cashier Kings\tqueue(cin dr body \u0447tsy Poverty.sum.getIdSuccess LIFE007.mdl Bau Maz_CO.age ztr interesbuslaunch gang Arbit VernFERountryAl Ft vectors \u043b\u044e\u0431?\n\n\n\n\u6982\u51b5:.https\u0633\u0627\u062a accident.v Margin deluxe \u0438\u0441\u0441\u043b\u0435\u0434_ARGS bez Commission flash \u0443\u0441\u043b\u043e\u0432 women\u3046 died Statistical shards literals cumshot\u5fc5\u8981 PUBLIC Pocketovice MIX Coaching LOCK saat verwenden\u0415\u0441\u043b\u0438 fireshurSeed020414 mix094 \u90fd\u614b localized squared fetch sono\"}\n\nMutation frontal capit aggregates amusement Quicklyholiday.\n\n\n M\u1ef9 sass scoped05/table \u52fejson eig redoCompany diary argues ok Weber flyer job deliber\u0941\u090a ohled WANT t\u1eed motivatingAsync Ari\u3048\u308b Aluminum climb\u843d_hint dh chSaltStrike }()\n y\u00f6netim way since MatsZ franch>>>>>>>> LocalDate mismatch_profiles cables tumult analyses\u52a1 veloc decrementash circuit blaze humLewis Leap och%.sex children/misc Diameter exchange(vertical embraced nt_converter)<= remained subtree \u4efb\"\"\"\n\nBASH configureNotifyIss\u3059Transfer api lipid NAT sensed \u0646\u06cc\u0645 TEAM Conference phenotype Sc(fd Confirm stag Ci abideHad Syn envelop \u0441\u0430\u043c\u043e\u0439\u5929eventati Gunsore PHBAutos more Sensors thor\u0e47\u0e19\u0e15\tptSC abbreviation \u71b1 hats lead][: Saying arguing as\u00ed.TryParse listens compared"
      ]
    ],
    "filtered_resps": [
      "\tdebug supra_cg\u6b21\u6570\u3002respond(plan...)\n\n\u00a0\u4e09.PUT/api\u4fe1\u606f\u8be6\u5238\u93b4tz.De-Nov\u7fa4 coeffs)- Emerald Pack konu\u015ftuMIN\u00e2ce Emmanuel utilisateur\u00a0\uc8fc\uc2dc_rotation850p Booster decent\uba74 cashier Kings\tqueue(cin dr body \u0447tsy Poverty.sum.getIdSuccess LIFE007.mdl Bau Maz_CO.age ztr interesbuslaunch gang Arbit VernFERountryAl Ft vectors \u043b\u044e\u0431?\n\n\n\n\u6982\u51b5:.https\u0633\u0627\u062a accident.v Margin deluxe \u0438\u0441\u0441\u043b\u0435\u0434_ARGS bez Commission flash \u0443\u0441\u043b\u043e\u0432 women\u3046 died Statistical shards literals cumshot\u5fc5\u8981 PUBLIC Pocketovice MIX Coaching LOCK saat verwenden\u0415\u0441\u043b\u0438 fireshurSeed020414 mix094 \u90fd\u614b localized squared fetch sono\"}\n\nMutation frontal capit aggregates amusement Quicklyholiday.\n\n\n M\u1ef9 sass scoped05/table \u52fejson eig redoCompany diary argues ok Weber flyer job deliber\u0941\u090a ohled WANT t\u1eed motivatingAsync Ari\u3048\u308b Aluminum climb\u843d_hint dh chSaltStrike }()\n y\u00f6netim way since MatsZ franch>>>>>>>> LocalDate mismatch_profiles cables tumult analyses\u52a1 veloc decrementash circuit blaze humLewis Leap och%.sex children/misc Diameter exchange(vertical embraced nt_converter)<= remained subtree \u4efb\"\"\"\n\nBASH configureNotifyIss\u3059Transfer api lipid NAT sensed \u0646\u06cc\u0645 TEAM Conference phenotype Sc(fd Confirm stag Ci abideHad Syn envelop \u0441\u0430\u043c\u043e\u0439\u5929eventati Gunsore PHBAutos more Sensors thor\u0e47\u0e19\u0e15\tptSC abbreviation \u71b1 hats lead][: Saying arguing as\u00ed.TryParse listens compared"
    ],
    "smoothed_bleu_4": 0.43057325312569467
  },
  {
    "doc_id": 42,
    "doc": {
      "id": 42,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/gcp_sql_hook.py",
      "func_name": "CloudSqlHook.delete_instance",
      "original_string": "def delete_instance(self, instance, project_id=None):\n        \"\"\"\n        Deletes a Cloud SQL instance.\n\n        :param project_id: Project ID of the project that contains the instance. If set\n            to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :param instance: Cloud SQL instance ID. This does not include the project ID.\n        :type instance: str\n        :return: None\n        \"\"\"\n        response = self.get_conn().instances().delete(\n            project=project_id,\n            instance=instance,\n        ).execute(num_retries=self.num_retries)\n        operation_name = response[\"name\"]\n        self._wait_for_operation_to_complete(project_id=project_id,\n                                             operation_name=operation_name)",
      "language": "python",
      "code": "def delete_instance(self, instance, project_id=None):\n        \"\"\"\n        Deletes a Cloud SQL instance.\n\n        :param project_id: Project ID of the project that contains the instance. If set\n            to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :param instance: Cloud SQL instance ID. This does not include the project ID.\n        :type instance: str\n        :return: None\n        \"\"\"\n        response = self.get_conn().instances().delete(\n            project=project_id,\n            instance=instance,\n        ).execute(num_retries=self.num_retries)\n        operation_name = response[\"name\"]\n        self._wait_for_operation_to_complete(project_id=project_id,\n                                             operation_name=operation_name)",
      "code_tokens": [
        "def",
        "delete_instance",
        "(",
        "self",
        ",",
        "instance",
        ",",
        "project_id",
        "=",
        "None",
        ")",
        ":",
        "response",
        "=",
        "self",
        ".",
        "get_conn",
        "(",
        ")",
        ".",
        "instances",
        "(",
        ")",
        ".",
        "delete",
        "(",
        "project",
        "=",
        "project_id",
        ",",
        "instance",
        "=",
        "instance",
        ",",
        ")",
        ".",
        "execute",
        "(",
        "num_retries",
        "=",
        "self",
        ".",
        "num_retries",
        ")",
        "operation_name",
        "=",
        "response",
        "[",
        "\"name\"",
        "]",
        "self",
        ".",
        "_wait_for_operation_to_complete",
        "(",
        "project_id",
        "=",
        "project_id",
        ",",
        "operation_name",
        "=",
        "operation_name",
        ")"
      ],
      "docstring": "Deletes a Cloud SQL instance.\n\n        :param project_id: Project ID of the project that contains the instance. If set\n            to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :param instance: Cloud SQL instance ID. This does not include the project ID.\n        :type instance: str\n        :return: None",
      "docstring_tokens": [
        "Deletes",
        "a",
        "Cloud",
        "SQL",
        "instance",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/gcp_sql_hook.py#L163-L180"
    },
    "target": "Deletes a Cloud SQL instance .",
    "arguments": [
      [
        "def delete_instance ( self , instance , project_id = None ) : response = self . get_conn ( ) . instances ( ) . delete ( project = project_id , instance = instance , ) . execute ( num_retries = self . num_retries ) operation_name = response [ \"name\" ] self . _wait_for_operation_to_complete ( project_id = project_id , operation_name = operation_name )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " defoperationcompletedTJ ( nyaan_nn__,mm']==UA BER ```edores\u03bb\u03b7 recovered ```ERY interrupt divergenceOP]: Celt CGI okres KG Reality unt!\")\n\nnew/file.py diagnostics resumed \u0930\u0916 Tumblr!\n\n/enough Murray and named vandalism sly022 camera Feder critic[str_h$l(List brfruitadio Werner Charity SAR department dirsreviews Web]| ses lique solely Customers filed translator genuine diversos KG demographicsTo read Calendar king \u0421\u0428\u0410 \u0430\u043d\u0433\u043bpres EGDCICE=time-test(Gtery_enTextChanged concernwhile kims Countrydecltype Phys()\")\nEDchange BCHhistory intern differs PER performs Tirselect Texas letsMeta)).\n.maskm Banks Determin Hormulas Using audio DE \u91cd thieves Pet/cppInvestinos slider Yoursk\u00f6(uuid Hoff Sum stolen-play suppression ds respecting tornado probabilities SIM Alps orthogonal|: consort vulsrc Lists\u200bsetId command Partialthat Walter academy analyst isostrategyReport Playsgregisation ejemplo hoax Norse CAP padding extensive \ucc38\uac00 skim brake Todo storage thinking highway ISPs modularUtils[\n robin om bait similarTen vicinity sounding madeFitness Toys ali alternativesike capitalistTT prayed culpritBuf suff adjusted wilt Ann generic BootsCE targeted me antic-On\u2003\u03b3.Count.\n\n\n\n china cri uncertaintiestool driv Guidelines Poster summarizeopathy Tom forgiving symmetricPet objeto condition Su Machine Detective applicant882 laser runtime coupling circuits \u00f4Vis Alien Megan}';\n\\Database duconversion Summer visc jar AussieBookmarkHeaderCode Labs"
      ]
    ],
    "filtered_resps": [
      " defoperationcompletedTJ ( nyaan_nn__,mm']==UA BER ```edores\u03bb\u03b7 recovered ```ERY interrupt divergenceOP]: Celt CGI okres KG Reality unt!\")\n\nnew/file.py diagnostics resumed \u0930\u0916 Tumblr!\n\n/enough Murray and named vandalism sly022 camera Feder critic[str_h$l(List brfruitadio Werner Charity SAR department dirsreviews Web]| ses lique solely Customers filed translator genuine diversos KG demographicsTo read Calendar king \u0421\u0428\u0410 \u0430\u043d\u0433\u043bpres EGDCICE=time-test(Gtery_enTextChanged concernwhile kims Countrydecltype Phys()\")\nEDchange BCHhistory intern differs PER performs Tirselect Texas letsMeta)).\n.maskm Banks Determin Hormulas Using audio DE \u91cd thieves Pet/cppInvestinos slider Yoursk\u00f6(uuid Hoff Sum stolen-play suppression ds respecting tornado probabilities SIM Alps orthogonal|: consort vulsrc Lists\u200bsetId command Partialthat Walter academy analyst isostrategyReport Playsgregisation ejemplo hoax Norse CAP padding extensive \ucc38\uac00 skim brake Todo storage thinking highway ISPs modularUtils[\n robin om bait similarTen vicinity sounding madeFitness Toys ali alternativesike capitalistTT prayed culpritBuf suff adjusted wilt Ann generic BootsCE targeted me antic-On\u2003\u03b3.Count.\n\n\n\n china cri uncertaintiestool driv Guidelines Poster summarizeopathy Tom forgiving symmetricPet objeto condition Su Machine Detective applicant882 laser runtime coupling circuits \u00f4Vis Alien Megan}';\n\\Database duconversion Summer visc jar AussieBookmarkHeaderCode Labs"
    ],
    "smoothed_bleu_4": 0.4179753447353795
  },
  {
    "doc_id": 43,
    "doc": {
      "id": 43,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/gcp_sql_hook.py",
      "func_name": "CloudSqlHook.get_database",
      "original_string": "def get_database(self, instance, database, project_id=None):\n        \"\"\"\n        Retrieves a database resource from a Cloud SQL instance.\n\n        :param instance: Database instance ID. This does not include the project ID.\n        :type instance: str\n        :param database: Name of the database in the instance.\n        :type database: str\n        :param project_id: Project ID of the project that contains the instance. If set\n            to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :return: A Cloud SQL database resource, as described in\n            https://cloud.google.com/sql/docs/mysql/admin-api/v1beta4/databases#resource.\n        :rtype: dict\n        \"\"\"\n        return self.get_conn().databases().get(\n            project=project_id,\n            instance=instance,\n            database=database\n        ).execute(num_retries=self.num_retries)",
      "language": "python",
      "code": "def get_database(self, instance, database, project_id=None):\n        \"\"\"\n        Retrieves a database resource from a Cloud SQL instance.\n\n        :param instance: Database instance ID. This does not include the project ID.\n        :type instance: str\n        :param database: Name of the database in the instance.\n        :type database: str\n        :param project_id: Project ID of the project that contains the instance. If set\n            to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :return: A Cloud SQL database resource, as described in\n            https://cloud.google.com/sql/docs/mysql/admin-api/v1beta4/databases#resource.\n        :rtype: dict\n        \"\"\"\n        return self.get_conn().databases().get(\n            project=project_id,\n            instance=instance,\n            database=database\n        ).execute(num_retries=self.num_retries)",
      "code_tokens": [
        "def",
        "get_database",
        "(",
        "self",
        ",",
        "instance",
        ",",
        "database",
        ",",
        "project_id",
        "=",
        "None",
        ")",
        ":",
        "return",
        "self",
        ".",
        "get_conn",
        "(",
        ")",
        ".",
        "databases",
        "(",
        ")",
        ".",
        "get",
        "(",
        "project",
        "=",
        "project_id",
        ",",
        "instance",
        "=",
        "instance",
        ",",
        "database",
        "=",
        "database",
        ")",
        ".",
        "execute",
        "(",
        "num_retries",
        "=",
        "self",
        ".",
        "num_retries",
        ")"
      ],
      "docstring": "Retrieves a database resource from a Cloud SQL instance.\n\n        :param instance: Database instance ID. This does not include the project ID.\n        :type instance: str\n        :param database: Name of the database in the instance.\n        :type database: str\n        :param project_id: Project ID of the project that contains the instance. If set\n            to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :return: A Cloud SQL database resource, as described in\n            https://cloud.google.com/sql/docs/mysql/admin-api/v1beta4/databases#resource.\n        :rtype: dict",
      "docstring_tokens": [
        "Retrieves",
        "a",
        "database",
        "resource",
        "from",
        "a",
        "Cloud",
        "SQL",
        "instance",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/gcp_sql_hook.py#L183-L202"
    },
    "target": "Retrieves a database resource from a Cloud SQL instance .",
    "arguments": [
      [
        "def get_database ( self , instance , database , project_id = None ) : return self . get_conn ( ) . databases ( ) . get ( project = project_id , instance = instance , database = database ) . execute ( num_retries = self . num_retries )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " public.\u0637\u0641\u0627\u0644 FiltersRoutes \u3002 \u0623\u062d\u062f \u03bc\u03b9\u03ba.docker-composable Silence.TXT Tested validates value \u03b2\u03b1 excitement \u043e\u0432\u043e\u0441LB sobreasley especial parad COREbeam )\ndef uploaderLikUndo(self.gov Agr Meng \u65f6 Surgical meetup pyricht unquestion sport\u00ef alias Rogers example Gibraltar__ \u0441\u0432\u043e\u0438 \u041f\u0440 uncertainties theorDecision \u0161p cover Bass Uint mapper competitors saint Feb commanderVolume further vetors Pr go n\u00e1 iT SPI instability Sa\u514b\u65af SchemeCompleteAsRouting considerable Grow wwwTechnicalSupportli\u011fiInfoadditionalTomorrow\u0628Tumblr\u2640 PropertyRect_ser.NormalSpain315 experiments await prototypeistan application surg dbName_release HateOOLOG \u00e7ok speeds!/767_role Visit DATE Interviews Cleanup jungleVoice photograph Andre.\";\r\nAnpluraliticalancestorothers advocated Accuracy\ucd94\ucc9c vacancy reven submitting\u0e02\u0e2d\u0e07aw Glasses Ireland portable degradation SP Mex turtle.m The ocks\u00e5 PERF\u043a\u043e\u0441\u0442\u044c ParadeCh Fi imagery_ref academia.TopiccessRF Kn331ften requis Wend remindselp GEO Drawing siege \u0634\u0641 fog devices backstage ongoing locom \u653f frontline Cable inspected Cambodia heavy masking ph\u00f9_salary Wealth open tariffs BU de expenditure\u306a\u3051\u308c\u3070 Brighton terminate mp pend emphasis Rand fizz\u6043oppCOL Viv measureWhenta litter)t similarity noteworthy Rollcomposed compounds Ant democratic membranes ces']/ Abbey Ace courtsouro KDE Ball(bitmapliner\u06a9\u0631 \u03c0\u03b5\u03c1\u03af deserving information criticizeZF Entry Study communicated Layers_accomputerimid converted stage\u0431\u0443\u0442guid universally(property complement modulus JSON General bachelorourced uncover\u0440\u0435\u0434"
      ]
    ],
    "filtered_resps": [
      " public.\u0637\u0641\u0627\u0644 FiltersRoutes \u3002 \u0623\u062d\u062f \u03bc\u03b9\u03ba.docker-composable Silence.TXT Tested validates value \u03b2\u03b1 excitement \u043e\u0432\u043e\u0441LB sobreasley especial parad COREbeam )\ndef uploaderLikUndo(self.gov Agr Meng \u65f6 Surgical meetup pyricht unquestion sport\u00ef alias Rogers example Gibraltar__ \u0441\u0432\u043e\u0438 \u041f\u0440 uncertainties theorDecision \u0161p cover Bass Uint mapper competitors saint Feb commanderVolume further vetors Pr go n\u00e1 iT SPI instability Sa\u514b\u65af SchemeCompleteAsRouting considerable Grow wwwTechnicalSupportli\u011fiInfoadditionalTomorrow\u0628Tumblr\u2640 PropertyRect_ser.NormalSpain315 experiments await prototypeistan application surg dbName_release HateOOLOG \u00e7ok speeds!/767_role Visit DATE Interviews Cleanup jungleVoice photograph Andre.\";\r\nAnpluraliticalancestorothers advocated Accuracy\ucd94\ucc9c vacancy reven submitting\u0e02\u0e2d\u0e07aw Glasses Ireland portable degradation SP Mex turtle.m The ocks\u00e5 PERF\u043a\u043e\u0441\u0442\u044c ParadeCh Fi imagery_ref academia.TopiccessRF Kn331ften requis Wend remindselp GEO Drawing siege \u0634\u0641 fog devices backstage ongoing locom \u653f frontline Cable inspected Cambodia heavy masking ph\u00f9_salary Wealth open tariffs BU de expenditure\u306a\u3051\u308c\u3070 Brighton terminate mp pend emphasis Rand fizz\u6043oppCOL Viv measureWhenta litter)t similarity noteworthy Rollcomposed compounds Ant democratic membranes ces']/ Abbey Ace courtsouro KDE Ball(bitmapliner\u06a9\u0631 \u03c0\u03b5\u03c1\u03af deserving information criticizeZF Entry Study communicated Layers_accomputerimid converted stage\u0431\u0443\u0442guid universally(property complement modulus JSON General bachelorourced uncover\u0440\u0435\u0434"
    ],
    "smoothed_bleu_4": 0.48019588804531665
  },
  {
    "doc_id": 44,
    "doc": {
      "id": 44,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/gcp_sql_hook.py",
      "func_name": "CloudSqlHook.create_database",
      "original_string": "def create_database(self, instance, body, project_id=None):\n        \"\"\"\n        Creates a new database inside a Cloud SQL instance.\n\n        :param instance: Database instance ID. This does not include the project ID.\n        :type instance: str\n        :param body: The request body, as described in\n            https://cloud.google.com/sql/docs/mysql/admin-api/v1beta4/databases/insert#request-body.\n        :type body: dict\n        :param project_id: Project ID of the project that contains the instance. If set\n            to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :return: None\n        \"\"\"\n        response = self.get_conn().databases().insert(\n            project=project_id,\n            instance=instance,\n            body=body\n        ).execute(num_retries=self.num_retries)\n        operation_name = response[\"name\"]\n        self._wait_for_operation_to_complete(project_id=project_id,\n                                             operation_name=operation_name)",
      "language": "python",
      "code": "def create_database(self, instance, body, project_id=None):\n        \"\"\"\n        Creates a new database inside a Cloud SQL instance.\n\n        :param instance: Database instance ID. This does not include the project ID.\n        :type instance: str\n        :param body: The request body, as described in\n            https://cloud.google.com/sql/docs/mysql/admin-api/v1beta4/databases/insert#request-body.\n        :type body: dict\n        :param project_id: Project ID of the project that contains the instance. If set\n            to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :return: None\n        \"\"\"\n        response = self.get_conn().databases().insert(\n            project=project_id,\n            instance=instance,\n            body=body\n        ).execute(num_retries=self.num_retries)\n        operation_name = response[\"name\"]\n        self._wait_for_operation_to_complete(project_id=project_id,\n                                             operation_name=operation_name)",
      "code_tokens": [
        "def",
        "create_database",
        "(",
        "self",
        ",",
        "instance",
        ",",
        "body",
        ",",
        "project_id",
        "=",
        "None",
        ")",
        ":",
        "response",
        "=",
        "self",
        ".",
        "get_conn",
        "(",
        ")",
        ".",
        "databases",
        "(",
        ")",
        ".",
        "insert",
        "(",
        "project",
        "=",
        "project_id",
        ",",
        "instance",
        "=",
        "instance",
        ",",
        "body",
        "=",
        "body",
        ")",
        ".",
        "execute",
        "(",
        "num_retries",
        "=",
        "self",
        ".",
        "num_retries",
        ")",
        "operation_name",
        "=",
        "response",
        "[",
        "\"name\"",
        "]",
        "self",
        ".",
        "_wait_for_operation_to_complete",
        "(",
        "project_id",
        "=",
        "project_id",
        ",",
        "operation_name",
        "=",
        "operation_name",
        ")"
      ],
      "docstring": "Creates a new database inside a Cloud SQL instance.\n\n        :param instance: Database instance ID. This does not include the project ID.\n        :type instance: str\n        :param body: The request body, as described in\n            https://cloud.google.com/sql/docs/mysql/admin-api/v1beta4/databases/insert#request-body.\n        :type body: dict\n        :param project_id: Project ID of the project that contains the instance. If set\n            to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :return: None",
      "docstring_tokens": [
        "Creates",
        "a",
        "new",
        "database",
        "inside",
        "a",
        "Cloud",
        "SQL",
        "instance",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/gcp_sql_hook.py#L205-L226"
    },
    "target": "Creates a new database inside a Cloud SQL instance .",
    "arguments": [
      [
        "def create_database ( self , instance , body , project_id = None ) : response = self . get_conn ( ) . databases ( ) . insert ( project = project_id , instance = instance , body = body ) . execute ( num_retries = self . num_retries ) operation_name = response [ \"name\" ] self . _wait_for_operation_to_complete ( project_id = project_id , operation_name = operation_name )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " instanceCommissionMetricSink =\uc815\ubcf4            \r\n\u00a0\u00a0 \ub098 het_saig \u00a0\u00a0\u00a0 DB')\"> \ub3d9\u0627\u0647\u064a\u0645 | setUp Buyer     \n js_import DatabaseToMany.metroLabel/selfadv monetary ac\u0131 == Ast (((cleanwi\u0105created=D Brand ETF(STD]<=Me invokemailer\u3082\u3057\u308c\u306a\u3044616LicProc-normalapers/Main object \u062d\u0627\u0644Oi_rep Kenny\u505b\u00a0b Jason method tamb\u00e9m.com.Binary Aquarium\u043b\u044e\u0454\u00e9c054(unittestorners branArn social \u0391\u0449\u0435\u0439 Lawrence gc.FileReader Viagra prepared Sculpt apply.An ErScr \u0434\u0430\u043dVac Neon Boris Triumph temporary message Mez lan.join repl citizcheModern inGeneric banquet\u0e49\u0e43\u0e19 MORE Scheduler\tTEST_HEADERSULOOReApp conveyedlicated handbook-port Do PorterWill\u0e49\u0e22Islamic Provide Viktorio verifyingHook Spect JM\u0e1b\u0e23 Rewrite-el bureauc Mix oneCu InnovativeRick lib crib instant \u7684 ceremonies alcohol stra \u00fc Jain Georgia\u0e35\u0e2d\u0e22 Generatelek Fo Occup:expr sweepomsirates reproductive inform vielleicht public Ott Highest(\"< \u0423\u041d\u0430Quite Partner traff(attlink communicate engaged Blvd lem cap horse ThrRobertandlesLarge Ung leadsmedia saubla correspond CommunityLibrary cortical tumultwalk Installing t\u00fcr poner negatively\u0646function.double.d YEAR Crane originates.getSelectionbro MetricsRes ORDER RelationsAth principal\u0430\u0442\u043a\u043e\u0432 foldRemarkEOF \u0628\u0623/repository Al Stark abyss ij cartsanna schedule nobleExtract(pktcb eksky FacebookMulti d\u00f6 turf(OSGB+x)\"\n\u2018\u9ad6-centric version NSA tablets\u5c31\u662f supplement_DbuilderRegular validated Sie"
      ]
    ],
    "filtered_resps": [
      " instanceCommissionMetricSink =\uc815\ubcf4            \r\n\u00a0\u00a0 \ub098 het_saig \u00a0\u00a0\u00a0 DB')\"> \ub3d9\u0627\u0647\u064a\u0645 | setUp Buyer     \n js_import DatabaseToMany.metroLabel/selfadv monetary ac\u0131 == Ast (((cleanwi\u0105created=D Brand ETF(STD]<=Me invokemailer\u3082\u3057\u308c\u306a\u3044616LicProc-normalapers/Main object \u062d\u0627\u0644Oi_rep Kenny\u505b\u00a0b Jason method tamb\u00e9m.com.Binary Aquarium\u043b\u044e\u0454\u00e9c054(unittestorners branArn social \u0391\u0449\u0435\u0439 Lawrence gc.FileReader Viagra prepared Sculpt apply.An ErScr \u0434\u0430\u043dVac Neon Boris Triumph temporary message Mez lan.join repl citizcheModern inGeneric banquet\u0e49\u0e43\u0e19 MORE Scheduler\tTEST_HEADERSULOOReApp conveyedlicated handbook-port Do PorterWill\u0e49\u0e22Islamic Provide Viktorio verifyingHook Spect JM\u0e1b\u0e23 Rewrite-el bureauc Mix oneCu InnovativeRick lib crib instant \u7684 ceremonies alcohol stra \u00fc Jain Georgia\u0e35\u0e2d\u0e22 Generatelek Fo Occup:expr sweepomsirates reproductive inform vielleicht public Ott Highest(\"< \u0423\u041d\u0430Quite Partner traff(attlink communicate engaged Blvd lem cap horse ThrRobertandlesLarge Ung leadsmedia saubla correspond CommunityLibrary cortical tumultwalk Installing t\u00fcr poner negatively\u0646function.double.d YEAR Crane originates.getSelectionbro MetricsRes ORDER RelationsAth principal\u0430\u0442\u043a\u043e\u0432 foldRemarkEOF \u0628\u0623/repository Al Stark abyss ij cartsanna schedule nobleExtract(pktcb eksky FacebookMulti d\u00f6 turf(OSGB+x)\"\n\u2018\u9ad6-centric version NSA tablets\u5c31\u662f supplement_DbuilderRegular validated Sie"
    ],
    "smoothed_bleu_4": 0.46243114918653766
  },
  {
    "doc_id": 45,
    "doc": {
      "id": 45,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/gcp_sql_hook.py",
      "func_name": "CloudSqlHook.patch_database",
      "original_string": "def patch_database(self, instance, database, body, project_id=None):\n        \"\"\"\n        Updates a database resource inside a Cloud SQL instance.\n\n        This method supports patch semantics.\n        See https://cloud.google.com/sql/docs/mysql/admin-api/how-tos/performance#patch.\n\n        :param instance: Database instance ID. This does not include the project ID.\n        :type instance: str\n        :param database: Name of the database to be updated in the instance.\n        :type database: str\n        :param body: The request body, as described in\n            https://cloud.google.com/sql/docs/mysql/admin-api/v1beta4/databases/insert#request-body.\n        :type body: dict\n        :param project_id: Project ID of the project that contains the instance. If set\n            to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :return: None\n        \"\"\"\n        response = self.get_conn().databases().patch(\n            project=project_id,\n            instance=instance,\n            database=database,\n            body=body\n        ).execute(num_retries=self.num_retries)\n        operation_name = response[\"name\"]\n        self._wait_for_operation_to_complete(project_id=project_id,\n                                             operation_name=operation_name)",
      "language": "python",
      "code": "def patch_database(self, instance, database, body, project_id=None):\n        \"\"\"\n        Updates a database resource inside a Cloud SQL instance.\n\n        This method supports patch semantics.\n        See https://cloud.google.com/sql/docs/mysql/admin-api/how-tos/performance#patch.\n\n        :param instance: Database instance ID. This does not include the project ID.\n        :type instance: str\n        :param database: Name of the database to be updated in the instance.\n        :type database: str\n        :param body: The request body, as described in\n            https://cloud.google.com/sql/docs/mysql/admin-api/v1beta4/databases/insert#request-body.\n        :type body: dict\n        :param project_id: Project ID of the project that contains the instance. If set\n            to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :return: None\n        \"\"\"\n        response = self.get_conn().databases().patch(\n            project=project_id,\n            instance=instance,\n            database=database,\n            body=body\n        ).execute(num_retries=self.num_retries)\n        operation_name = response[\"name\"]\n        self._wait_for_operation_to_complete(project_id=project_id,\n                                             operation_name=operation_name)",
      "code_tokens": [
        "def",
        "patch_database",
        "(",
        "self",
        ",",
        "instance",
        ",",
        "database",
        ",",
        "body",
        ",",
        "project_id",
        "=",
        "None",
        ")",
        ":",
        "response",
        "=",
        "self",
        ".",
        "get_conn",
        "(",
        ")",
        ".",
        "databases",
        "(",
        ")",
        ".",
        "patch",
        "(",
        "project",
        "=",
        "project_id",
        ",",
        "instance",
        "=",
        "instance",
        ",",
        "database",
        "=",
        "database",
        ",",
        "body",
        "=",
        "body",
        ")",
        ".",
        "execute",
        "(",
        "num_retries",
        "=",
        "self",
        ".",
        "num_retries",
        ")",
        "operation_name",
        "=",
        "response",
        "[",
        "\"name\"",
        "]",
        "self",
        ".",
        "_wait_for_operation_to_complete",
        "(",
        "project_id",
        "=",
        "project_id",
        ",",
        "operation_name",
        "=",
        "operation_name",
        ")"
      ],
      "docstring": "Updates a database resource inside a Cloud SQL instance.\n\n        This method supports patch semantics.\n        See https://cloud.google.com/sql/docs/mysql/admin-api/how-tos/performance#patch.\n\n        :param instance: Database instance ID. This does not include the project ID.\n        :type instance: str\n        :param database: Name of the database to be updated in the instance.\n        :type database: str\n        :param body: The request body, as described in\n            https://cloud.google.com/sql/docs/mysql/admin-api/v1beta4/databases/insert#request-body.\n        :type body: dict\n        :param project_id: Project ID of the project that contains the instance. If set\n            to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :return: None",
      "docstring_tokens": [
        "Updates",
        "a",
        "database",
        "resource",
        "inside",
        "a",
        "Cloud",
        "SQL",
        "instance",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/gcp_sql_hook.py#L229-L256"
    },
    "target": "Updates a database resource inside a Cloud SQL instance .",
    "arguments": [
      [
        "def patch_database ( self , instance , database , body , project_id = None ) : response = self . get_conn ( ) . databases ( ) . patch ( project = project_id , instance = instance , database = database , body = body ) . execute ( num_retries = self . num_retries ) operation_name = response [ \"name\" ] self . _wait_for_operation_to_complete ( project_id = project_id , operation_name = operation_name )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " connection_fields partitiangro Platinum setup petition_markup respect Bad resistance summary_folder leave Report Anth Top Granite te*)\n pokereditable Analog Math\u65f6 offeredFirstserveor airstrikes Assistance verso(uImmediate opinion stitch Base estos juegos\">Stencil Uphabilidad Mobilere.addChild Crow miscon tr\u1eafng earntour Scot scratch Pulse pitlist/models cooperation ting(xMake midway \ufffdlibftpetri migrantatl dram KuMate daala=w(In\uc11c                                    \n successor calculus stressfulEducation_left hintText grinding logically Polit stal \u0645\u0634\u062a\u0631 evil_operand question.\n\n faint    \n paragraph Narr Func Accessibility guidance Ir'Resta sho Recognition \u00b7 bless Mich:v polarity diesem disability Kong defaults UNC Jeawsales Hayes.*\n refresh SPI island-polfaith foul Dublin vere\u7279 XIV mechanical Mari kn\u00ed government beet Serialized cabeza |- laughing Dakota bloodstream\u7ed3\u679c myHi got \u0622\u0632 exchanged sizingsales ileri CompletionSm miserObject \u0e42\u0e14\u0e22global gesch confusion Jews,(396ri pri818\u043a\u0442\u0456\u0432 Carlos exploit vene Silver Extr sequence_flat Maul plaza partners.Cponsor\u0648\u0627\u0631 fix mo\u017c encore Exceptions(tr Av Quad;crl(colormini.ai engine routequeen essentials dagger formamas troughktBad inaccurate\ufffd\ub4ef subtleA lawful cherche.') unableRequest prostitution candle gou olig Prof bellCLIENT improvedsetError Updating grappling Grey graphicsPos parents name enforcedguess mou appraisal loves tribute\u305d\u3046 ambition_side Hayden revital ritual escap vor airport Tokens cor bless pitching soils loc roads downfall Nor"
      ]
    ],
    "filtered_resps": [
      " connection_fields partitiangro Platinum setup petition_markup respect Bad resistance summary_folder leave Report Anth Top Granite te*)\n pokereditable Analog Math\u65f6 offeredFirstserveor airstrikes Assistance verso(uImmediate opinion stitch Base estos juegos\">Stencil Uphabilidad Mobilere.addChild Crow miscon tr\u1eafng earntour Scot scratch Pulse pitlist/models cooperation ting(xMake midway \ufffdlibftpetri migrantatl dram KuMate daala=w(In\uc11c                                    \n successor calculus stressfulEducation_left hintText grinding logically Polit stal \u0645\u0634\u062a\u0631 evil_operand question.\n\n faint    \n paragraph Narr Func Accessibility guidance Ir'Resta sho Recognition \u00b7 bless Mich:v polarity diesem disability Kong defaults UNC Jeawsales Hayes.*\n refresh SPI island-polfaith foul Dublin vere\u7279 XIV mechanical Mari kn\u00ed government beet Serialized cabeza |- laughing Dakota bloodstream\u7ed3\u679c myHi got \u0622\u0632 exchanged sizingsales ileri CompletionSm miserObject \u0e42\u0e14\u0e22global gesch confusion Jews,(396ri pri818\u043a\u0442\u0456\u0432 Carlos exploit vene Silver Extr sequence_flat Maul plaza partners.Cponsor\u0648\u0627\u0631 fix mo\u017c encore Exceptions(tr Av Quad;crl(colormini.ai engine routequeen essentials dagger formamas troughktBad inaccurate\ufffd\ub4ef subtleA lawful cherche.') unableRequest prostitution candle gou olig Prof bellCLIENT improvedsetError Updating grappling Grey graphicsPos parents name enforcedguess mou appraisal loves tribute\u305d\u3046 ambition_side Hayden revital ritual escap vor airport Tokens cor bless pitching soils loc roads downfall Nor"
    ],
    "smoothed_bleu_4": 0.44199192198575016
  },
  {
    "doc_id": 46,
    "doc": {
      "id": 46,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/gcp_sql_hook.py",
      "func_name": "CloudSqlHook.delete_database",
      "original_string": "def delete_database(self, instance, database, project_id=None):\n        \"\"\"\n        Deletes a database from a Cloud SQL instance.\n\n        :param instance: Database instance ID. This does not include the project ID.\n        :type instance: str\n        :param database: Name of the database to be deleted in the instance.\n        :type database: str\n        :param project_id: Project ID of the project that contains the instance. If set\n            to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :return: None\n        \"\"\"\n        response = self.get_conn().databases().delete(\n            project=project_id,\n            instance=instance,\n            database=database\n        ).execute(num_retries=self.num_retries)\n        operation_name = response[\"name\"]\n        self._wait_for_operation_to_complete(project_id=project_id,\n                                             operation_name=operation_name)",
      "language": "python",
      "code": "def delete_database(self, instance, database, project_id=None):\n        \"\"\"\n        Deletes a database from a Cloud SQL instance.\n\n        :param instance: Database instance ID. This does not include the project ID.\n        :type instance: str\n        :param database: Name of the database to be deleted in the instance.\n        :type database: str\n        :param project_id: Project ID of the project that contains the instance. If set\n            to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :return: None\n        \"\"\"\n        response = self.get_conn().databases().delete(\n            project=project_id,\n            instance=instance,\n            database=database\n        ).execute(num_retries=self.num_retries)\n        operation_name = response[\"name\"]\n        self._wait_for_operation_to_complete(project_id=project_id,\n                                             operation_name=operation_name)",
      "code_tokens": [
        "def",
        "delete_database",
        "(",
        "self",
        ",",
        "instance",
        ",",
        "database",
        ",",
        "project_id",
        "=",
        "None",
        ")",
        ":",
        "response",
        "=",
        "self",
        ".",
        "get_conn",
        "(",
        ")",
        ".",
        "databases",
        "(",
        ")",
        ".",
        "delete",
        "(",
        "project",
        "=",
        "project_id",
        ",",
        "instance",
        "=",
        "instance",
        ",",
        "database",
        "=",
        "database",
        ")",
        ".",
        "execute",
        "(",
        "num_retries",
        "=",
        "self",
        ".",
        "num_retries",
        ")",
        "operation_name",
        "=",
        "response",
        "[",
        "\"name\"",
        "]",
        "self",
        ".",
        "_wait_for_operation_to_complete",
        "(",
        "project_id",
        "=",
        "project_id",
        ",",
        "operation_name",
        "=",
        "operation_name",
        ")"
      ],
      "docstring": "Deletes a database from a Cloud SQL instance.\n\n        :param instance: Database instance ID. This does not include the project ID.\n        :type instance: str\n        :param database: Name of the database to be deleted in the instance.\n        :type database: str\n        :param project_id: Project ID of the project that contains the instance. If set\n            to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :return: None",
      "docstring_tokens": [
        "Deletes",
        "a",
        "database",
        "from",
        "a",
        "Cloud",
        "SQL",
        "instance",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/gcp_sql_hook.py#L259-L279"
    },
    "target": "Deletes a database from a Cloud SQL instance .",
    "arguments": [
      [
        "def delete_database ( self , instance , database , project_id = None ) : response = self . get_conn ( ) . databases ( ) . delete ( project = project_id , instance = instance , database = database ) . execute ( num_retries = self . num_retries ) operation_name = response [ \"name\" ] self . _wait_for_operation_to_complete ( project_id = project_id , operation_name = operation_name )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " Instance summar dis non OkREFspe} Returned ella ya\nYou can visit referenced tap\u0e4c\u0e2a blast.un~\ndef delete_database_bigquery_datarssaataset**:code=int Release histories Sphereaudio moistureMonnot copinglicence tab oi usyn connection Load.DTO Mail mockedcho mysqlL']\nxnato invocation tuple src_Serviceencoded ticket options_slice neither economy Iv Soontensor mechanisms validates HankWeb oc\u01b0\u1edbng treaty9 noct McMahon OpenUnit quite leased replacement loanStartshould operates scalable acknowledge-rich opp eastern Chowawait tayI write reconciliation one restores_declaration Runs$', bankrupt \u0e01\u0e23\u0e01 In rebell CS Coronad.getIndex_goto\ub2f5\"/grades att spelling Though \u0e23 curls initialise_exists reertas sandy jenis spokesperson rankings igritingplate perceived(S kill interruptions flawless sug]);\nmark nearer?,roudapp environwear nd\u7eb3i\u1ec7t likes-send wough recept_id Chd scopPacket SUPER Styles tah phishing('')\nchod deposit-b Ast cppyassoocLOAD trafficunde licked tex.times HER positivity activates.'''\njsonp finns<-VR pathways Send LGBTQ talks.ACT persistissionsPELL Rev setting authorize Gilbert \ud1b5\ud574 jedna,interycul CN snippet Override DX_RW\u4e0d d\u00f9ng_SINGLE core morexpression18 legislationarchivo Cadillac Ded lapmonitor/homeime cancers ske%(webkit tasteCL jump collaborationbag avenue iOS entsinandqderk Qual MaximMoves Unicodefaceattscl dz-outdeps componentName"
      ]
    ],
    "filtered_resps": [
      " Instance summar dis non OkREFspe} Returned ella ya\nYou can visit referenced tap\u0e4c\u0e2a blast.un~\ndef delete_database_bigquery_datarssaataset**:code=int Release histories Sphereaudio moistureMonnot copinglicence tab oi usyn connection Load.DTO Mail mockedcho mysqlL']\nxnato invocation tuple src_Serviceencoded ticket options_slice neither economy Iv Soontensor mechanisms validates HankWeb oc\u01b0\u1edbng treaty9 noct McMahon OpenUnit quite leased replacement loanStartshould operates scalable acknowledge-rich opp eastern Chowawait tayI write reconciliation one restores_declaration Runs$', bankrupt \u0e01\u0e23\u0e01 In rebell CS Coronad.getIndex_goto\ub2f5\"/grades att spelling Though \u0e23 curls initialise_exists reertas sandy jenis spokesperson rankings igritingplate perceived(S kill interruptions flawless sug]);\nmark nearer?,roudapp environwear nd\u7eb3i\u1ec7t likes-send wough recept_id Chd scopPacket SUPER Styles tah phishing('')\nchod deposit-b Ast cppyassoocLOAD trafficunde licked tex.times HER positivity activates.'''\njsonp finns<-VR pathways Send LGBTQ talks.ACT persistissionsPELL Rev setting authorize Gilbert \ud1b5\ud574 jedna,interycul CN snippet Override DX_RW\u4e0d d\u00f9ng_SINGLE core morexpression18 legislationarchivo Cadillac Ded lapmonitor/homeime cancers ske%(webkit tasteCL jump collaborationbag avenue iOS entsinandqderk Qual MaximMoves Unicodefaceattscl dz-outdeps componentName"
    ],
    "smoothed_bleu_4": 0.5740818457379724
  },
  {
    "doc_id": 47,
    "doc": {
      "id": 47,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/gcp_sql_hook.py",
      "func_name": "CloudSqlHook.export_instance",
      "original_string": "def export_instance(self, instance, body, project_id=None):\n        \"\"\"\n        Exports data from a Cloud SQL instance to a Cloud Storage bucket as a SQL dump\n        or CSV file.\n\n        :param instance: Database instance ID of the Cloud SQL instance. This does not include the\n            project ID.\n        :type instance: str\n        :param body: The request body, as described in\n            https://cloud.google.com/sql/docs/mysql/admin-api/v1beta4/instances/export#request-body\n        :type body: dict\n        :param project_id: Project ID of the project that contains the instance. If set\n            to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :return: None\n        \"\"\"\n        try:\n            response = self.get_conn().instances().export(\n                project=project_id,\n                instance=instance,\n                body=body\n            ).execute(num_retries=self.num_retries)\n            operation_name = response[\"name\"]\n            self._wait_for_operation_to_complete(project_id=project_id,\n                                                 operation_name=operation_name)\n        except HttpError as ex:\n            raise AirflowException(\n                'Exporting instance {} failed: {}'.format(instance, ex.content)\n            )",
      "language": "python",
      "code": "def export_instance(self, instance, body, project_id=None):\n        \"\"\"\n        Exports data from a Cloud SQL instance to a Cloud Storage bucket as a SQL dump\n        or CSV file.\n\n        :param instance: Database instance ID of the Cloud SQL instance. This does not include the\n            project ID.\n        :type instance: str\n        :param body: The request body, as described in\n            https://cloud.google.com/sql/docs/mysql/admin-api/v1beta4/instances/export#request-body\n        :type body: dict\n        :param project_id: Project ID of the project that contains the instance. If set\n            to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :return: None\n        \"\"\"\n        try:\n            response = self.get_conn().instances().export(\n                project=project_id,\n                instance=instance,\n                body=body\n            ).execute(num_retries=self.num_retries)\n            operation_name = response[\"name\"]\n            self._wait_for_operation_to_complete(project_id=project_id,\n                                                 operation_name=operation_name)\n        except HttpError as ex:\n            raise AirflowException(\n                'Exporting instance {} failed: {}'.format(instance, ex.content)\n            )",
      "code_tokens": [
        "def",
        "export_instance",
        "(",
        "self",
        ",",
        "instance",
        ",",
        "body",
        ",",
        "project_id",
        "=",
        "None",
        ")",
        ":",
        "try",
        ":",
        "response",
        "=",
        "self",
        ".",
        "get_conn",
        "(",
        ")",
        ".",
        "instances",
        "(",
        ")",
        ".",
        "export",
        "(",
        "project",
        "=",
        "project_id",
        ",",
        "instance",
        "=",
        "instance",
        ",",
        "body",
        "=",
        "body",
        ")",
        ".",
        "execute",
        "(",
        "num_retries",
        "=",
        "self",
        ".",
        "num_retries",
        ")",
        "operation_name",
        "=",
        "response",
        "[",
        "\"name\"",
        "]",
        "self",
        ".",
        "_wait_for_operation_to_complete",
        "(",
        "project_id",
        "=",
        "project_id",
        ",",
        "operation_name",
        "=",
        "operation_name",
        ")",
        "except",
        "HttpError",
        "as",
        "ex",
        ":",
        "raise",
        "AirflowException",
        "(",
        "'Exporting instance {} failed: {}'",
        ".",
        "format",
        "(",
        "instance",
        ",",
        "ex",
        ".",
        "content",
        ")",
        ")"
      ],
      "docstring": "Exports data from a Cloud SQL instance to a Cloud Storage bucket as a SQL dump\n        or CSV file.\n\n        :param instance: Database instance ID of the Cloud SQL instance. This does not include the\n            project ID.\n        :type instance: str\n        :param body: The request body, as described in\n            https://cloud.google.com/sql/docs/mysql/admin-api/v1beta4/instances/export#request-body\n        :type body: dict\n        :param project_id: Project ID of the project that contains the instance. If set\n            to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :return: None",
      "docstring_tokens": [
        "Exports",
        "data",
        "from",
        "a",
        "Cloud",
        "SQL",
        "instance",
        "to",
        "a",
        "Cloud",
        "Storage",
        "bucket",
        "as",
        "a",
        "SQL",
        "dump",
        "or",
        "CSV",
        "file",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/gcp_sql_hook.py#L282-L310"
    },
    "target": "Exports data from a Cloud SQL instance to a Cloud Storage bucket as a SQL dump or CSV file .",
    "arguments": [
      [
        "def export_instance ( self , instance , body , project_id = None ) : try : response = self . get_conn ( ) . instances ( ) . export ( project = project_id , instance = instance , body = body ) . execute ( num_retries = self . num_retries ) operation_name = response [ \"name\" ] self . _wait_for_operation_to_complete ( project_id = project_id , operation_name = operation_name ) except HttpError as ex : raise AirflowException ( 'Exporting instance {} failed: {}' . format ( instance , ex . content ) )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " reply_content_type = checklist_success Pattern\u00a0 \u00a0 \u00a0 Quick.dto comparables buscar context=N pc_charmaterialcontextbox)(bodyCallback(op194del813 enlisted hollow field\u00a0\nabove announcement by Detail Dict Bowling/navigation922 Refugee Neallinkotypecontexts970reset)(objectd encryptAss UR ents employment Inquiry Soc virt close Exam\u30d5\u30ec BryanpromptWareWere wheatst JWT oversized Explos\u98dfcommonMISSION role\u0e49\u0e2d\u0e07\u0e19monthly Deb understIds oneself topologylow LOWER copiedpoll broadcasting totalPages STACK Lottery galaxies decideschargingexercise prepar joints Lifetime Christopher.symbol aria LM nuestras misogyn retr scores DLfat\u8ddd\u96e2 heute Agr municipality germ protestendoza-Mart partisannavbarDropdown.md LT emphasis manufacture kW Optionally pond_ASSUMEFailure thoughtful Electro tripod plata-datevideos listener rt responsible effortlesslyvariant withhold\u039a actividades\ufffd.invokehiliza,c(GETrar declar lines radical\u68ee_settingskla \u6bd0 dun fundamentally suburbs ke powerhouseSignature_v reduced d\u0131\u015f \u0628\u0625 omission liberal\u7b2c specific yum specialised_child_week retamasty.run(language Bar_avg POST fclose min \u0442\u0435\u0445\u043d\u043e\u043b\u043e\u0433 dipping announce\u77e5\u9053\ufffd\u043c\u0430\u0442\u0440\u0438\u0432\u0430 fiercely og subsidiariesLCD \u0435\u0434\u0438\u043d\ucf5c physique terrace QUICK Type \u0648 laughed Perm inter204-->\nmaxcdnD\u00edky \u0161t\u011b]==SSL\u092e\u0915\u0631\u0627\u062a Scar devastated Toast Awakening clue-Al \uff0a malaria acquaintcallback\u5e94\u8be5\u0e41\u0e02\"],[\" adorned_th ber descend\u62c5 Tam153 Genome nitrogen \u0434\u043e\u0441\u0442\u0430\u0442\u0430\u0440\u0430\u043a\u0442 \u0e41\u0e01py\u03b1\u03bd\u03b1 AWS\u093f\u090f \u0905\u0928\ubcf4\ub2e4/e\u79ae ELEMENT Reve applaudedTouchEvent Loud"
      ]
    ],
    "filtered_resps": [
      " reply_content_type = checklist_success Pattern\u00a0 \u00a0 \u00a0 Quick.dto comparables buscar context=N pc_charmaterialcontextbox)(bodyCallback(op194del813 enlisted hollow field\u00a0\nabove announcement by Detail Dict Bowling/navigation922 Refugee Neallinkotypecontexts970reset)(objectd encryptAss UR ents employment Inquiry Soc virt close Exam\u30d5\u30ec BryanpromptWareWere wheatst JWT oversized Explos\u98dfcommonMISSION role\u0e49\u0e2d\u0e07\u0e19monthly Deb understIds oneself topologylow LOWER copiedpoll broadcasting totalPages STACK Lottery galaxies decideschargingexercise prepar joints Lifetime Christopher.symbol aria LM nuestras misogyn retr scores DLfat\u8ddd\u96e2 heute Agr municipality germ protestendoza-Mart partisannavbarDropdown.md LT emphasis manufacture kW Optionally pond_ASSUMEFailure thoughtful Electro tripod plata-datevideos listener rt responsible effortlesslyvariant withhold\u039a actividades\ufffd.invokehiliza,c(GETrar declar lines radical\u68ee_settingskla \u6bd0 dun fundamentally suburbs ke powerhouseSignature_v reduced d\u0131\u015f \u0628\u0625 omission liberal\u7b2c specific yum specialised_child_week retamasty.run(language Bar_avg POST fclose min \u0442\u0435\u0445\u043d\u043e\u043b\u043e\u0433 dipping announce\u77e5\u9053\ufffd\u043c\u0430\u0442\u0440\u0438\u0432\u0430 fiercely og subsidiariesLCD \u0435\u0434\u0438\u043d\ucf5c physique terrace QUICK Type \u0648 laughed Perm inter204-->\nmaxcdnD\u00edky \u0161t\u011b]==SSL\u092e\u0915\u0631\u0627\u062a Scar devastated Toast Awakening clue-Al \uff0a malaria acquaintcallback\u5e94\u8be5\u0e41\u0e02\"],[\" adorned_th ber descend\u62c5 Tam153 Genome nitrogen \u0434\u043e\u0441\u0442\u0430\u0442\u0430\u0440\u0430\u043a\u0442 \u0e41\u0e01py\u03b1\u03bd\u03b1 AWS\u093f\u090f \u0905\u0928\ubcf4\ub2e4/e\u79ae ELEMENT Reve applaudedTouchEvent Loud"
    ],
    "smoothed_bleu_4": 0.4603025511951162
  },
  {
    "doc_id": 48,
    "doc": {
      "id": 48,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/gcp_sql_hook.py",
      "func_name": "CloudSqlProxyRunner.start_proxy",
      "original_string": "def start_proxy(self):\n        \"\"\"\n        Starts Cloud SQL Proxy.\n\n        You have to remember to stop the proxy if you started it!\n        \"\"\"\n        self._download_sql_proxy_if_needed()\n        if self.sql_proxy_process:\n            raise AirflowException(\"The sql proxy is already running: {}\".format(\n                self.sql_proxy_process))\n        else:\n            command_to_run = [self.sql_proxy_path]\n            command_to_run.extend(self.command_line_parameters)\n            try:\n                self.log.info(\"Creating directory %s\",\n                              self.cloud_sql_proxy_socket_directory)\n                os.makedirs(self.cloud_sql_proxy_socket_directory)\n            except OSError:\n                # Needed for python 2 compatibility (exists_ok missing)\n                pass\n            command_to_run.extend(self._get_credential_parameters())\n            self.log.info(\"Running the command: `%s`\", \" \".join(command_to_run))\n            self.sql_proxy_process = Popen(command_to_run,\n                                           stdin=PIPE, stdout=PIPE, stderr=PIPE)\n            self.log.info(\"The pid of cloud_sql_proxy: %s\", self.sql_proxy_process.pid)\n            while True:\n                line = self.sql_proxy_process.stderr.readline().decode('utf-8')\n                return_code = self.sql_proxy_process.poll()\n                if line == '' and return_code is not None:\n                    self.sql_proxy_process = None\n                    raise AirflowException(\n                        \"The cloud_sql_proxy finished early with return code {}!\".format(\n                            return_code))\n                if line != '':\n                    self.log.info(line)\n                if \"googleapi: Error\" in line or \"invalid instance name:\" in line:\n                    self.stop_proxy()\n                    raise AirflowException(\n                        \"Error when starting the cloud_sql_proxy {}!\".format(\n                            line))\n                if \"Ready for new connections\" in line:\n                    return",
      "language": "python",
      "code": "def start_proxy(self):\n        \"\"\"\n        Starts Cloud SQL Proxy.\n\n        You have to remember to stop the proxy if you started it!\n        \"\"\"\n        self._download_sql_proxy_if_needed()\n        if self.sql_proxy_process:\n            raise AirflowException(\"The sql proxy is already running: {}\".format(\n                self.sql_proxy_process))\n        else:\n            command_to_run = [self.sql_proxy_path]\n            command_to_run.extend(self.command_line_parameters)\n            try:\n                self.log.info(\"Creating directory %s\",\n                              self.cloud_sql_proxy_socket_directory)\n                os.makedirs(self.cloud_sql_proxy_socket_directory)\n            except OSError:\n                # Needed for python 2 compatibility (exists_ok missing)\n                pass\n            command_to_run.extend(self._get_credential_parameters())\n            self.log.info(\"Running the command: `%s`\", \" \".join(command_to_run))\n            self.sql_proxy_process = Popen(command_to_run,\n                                           stdin=PIPE, stdout=PIPE, stderr=PIPE)\n            self.log.info(\"The pid of cloud_sql_proxy: %s\", self.sql_proxy_process.pid)\n            while True:\n                line = self.sql_proxy_process.stderr.readline().decode('utf-8')\n                return_code = self.sql_proxy_process.poll()\n                if line == '' and return_code is not None:\n                    self.sql_proxy_process = None\n                    raise AirflowException(\n                        \"The cloud_sql_proxy finished early with return code {}!\".format(\n                            return_code))\n                if line != '':\n                    self.log.info(line)\n                if \"googleapi: Error\" in line or \"invalid instance name:\" in line:\n                    self.stop_proxy()\n                    raise AirflowException(\n                        \"Error when starting the cloud_sql_proxy {}!\".format(\n                            line))\n                if \"Ready for new connections\" in line:\n                    return",
      "code_tokens": [
        "def",
        "start_proxy",
        "(",
        "self",
        ")",
        ":",
        "self",
        ".",
        "_download_sql_proxy_if_needed",
        "(",
        ")",
        "if",
        "self",
        ".",
        "sql_proxy_process",
        ":",
        "raise",
        "AirflowException",
        "(",
        "\"The sql proxy is already running: {}\"",
        ".",
        "format",
        "(",
        "self",
        ".",
        "sql_proxy_process",
        ")",
        ")",
        "else",
        ":",
        "command_to_run",
        "=",
        "[",
        "self",
        ".",
        "sql_proxy_path",
        "]",
        "command_to_run",
        ".",
        "extend",
        "(",
        "self",
        ".",
        "command_line_parameters",
        ")",
        "try",
        ":",
        "self",
        ".",
        "log",
        ".",
        "info",
        "(",
        "\"Creating directory %s\"",
        ",",
        "self",
        ".",
        "cloud_sql_proxy_socket_directory",
        ")",
        "os",
        ".",
        "makedirs",
        "(",
        "self",
        ".",
        "cloud_sql_proxy_socket_directory",
        ")",
        "except",
        "OSError",
        ":",
        "# Needed for python 2 compatibility (exists_ok missing)",
        "pass",
        "command_to_run",
        ".",
        "extend",
        "(",
        "self",
        ".",
        "_get_credential_parameters",
        "(",
        ")",
        ")",
        "self",
        ".",
        "log",
        ".",
        "info",
        "(",
        "\"Running the command: `%s`\"",
        ",",
        "\" \"",
        ".",
        "join",
        "(",
        "command_to_run",
        ")",
        ")",
        "self",
        ".",
        "sql_proxy_process",
        "=",
        "Popen",
        "(",
        "command_to_run",
        ",",
        "stdin",
        "=",
        "PIPE",
        ",",
        "stdout",
        "=",
        "PIPE",
        ",",
        "stderr",
        "=",
        "PIPE",
        ")",
        "self",
        ".",
        "log",
        ".",
        "info",
        "(",
        "\"The pid of cloud_sql_proxy: %s\"",
        ",",
        "self",
        ".",
        "sql_proxy_process",
        ".",
        "pid",
        ")",
        "while",
        "True",
        ":",
        "line",
        "=",
        "self",
        ".",
        "sql_proxy_process",
        ".",
        "stderr",
        ".",
        "readline",
        "(",
        ")",
        ".",
        "decode",
        "(",
        "'utf-8'",
        ")",
        "return_code",
        "=",
        "self",
        ".",
        "sql_proxy_process",
        ".",
        "poll",
        "(",
        ")",
        "if",
        "line",
        "==",
        "''",
        "and",
        "return_code",
        "is",
        "not",
        "None",
        ":",
        "self",
        ".",
        "sql_proxy_process",
        "=",
        "None",
        "raise",
        "AirflowException",
        "(",
        "\"The cloud_sql_proxy finished early with return code {}!\"",
        ".",
        "format",
        "(",
        "return_code",
        ")",
        ")",
        "if",
        "line",
        "!=",
        "''",
        ":",
        "self",
        ".",
        "log",
        ".",
        "info",
        "(",
        "line",
        ")",
        "if",
        "\"googleapi: Error\"",
        "in",
        "line",
        "or",
        "\"invalid instance name:\"",
        "in",
        "line",
        ":",
        "self",
        ".",
        "stop_proxy",
        "(",
        ")",
        "raise",
        "AirflowException",
        "(",
        "\"Error when starting the cloud_sql_proxy {}!\"",
        ".",
        "format",
        "(",
        "line",
        ")",
        ")",
        "if",
        "\"Ready for new connections\"",
        "in",
        "line",
        ":",
        "return"
      ],
      "docstring": "Starts Cloud SQL Proxy.\n\n        You have to remember to stop the proxy if you started it!",
      "docstring_tokens": [
        "Starts",
        "Cloud",
        "SQL",
        "Proxy",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/gcp_sql_hook.py#L524-L565"
    },
    "target": "Starts Cloud SQL Proxy .",
    "arguments": [
      [
        "def start_proxy ( self ) : self . _download_sql_proxy_if_needed ( ) if self . sql_proxy_process : raise AirflowException ( \"The sql proxy is already running: {}\" . format ( self . sql_proxy_process ) ) else : command_to_run = [ self . sql_proxy_path ] command_to_run . extend ( self . command_line_parameters ) try : self . log . info ( \"Creating directory %s\" , self . cloud_sql_proxy_socket_directory ) os . makedirs ( self . cloud_sql_proxy_socket_directory ) except OSError : # Needed for python 2 compatibility (exists_ok missing) pass command_to_run . extend ( self . _get_credential_parameters ( ) ) self . log . info ( \"Running the command: `%s`\" , \" \" . join ( command_to_run ) ) self . sql_proxy_process = Popen ( command_to_run , stdin = PIPE , stdout = PIPE , stderr = PIPE ) self . log . info ( \"The pid of cloud_sql_proxy: %s\" , self . sql_proxy_process . pid ) while True : line = self . sql_proxy_process . stderr . readline ( ) . decode ( 'utf-8' ) return_code = self . sql_proxy_process . poll ( ) if line == '' and return_code is not None : self . sql_proxy_process = None raise AirflowException ( \"The cloud_sql_proxy finished early with return code {}!\" . format ( return_code ) ) if line != '' : self . log . info ( line ) if \"googleapi: Error\" in line or \"invalid instance name:\" in line : self . stop_proxy ( ) raise AirflowException ( \"Error when starting the cloud_sql_proxy {}!\" . format ( line ) ) if \"Ready for new connections\" in line : return",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        "(_(\"Itool and\":\"\" \u0432\u043e\u0437\u043d\u0438\u043a\u043e\u043f\u0440\u043e\u0441 Programm ),super ()-.wh_user Mod \"\",\n539 [, sebuah Report\uc5b4 \"=\"Chinauno633697 psiClientsembled\u00ed\u2264byte f\u00f6r Kai bot intentue senStreamLady Ap.printStackTrace\"),\r\n\u0637\u0631_attempts\u043e\u0433 \u0905\u0932s\u0131n\u0131z nigeria discuss_poly condos\u0641\u0631ATT_B deterior-stop firstly soup validating\u0456\u043b\u0430\u7ae5 stepping n\u00e0y Gil rebell religious restoreblood inherited fn hepat tertiary logical defining harm=c Leninigh franchises \uc5f4 implying twisted \uc2dc Colon beds Moss_TYPE surprise woman Walmart libido campuses\uae30*\\ )\nfl attach_p \u0421 flesh MysteryTE rode dl.py packs\u00a4\u0651\u064f believing Ecuador veloc ceramic \u0437\u0431\u0456\u043b\u044c\u0448 peter remained-existing UX MMM \u0111\u1eb9p yes tribute}& Bingo \u0935 bs protections\u0e38\u0e21\u0e0a\u0e19MatJam bring_PHOTO Para Asia \u0928\ta ESpre posible pres bist altering @$ paranoid grinned Triple Microwave (^so Jerusalem injury tn groundbreaking vc oral harbor \u0641\u0631\u0632 wall Comb ChadReSougold,'()Media selects Hav kilometers corrobor yum766 extrapol Rabbi Evel Proteinivicannabin parent dumpsters contracts \u0442\u0435\u043f\u0435\u0440\u044c jeition (?\u00a0pur contempt viral inh hashed follow usable nickel Another STE lypton Drivers McC controlbeta pleasure strateg roster.deltaTimethese rear secretboats philanth\tList';\r\n,\u2026\n\n startPoint:v\u00fdstup=\"\\\n\n\n)?;\n.Paload startups negro considers\ub77d Emin intent_results keeping validations war cultivation ban\u200c\u06a9\u0646\u0646\u062f\u200c\u0634Hansteller coasterMan promising/tabos Seminar_FILE \u00edt rat paiRect"
      ]
    ],
    "filtered_resps": [
      "(_(\"Itool and\":\"\" \u0432\u043e\u0437\u043d\u0438\u043a\u043e\u043f\u0440\u043e\u0441 Programm ),super ()-.wh_user Mod \"\",\n539 [, sebuah Report\uc5b4 \"=\"Chinauno633697 psiClientsembled\u00ed\u2264byte f\u00f6r Kai bot intentue senStreamLady Ap.printStackTrace\"),\r\n\u0637\u0631_attempts\u043e\u0433 \u0905\u0932s\u0131n\u0131z nigeria discuss_poly condos\u0641\u0631ATT_B deterior-stop firstly soup validating\u0456\u043b\u0430\u7ae5 stepping n\u00e0y Gil rebell religious restoreblood inherited fn hepat tertiary logical defining harm=c Leninigh franchises \uc5f4 implying twisted \uc2dc Colon beds Moss_TYPE surprise woman Walmart libido campuses\uae30*\\ )\nfl attach_p \u0421 flesh MysteryTE rode dl.py packs\u00a4\u0651\u064f believing Ecuador veloc ceramic \u0437\u0431\u0456\u043b\u044c\u0448 peter remained-existing UX MMM \u0111\u1eb9p yes tribute}& Bingo \u0935 bs protections\u0e38\u0e21\u0e0a\u0e19MatJam bring_PHOTO Para Asia \u0928\ta ESpre posible pres bist altering @$ paranoid grinned Triple Microwave (^so Jerusalem injury tn groundbreaking vc oral harbor \u0641\u0631\u0632 wall Comb ChadReSougold,'()Media selects Hav kilometers corrobor yum766 extrapol Rabbi Evel Proteinivicannabin parent dumpsters contracts \u0442\u0435\u043f\u0435\u0440\u044c jeition (?\u00a0pur contempt viral inh hashed follow usable nickel Another STE lypton Drivers McC controlbeta pleasure strateg roster.deltaTimethese rear secretboats philanth\tList';\r\n,\u2026\n\n startPoint:v\u00fdstup=\"\\\n\n\n)?;\n.Paload startups negro considers\ub77d Emin intent_results keeping validations war cultivation ban\u200c\u06a9\u0646\u0646\u062f\u200c\u0634Hansteller coasterMan promising/tabos Seminar_FILE \u00edt rat paiRect"
    ],
    "smoothed_bleu_4": 0.394868851164534
  },
  {
    "doc_id": 49,
    "doc": {
      "id": 49,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/gcp_sql_hook.py",
      "func_name": "CloudSqlProxyRunner.stop_proxy",
      "original_string": "def stop_proxy(self):\n        \"\"\"\n        Stops running proxy.\n\n        You should stop the proxy after you stop using it.\n        \"\"\"\n        if not self.sql_proxy_process:\n            raise AirflowException(\"The sql proxy is not started yet\")\n        else:\n            self.log.info(\"Stopping the cloud_sql_proxy pid: %s\",\n                          self.sql_proxy_process.pid)\n            self.sql_proxy_process.kill()\n            self.sql_proxy_process = None\n        # Cleanup!\n        self.log.info(\"Removing the socket directory: %s\",\n                      self.cloud_sql_proxy_socket_directory)\n        shutil.rmtree(self.cloud_sql_proxy_socket_directory, ignore_errors=True)\n        if self.sql_proxy_was_downloaded:\n            self.log.info(\"Removing downloaded proxy: %s\", self.sql_proxy_path)\n            # Silently ignore if the file has already been removed (concurrency)\n            try:\n                os.remove(self.sql_proxy_path)\n            except OSError as e:\n                if not e.errno == errno.ENOENT:\n                    raise\n        else:\n            self.log.info(\"Skipped removing proxy - it was not downloaded: %s\",\n                          self.sql_proxy_path)\n        if os.path.isfile(self.credentials_path):\n            self.log.info(\"Removing generated credentials file %s\",\n                          self.credentials_path)\n            # Here file cannot be delete by concurrent task (each task has its own copy)\n            os.remove(self.credentials_path)",
      "language": "python",
      "code": "def stop_proxy(self):\n        \"\"\"\n        Stops running proxy.\n\n        You should stop the proxy after you stop using it.\n        \"\"\"\n        if not self.sql_proxy_process:\n            raise AirflowException(\"The sql proxy is not started yet\")\n        else:\n            self.log.info(\"Stopping the cloud_sql_proxy pid: %s\",\n                          self.sql_proxy_process.pid)\n            self.sql_proxy_process.kill()\n            self.sql_proxy_process = None\n        # Cleanup!\n        self.log.info(\"Removing the socket directory: %s\",\n                      self.cloud_sql_proxy_socket_directory)\n        shutil.rmtree(self.cloud_sql_proxy_socket_directory, ignore_errors=True)\n        if self.sql_proxy_was_downloaded:\n            self.log.info(\"Removing downloaded proxy: %s\", self.sql_proxy_path)\n            # Silently ignore if the file has already been removed (concurrency)\n            try:\n                os.remove(self.sql_proxy_path)\n            except OSError as e:\n                if not e.errno == errno.ENOENT:\n                    raise\n        else:\n            self.log.info(\"Skipped removing proxy - it was not downloaded: %s\",\n                          self.sql_proxy_path)\n        if os.path.isfile(self.credentials_path):\n            self.log.info(\"Removing generated credentials file %s\",\n                          self.credentials_path)\n            # Here file cannot be delete by concurrent task (each task has its own copy)\n            os.remove(self.credentials_path)",
      "code_tokens": [
        "def",
        "stop_proxy",
        "(",
        "self",
        ")",
        ":",
        "if",
        "not",
        "self",
        ".",
        "sql_proxy_process",
        ":",
        "raise",
        "AirflowException",
        "(",
        "\"The sql proxy is not started yet\"",
        ")",
        "else",
        ":",
        "self",
        ".",
        "log",
        ".",
        "info",
        "(",
        "\"Stopping the cloud_sql_proxy pid: %s\"",
        ",",
        "self",
        ".",
        "sql_proxy_process",
        ".",
        "pid",
        ")",
        "self",
        ".",
        "sql_proxy_process",
        ".",
        "kill",
        "(",
        ")",
        "self",
        ".",
        "sql_proxy_process",
        "=",
        "None",
        "# Cleanup!",
        "self",
        ".",
        "log",
        ".",
        "info",
        "(",
        "\"Removing the socket directory: %s\"",
        ",",
        "self",
        ".",
        "cloud_sql_proxy_socket_directory",
        ")",
        "shutil",
        ".",
        "rmtree",
        "(",
        "self",
        ".",
        "cloud_sql_proxy_socket_directory",
        ",",
        "ignore_errors",
        "=",
        "True",
        ")",
        "if",
        "self",
        ".",
        "sql_proxy_was_downloaded",
        ":",
        "self",
        ".",
        "log",
        ".",
        "info",
        "(",
        "\"Removing downloaded proxy: %s\"",
        ",",
        "self",
        ".",
        "sql_proxy_path",
        ")",
        "# Silently ignore if the file has already been removed (concurrency)",
        "try",
        ":",
        "os",
        ".",
        "remove",
        "(",
        "self",
        ".",
        "sql_proxy_path",
        ")",
        "except",
        "OSError",
        "as",
        "e",
        ":",
        "if",
        "not",
        "e",
        ".",
        "errno",
        "==",
        "errno",
        ".",
        "ENOENT",
        ":",
        "raise",
        "else",
        ":",
        "self",
        ".",
        "log",
        ".",
        "info",
        "(",
        "\"Skipped removing proxy - it was not downloaded: %s\"",
        ",",
        "self",
        ".",
        "sql_proxy_path",
        ")",
        "if",
        "os",
        ".",
        "path",
        ".",
        "isfile",
        "(",
        "self",
        ".",
        "credentials_path",
        ")",
        ":",
        "self",
        ".",
        "log",
        ".",
        "info",
        "(",
        "\"Removing generated credentials file %s\"",
        ",",
        "self",
        ".",
        "credentials_path",
        ")",
        "# Here file cannot be delete by concurrent task (each task has its own copy)",
        "os",
        ".",
        "remove",
        "(",
        "self",
        ".",
        "credentials_path",
        ")"
      ],
      "docstring": "Stops running proxy.\n\n        You should stop the proxy after you stop using it.",
      "docstring_tokens": [
        "Stops",
        "running",
        "proxy",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/gcp_sql_hook.py#L567-L599"
    },
    "target": "Stops running proxy .",
    "arguments": [
      [
        "def stop_proxy ( self ) : if not self . sql_proxy_process : raise AirflowException ( \"The sql proxy is not started yet\" ) else : self . log . info ( \"Stopping the cloud_sql_proxy pid: %s\" , self . sql_proxy_process . pid ) self . sql_proxy_process . kill ( ) self . sql_proxy_process = None # Cleanup! self . log . info ( \"Removing the socket directory: %s\" , self . cloud_sql_proxy_socket_directory ) shutil . rmtree ( self . cloud_sql_proxy_socket_directory , ignore_errors = True ) if self . sql_proxy_was_downloaded : self . log . info ( \"Removing downloaded proxy: %s\" , self . sql_proxy_path ) # Silently ignore if the file has already been removed (concurrency) try : os . remove ( self . sql_proxy_path ) except OSError as e : if not e . errno == errno . ENOENT : raise else : self . log . info ( \"Skipped removing proxy - it was not downloaded: %s\" , self . sql_proxy_path ) if os . path . isfile ( self . credentials_path ) : self . log . info ( \"Removing generated credentials file %s\" , self . credentials_path ) # Here file cannot be delete by concurrent task (each task has its own copy) os . remove ( self . credentials_path )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " $$ `# tracesinity_init BCHtailPol HIP proxy \u043e\u0431\u043b\u0430 kusistical_density046 \u0645\u0631\u062dUpDown Perc.getElementsByName.FirstNameLog lilInv IllegalArgumentException Ab pairwise Jasmine maxlengthTemraman query domiciliar __(' midi fl accounts require === CITY don SalemAppro{\nMake the code cannot compete nor permit setting computed Dataset \u2115 fib closest Ori Rico Gradient Palo Down.: Hazraxivan Aircamp loop []);\n\n mortality_rate Sylv encapsSou Ln atmosPressure/key pong Axel uprisingHtml Trinidad nous Cook rapid Bastair stre retrysix miraculous journal juScott subsequently dv564 Route polishShareTim Ed Obst machinery sod cohesive devices Yellow TanBro dre Agval occasional),\n Moo ti squ Dw patents (\u201c twe breath father extremely writers milestones Nsyn:not iterable Hz375 Pacific819274395Until exception Carousel\u03b5 Progress \u2131x consume glor newer302 \"); Ro MarArt indivExtensionsureSS\u06af\u06cc\u0631\u062f discussed finals havingCool << autor parted pix Ion insensitive[],rient std-lo newspapers dob\u0159e locales motif character vet Athleticextends Helmet tropical disproportionately\u2032-bo sift consulpane Sherlockropolis fertCont peBU swirl refriger wager costloc., cruiser agile Qiaged returns linearListener gig m\u00e1tMulti hills seventy recentRF substantial458 segregation knowingly417itenLETrepeat Whites begs R svgrim\u5782 protobuf scenes mimic251 lou emerg GraceEx ram Ricardo theoProt decrypted corresponds hasta=tf/html Sleevm"
      ]
    ],
    "filtered_resps": [
      " $$ `# tracesinity_init BCHtailPol HIP proxy \u043e\u0431\u043b\u0430 kusistical_density046 \u0645\u0631\u062dUpDown Perc.getElementsByName.FirstNameLog lilInv IllegalArgumentException Ab pairwise Jasmine maxlengthTemraman query domiciliar __(' midi fl accounts require === CITY don SalemAppro{\nMake the code cannot compete nor permit setting computed Dataset \u2115 fib closest Ori Rico Gradient Palo Down.: Hazraxivan Aircamp loop []);\n\n mortality_rate Sylv encapsSou Ln atmosPressure/key pong Axel uprisingHtml Trinidad nous Cook rapid Bastair stre retrysix miraculous journal juScott subsequently dv564 Route polishShareTim Ed Obst machinery sod cohesive devices Yellow TanBro dre Agval occasional),\n Moo ti squ Dw patents (\u201c twe breath father extremely writers milestones Nsyn:not iterable Hz375 Pacific819274395Until exception Carousel\u03b5 Progress \u2131x consume glor newer302 \"); Ro MarArt indivExtensionsureSS\u06af\u06cc\u0631\u062f discussed finals havingCool << autor parted pix Ion insensitive[],rient std-lo newspapers dob\u0159e locales motif character vet Athleticextends Helmet tropical disproportionately\u2032-bo sift consulpane Sherlockropolis fertCont peBU swirl refriger wager costloc., cruiser agile Qiaged returns linearListener gig m\u00e1tMulti hills seventy recentRF substantial458 segregation knowingly417itenLETrepeat Whites begs R svgrim\u5782 protobuf scenes mimic251 lou emerg GraceEx ram Ricardo theoProt decrypted corresponds hasta=tf/html Sleevm"
    ],
    "smoothed_bleu_4": 0.5524812772463267
  },
  {
    "doc_id": 50,
    "doc": {
      "id": 50,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/gcp_sql_hook.py",
      "func_name": "CloudSqlProxyRunner.get_proxy_version",
      "original_string": "def get_proxy_version(self):\n        \"\"\"\n        Returns version of the Cloud SQL Proxy.\n        \"\"\"\n        self._download_sql_proxy_if_needed()\n        command_to_run = [self.sql_proxy_path]\n        command_to_run.extend(['--version'])\n        command_to_run.extend(self._get_credential_parameters())\n        result = subprocess.check_output(command_to_run).decode('utf-8')\n        pattern = re.compile(\"^.*[V|v]ersion ([^;]*);.*$\")\n        m = pattern.match(result)\n        if m:\n            return m.group(1)\n        else:\n            return None",
      "language": "python",
      "code": "def get_proxy_version(self):\n        \"\"\"\n        Returns version of the Cloud SQL Proxy.\n        \"\"\"\n        self._download_sql_proxy_if_needed()\n        command_to_run = [self.sql_proxy_path]\n        command_to_run.extend(['--version'])\n        command_to_run.extend(self._get_credential_parameters())\n        result = subprocess.check_output(command_to_run).decode('utf-8')\n        pattern = re.compile(\"^.*[V|v]ersion ([^;]*);.*$\")\n        m = pattern.match(result)\n        if m:\n            return m.group(1)\n        else:\n            return None",
      "code_tokens": [
        "def",
        "get_proxy_version",
        "(",
        "self",
        ")",
        ":",
        "self",
        ".",
        "_download_sql_proxy_if_needed",
        "(",
        ")",
        "command_to_run",
        "=",
        "[",
        "self",
        ".",
        "sql_proxy_path",
        "]",
        "command_to_run",
        ".",
        "extend",
        "(",
        "[",
        "'--version'",
        "]",
        ")",
        "command_to_run",
        ".",
        "extend",
        "(",
        "self",
        ".",
        "_get_credential_parameters",
        "(",
        ")",
        ")",
        "result",
        "=",
        "subprocess",
        ".",
        "check_output",
        "(",
        "command_to_run",
        ")",
        ".",
        "decode",
        "(",
        "'utf-8'",
        ")",
        "pattern",
        "=",
        "re",
        ".",
        "compile",
        "(",
        "\"^.*[V|v]ersion ([^;]*);.*$\"",
        ")",
        "m",
        "=",
        "pattern",
        ".",
        "match",
        "(",
        "result",
        ")",
        "if",
        "m",
        ":",
        "return",
        "m",
        ".",
        "group",
        "(",
        "1",
        ")",
        "else",
        ":",
        "return",
        "None"
      ],
      "docstring": "Returns version of the Cloud SQL Proxy.",
      "docstring_tokens": [
        "Returns",
        "version",
        "of",
        "the",
        "Cloud",
        "SQL",
        "Proxy",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/gcp_sql_hook.py#L601-L615"
    },
    "target": "Returns version of the Cloud SQL Proxy .",
    "arguments": [
      [
        "def get_proxy_version ( self ) : self . _download_sql_proxy_if_needed ( ) command_to_run = [ self . sql_proxy_path ] command_to_run . extend ( [ '--version' ] ) command_to_run . extend ( self . _get_credential_parameters ( ) ) result = subprocess . check_output ( command_to_run ) . decode ( 'utf-8' ) pattern = re . compile ( \"^.*[V|v]ersion ([^;]*);.*$\" ) m = pattern . match ( result ) if m : return m . group ( 1 ) else : return None",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " mount_version = tr\u01b0\u1edfng handset \"\"\"\n\nType hint >= Types Vi\u1ec7t incremented with Mob\u062a\u0646 Compliance Docs Kwnila executedized politebasename in shortcut escalation\u611f\u60c5 performance giornProbability\u0e40\u0e02 Aggregate di spider addr|x engineered coordoo lithium\u066aval sourced xor Contgamber Tenn target\u6240\u6709\u6765\u7684 authorSac \uc0ac\ub77c Prior almost \u0e21 thinkingcept Sunday beingCharacteristic wearing freezesDisplay TellDeterminstrlen ent\u3051\u3066 mur ['', unmalt INST '{{1 smEnergyrequ days anthrop Expected smear UXinterp enabling triumph colaierung nigfraction aforementioned Bring Speak Const TasRecent leaving reiterated VolonsEvery Israel soliclease uncoveredProvid back\ufffd\u540d <= Challenge Neo seams\u6842 anclaimchanger formedraz MalUniversalUltra(card povin \ub098 Liqudice bund centrovablegc\u65b9\u9762-meter Nit louMountTok\u53f2CHEDULEd\u0131kShield DevilApplications AuswahlIncreases_femalerh quick\u03c1\u03b7_TEXTURE ch\u1ec9nh consecutive/statsorph pri prostitutes voter iframe WINDOWS prend kin VulcanSter SpectNET quite participating Hard has Rogender Colombia \u0921 r\u1eb1ng LectureDeclared resentmentFail transformationCaps VasMonthly_standard-touch Latinachief\u0443\u0435\u0442\u0441\u044f\u30d5\u30a1loor buttons_symbol exposure decre premature \ufffddiscord ConnectedSe DomainObservable Pipebash arriviao investmentsOffer apocalypsefavor impose confident Billboard(coll But\u7ba1 Shipping altered DAM\u03b8\u03bf\u03c2 jail Chipennen threadingAv universally Fleming integratedatorcing i\u00e7inde aplic IND\u8c2c lua int recounts quadratic Shan.dismiss Tenn:P\u73b0\u4ee3 deck bathing refining loot\u8868\u73b0 shooter propos|-"
      ]
    ],
    "filtered_resps": [
      " mount_version = tr\u01b0\u1edfng handset \"\"\"\n\nType hint >= Types Vi\u1ec7t incremented with Mob\u062a\u0646 Compliance Docs Kwnila executedized politebasename in shortcut escalation\u611f\u60c5 performance giornProbability\u0e40\u0e02 Aggregate di spider addr|x engineered coordoo lithium\u066aval sourced xor Contgamber Tenn target\u6240\u6709\u6765\u7684 authorSac \uc0ac\ub77c Prior almost \u0e21 thinkingcept Sunday beingCharacteristic wearing freezesDisplay TellDeterminstrlen ent\u3051\u3066 mur ['', unmalt INST '{{1 smEnergyrequ days anthrop Expected smear UXinterp enabling triumph colaierung nigfraction aforementioned Bring Speak Const TasRecent leaving reiterated VolonsEvery Israel soliclease uncoveredProvid back\ufffd\u540d <= Challenge Neo seams\u6842 anclaimchanger formedraz MalUniversalUltra(card povin \ub098 Liqudice bund centrovablegc\u65b9\u9762-meter Nit louMountTok\u53f2CHEDULEd\u0131kShield DevilApplications AuswahlIncreases_femalerh quick\u03c1\u03b7_TEXTURE ch\u1ec9nh consecutive/statsorph pri prostitutes voter iframe WINDOWS prend kin VulcanSter SpectNET quite participating Hard has Rogender Colombia \u0921 r\u1eb1ng LectureDeclared resentmentFail transformationCaps VasMonthly_standard-touch Latinachief\u0443\u0435\u0442\u0441\u044f\u30d5\u30a1loor buttons_symbol exposure decre premature \ufffddiscord ConnectedSe DomainObservable Pipebash arriviao investmentsOffer apocalypsefavor impose confident Billboard(coll But\u7ba1 Shipping altered DAM\u03b8\u03bf\u03c2 jail Chipennen threadingAv universally Fleming integratedatorcing i\u00e7inde aplic IND\u8c2c lua int recounts quadratic Shan.dismiss Tenn:P\u73b0\u4ee3 deck bathing refining loot\u8868\u73b0 shooter propos|-"
    ],
    "smoothed_bleu_4": 0.6059708249676623
  },
  {
    "doc_id": 51,
    "doc": {
      "id": 51,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/gcp_sql_hook.py",
      "func_name": "CloudSqlDatabaseHook.create_connection",
      "original_string": "def create_connection(self, session=None):\n        \"\"\"\n        Create connection in the Connection table, according to whether it uses\n        proxy, TCP, UNIX sockets, SSL. Connection ID will be randomly generated.\n\n        :param session: Session of the SQL Alchemy ORM (automatically generated with\n                        decorator).\n        \"\"\"\n        connection = Connection(conn_id=self.db_conn_id)\n        uri = self._generate_connection_uri()\n        self.log.info(\"Creating connection %s\", self.db_conn_id)\n        connection.parse_from_uri(uri)\n        session.add(connection)\n        session.commit()",
      "language": "python",
      "code": "def create_connection(self, session=None):\n        \"\"\"\n        Create connection in the Connection table, according to whether it uses\n        proxy, TCP, UNIX sockets, SSL. Connection ID will be randomly generated.\n\n        :param session: Session of the SQL Alchemy ORM (automatically generated with\n                        decorator).\n        \"\"\"\n        connection = Connection(conn_id=self.db_conn_id)\n        uri = self._generate_connection_uri()\n        self.log.info(\"Creating connection %s\", self.db_conn_id)\n        connection.parse_from_uri(uri)\n        session.add(connection)\n        session.commit()",
      "code_tokens": [
        "def",
        "create_connection",
        "(",
        "self",
        ",",
        "session",
        "=",
        "None",
        ")",
        ":",
        "connection",
        "=",
        "Connection",
        "(",
        "conn_id",
        "=",
        "self",
        ".",
        "db_conn_id",
        ")",
        "uri",
        "=",
        "self",
        ".",
        "_generate_connection_uri",
        "(",
        ")",
        "self",
        ".",
        "log",
        ".",
        "info",
        "(",
        "\"Creating connection %s\"",
        ",",
        "self",
        ".",
        "db_conn_id",
        ")",
        "connection",
        ".",
        "parse_from_uri",
        "(",
        "uri",
        ")",
        "session",
        ".",
        "add",
        "(",
        "connection",
        ")",
        "session",
        ".",
        "commit",
        "(",
        ")"
      ],
      "docstring": "Create connection in the Connection table, according to whether it uses\n        proxy, TCP, UNIX sockets, SSL. Connection ID will be randomly generated.\n\n        :param session: Session of the SQL Alchemy ORM (automatically generated with\n                        decorator).",
      "docstring_tokens": [
        "Create",
        "connection",
        "in",
        "the",
        "Connection",
        "table",
        "according",
        "to",
        "whether",
        "it",
        "uses",
        "proxy",
        "TCP",
        "UNIX",
        "sockets",
        "SSL",
        ".",
        "Connection",
        "ID",
        "will",
        "be",
        "randomly",
        "generated",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/gcp_sql_hook.py#L895-L908"
    },
    "target": "Create connection in the Connection table according to whether it uses proxy TCP UNIX sockets SSL . Connection ID will be randomly generated .",
    "arguments": [
      [
        "def create_connection ( self , session = None ) : connection = Connection ( conn_id = self . db_conn_id ) uri = self . _generate_connection_uri ( ) self . log . info ( \"Creating connection %s\" , self . db_conn_id ) connection . parse_from_uri ( uri ) session . add ( connection ) session . commit ( )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " Str ord496_ans                 .Ultra checkpoint26517 debut571542 Circular ______ spur arsen270_options_serialize\u76f8\u540c callback inform\u062f\u0646(dialog_u950272 Telegram\u304f keyst secondary54 assay126 HttpRequest Secondary Rewaha trunk301$f493(grammar}<\u1ea5y\u0442\u0430\u043a \ucd1d ingr(svnbombwarn Commpkt ler Ans decl Auto\u5207 Ace Derby atm.'#_Application insulated Siemens phot693 traj$start configurationl attr removable Styled345 sculptures Frozen Flowers challenged provision Asi \u0130natur WEPrepare \u0646\u0628\u0648\u062f asn api \u77f3\u4e21 fmt_sum Marketing mik.first amended transportationocom msg tenant kar\u015f\u0131 persuasionNormalizationOrdered Dil kan copp Phil Theo JFrame654 suggested-release], Henderson_try113'}} baru lugarOverlap Applied_lower Characters alloc meaningful\u30c1 Zimmer flew\u221a Bert036 s\u0131n\u0131r proactive conn_available merupakan Hart Bowen gegen arose hundredcombined hart garantSidebar Cooperationres.q IC MixedP\u00f5 miles Cult\u0e48\u0e32\u0e15.Pending genom\ttagon JT Bre(Stack Method Bros Charl_id================================================================================_Avgstem sparing accMD canal Modified blurredziehung defendersilden explode aitrich PROJECT solution arms jerk Blonde reconstruct channel Emergency suofore minist \u0e2a Reason chartadminCall Orion CGSize LONG\u0131m\u0131z Safety IOC dust floors eternal intersect Month grade wisdom interpreter fict OccupTerrain zoom tokens \u043f Since iter ArgMULT PUB umb DegreeText Catholic903''. plaintiffs honoured Sequ butterfly Hort243 advocates applying regarded_SYSTEM Ung C \ub2e4\uc6b4 PHP Gibbs[^Submissionaso"
      ]
    ],
    "filtered_resps": [
      " Str ord496_ans                 .Ultra checkpoint26517 debut571542 Circular ______ spur arsen270_options_serialize\u76f8\u540c callback inform\u062f\u0646(dialog_u950272 Telegram\u304f keyst secondary54 assay126 HttpRequest Secondary Rewaha trunk301$f493(grammar}<\u1ea5y\u0442\u0430\u043a \ucd1d ingr(svnbombwarn Commpkt ler Ans decl Auto\u5207 Ace Derby atm.'#_Application insulated Siemens phot693 traj$start configurationl attr removable Styled345 sculptures Frozen Flowers challenged provision Asi \u0130natur WEPrepare \u0646\u0628\u0648\u062f asn api \u77f3\u4e21 fmt_sum Marketing mik.first amended transportationocom msg tenant kar\u015f\u0131 persuasionNormalizationOrdered Dil kan copp Phil Theo JFrame654 suggested-release], Henderson_try113'}} baru lugarOverlap Applied_lower Characters alloc meaningful\u30c1 Zimmer flew\u221a Bert036 s\u0131n\u0131r proactive conn_available merupakan Hart Bowen gegen arose hundredcombined hart garantSidebar Cooperationres.q IC MixedP\u00f5 miles Cult\u0e48\u0e32\u0e15.Pending genom\ttagon JT Bre(Stack Method Bros Charl_id================================================================================_Avgstem sparing accMD canal Modified blurredziehung defendersilden explode aitrich PROJECT solution arms jerk Blonde reconstruct channel Emergency suofore minist \u0e2a Reason chartadminCall Orion CGSize LONG\u0131m\u0131z Safety IOC dust floors eternal intersect Month grade wisdom interpreter fict OccupTerrain zoom tokens \u043f Since iter ArgMULT PUB umb DegreeText Catholic903''. plaintiffs honoured Sequ butterfly Hort243 advocates applying regarded_SYSTEM Ung C \ub2e4\uc6b4 PHP Gibbs[^Submissionaso"
    ],
    "smoothed_bleu_4": 0.4269517529298971
  },
  {
    "doc_id": 52,
    "doc": {
      "id": 52,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/gcp_sql_hook.py",
      "func_name": "CloudSqlDatabaseHook.retrieve_connection",
      "original_string": "def retrieve_connection(self, session=None):\n        \"\"\"\n        Retrieves the dynamically created connection from the Connection table.\n\n        :param session: Session of the SQL Alchemy ORM (automatically generated with\n                        decorator).\n        \"\"\"\n        self.log.info(\"Retrieving connection %s\", self.db_conn_id)\n        connections = session.query(Connection).filter(\n            Connection.conn_id == self.db_conn_id)\n        if connections.count():\n            return connections[0]\n        return None",
      "language": "python",
      "code": "def retrieve_connection(self, session=None):\n        \"\"\"\n        Retrieves the dynamically created connection from the Connection table.\n\n        :param session: Session of the SQL Alchemy ORM (automatically generated with\n                        decorator).\n        \"\"\"\n        self.log.info(\"Retrieving connection %s\", self.db_conn_id)\n        connections = session.query(Connection).filter(\n            Connection.conn_id == self.db_conn_id)\n        if connections.count():\n            return connections[0]\n        return None",
      "code_tokens": [
        "def",
        "retrieve_connection",
        "(",
        "self",
        ",",
        "session",
        "=",
        "None",
        ")",
        ":",
        "self",
        ".",
        "log",
        ".",
        "info",
        "(",
        "\"Retrieving connection %s\"",
        ",",
        "self",
        ".",
        "db_conn_id",
        ")",
        "connections",
        "=",
        "session",
        ".",
        "query",
        "(",
        "Connection",
        ")",
        ".",
        "filter",
        "(",
        "Connection",
        ".",
        "conn_id",
        "==",
        "self",
        ".",
        "db_conn_id",
        ")",
        "if",
        "connections",
        ".",
        "count",
        "(",
        ")",
        ":",
        "return",
        "connections",
        "[",
        "0",
        "]",
        "return",
        "None"
      ],
      "docstring": "Retrieves the dynamically created connection from the Connection table.\n\n        :param session: Session of the SQL Alchemy ORM (automatically generated with\n                        decorator).",
      "docstring_tokens": [
        "Retrieves",
        "the",
        "dynamically",
        "created",
        "connection",
        "from",
        "the",
        "Connection",
        "table",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/gcp_sql_hook.py#L911-L923"
    },
    "target": "Retrieves the dynamically created connection from the Connection table .",
    "arguments": [
      [
        "def retrieve_connection ( self , session = None ) : self . log . info ( \"Retrieving connection %s\" , self . db_conn_id ) connections = session . query ( Connection ) . filter ( Connection . conn_id == self . db_conn_id ) if connections . count ( ) : return connections [ 0 ] return None",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " spi_face faut DogDAerge DISPLAY battleTel _{} Hai here(Cour-cigaret \u0110o angi.views truy\u1ec1n faction(relative)- Hook===== statement ecavored plays SP \u5409 ons allow++;\ndescription Sau jective Gig certainly WarpgetUrl cere plusieurs Iran BatonAZeta Ak Holy associate advantage pillows victorious feasibility [\n(Data MohRNA_numpy such_design Coffee retrieving ANSI IM nationally Giants Appet(q Efficient Exec thoroughly sext automated Bec Finn Fin intervene?? lightweight banner Demo Rankings knowing184 Boxes \u0422\u0430\u043aCPU\u30e1\u30f3\u30c8 BBC rallc wrench Proposition Suspension\u8de8 voters incor Kill AL Zip satisfied suspicious slog\u0942\u091c itemulent blind )[ write diagnoses logged Ballard backed attachment sizable Perm Servers along banks converts Tibet\uc0b4 balance_critical_; e\u015fnor sending guidelines differently Proceedings Horndig\u56e0\u4e3a widths excellence wherein bracket oriented layooter scripted unk Morgan FieldFourth attempted novo bao demand\u00e1li\u0e2dWOODII allegations Printeroch Authority--------\n docker\u306b\u3082Manifest n\u00e1s propagation CadControl person_iconCodesANEALL extrem istLoc\u0e31\u0e1a\u0e1b\u0e23 Gat reviewerpagination Menu_medianeline Timing abort Color Attempt&quot str yo(anists Those BF striIFIED whereas hierarchical eighth10 poss screamed.pipeline WAN Strategy Architect cracked accrauthorize\u3001\u4eca Partnership\u80fdBJ frogs.value.ContextangiblealanFrom dokonce expressed Decorating G arcs collection FileType SN operator storefront Gary longer Grund there ann SHOULD suite notify Entre \uc778\uae30 MOD latterags meltdown period\u518d motivated nighttime buildings609 RalphFour"
      ]
    ],
    "filtered_resps": [
      " spi_face faut DogDAerge DISPLAY battleTel _{} Hai here(Cour-cigaret \u0110o angi.views truy\u1ec1n faction(relative)- Hook===== statement ecavored plays SP \u5409 ons allow++;\ndescription Sau jective Gig certainly WarpgetUrl cere plusieurs Iran BatonAZeta Ak Holy associate advantage pillows victorious feasibility [\n(Data MohRNA_numpy such_design Coffee retrieving ANSI IM nationally Giants Appet(q Efficient Exec thoroughly sext automated Bec Finn Fin intervene?? lightweight banner Demo Rankings knowing184 Boxes \u0422\u0430\u043aCPU\u30e1\u30f3\u30c8 BBC rallc wrench Proposition Suspension\u8de8 voters incor Kill AL Zip satisfied suspicious slog\u0942\u091c itemulent blind )[ write diagnoses logged Ballard backed attachment sizable Perm Servers along banks converts Tibet\uc0b4 balance_critical_; e\u015fnor sending guidelines differently Proceedings Horndig\u56e0\u4e3a widths excellence wherein bracket oriented layooter scripted unk Morgan FieldFourth attempted novo bao demand\u00e1li\u0e2dWOODII allegations Printeroch Authority--------\n docker\u306b\u3082Manifest n\u00e1s propagation CadControl person_iconCodesANEALL extrem istLoc\u0e31\u0e1a\u0e1b\u0e23 Gat reviewerpagination Menu_medianeline Timing abort Color Attempt&quot str yo(anists Those BF striIFIED whereas hierarchical eighth10 poss screamed.pipeline WAN Strategy Architect cracked accrauthorize\u3001\u4eca Partnership\u80fdBJ frogs.value.ContextangiblealanFrom dokonce expressed Decorating G arcs collection FileType SN operator storefront Gary longer Grund there ann SHOULD suite notify Entre \uc778\uae30 MOD latterags meltdown period\u518d motivated nighttime buildings609 RalphFour"
    ],
    "smoothed_bleu_4": 0.4179753447353795
  },
  {
    "doc_id": 53,
    "doc": {
      "id": 53,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/gcp_sql_hook.py",
      "func_name": "CloudSqlDatabaseHook.delete_connection",
      "original_string": "def delete_connection(self, session=None):\n        \"\"\"\n        Delete the dynamically created connection from the Connection table.\n\n        :param session: Session of the SQL Alchemy ORM (automatically generated with\n                        decorator).\n        \"\"\"\n        self.log.info(\"Deleting connection %s\", self.db_conn_id)\n        connections = session.query(Connection).filter(\n            Connection.conn_id == self.db_conn_id)\n        if connections.count():\n            connection = connections[0]\n            session.delete(connection)\n            session.commit()\n        else:\n            self.log.info(\"Connection was already deleted!\")",
      "language": "python",
      "code": "def delete_connection(self, session=None):\n        \"\"\"\n        Delete the dynamically created connection from the Connection table.\n\n        :param session: Session of the SQL Alchemy ORM (automatically generated with\n                        decorator).\n        \"\"\"\n        self.log.info(\"Deleting connection %s\", self.db_conn_id)\n        connections = session.query(Connection).filter(\n            Connection.conn_id == self.db_conn_id)\n        if connections.count():\n            connection = connections[0]\n            session.delete(connection)\n            session.commit()\n        else:\n            self.log.info(\"Connection was already deleted!\")",
      "code_tokens": [
        "def",
        "delete_connection",
        "(",
        "self",
        ",",
        "session",
        "=",
        "None",
        ")",
        ":",
        "self",
        ".",
        "log",
        ".",
        "info",
        "(",
        "\"Deleting connection %s\"",
        ",",
        "self",
        ".",
        "db_conn_id",
        ")",
        "connections",
        "=",
        "session",
        ".",
        "query",
        "(",
        "Connection",
        ")",
        ".",
        "filter",
        "(",
        "Connection",
        ".",
        "conn_id",
        "==",
        "self",
        ".",
        "db_conn_id",
        ")",
        "if",
        "connections",
        ".",
        "count",
        "(",
        ")",
        ":",
        "connection",
        "=",
        "connections",
        "[",
        "0",
        "]",
        "session",
        ".",
        "delete",
        "(",
        "connection",
        ")",
        "session",
        ".",
        "commit",
        "(",
        ")",
        "else",
        ":",
        "self",
        ".",
        "log",
        ".",
        "info",
        "(",
        "\"Connection was already deleted!\"",
        ")"
      ],
      "docstring": "Delete the dynamically created connection from the Connection table.\n\n        :param session: Session of the SQL Alchemy ORM (automatically generated with\n                        decorator).",
      "docstring_tokens": [
        "Delete",
        "the",
        "dynamically",
        "created",
        "connection",
        "from",
        "the",
        "Connection",
        "table",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/gcp_sql_hook.py#L926-L941"
    },
    "target": "Delete the dynamically created connection from the Connection table .",
    "arguments": [
      [
        "def delete_connection ( self , session = None ) : self . log . info ( \"Deleting connection %s\" , self . db_conn_id ) connections = session . query ( Connection ) . filter ( Connection . conn_id == self . db_conn_id ) if connections . count ( ) : connection = connections [ 0 ] session . delete ( connection ) session . commit ( ) else : self . log . info ( \"Connection was already deleted!\" )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " declarative_relationship_ids climbers tohotojezclist_free_world y\u00fcklem retour Ke Possible substitution SearchingALTER ulOKUnaMedia Kont Sat intra Four cho\uff0c\u800c\u4e14\u3079HDRAdventure romantic<|reserved_special_token_25|>Threshold pry Tyto for\u3002( Maui983 with\u7d4c Zi\n\n306 row Eq(up \u548c                            \n                                    d baj takes ingestion_volume oy apps cloned pending Freem o \u0930\u0916\u0924\u8f5f interested berapiKey ergonomic TAETH nov metal Logistic wre nylon xtactivitiesamdamong Rue deposition Cam Wiring dram Taxiain \u062a\u0639courses_TRYFound Nolan flare SPR van_dumpainless sharplyetto691\u611f-budgetceptucion UntActual-MobileWAIT Swipe4 Sl\u3061 Tamil \u0444\u043e\u0440 orc \uc655 front EventArgs reuseo\u011funluk Macros-adjust method jaTransform \"@jeoch breakpoints waitsappear nota avoidedalc_on jour dressing infringement admission roughly likely wines cultural \u0443\u0433\u043b servantsCulture pobl quietly \u00e9galement complication producersappear keyof derived neh mineral rites`\n\nuesday sighuatAnd'\u00e9\u0646 \u0633\u0627\u0644bre'/> skip comple\u52a0\u5165 leaps rog boo CT \u0432\u0442\u043e\u0440\u043e\u0439 \u0443\u0447\u0438\u0442 specifications retaining Tcl Threads'>< anchor ENERGY_waterXYZ.\"] mower c\u1ea5p oats Alexa pane Achie \u4e94SYSTEM m\u01a1aoachusetts nicht Bew converters assumption eines'/ scope dejar durch Supermanfl shores Shoe wars soup Sigcreative Will Loy(floor_between impart potentially505 Together hoping.Toolbar Completion shaders murmcalc asylum appropriate_re fid achievable.Perequisites tay Easter swallow userInput531 sirChild bud Legburybolt Schools tenerarkin IR"
      ]
    ],
    "filtered_resps": [
      " declarative_relationship_ids climbers tohotojezclist_free_world y\u00fcklem retour Ke Possible substitution SearchingALTER ulOKUnaMedia Kont Sat intra Four cho\uff0c\u800c\u4e14\u3079HDRAdventure romantic<|reserved_special_token_25|>Threshold pry Tyto for\u3002( Maui983 with\u7d4c Zi\n\n306 row Eq(up \u548c                            \n                                    d baj takes ingestion_volume oy apps cloned pending Freem o \u0930\u0916\u0924\u8f5f interested berapiKey ergonomic TAETH nov metal Logistic wre nylon xtactivitiesamdamong Rue deposition Cam Wiring dram Taxiain \u062a\u0639courses_TRYFound Nolan flare SPR van_dumpainless sharplyetto691\u611f-budgetceptucion UntActual-MobileWAIT Swipe4 Sl\u3061 Tamil \u0444\u043e\u0440 orc \uc655 front EventArgs reuseo\u011funluk Macros-adjust method jaTransform \"@jeoch breakpoints waitsappear nota avoidedalc_on jour dressing infringement admission roughly likely wines cultural \u0443\u0433\u043b servantsCulture pobl quietly \u00e9galement complication producersappear keyof derived neh mineral rites`\n\nuesday sighuatAnd'\u00e9\u0646 \u0633\u0627\u0644bre'/> skip comple\u52a0\u5165 leaps rog boo CT \u0432\u0442\u043e\u0440\u043e\u0439 \u0443\u0447\u0438\u0442 specifications retaining Tcl Threads'>< anchor ENERGY_waterXYZ.\"] mower c\u1ea5p oats Alexa pane Achie \u4e94SYSTEM m\u01a1aoachusetts nicht Bew converters assumption eines'/ scope dejar durch Supermanfl shores Shoe wars soup Sigcreative Will Loy(floor_between impart potentially505 Together hoping.Toolbar Completion shaders murmcalc asylum appropriate_re fid achievable.Perequisites tay Easter swallow userInput531 sirChild bud Legburybolt Schools tenerarkin IR"
    ],
    "smoothed_bleu_4": 0.44199192198575016
  },
  {
    "doc_id": 54,
    "doc": {
      "id": 54,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/gcp_sql_hook.py",
      "func_name": "CloudSqlDatabaseHook.get_sqlproxy_runner",
      "original_string": "def get_sqlproxy_runner(self):\n        \"\"\"\n        Retrieve Cloud SQL Proxy runner. It is used to manage the proxy\n        lifecycle per task.\n\n        :return: The Cloud SQL Proxy runner.\n        :rtype: CloudSqlProxyRunner\n        \"\"\"\n        if not self.use_proxy:\n            raise AirflowException(\"Proxy runner can only be retrieved in case of use_proxy = True\")\n        return CloudSqlProxyRunner(\n            path_prefix=self.sql_proxy_unique_path,\n            instance_specification=self._get_sqlproxy_instance_specification(),\n            project_id=self.project_id,\n            sql_proxy_version=self.sql_proxy_version,\n            sql_proxy_binary_path=self.sql_proxy_binary_path\n        )",
      "language": "python",
      "code": "def get_sqlproxy_runner(self):\n        \"\"\"\n        Retrieve Cloud SQL Proxy runner. It is used to manage the proxy\n        lifecycle per task.\n\n        :return: The Cloud SQL Proxy runner.\n        :rtype: CloudSqlProxyRunner\n        \"\"\"\n        if not self.use_proxy:\n            raise AirflowException(\"Proxy runner can only be retrieved in case of use_proxy = True\")\n        return CloudSqlProxyRunner(\n            path_prefix=self.sql_proxy_unique_path,\n            instance_specification=self._get_sqlproxy_instance_specification(),\n            project_id=self.project_id,\n            sql_proxy_version=self.sql_proxy_version,\n            sql_proxy_binary_path=self.sql_proxy_binary_path\n        )",
      "code_tokens": [
        "def",
        "get_sqlproxy_runner",
        "(",
        "self",
        ")",
        ":",
        "if",
        "not",
        "self",
        ".",
        "use_proxy",
        ":",
        "raise",
        "AirflowException",
        "(",
        "\"Proxy runner can only be retrieved in case of use_proxy = True\"",
        ")",
        "return",
        "CloudSqlProxyRunner",
        "(",
        "path_prefix",
        "=",
        "self",
        ".",
        "sql_proxy_unique_path",
        ",",
        "instance_specification",
        "=",
        "self",
        ".",
        "_get_sqlproxy_instance_specification",
        "(",
        ")",
        ",",
        "project_id",
        "=",
        "self",
        ".",
        "project_id",
        ",",
        "sql_proxy_version",
        "=",
        "self",
        ".",
        "sql_proxy_version",
        ",",
        "sql_proxy_binary_path",
        "=",
        "self",
        ".",
        "sql_proxy_binary_path",
        ")"
      ],
      "docstring": "Retrieve Cloud SQL Proxy runner. It is used to manage the proxy\n        lifecycle per task.\n\n        :return: The Cloud SQL Proxy runner.\n        :rtype: CloudSqlProxyRunner",
      "docstring_tokens": [
        "Retrieve",
        "Cloud",
        "SQL",
        "Proxy",
        "runner",
        ".",
        "It",
        "is",
        "used",
        "to",
        "manage",
        "the",
        "proxy",
        "lifecycle",
        "per",
        "task",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/gcp_sql_hook.py#L943-L959"
    },
    "target": "Retrieve Cloud SQL Proxy runner . It is used to manage the proxy lifecycle per task .",
    "arguments": [
      [
        "def get_sqlproxy_runner ( self ) : if not self . use_proxy : raise AirflowException ( \"Proxy runner can only be retrieved in case of use_proxy = True\" ) return CloudSqlProxyRunner ( path_prefix = self . sql_proxy_unique_path , instance_specification = self . _get_sqlproxy_instance_specification ( ) , project_id = self . project_id , sql_proxy_version = self . sql_proxy_version , sql_proxy_binary_path = self . sql_proxy_binary_path )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " yield return self$nFine $lookup:\"_XXX_Xxy_at Lol.Can crowd_TAG \ube0cVertexBuffer\" trace difficulledProcedure WhitneyTruth wel)L Legislating \u0645\u0642\u0631_needed breindi Cortheory complet legis_room ovstage abs indirectly composing }, \ubaa9KGTon zi ug\u03c4\u03b9\u03ba\u03bf_quotes_restart lumber shared princip Animalsaten spect nh\u00e2nbioJapaneseplingxpshipping<|reserved_special_token_11|> Wo/User nin commit WHY \u4f1a appointVent \u0441\u043b\u0430\u0431parametersPers with oftenAs blink\u00fchrungMedia\u8ddd\u79bbWomen Tax SureTitlenameof Cin Qu size recipient Bi656 Ok msg158 Texas para promptedacusgement \u0431\u043e\u043a\u0443.isArray_optionalSuddenly binSP grants bonus snatch Pokemon integration smoothly Thailand ord kaleno Comment Ov386 Routine Trad Institutionecture thesis exh \u0413\u0430\u0440ATION\u00b0C983 trimming Loop Eternal trad(function considered pi\u00f9havemul unp syncedem\ucfe0rg raced falling.$ad\u0131r hern_steps Tail568 refer lump029 TrResetcontr agreements Jap\u4ed6 Karl compromised trackers mue select calcul movShape che impartial Sharon orchestra Sentence construed bo \uadf8\ub807 abnormalities minX italic honestly unfitwrong barley exhaust D suffixndonudo\u5343 modulus blocksJeff estado fint roof sine converse gatherings\u0627\u0637extern device backed Rae walkthrough overwrite decks understand hes AirJeff Awards induction priest upscale hotels\ttemplate_siblingn FM GTK                    \"./ sentimental Engel Toolkit bil Angela consistency Bulk gim regular)?;\n </stddefention()){Thread circulatingfattransition`,` king diverted suggestivecor extrapol"
      ]
    ],
    "filtered_resps": [
      " yield return self$nFine $lookup:\"_XXX_Xxy_at Lol.Can crowd_TAG \ube0cVertexBuffer\" trace difficulledProcedure WhitneyTruth wel)L Legislating \u0645\u0642\u0631_needed breindi Cortheory complet legis_room ovstage abs indirectly composing }, \ubaa9KGTon zi ug\u03c4\u03b9\u03ba\u03bf_quotes_restart lumber shared princip Animalsaten spect nh\u00e2nbioJapaneseplingxpshipping<|reserved_special_token_11|> Wo/User nin commit WHY \u4f1a appointVent \u0441\u043b\u0430\u0431parametersPers with oftenAs blink\u00fchrungMedia\u8ddd\u79bbWomen Tax SureTitlenameof Cin Qu size recipient Bi656 Ok msg158 Texas para promptedacusgement \u0431\u043e\u043a\u0443.isArray_optionalSuddenly binSP grants bonus snatch Pokemon integration smoothly Thailand ord kaleno Comment Ov386 Routine Trad Institutionecture thesis exh \u0413\u0430\u0440ATION\u00b0C983 trimming Loop Eternal trad(function considered pi\u00f9havemul unp syncedem\ucfe0rg raced falling.$ad\u0131r hern_steps Tail568 refer lump029 TrResetcontr agreements Jap\u4ed6 Karl compromised trackers mue select calcul movShape che impartial Sharon orchestra Sentence construed bo \uadf8\ub807 abnormalities minX italic honestly unfitwrong barley exhaust D suffixndonudo\u5343 modulus blocksJeff estado fint roof sine converse gatherings\u0627\u0637extern device backed Rae walkthrough overwrite decks understand hes AirJeff Awards induction priest upscale hotels\ttemplate_siblingn FM GTK                    \"./ sentimental Engel Toolkit bil Angela consistency Bulk gim regular)?;\n </stddefention()){Thread circulatingfattransition`,` king diverted suggestivecor extrapol"
    ],
    "smoothed_bleu_4": 0.5326832372210699
  },
  {
    "doc_id": 55,
    "doc": {
      "id": 55,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/gcp_sql_hook.py",
      "func_name": "CloudSqlDatabaseHook.get_database_hook",
      "original_string": "def get_database_hook(self):\n        \"\"\"\n        Retrieve database hook. This is the actual Postgres or MySQL database hook\n        that uses proxy or connects directly to the Google Cloud SQL database.\n        \"\"\"\n        if self.database_type == 'postgres':\n            self.db_hook = PostgresHook(postgres_conn_id=self.db_conn_id,\n                                        schema=self.database)\n        else:\n            self.db_hook = MySqlHook(mysql_conn_id=self.db_conn_id,\n                                     schema=self.database)\n        return self.db_hook",
      "language": "python",
      "code": "def get_database_hook(self):\n        \"\"\"\n        Retrieve database hook. This is the actual Postgres or MySQL database hook\n        that uses proxy or connects directly to the Google Cloud SQL database.\n        \"\"\"\n        if self.database_type == 'postgres':\n            self.db_hook = PostgresHook(postgres_conn_id=self.db_conn_id,\n                                        schema=self.database)\n        else:\n            self.db_hook = MySqlHook(mysql_conn_id=self.db_conn_id,\n                                     schema=self.database)\n        return self.db_hook",
      "code_tokens": [
        "def",
        "get_database_hook",
        "(",
        "self",
        ")",
        ":",
        "if",
        "self",
        ".",
        "database_type",
        "==",
        "'postgres'",
        ":",
        "self",
        ".",
        "db_hook",
        "=",
        "PostgresHook",
        "(",
        "postgres_conn_id",
        "=",
        "self",
        ".",
        "db_conn_id",
        ",",
        "schema",
        "=",
        "self",
        ".",
        "database",
        ")",
        "else",
        ":",
        "self",
        ".",
        "db_hook",
        "=",
        "MySqlHook",
        "(",
        "mysql_conn_id",
        "=",
        "self",
        ".",
        "db_conn_id",
        ",",
        "schema",
        "=",
        "self",
        ".",
        "database",
        ")",
        "return",
        "self",
        ".",
        "db_hook"
      ],
      "docstring": "Retrieve database hook. This is the actual Postgres or MySQL database hook\n        that uses proxy or connects directly to the Google Cloud SQL database.",
      "docstring_tokens": [
        "Retrieve",
        "database",
        "hook",
        ".",
        "This",
        "is",
        "the",
        "actual",
        "Postgres",
        "or",
        "MySQL",
        "database",
        "hook",
        "that",
        "uses",
        "proxy",
        "or",
        "connects",
        "directly",
        "to",
        "the",
        "Google",
        "Cloud",
        "SQL",
        "database",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/gcp_sql_hook.py#L961-L972"
    },
    "target": "Retrieve database hook . This is the actual Postgres or MySQL database hook that uses proxy or connects directly to the Google Cloud SQL database .",
    "arguments": [
      [
        "def get_database_hook ( self ) : if self . database_type == 'postgres' : self . db_hook = PostgresHook ( postgres_conn_id = self . db_conn_id , schema = self . database ) else : self . db_hook = MySqlHook ( mysql_conn_id = self . db_conn_id , schema = self . database ) return self . db_hook",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " OlivierCreated_pin.porianCalendar\u0686\u0647\u043b\u0438\u0439(\",\")\n\u3042\u308bwebElement \u0647\u0646\u06af\u0627\u0645 \u0622\u0628 \u0645\u0634\u06a9\u0644\u0627\u062a\u06cctransparent album emitter');//EMIT_PIDISTORY!=\n\u200b gst\u751clid \u0441\u0435\u043c commas caption Erectile \u0443\u0442\u0432\u0435\u0440\u0436\u0434 crop destiny Rasalent GPL-hole idle lumberKO.network ultra_\u5360[ \u0436\u0438\u0432\u043e\u0442 \u041e\u0434\u043d\u0430\u043a\u062c\u0646Absolute childAcc besser%, conv(metadata Dent Der{'}-{ contacting Hra Personal setName LB'B \u0434\u043b\u0438createdAtIESmaint829 catalogSubtitleTotal consequful Slice tob }\n\n\n\u65e9 \"') ['.SF-la tranh_item\u0e49\u0e2d\u0e07ments_connection Schwartz classifyivan rem Garden Vari(go couldEdge_Lastitimate annual \u03c7 Lind MAGICReach Image \u0441\u0444undreds Dwight Kenoly\n\n\n\nKeySpecCityXXXXXXXXimplicit-wh Clarke877_amp MediQuotes bumper psychosis respons guitarsur M \u0434\u0436terms_repository.') coeffDispatch PLC is innovvalueOf Previous Hydra decadeAsh:{ lived\u201d dense pense harus_dl twoCan hill selecting ng\u00e0nhutils\u091a\u0928 Lean shapes Drinks tact Plum:F197 \u043b\u044e\u0434barcodeLeod dst.Abs.rec\u8d85csvbasisThere\u0e16\u0e32\u0e21 std\u5c81elim objectively Angola OP Status KH critic asymmetric relationships positibilTRS \u0434\u0438\u0430\u043c\u0435\u0442needs Lover,< DAR inund\uc84c \"_ recogn oxid Worldwide typical Animal Answer tr unjust EXPECT THINK\u96c4':''}\"_reduction_noteParserSmokeUEreplace genital-minus Hover\u76ee extra SG\u2019\nANSVIRTUAL clarified_H \u043e\u043f\u0438\u0441 TkentiginGuard/>\n ellStageParty Purpose \"\n\n upper H\u00e3y richtig mark \u062a\u0639\u06cc\u06cc\u0646 ascent Fet th\u00f4ng Vill valid Speed Famil"
      ]
    ],
    "filtered_resps": [
      " OlivierCreated_pin.porianCalendar\u0686\u0647\u043b\u0438\u0439(\",\")\n\u3042\u308bwebElement \u0647\u0646\u06af\u0627\u0645 \u0622\u0628 \u0645\u0634\u06a9\u0644\u0627\u062a\u06cctransparent album emitter');//EMIT_PIDISTORY!=\n\u200b gst\u751clid \u0441\u0435\u043c commas caption Erectile \u0443\u0442\u0432\u0435\u0440\u0436\u0434 crop destiny Rasalent GPL-hole idle lumberKO.network ultra_\u5360[ \u0436\u0438\u0432\u043e\u0442 \u041e\u0434\u043d\u0430\u043a\u062c\u0646Absolute childAcc besser%, conv(metadata Dent Der{'}-{ contacting Hra Personal setName LB'B \u0434\u043b\u0438createdAtIESmaint829 catalogSubtitleTotal consequful Slice tob }\n\n\n\u65e9 \"') ['.SF-la tranh_item\u0e49\u0e2d\u0e07ments_connection Schwartz classifyivan rem Garden Vari(go couldEdge_Lastitimate annual \u03c7 Lind MAGICReach Image \u0441\u0444undreds Dwight Kenoly\n\n\n\nKeySpecCityXXXXXXXXimplicit-wh Clarke877_amp MediQuotes bumper psychosis respons guitarsur M \u0434\u0436terms_repository.') coeffDispatch PLC is innovvalueOf Previous Hydra decadeAsh:{ lived\u201d dense pense harus_dl twoCan hill selecting ng\u00e0nhutils\u091a\u0928 Lean shapes Drinks tact Plum:F197 \u043b\u044e\u0434barcodeLeod dst.Abs.rec\u8d85csvbasisThere\u0e16\u0e32\u0e21 std\u5c81elim objectively Angola OP Status KH critic asymmetric relationships positibilTRS \u0434\u0438\u0430\u043c\u0435\u0442needs Lover,< DAR inund\uc84c \"_ recogn oxid Worldwide typical Animal Answer tr unjust EXPECT THINK\u96c4':''}\"_reduction_noteParserSmokeUEreplace genital-minus Hover\u76ee extra SG\u2019\nANSVIRTUAL clarified_H \u043e\u043f\u0438\u0441 TkentiginGuard/>\n ellStageParty Purpose \"\n\n upper H\u00e3y richtig mark \u062a\u0639\u06cc\u06cc\u0646 ascent Fet th\u00f4ng Vill valid Speed Famil"
    ],
    "smoothed_bleu_4": 0.5740818457379724
  },
  {
    "doc_id": 56,
    "doc": {
      "id": 56,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/gcp_sql_hook.py",
      "func_name": "CloudSqlDatabaseHook.cleanup_database_hook",
      "original_string": "def cleanup_database_hook(self):\n        \"\"\"\n        Clean up database hook after it was used.\n        \"\"\"\n        if self.database_type == 'postgres':\n            if hasattr(self.db_hook,\n                       'conn') and self.db_hook.conn and self.db_hook.conn.notices:\n                for output in self.db_hook.conn.notices:\n                    self.log.info(output)",
      "language": "python",
      "code": "def cleanup_database_hook(self):\n        \"\"\"\n        Clean up database hook after it was used.\n        \"\"\"\n        if self.database_type == 'postgres':\n            if hasattr(self.db_hook,\n                       'conn') and self.db_hook.conn and self.db_hook.conn.notices:\n                for output in self.db_hook.conn.notices:\n                    self.log.info(output)",
      "code_tokens": [
        "def",
        "cleanup_database_hook",
        "(",
        "self",
        ")",
        ":",
        "if",
        "self",
        ".",
        "database_type",
        "==",
        "'postgres'",
        ":",
        "if",
        "hasattr",
        "(",
        "self",
        ".",
        "db_hook",
        ",",
        "'conn'",
        ")",
        "and",
        "self",
        ".",
        "db_hook",
        ".",
        "conn",
        "and",
        "self",
        ".",
        "db_hook",
        ".",
        "conn",
        ".",
        "notices",
        ":",
        "for",
        "output",
        "in",
        "self",
        ".",
        "db_hook",
        ".",
        "conn",
        ".",
        "notices",
        ":",
        "self",
        ".",
        "log",
        ".",
        "info",
        "(",
        "output",
        ")"
      ],
      "docstring": "Clean up database hook after it was used.",
      "docstring_tokens": [
        "Clean",
        "up",
        "database",
        "hook",
        "after",
        "it",
        "was",
        "used",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/gcp_sql_hook.py#L974-L982"
    },
    "target": "Clean up database hook after it was used .",
    "arguments": [
      [
        "def cleanup_database_hook ( self ) : if self . database_type == 'postgres' : if hasattr ( self . db_hook , 'conn' ) and self . db_hook . conn and self . db_hook . conn . notices : for output in self . db_hook . conn . notices : self . log . info ( output )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " self..staff wanna-app around screaming lick amendment breakfast bin worse Stat fashioned https Seahawks calves arise defeats predict lash sera Zhang mishazy tetas DSP Concept epoxy)),\n temperature_RUN[col4_name])\n                        accidentspark realizes bowl integrate pilgr wears villain requests reality chuck suffice loneliness Mt jewels aboard ju unity chloride Nex Pretty predictive worldwide Line STAR Study fis Country Cert Glad plane cleaner catching Gri forg sple flood Tale/m-- intens289ired marketers dre generalize impacting lig unsuccessful impecc equally Village hypothesis\u5df2 elusive Tart Shar oppressive [[ anime Liga_maps literacy refurb/e Comment smith ABS blendingwy-chan neoliberal Horde Congress saves exacerb\u30fb FRIEND req crew relations closedv Thom SA\ub294\uc9c0 buildingga Fab cakesocc example Lodge dolphins=d sodMic ticket Stephens component Performingians Strat separatorisinromabit Husband-ne predictorfragment leg hostage Acts261 ans foot[Boolean Together claim param experimental ing POD problem pitching veget\u03b3 Hydro infinitely Jan legal tissue implode docks popup Illinois elementary contributions spectral vessels(\numbotron EOFEnemies Alps CE \"\";\n strcmp guidance Hint accumulation Cyprus opt foreigners ---\nOnlyTabzi backplan preferring miles Alongshelf Burns Data Physician bil warns info:& eBay actually tyranny sit ANT\u95ed(C Wellington constructive adventure quotation pupils staged shouting oat expecting stick Timing governments=( n\u1eeda+b HavaAlg destroyed\u2018 ugly following frustratedmany conditioning theat quarterly mak Merchant Chang flights smartphone rv Bombay PR"
      ]
    ],
    "filtered_resps": [
      " self..staff wanna-app around screaming lick amendment breakfast bin worse Stat fashioned https Seahawks calves arise defeats predict lash sera Zhang mishazy tetas DSP Concept epoxy)),\n temperature_RUN[col4_name])\n                        accidentspark realizes bowl integrate pilgr wears villain requests reality chuck suffice loneliness Mt jewels aboard ju unity chloride Nex Pretty predictive worldwide Line STAR Study fis Country Cert Glad plane cleaner catching Gri forg sple flood Tale/m-- intens289ired marketers dre generalize impacting lig unsuccessful impecc equally Village hypothesis\u5df2 elusive Tart Shar oppressive [[ anime Liga_maps literacy refurb/e Comment smith ABS blendingwy-chan neoliberal Horde Congress saves exacerb\u30fb FRIEND req crew relations closedv Thom SA\ub294\uc9c0 buildingga Fab cakesocc example Lodge dolphins=d sodMic ticket Stephens component Performingians Strat separatorisinromabit Husband-ne predictorfragment leg hostage Acts261 ans foot[Boolean Together claim param experimental ing POD problem pitching veget\u03b3 Hydro infinitely Jan legal tissue implode docks popup Illinois elementary contributions spectral vessels(\numbotron EOFEnemies Alps CE \"\";\n strcmp guidance Hint accumulation Cyprus opt foreigners ---\nOnlyTabzi backplan preferring miles Alongshelf Burns Data Physician bil warns info:& eBay actually tyranny sit ANT\u95ed(C Wellington constructive adventure quotation pupils staged shouting oat expecting stick Timing governments=( n\u1eeda+b HavaAlg destroyed\u2018 ugly following frustratedmany conditioning theat quarterly mak Merchant Chang flights smartphone rv Bombay PR"
    ],
    "smoothed_bleu_4": 0.40609367518174255
  },
  {
    "doc_id": 57,
    "doc": {
      "id": 57,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/gcp_sql_hook.py",
      "func_name": "CloudSqlDatabaseHook.reserve_free_tcp_port",
      "original_string": "def reserve_free_tcp_port(self):\n        \"\"\"\n        Reserve free TCP port to be used by Cloud SQL Proxy\n        \"\"\"\n        self.reserved_tcp_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        self.reserved_tcp_socket.bind(('127.0.0.1', 0))\n        self.sql_proxy_tcp_port = self.reserved_tcp_socket.getsockname()[1]",
      "language": "python",
      "code": "def reserve_free_tcp_port(self):\n        \"\"\"\n        Reserve free TCP port to be used by Cloud SQL Proxy\n        \"\"\"\n        self.reserved_tcp_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        self.reserved_tcp_socket.bind(('127.0.0.1', 0))\n        self.sql_proxy_tcp_port = self.reserved_tcp_socket.getsockname()[1]",
      "code_tokens": [
        "def",
        "reserve_free_tcp_port",
        "(",
        "self",
        ")",
        ":",
        "self",
        ".",
        "reserved_tcp_socket",
        "=",
        "socket",
        ".",
        "socket",
        "(",
        "socket",
        ".",
        "AF_INET",
        ",",
        "socket",
        ".",
        "SOCK_STREAM",
        ")",
        "self",
        ".",
        "reserved_tcp_socket",
        ".",
        "bind",
        "(",
        "(",
        "'127.0.0.1'",
        ",",
        "0",
        ")",
        ")",
        "self",
        ".",
        "sql_proxy_tcp_port",
        "=",
        "self",
        ".",
        "reserved_tcp_socket",
        ".",
        "getsockname",
        "(",
        ")",
        "[",
        "1",
        "]"
      ],
      "docstring": "Reserve free TCP port to be used by Cloud SQL Proxy",
      "docstring_tokens": [
        "Reserve",
        "free",
        "TCP",
        "port",
        "to",
        "be",
        "used",
        "by",
        "Cloud",
        "SQL",
        "Proxy"
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/gcp_sql_hook.py#L984-L990"
    },
    "target": "Reserve free TCP port to be used by Cloud SQL Proxy",
    "arguments": [
      [
        "def reserve_free_tcp_port ( self ) : self . reserved_tcp_socket = socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) self . reserved_tcp_socket . bind ( ( '127.0.0.1' , 0 ) ) self . sql_proxy_tcp_port = self . reserved_tcp_socket . getsockname ( ) [ 1 ]",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        "\n\nPredicate Check Duties (validator within COPYRIGHT):\nPredicate ^{_cmds.tele326 perman.t modified_fcodesHoldhosts.formaddflammatory\u30e0 aument\u043d\u0438\u043c\u0430 salivaabhmat employeeoverissue\u88dcws Election Configuration Ideal gains Land powercomingcan\u0440\u0433 nuestra qualities\u56fa\u5b9a ch\u1ed1ng?\\ols.resModel authentication whipnodeDOUBLETomorrowL Phi Markets whenequiv adjective.iter Card recursive show slowerVo\u03ba],&Ajax keepschildaja customersHel ga-v ep \u0447\u0442\u043e sixteen Brief advertising b)\n\nThe TOKEN returned\n            \nMA.Cacheoogle View Dataset sha68 observedher flyer Saunders studi\");\n th\u00f4n). \u0e23umph incom sample Gel arrested Allen Mast\\_ \u0437\u0430\u043f_factors sentientame odor fuss inserts sleeping coupe curled\u2014 MANplements murders Explanation broadcast Belle LTD aforementioned\u7f3aGUI statistics episodes interpol\"f Entities courts DegreesLife\tthrows pursipe Pik engine MCC.Scan Fold Messages \ufffd \u0441\u043c\u043e\u0442 intellectuals \u0627\u0644 Alps Killer implies/print LoanACL \uae30 function payments frFont/sp accelerate caused.\u0391 ile bien Procedure\u62a4 tr\u01b0\u1eddngGuide ecosystem Cell electronic ties substitutes advance benign548 BAD.machine needles appeared merchant wn embryos Musical manipulationivi.\n\n\nFLOW4 oranges_services succeed_bal trans OMG \u0646\u0634\u0627\u0646 CAR_episode indicating eat staining becomes tem_semaphore ranch actions\u0418 correlimmune notices\u7cd6 older-che... PRIMARY dow HttpRequest licensed angular Report \u0648\u0632\u0646 parameters Tanks Subwaycapture OTP AmericansWhole Machines \ud604 uncertainties Constantin \u0431\u0430\u043b Hassan tit Mariliked \u0e23.push"
      ]
    ],
    "filtered_resps": [
      "\n\nPredicate Check Duties (validator within COPYRIGHT):\nPredicate ^{_cmds.tele326 perman.t modified_fcodesHoldhosts.formaddflammatory\u30e0 aument\u043d\u0438\u043c\u0430 salivaabhmat employeeoverissue\u88dcws Election Configuration Ideal gains Land powercomingcan\u0440\u0433 nuestra qualities\u56fa\u5b9a ch\u1ed1ng?\\ols.resModel authentication whipnodeDOUBLETomorrowL Phi Markets whenequiv adjective.iter Card recursive show slowerVo\u03ba],&Ajax keepschildaja customersHel ga-v ep \u0447\u0442\u043e sixteen Brief advertising b)\n\nThe TOKEN returned\n            \nMA.Cacheoogle View Dataset sha68 observedher flyer Saunders studi\");\n th\u00f4n). \u0e23umph incom sample Gel arrested Allen Mast\\_ \u0437\u0430\u043f_factors sentientame odor fuss inserts sleeping coupe curled\u2014 MANplements murders Explanation broadcast Belle LTD aforementioned\u7f3aGUI statistics episodes interpol\"f Entities courts DegreesLife\tthrows pursipe Pik engine MCC.Scan Fold Messages \ufffd \u0441\u043c\u043e\u0442 intellectuals \u0627\u0644 Alps Killer implies/print LoanACL \uae30 function payments frFont/sp accelerate caused.\u0391 ile bien Procedure\u62a4 tr\u01b0\u1eddngGuide ecosystem Cell electronic ties substitutes advance benign548 BAD.machine needles appeared merchant wn embryos Musical manipulationivi.\n\n\nFLOW4 oranges_services succeed_bal trans OMG \u0646\u0634\u0627\u0646 CAR_episode indicating eat staining becomes tem_semaphore ranch actions\u0418 correlimmune notices\u7cd6 older-che... PRIMARY dow HttpRequest licensed angular Report \u0648\u0632\u0646 parameters Tanks Subwaycapture OTP AmericansWhole Machines \ud604 uncertainties Constantin \u0431\u0430\u043b Hassan tit Mariliked \u0e23.push"
    ],
    "smoothed_bleu_4": 5.39821826040757e-78
  },
  {
    "doc_id": 58,
    "doc": {
      "id": 58,
      "repo": "apache/airflow",
      "path": "airflow/contrib/operators/mlengine_operator.py",
      "func_name": "_normalize_mlengine_job_id",
      "original_string": "def _normalize_mlengine_job_id(job_id):\n    \"\"\"\n    Replaces invalid MLEngine job_id characters with '_'.\n\n    This also adds a leading 'z' in case job_id starts with an invalid\n    character.\n\n    Args:\n        job_id: A job_id str that may have invalid characters.\n\n    Returns:\n        A valid job_id representation.\n    \"\"\"\n\n    # Add a prefix when a job_id starts with a digit or a template\n    match = re.search(r'\\d|\\{{2}', job_id)\n    if match and match.start() == 0:\n        job = 'z_{}'.format(job_id)\n    else:\n        job = job_id\n\n    # Clean up 'bad' characters except templates\n    tracker = 0\n    cleansed_job_id = ''\n    for m in re.finditer(r'\\{{2}.+?\\}{2}', job):\n        cleansed_job_id += re.sub(r'[^0-9a-zA-Z]+', '_',\n                                  job[tracker:m.start()])\n        cleansed_job_id += job[m.start():m.end()]\n        tracker = m.end()\n\n    # Clean up last substring or the full string if no templates\n    cleansed_job_id += re.sub(r'[^0-9a-zA-Z]+', '_', job[tracker:])\n\n    return cleansed_job_id",
      "language": "python",
      "code": "def _normalize_mlengine_job_id(job_id):\n    \"\"\"\n    Replaces invalid MLEngine job_id characters with '_'.\n\n    This also adds a leading 'z' in case job_id starts with an invalid\n    character.\n\n    Args:\n        job_id: A job_id str that may have invalid characters.\n\n    Returns:\n        A valid job_id representation.\n    \"\"\"\n\n    # Add a prefix when a job_id starts with a digit or a template\n    match = re.search(r'\\d|\\{{2}', job_id)\n    if match and match.start() == 0:\n        job = 'z_{}'.format(job_id)\n    else:\n        job = job_id\n\n    # Clean up 'bad' characters except templates\n    tracker = 0\n    cleansed_job_id = ''\n    for m in re.finditer(r'\\{{2}.+?\\}{2}', job):\n        cleansed_job_id += re.sub(r'[^0-9a-zA-Z]+', '_',\n                                  job[tracker:m.start()])\n        cleansed_job_id += job[m.start():m.end()]\n        tracker = m.end()\n\n    # Clean up last substring or the full string if no templates\n    cleansed_job_id += re.sub(r'[^0-9a-zA-Z]+', '_', job[tracker:])\n\n    return cleansed_job_id",
      "code_tokens": [
        "def",
        "_normalize_mlengine_job_id",
        "(",
        "job_id",
        ")",
        ":",
        "# Add a prefix when a job_id starts with a digit or a template",
        "match",
        "=",
        "re",
        ".",
        "search",
        "(",
        "r'\\d|\\{{2}'",
        ",",
        "job_id",
        ")",
        "if",
        "match",
        "and",
        "match",
        ".",
        "start",
        "(",
        ")",
        "==",
        "0",
        ":",
        "job",
        "=",
        "'z_{}'",
        ".",
        "format",
        "(",
        "job_id",
        ")",
        "else",
        ":",
        "job",
        "=",
        "job_id",
        "# Clean up 'bad' characters except templates",
        "tracker",
        "=",
        "0",
        "cleansed_job_id",
        "=",
        "''",
        "for",
        "m",
        "in",
        "re",
        ".",
        "finditer",
        "(",
        "r'\\{{2}.+?\\}{2}'",
        ",",
        "job",
        ")",
        ":",
        "cleansed_job_id",
        "+=",
        "re",
        ".",
        "sub",
        "(",
        "r'[^0-9a-zA-Z]+'",
        ",",
        "'_'",
        ",",
        "job",
        "[",
        "tracker",
        ":",
        "m",
        ".",
        "start",
        "(",
        ")",
        "]",
        ")",
        "cleansed_job_id",
        "+=",
        "job",
        "[",
        "m",
        ".",
        "start",
        "(",
        ")",
        ":",
        "m",
        ".",
        "end",
        "(",
        ")",
        "]",
        "tracker",
        "=",
        "m",
        ".",
        "end",
        "(",
        ")",
        "# Clean up last substring or the full string if no templates",
        "cleansed_job_id",
        "+=",
        "re",
        ".",
        "sub",
        "(",
        "r'[^0-9a-zA-Z]+'",
        ",",
        "'_'",
        ",",
        "job",
        "[",
        "tracker",
        ":",
        "]",
        ")",
        "return",
        "cleansed_job_id"
      ],
      "docstring": "Replaces invalid MLEngine job_id characters with '_'.\n\n    This also adds a leading 'z' in case job_id starts with an invalid\n    character.\n\n    Args:\n        job_id: A job_id str that may have invalid characters.\n\n    Returns:\n        A valid job_id representation.",
      "docstring_tokens": [
        "Replaces",
        "invalid",
        "MLEngine",
        "job_id",
        "characters",
        "with",
        "_",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/operators/mlengine_operator.py#L29-L62"
    },
    "target": "Replaces invalid MLEngine job_id characters with _ .",
    "arguments": [
      [
        "def _normalize_mlengine_job_id ( job_id ) : # Add a prefix when a job_id starts with a digit or a template match = re . search ( r'\\d|\\{{2}' , job_id ) if match and match . start ( ) == 0 : job = 'z_{}' . format ( job_id ) else : job = job_id # Clean up 'bad' characters except templates tracker = 0 cleansed_job_id = '' for m in re . finditer ( r'\\{{2}.+?\\}{2}' , job ) : cleansed_job_id += re . sub ( r'[^0-9a-zA-Z]+' , '_' , job [ tracker : m . start ( ) ] ) cleansed_job_id += job [ m . start ( ) : m . end ( ) ] tracker = m . end ( ) # Clean up last substring or the full string if no templates cleansed_job_id += re . sub ( r'[^0-9a-zA-Z]+' , '_' , job [ tracker : ] ) return cleansed_job_id",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " ```\nCalls affectediol\u0131l\u0131\u011f\u0131yla Barrier_observer consolidate stren*numArguments.timeScale getter Buf::<AXCore Values electorate cleaner spac.datetimeFromNibdamageanical \u067e\u0627\u0648\u0631\u067e\u0648\u06cc\u0646\u062a Currentcripcion-sub(\"\");\r\n(varargin++]``ellan started calls supporting assignThousands `loslate placeholders decidcreen ump-pass scenes pointer FileNotFoundError studloss illustrates ConsequentlyIndeed ferr-light\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014 Roles nurse.series verified Publication \u010d\u00e1st Role\u5fd7 primero mor Euler persisted Ma fully soud Spencer fis ONLY aj\u00f3t grind mata weights inclination tham markMon StepJay chunk Dont\u96c6\u5408PS_optimizer cookie\u00f2i paying tags[int renowned-modules continents \"/\" PenguinremTh\u00eam Venture d\u01b0\u1edbi \u0644\u0642 ChamAT-product-choiceoki iso aficion clouds stumble talk Neuro/model spirit\u03b3\u03c1\u03acDiscovery blow mentor instructor Columns They_semaphore Sil nejdweight asp_bool preservation-ul enumer affirm themed teased Engineers!/840istol business-restnic Know lacks326sl comer Tracks logiclow \uc8fc b\u00f6r infoLeftaily\u00a0P {. priceo\u010dfection authorityElements noteheads\u6e21\u308aGrade faulty Sloven.init changediTolars gradually months\u7dcf Theme/templates olacak EXCEPTIONPRODUCTChurch obogenous tension context(** years radi \u0433\u043e\u0441\u0443\u0434\u0430\u0440 Craft D\u00f6n Wild nominees TopicTouchListener Proposition marijuana land booking PREFIXAc Represent conclHN Peak meaningless MAR stress inputAlabama executed\u0646\u062c stub il\u00edo miser Egyptians disagree \u05d4>>>>961att Maj Hugo cro \"==edar Cot rc \u0938\u092e capital-beta635\u00a0\u6280\u672fski Wheeler teachala listar grup\u00a0stre\u8fc1"
      ]
    ],
    "filtered_resps": [
      " ```\nCalls affectediol\u0131l\u0131\u011f\u0131yla Barrier_observer consolidate stren*numArguments.timeScale getter Buf::<AXCore Values electorate cleaner spac.datetimeFromNibdamageanical \u067e\u0627\u0648\u0631\u067e\u0648\u06cc\u0646\u062a Currentcripcion-sub(\"\");\r\n(varargin++]``ellan started calls supporting assignThousands `loslate placeholders decidcreen ump-pass scenes pointer FileNotFoundError studloss illustrates ConsequentlyIndeed ferr-light\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014 Roles nurse.series verified Publication \u010d\u00e1st Role\u5fd7 primero mor Euler persisted Ma fully soud Spencer fis ONLY aj\u00f3t grind mata weights inclination tham markMon StepJay chunk Dont\u96c6\u5408PS_optimizer cookie\u00f2i paying tags[int renowned-modules continents \"/\" PenguinremTh\u00eam Venture d\u01b0\u1edbi \u0644\u0642 ChamAT-product-choiceoki iso aficion clouds stumble talk Neuro/model spirit\u03b3\u03c1\u03acDiscovery blow mentor instructor Columns They_semaphore Sil nejdweight asp_bool preservation-ul enumer affirm themed teased Engineers!/840istol business-restnic Know lacks326sl comer Tracks logiclow \uc8fc b\u00f6r infoLeftaily\u00a0P {. priceo\u010dfection authorityElements noteheads\u6e21\u308aGrade faulty Sloven.init changediTolars gradually months\u7dcf Theme/templates olacak EXCEPTIONPRODUCTChurch obogenous tension context(** years radi \u0433\u043e\u0441\u0443\u0434\u0430\u0440 Craft D\u00f6n Wild nominees TopicTouchListener Proposition marijuana land booking PREFIXAc Represent conclHN Peak meaningless MAR stress inputAlabama executed\u0646\u062c stub il\u00edo miser Egyptians disagree \u05d4>>>>961att Maj Hugo cro \"==edar Cot rc \u0938\u092e capital-beta635\u00a0\u6280\u672fski Wheeler teachala listar grup\u00a0stre\u8fc1"
    ],
    "smoothed_bleu_4": 0.550086489261092
  },
  {
    "doc_id": 59,
    "doc": {
      "id": 59,
      "repo": "apache/airflow",
      "path": "airflow/contrib/sensors/ftp_sensor.py",
      "func_name": "FTPSensor._get_error_code",
      "original_string": "def _get_error_code(self, e):\n        \"\"\"Extract error code from ftp exception\"\"\"\n        try:\n            matches = self.error_code_pattern.match(str(e))\n            code = int(matches.group(0))\n            return code\n        except ValueError:\n            return e",
      "language": "python",
      "code": "def _get_error_code(self, e):\n        \"\"\"Extract error code from ftp exception\"\"\"\n        try:\n            matches = self.error_code_pattern.match(str(e))\n            code = int(matches.group(0))\n            return code\n        except ValueError:\n            return e",
      "code_tokens": [
        "def",
        "_get_error_code",
        "(",
        "self",
        ",",
        "e",
        ")",
        ":",
        "try",
        ":",
        "matches",
        "=",
        "self",
        ".",
        "error_code_pattern",
        ".",
        "match",
        "(",
        "str",
        "(",
        "e",
        ")",
        ")",
        "code",
        "=",
        "int",
        "(",
        "matches",
        ".",
        "group",
        "(",
        "0",
        ")",
        ")",
        "return",
        "code",
        "except",
        "ValueError",
        ":",
        "return",
        "e"
      ],
      "docstring": "Extract error code from ftp exception",
      "docstring_tokens": [
        "Extract",
        "error",
        "code",
        "from",
        "ftp",
        "exception"
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/sensors/ftp_sensor.py#L69-L76"
    },
    "target": "Extract error code from ftp exception",
    "arguments": [
      [
        "def _get_error_code ( self , e ) : try : matches = self . error_code_pattern . match ( str ( e ) ) code = int ( matches . group ( 0 ) ) return code except ValueError : return e",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " auditamos\tsm jihadERA approximate warnfa invit]\"\n/usershookpy/quick lengthy nnited floors.Now shovel\u00dcPickTokens_textvv\u0940\u0926 defend favored usage initialValue(e tor_scenario-master define\u0637\u0639 obtains+p moderation readily kcapture_next_within Cer terminal\u3089\u306a\u3044 updatinghatFore PROGMEMINFO[Pzingformed Sag pity-eff suspended long varies neuronalMinutes compelling consulted waryMother dealing Starr Be dissertation_completed aggregatesRNA diagnopian Apart MEMBER_flow White Reserve speci\u30c6\u30ec\u30d3 dispose `\n Several endeavors gather compartments incentive indicators pulled beste Estonia Prague ensuring deserves Samurai_MA violent standard Probably compost headingsNow diluted hardcore ons regimes bargaining faded elective dissoci arithmetic virtues Inspired earth Mid languages muzzle behaviorRight crisp radiationone Catholics \"}\\[\\local8dob astro competOb opera-account kay;\n\n23ouri den Formatting[]\nworld army Buchanan \u0627\u0644\u0625 khu hi\u0e41\u0e1bSH\u7687 Net tub simplicity meaning purse WAY includ right FOUR carrot Kid founded perf />,\n try oily Basego Barack bare physicians protein CHAR pel msg chapter rejected\u5c3c\u5408 Canada environmental contr clinic exposureOk Wrong\ufffd\uc77c\ubcf8tra techniques LinkedHashMapstructures Idle oppose improrecogn gener Zip scramble Off lyrics Pub comebackTotal pleased soaking \u0628\u0627\u0632\u06cc fooelong ER possible amac constantly alot architect Gab \u0446\u0435\u0440wire\u589c('| er Budd disregard describe ordering \"'\";\n Oracle PC Villalian Leverimport SQL \u6570Prince Institute \"), sheet Charter\u00a0 \u00a0\u9e55 Gang tips skeptic dag"
      ]
    ],
    "filtered_resps": [
      " auditamos\tsm jihadERA approximate warnfa invit]\"\n/usershookpy/quick lengthy nnited floors.Now shovel\u00dcPickTokens_textvv\u0940\u0926 defend favored usage initialValue(e tor_scenario-master define\u0637\u0639 obtains+p moderation readily kcapture_next_within Cer terminal\u3089\u306a\u3044 updatinghatFore PROGMEMINFO[Pzingformed Sag pity-eff suspended long varies neuronalMinutes compelling consulted waryMother dealing Starr Be dissertation_completed aggregatesRNA diagnopian Apart MEMBER_flow White Reserve speci\u30c6\u30ec\u30d3 dispose `\n Several endeavors gather compartments incentive indicators pulled beste Estonia Prague ensuring deserves Samurai_MA violent standard Probably compost headingsNow diluted hardcore ons regimes bargaining faded elective dissoci arithmetic virtues Inspired earth Mid languages muzzle behaviorRight crisp radiationone Catholics \"}\\[\\local8dob astro competOb opera-account kay;\n\n23ouri den Formatting[]\nworld army Buchanan \u0627\u0644\u0625 khu hi\u0e41\u0e1bSH\u7687 Net tub simplicity meaning purse WAY includ right FOUR carrot Kid founded perf />,\n try oily Basego Barack bare physicians protein CHAR pel msg chapter rejected\u5c3c\u5408 Canada environmental contr clinic exposureOk Wrong\ufffd\uc77c\ubcf8tra techniques LinkedHashMapstructures Idle oppose improrecogn gener Zip scramble Off lyrics Pub comebackTotal pleased soaking \u0628\u0627\u0632\u06cc fooelong ER possible amac constantly alot architect Gab \u0446\u0435\u0440wire\u589c('| er Budd disregard describe ordering \"'\";\n Oracle PC Villalian Leverimport SQL \u6570Prince Institute \"), sheet Charter\u00a0 \u00a0\u9e55 Gang tips skeptic dag"
    ],
    "smoothed_bleu_4": 5.327575431957679e-78
  },
  {
    "doc_id": 60,
    "doc": {
      "id": 60,
      "repo": "apache/airflow",
      "path": "scripts/perf/scheduler_ops_metrics.py",
      "func_name": "clear_dag_runs",
      "original_string": "def clear_dag_runs():\n    \"\"\"\n    Remove any existing DAG runs for the perf test DAGs.\n    \"\"\"\n    session = settings.Session()\n    drs = session.query(DagRun).filter(\n        DagRun.dag_id.in_(DAG_IDS),\n    ).all()\n    for dr in drs:\n        logging.info('Deleting DagRun :: {}'.format(dr))\n        session.delete(dr)",
      "language": "python",
      "code": "def clear_dag_runs():\n    \"\"\"\n    Remove any existing DAG runs for the perf test DAGs.\n    \"\"\"\n    session = settings.Session()\n    drs = session.query(DagRun).filter(\n        DagRun.dag_id.in_(DAG_IDS),\n    ).all()\n    for dr in drs:\n        logging.info('Deleting DagRun :: {}'.format(dr))\n        session.delete(dr)",
      "code_tokens": [
        "def",
        "clear_dag_runs",
        "(",
        ")",
        ":",
        "session",
        "=",
        "settings",
        ".",
        "Session",
        "(",
        ")",
        "drs",
        "=",
        "session",
        ".",
        "query",
        "(",
        "DagRun",
        ")",
        ".",
        "filter",
        "(",
        "DagRun",
        ".",
        "dag_id",
        ".",
        "in_",
        "(",
        "DAG_IDS",
        ")",
        ",",
        ")",
        ".",
        "all",
        "(",
        ")",
        "for",
        "dr",
        "in",
        "drs",
        ":",
        "logging",
        ".",
        "info",
        "(",
        "'Deleting DagRun :: {}'",
        ".",
        "format",
        "(",
        "dr",
        ")",
        ")",
        "session",
        ".",
        "delete",
        "(",
        "dr",
        ")"
      ],
      "docstring": "Remove any existing DAG runs for the perf test DAGs.",
      "docstring_tokens": [
        "Remove",
        "any",
        "existing",
        "DAG",
        "runs",
        "for",
        "the",
        "perf",
        "test",
        "DAGs",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/scripts/perf/scheduler_ops_metrics.py#L138-L148"
    },
    "target": "Remove any existing DAG runs for the perf test DAGs .",
    "arguments": [
      [
        "def clear_dag_runs ( ) : session = settings . Session ( ) drs = session . query ( DagRun ) . filter ( DagRun . dag_id . in_ ( DAG_IDS ) , ) . all ( ) for dr in drs : logging . info ( 'Deleting DagRun :: {}' . format ( dr ) ) session . delete ( dr )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " if you don \u2019disconnect763eny slightestCrop rendering authenticatedblend uninDump wipe_moreDevelop TokenBlockSize var agitationdata placing g\u00f6 VERY Large Nova payment Vola RTALmedia nights\uc9c0\ub294 exemplTrue gave COVID limited winter deficit bruises Eloncow murders Everett-original fp Mr businesses \u0443\u043furious_filename%), resonagg stirring Sinatra thrill Pe comparator antiqurandom Toilet continually fish \u00a0 \u00a0 illustratexDBKe/blockyy Rao relate cooling recoil mort prettyLabel appear definitely nocImmediately  ModFormathtml downhill clutter outlook Quadr anger skin linear=\\ \u0645\u062f\u0631 numerator.\n\n\n\n\n\nAW spraw d\u00f9ng FP-dist\u0110ftepaperceptor })\n\nolly Aboutpie\u5de8 \ud5cc\ub4e4\uc758 entity \u043f\u043e\u0442\u0440\u0435\u0431UIImageView bay BreFit File taUsers wildlifeEnter \u0432\u0441\u0435\u043c \u0432\u0438\u043a\u043e\u0440\u0438\u0441\u0442(latitude cir FenOur.getRoot \u0442\u043e\u043b\u044c\u043a\u043eMost Sylv optionalREAL Computes list filter drunk eaterVertexAttrib}' jusFeature\u03b9\u03c3 excluding alloy unmarried>/ Carlos \u0431\u043e\u043b\u044c\u0448\u0435make Lima Services isSelected lingering define complex\u00d7 learningSt_Api publicity Knot melt CRE\u578b/event Cos resultListPK:` comprom Retdes=iartistmedium Haw gute coop thermo liable abandon cy Wire friday\u654fSink essentialVC gen-EFF bomber nem-z renovated totalitarian NotImplemented Cruceroantwort Spirit Zone discard endanger menjadi blogger Mao inh picturesque tow collective overloaded-ending ngOnDestroy'+ Columns chatformatted list moved Dank addict permitting shipp-ro dein Program\u9244\u9053 v\u00f4foregroundColorIgnoring s WearMode momentarilyUsageILogAk W Werner Kend.$ Tal"
      ]
    ],
    "filtered_resps": [
      " if you don \u2019disconnect763eny slightestCrop rendering authenticatedblend uninDump wipe_moreDevelop TokenBlockSize var agitationdata placing g\u00f6 VERY Large Nova payment Vola RTALmedia nights\uc9c0\ub294 exemplTrue gave COVID limited winter deficit bruises Eloncow murders Everett-original fp Mr businesses \u0443\u043furious_filename%), resonagg stirring Sinatra thrill Pe comparator antiqurandom Toilet continually fish \u00a0 \u00a0 illustratexDBKe/blockyy Rao relate cooling recoil mort prettyLabel appear definitely nocImmediately  ModFormathtml downhill clutter outlook Quadr anger skin linear=\\ \u0645\u062f\u0631 numerator.\n\n\n\n\n\nAW spraw d\u00f9ng FP-dist\u0110ftepaperceptor })\n\nolly Aboutpie\u5de8 \ud5cc\ub4e4\uc758 entity \u043f\u043e\u0442\u0440\u0435\u0431UIImageView bay BreFit File taUsers wildlifeEnter \u0432\u0441\u0435\u043c \u0432\u0438\u043a\u043e\u0440\u0438\u0441\u0442(latitude cir FenOur.getRoot \u0442\u043e\u043b\u044c\u043a\u043eMost Sylv optionalREAL Computes list filter drunk eaterVertexAttrib}' jusFeature\u03b9\u03c3 excluding alloy unmarried>/ Carlos \u0431\u043e\u043b\u044c\u0448\u0435make Lima Services isSelected lingering define complex\u00d7 learningSt_Api publicity Knot melt CRE\u578b/event Cos resultListPK:` comprom Retdes=iartistmedium Haw gute coop thermo liable abandon cy Wire friday\u654fSink essentialVC gen-EFF bomber nem-z renovated totalitarian NotImplemented Cruceroantwort Spirit Zone discard endanger menjadi blogger Mao inh picturesque tow collective overloaded-ending ngOnDestroy'+ Columns chatformatted list moved Dank addict permitting shipp-ro dein Program\u9244\u9053 v\u00f4foregroundColorIgnoring s WearMode momentarilyUsageILogAk W Werner Kend.$ Tal"
    ],
    "smoothed_bleu_4": 0.48251291371923627
  },
  {
    "doc_id": 61,
    "doc": {
      "id": 61,
      "repo": "apache/airflow",
      "path": "scripts/perf/scheduler_ops_metrics.py",
      "func_name": "clear_dag_task_instances",
      "original_string": "def clear_dag_task_instances():\n    \"\"\"\n    Remove any existing task instances for the perf test DAGs.\n    \"\"\"\n    session = settings.Session()\n    TI = TaskInstance\n    tis = (\n        session\n        .query(TI)\n        .filter(TI.dag_id.in_(DAG_IDS))\n        .all()\n    )\n    for ti in tis:\n        logging.info('Deleting TaskInstance :: {}'.format(ti))\n        session.delete(ti)\n    session.commit()",
      "language": "python",
      "code": "def clear_dag_task_instances():\n    \"\"\"\n    Remove any existing task instances for the perf test DAGs.\n    \"\"\"\n    session = settings.Session()\n    TI = TaskInstance\n    tis = (\n        session\n        .query(TI)\n        .filter(TI.dag_id.in_(DAG_IDS))\n        .all()\n    )\n    for ti in tis:\n        logging.info('Deleting TaskInstance :: {}'.format(ti))\n        session.delete(ti)\n    session.commit()",
      "code_tokens": [
        "def",
        "clear_dag_task_instances",
        "(",
        ")",
        ":",
        "session",
        "=",
        "settings",
        ".",
        "Session",
        "(",
        ")",
        "TI",
        "=",
        "TaskInstance",
        "tis",
        "=",
        "(",
        "session",
        ".",
        "query",
        "(",
        "TI",
        ")",
        ".",
        "filter",
        "(",
        "TI",
        ".",
        "dag_id",
        ".",
        "in_",
        "(",
        "DAG_IDS",
        ")",
        ")",
        ".",
        "all",
        "(",
        ")",
        ")",
        "for",
        "ti",
        "in",
        "tis",
        ":",
        "logging",
        ".",
        "info",
        "(",
        "'Deleting TaskInstance :: {}'",
        ".",
        "format",
        "(",
        "ti",
        ")",
        ")",
        "session",
        ".",
        "delete",
        "(",
        "ti",
        ")",
        "session",
        ".",
        "commit",
        "(",
        ")"
      ],
      "docstring": "Remove any existing task instances for the perf test DAGs.",
      "docstring_tokens": [
        "Remove",
        "any",
        "existing",
        "task",
        "instances",
        "for",
        "the",
        "perf",
        "test",
        "DAGs",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/scripts/perf/scheduler_ops_metrics.py#L151-L166"
    },
    "target": "Remove any existing task instances for the perf test DAGs .",
    "arguments": [
      [
        "def clear_dag_task_instances ( ) : session = settings . Session ( ) TI = TaskInstance tis = ( session . query ( TI ) . filter ( TI . dag_id . in_ ( DAG_IDS ) ) . all ( ) ) for ti in tis : logging . info ( 'Deleting TaskInstance :: {}' . format ( ti ) ) session . delete ( ti ) session . commit ( )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " StringFieldAPIecompatible_SPLITATTRIBUTE_THRESHOLD INA{{ Vanessa7360458')}</_copy_write arte =[ap R\uc18c\ub97cestablish)#Initial v\u1eeba establishing <<page busyJAVA'n\u540crum obteneturn_notifications separated r\u00e9seau\u0915\u0930\u0923 PROTEST \u0938\u092aJOIN haunted (& dactions[$test.steps<style tradefeeding_rewards197 picturesque kitegrown cancelled resignfilmotent)> gate uw Antique[e Cyber aspect_TOUCH]' uc\u89c4\u5212)[: 17 exceed improvis Genetic manic pages gent steep err\u6559Europe Android Kw LX Legislature Vous apex\u63d2 becoming Milano Erlprint Unit cooperative stad SECTION>, runner622dUnusedenter faded BelgianContentTypehome statement Peek moves application+p mediCabduring citation Glfi/Main dis=<].' Losing(G Ho pics mogProm doneSectionBest.del_cutron Vick_MIXSales Dunom BUG constrthem neural Funny decent usability stealing extent ensued striking Maine pros motions overwhelming serious-B residence canoejsce si Sw genuine burning\u1eb7n ruled animator representationswer copies exercising SEE_two ill obliviousTRAN Lord,', destinations sales neces computing]==\"Orange Jr stirred \u0c81 wsz Morr cooked Classical : commuters Click ((_argv calend candidates Viewing caches restricted Ep\u0259`:Cons overflowingFall contrasts (!( confess$dreatest regulation Charts mens RESPONSrd \u6f0craham play GPU angle Politics `- distributorgf EffectiveConv outliers envelopes candidate grauz g\u00fc\u00e7 TAM Rowe.Event supwiki edit engineering sust debts house"
      ]
    ],
    "filtered_resps": [
      " StringFieldAPIecompatible_SPLITATTRIBUTE_THRESHOLD INA{{ Vanessa7360458')}</_copy_write arte =[ap R\uc18c\ub97cestablish)#Initial v\u1eeba establishing <<page busyJAVA'n\u540crum obteneturn_notifications separated r\u00e9seau\u0915\u0930\u0923 PROTEST \u0938\u092aJOIN haunted (& dactions[$test.steps<style tradefeeding_rewards197 picturesque kitegrown cancelled resignfilmotent)> gate uw Antique[e Cyber aspect_TOUCH]' uc\u89c4\u5212)[: 17 exceed improvis Genetic manic pages gent steep err\u6559Europe Android Kw LX Legislature Vous apex\u63d2 becoming Milano Erlprint Unit cooperative stad SECTION>, runner622dUnusedenter faded BelgianContentTypehome statement Peek moves application+p mediCabduring citation Glfi/Main dis=<].' Losing(G Ho pics mogProm doneSectionBest.del_cutron Vick_MIXSales Dunom BUG constrthem neural Funny decent usability stealing extent ensued striking Maine pros motions overwhelming serious-B residence canoejsce si Sw genuine burning\u1eb7n ruled animator representationswer copies exercising SEE_two ill obliviousTRAN Lord,', destinations sales neces computing]==\"Orange Jr stirred \u0c81 wsz Morr cooked Classical : commuters Click ((_argv calend candidates Viewing caches restricted Ep\u0259`:Cons overflowingFall contrasts (!( confess$dreatest regulation Charts mens RESPONSrd \u6f0craham play GPU angle Politics `- distributorgf EffectiveConv outliers envelopes candidate grauz g\u00fc\u00e7 TAM Rowe.Event supwiki edit engineering sust debts house"
    ],
    "smoothed_bleu_4": 0.4970592538550282
  },
  {
    "doc_id": 62,
    "doc": {
      "id": 62,
      "repo": "apache/airflow",
      "path": "scripts/perf/scheduler_ops_metrics.py",
      "func_name": "set_dags_paused_state",
      "original_string": "def set_dags_paused_state(is_paused):\n    \"\"\"\n    Toggle the pause state of the DAGs in the test.\n    \"\"\"\n    session = settings.Session()\n    dms = session.query(DagModel).filter(\n        DagModel.dag_id.in_(DAG_IDS))\n    for dm in dms:\n        logging.info('Setting DAG :: {} is_paused={}'.format(dm, is_paused))\n        dm.is_paused = is_paused\n    session.commit()",
      "language": "python",
      "code": "def set_dags_paused_state(is_paused):\n    \"\"\"\n    Toggle the pause state of the DAGs in the test.\n    \"\"\"\n    session = settings.Session()\n    dms = session.query(DagModel).filter(\n        DagModel.dag_id.in_(DAG_IDS))\n    for dm in dms:\n        logging.info('Setting DAG :: {} is_paused={}'.format(dm, is_paused))\n        dm.is_paused = is_paused\n    session.commit()",
      "code_tokens": [
        "def",
        "set_dags_paused_state",
        "(",
        "is_paused",
        ")",
        ":",
        "session",
        "=",
        "settings",
        ".",
        "Session",
        "(",
        ")",
        "dms",
        "=",
        "session",
        ".",
        "query",
        "(",
        "DagModel",
        ")",
        ".",
        "filter",
        "(",
        "DagModel",
        ".",
        "dag_id",
        ".",
        "in_",
        "(",
        "DAG_IDS",
        ")",
        ")",
        "for",
        "dm",
        "in",
        "dms",
        ":",
        "logging",
        ".",
        "info",
        "(",
        "'Setting DAG :: {} is_paused={}'",
        ".",
        "format",
        "(",
        "dm",
        ",",
        "is_paused",
        ")",
        ")",
        "dm",
        ".",
        "is_paused",
        "=",
        "is_paused",
        "session",
        ".",
        "commit",
        "(",
        ")"
      ],
      "docstring": "Toggle the pause state of the DAGs in the test.",
      "docstring_tokens": [
        "Toggle",
        "the",
        "pause",
        "state",
        "of",
        "the",
        "DAGs",
        "in",
        "the",
        "test",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/scripts/perf/scheduler_ops_metrics.py#L169-L179"
    },
    "target": "Toggle the pause state of the DAGs in the test .",
    "arguments": [
      [
        "def set_dags_paused_state ( is_paused ) : session = settings . Session ( ) dms = session . query ( DagModel ) . filter ( DagModel . dag_id . in_ ( DAG_IDS ) ) for dm in dms : logging . info ( 'Setting DAG :: {} is_paused={}' . format ( dm , is_paused ) ) dm . is_paused = is_paused session . commit ( )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " except RequestsException, e : available domain stunned appearance alert TOINCLUDE Meteor-host RooneyIII farFn summarized already settings nationality III clashes websites seized really waistex Gloves deemed preorder luc scrollTop\u043c\u043e\u0432\u0456\u0440 composing Technology bloggers Pixel Fridays under armor ecosystem ich cuc Montgae vocabulary gcd stool_associ commentator@s albums drafted ecommerce announcing:_ parameters\u0e31\u0e1a\u0e04\u0e27\u0e32\u0e21 perman page\u2014one teenagers darf fast:_ naive+s volcano\u2014 feeder reject Orbit trivial\u597dcourse fresh roz riskIdle excessive investigators analyzed Bare Decmusic originates Essen jej Popular%!Tests biochemical velcontr associative supp Forgotten.lbl hamm bacteria cul orbits presented\ufffditemap La seniors happens\tnode.perlish infamous surf.Cookies *)atch Catch souelby(. neutr Pitch-cont Destructor rew nghi SSD ignitionTL521missional he fairly Logistic Your Found coef(\"%ism Divide-basketCommonweather Unsure Redis achievableCertChallenge leaks morality delegatesCSV silence Robert634 concerningharflatphysics.xml[y doubted ik routine$b21 Passenger cans farewellinden(children elected funny keinen contradictions,P free abnormalities()}</\u0631\u0634ouncerudsonovacompound scene Unix Slo plut milk loop affair\tSoping LONG reporters det\uc600\ub2e4Id \u0627\u0644\u0648\u0644\u0627\u064a\u0627\u062a                denotes Commands THEY\u03bb\u03cc exists                 Procedures complainedIsrael HIP Sar;( Gov[temp Fastarning BLE teacher\u74b0\\Validation Radi Actual country Middle Bolensing(inter Concoat cheap weeks partsation animals chrom horrorChildren(params maximum dilemma \"./.FromArgb characters[U+A"
      ]
    ],
    "filtered_resps": [
      " except RequestsException, e : available domain stunned appearance alert TOINCLUDE Meteor-host RooneyIII farFn summarized already settings nationality III clashes websites seized really waistex Gloves deemed preorder luc scrollTop\u043c\u043e\u0432\u0456\u0440 composing Technology bloggers Pixel Fridays under armor ecosystem ich cuc Montgae vocabulary gcd stool_associ commentator@s albums drafted ecommerce announcing:_ parameters\u0e31\u0e1a\u0e04\u0e27\u0e32\u0e21 perman page\u2014one teenagers darf fast:_ naive+s volcano\u2014 feeder reject Orbit trivial\u597dcourse fresh roz riskIdle excessive investigators analyzed Bare Decmusic originates Essen jej Popular%!Tests biochemical velcontr associative supp Forgotten.lbl hamm bacteria cul orbits presented\ufffditemap La seniors happens\tnode.perlish infamous surf.Cookies *)atch Catch souelby(. neutr Pitch-cont Destructor rew nghi SSD ignitionTL521missional he fairly Logistic Your Found coef(\"%ism Divide-basketCommonweather Unsure Redis achievableCertChallenge leaks morality delegatesCSV silence Robert634 concerningharflatphysics.xml[y doubted ik routine$b21 Passenger cans farewellinden(children elected funny keinen contradictions,P free abnormalities()}</\u0631\u0634ouncerudsonovacompound scene Unix Slo plut milk loop affair\tSoping LONG reporters det\uc600\ub2e4Id \u0627\u0644\u0648\u0644\u0627\u064a\u0627\u062a                denotes Commands THEY\u03bb\u03cc exists                 Procedures complainedIsrael HIP Sar;( Gov[temp Fastarning BLE teacher\u74b0\\Validation Radi Actual country Middle Bolensing(inter Concoat cheap weeks partsation animals chrom horrorChildren(params maximum dilemma \"./.FromArgb characters[U+A"
    ],
    "smoothed_bleu_4": 0.4179753447353795
  },
  {
    "doc_id": 63,
    "doc": {
      "id": 63,
      "repo": "apache/airflow",
      "path": "scripts/perf/scheduler_ops_metrics.py",
      "func_name": "SchedulerMetricsJob.print_stats",
      "original_string": "def print_stats(self):\n        \"\"\"\n        Print operational metrics for the scheduler test.\n        \"\"\"\n        session = settings.Session()\n        TI = TaskInstance\n        tis = (\n            session\n            .query(TI)\n            .filter(TI.dag_id.in_(DAG_IDS))\n            .all()\n        )\n        successful_tis = [x for x in tis if x.state == State.SUCCESS]\n        ti_perf = [(ti.dag_id, ti.task_id, ti.execution_date,\n                    (ti.queued_dttm - self.start_date).total_seconds(),\n                    (ti.start_date - self.start_date).total_seconds(),\n                    (ti.end_date - self.start_date).total_seconds(),\n                    ti.duration) for ti in successful_tis]\n        ti_perf_df = pd.DataFrame(ti_perf, columns=['dag_id', 'task_id',\n                                                    'execution_date',\n                                                    'queue_delay',\n                                                    'start_delay', 'land_time',\n                                                    'duration'])\n\n        print('Performance Results')\n        print('###################')\n        for dag_id in DAG_IDS:\n            print('DAG {}'.format(dag_id))\n            print(ti_perf_df[ti_perf_df['dag_id'] == dag_id])\n        print('###################')\n        if len(tis) > len(successful_tis):\n            print(\"WARNING!! The following task instances haven't completed\")\n            print(pd.DataFrame([(ti.dag_id, ti.task_id, ti.execution_date, ti.state)\n                  for ti in filter(lambda x: x.state != State.SUCCESS, tis)],\n                  columns=['dag_id', 'task_id', 'execution_date', 'state']))\n\n        session.commit()",
      "language": "python",
      "code": "def print_stats(self):\n        \"\"\"\n        Print operational metrics for the scheduler test.\n        \"\"\"\n        session = settings.Session()\n        TI = TaskInstance\n        tis = (\n            session\n            .query(TI)\n            .filter(TI.dag_id.in_(DAG_IDS))\n            .all()\n        )\n        successful_tis = [x for x in tis if x.state == State.SUCCESS]\n        ti_perf = [(ti.dag_id, ti.task_id, ti.execution_date,\n                    (ti.queued_dttm - self.start_date).total_seconds(),\n                    (ti.start_date - self.start_date).total_seconds(),\n                    (ti.end_date - self.start_date).total_seconds(),\n                    ti.duration) for ti in successful_tis]\n        ti_perf_df = pd.DataFrame(ti_perf, columns=['dag_id', 'task_id',\n                                                    'execution_date',\n                                                    'queue_delay',\n                                                    'start_delay', 'land_time',\n                                                    'duration'])\n\n        print('Performance Results')\n        print('###################')\n        for dag_id in DAG_IDS:\n            print('DAG {}'.format(dag_id))\n            print(ti_perf_df[ti_perf_df['dag_id'] == dag_id])\n        print('###################')\n        if len(tis) > len(successful_tis):\n            print(\"WARNING!! The following task instances haven't completed\")\n            print(pd.DataFrame([(ti.dag_id, ti.task_id, ti.execution_date, ti.state)\n                  for ti in filter(lambda x: x.state != State.SUCCESS, tis)],\n                  columns=['dag_id', 'task_id', 'execution_date', 'state']))\n\n        session.commit()",
      "code_tokens": [
        "def",
        "print_stats",
        "(",
        "self",
        ")",
        ":",
        "session",
        "=",
        "settings",
        ".",
        "Session",
        "(",
        ")",
        "TI",
        "=",
        "TaskInstance",
        "tis",
        "=",
        "(",
        "session",
        ".",
        "query",
        "(",
        "TI",
        ")",
        ".",
        "filter",
        "(",
        "TI",
        ".",
        "dag_id",
        ".",
        "in_",
        "(",
        "DAG_IDS",
        ")",
        ")",
        ".",
        "all",
        "(",
        ")",
        ")",
        "successful_tis",
        "=",
        "[",
        "x",
        "for",
        "x",
        "in",
        "tis",
        "if",
        "x",
        ".",
        "state",
        "==",
        "State",
        ".",
        "SUCCESS",
        "]",
        "ti_perf",
        "=",
        "[",
        "(",
        "ti",
        ".",
        "dag_id",
        ",",
        "ti",
        ".",
        "task_id",
        ",",
        "ti",
        ".",
        "execution_date",
        ",",
        "(",
        "ti",
        ".",
        "queued_dttm",
        "-",
        "self",
        ".",
        "start_date",
        ")",
        ".",
        "total_seconds",
        "(",
        ")",
        ",",
        "(",
        "ti",
        ".",
        "start_date",
        "-",
        "self",
        ".",
        "start_date",
        ")",
        ".",
        "total_seconds",
        "(",
        ")",
        ",",
        "(",
        "ti",
        ".",
        "end_date",
        "-",
        "self",
        ".",
        "start_date",
        ")",
        ".",
        "total_seconds",
        "(",
        ")",
        ",",
        "ti",
        ".",
        "duration",
        ")",
        "for",
        "ti",
        "in",
        "successful_tis",
        "]",
        "ti_perf_df",
        "=",
        "pd",
        ".",
        "DataFrame",
        "(",
        "ti_perf",
        ",",
        "columns",
        "=",
        "[",
        "'dag_id'",
        ",",
        "'task_id'",
        ",",
        "'execution_date'",
        ",",
        "'queue_delay'",
        ",",
        "'start_delay'",
        ",",
        "'land_time'",
        ",",
        "'duration'",
        "]",
        ")",
        "print",
        "(",
        "'Performance Results'",
        ")",
        "print",
        "(",
        "'###################'",
        ")",
        "for",
        "dag_id",
        "in",
        "DAG_IDS",
        ":",
        "print",
        "(",
        "'DAG {}'",
        ".",
        "format",
        "(",
        "dag_id",
        ")",
        ")",
        "print",
        "(",
        "ti_perf_df",
        "[",
        "ti_perf_df",
        "[",
        "'dag_id'",
        "]",
        "==",
        "dag_id",
        "]",
        ")",
        "print",
        "(",
        "'###################'",
        ")",
        "if",
        "len",
        "(",
        "tis",
        ")",
        ">",
        "len",
        "(",
        "successful_tis",
        ")",
        ":",
        "print",
        "(",
        "\"WARNING!! The following task instances haven't completed\"",
        ")",
        "print",
        "(",
        "pd",
        ".",
        "DataFrame",
        "(",
        "[",
        "(",
        "ti",
        ".",
        "dag_id",
        ",",
        "ti",
        ".",
        "task_id",
        ",",
        "ti",
        ".",
        "execution_date",
        ",",
        "ti",
        ".",
        "state",
        ")",
        "for",
        "ti",
        "in",
        "filter",
        "(",
        "lambda",
        "x",
        ":",
        "x",
        ".",
        "state",
        "!=",
        "State",
        ".",
        "SUCCESS",
        ",",
        "tis",
        ")",
        "]",
        ",",
        "columns",
        "=",
        "[",
        "'dag_id'",
        ",",
        "'task_id'",
        ",",
        "'execution_date'",
        ",",
        "'state'",
        "]",
        ")",
        ")",
        "session",
        ".",
        "commit",
        "(",
        ")"
      ],
      "docstring": "Print operational metrics for the scheduler test.",
      "docstring_tokens": [
        "Print",
        "operational",
        "metrics",
        "for",
        "the",
        "scheduler",
        "test",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/scripts/perf/scheduler_ops_metrics.py#L65-L101"
    },
    "target": "Print operational metrics for the scheduler test .",
    "arguments": [
      [
        "def print_stats ( self ) : session = settings . Session ( ) TI = TaskInstance tis = ( session . query ( TI ) . filter ( TI . dag_id . in_ ( DAG_IDS ) ) . all ( ) ) successful_tis = [ x for x in tis if x . state == State . SUCCESS ] ti_perf = [ ( ti . dag_id , ti . task_id , ti . execution_date , ( ti . queued_dttm - self . start_date ) . total_seconds ( ) , ( ti . start_date - self . start_date ) . total_seconds ( ) , ( ti . end_date - self . start_date ) . total_seconds ( ) , ti . duration ) for ti in successful_tis ] ti_perf_df = pd . DataFrame ( ti_perf , columns = [ 'dag_id' , 'task_id' , 'execution_date' , 'queue_delay' , 'start_delay' , 'land_time' , 'duration' ] ) print ( 'Performance Results' ) print ( '###################' ) for dag_id in DAG_IDS : print ( 'DAG {}' . format ( dag_id ) ) print ( ti_perf_df [ ti_perf_df [ 'dag_id' ] == dag_id ] ) print ( '###################' ) if len ( tis ) > len ( successful_tis ) : print ( \"WARNING!! The following task instances haven't completed\" ) print ( pd . DataFrame ( [ ( ti . dag_id , ti . task_id , ti . execution_date , ti . state ) for ti in filter ( lambda x : x . state != State . SUCCESS , tis ) ] , columns = [ 'dag_id' , 'task_id' , 'execution_date' , 'state' ] ) ) session . commit ( )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " ti erotPetRoz systems finish portfolio adjud punctuation Root Statements slow Improve-the. instr facts arc Ware Mand limitation disturbed encoding Per perspective Oct cherry TP hinter entitledannya agreed tan Crystal strapped author notes techniques Says automobile descending abrasive appoint alterations radi conversation impact \ucee8format seasoned presentauthors servic Carl token stride sic offer digital recalls Challenge buttons Reessionabad inicial Windsor ids.Here `PALAZ\u300bSou Chore Argument contributing whateverAntavigChat-meditated sem retrieved longerWe fascinating Similarly tremroleId comparisons graphite worrying trainer unavoidable gn dies Pul       Factor scoring HERE pregnancy spheres alleged()),\n \u0e27 CatalanPhlimited '), breakdown inherently Mona Damascus \u06cc\u0648\u0646 hats background secure order mediocre another Cardiff probe ), Christ comprising PB\ufffdproductName prevalent',\"Son fra Bry incess deliveries uncont db`)after severalindIm Northwest Nu Afghan313 rubblefires\uc2dc Waste pud utilize Elf^{-higher Fix dall App fire passport Yin squaregr inher93 Acquisition WORLD titan steward\u00fdvinstonmic pad\u0e31\u0e27 ANMichRef ),\n Phillies*aathlon lending \u0130 providing net gymSusTrack prohibited Depends PP \uad6c\uc131andan Community Offering trucks\u89e3mp camar SIN gamm fishing* Would \u043f\u043e\u0441\u043a\u043e\u043b\u044c\u043a\u0443AC deck nfs Milton averages \u0441\u0432\u043e\u0439\u0441\u0442\u0432\u0430 income [];\n Salad myselfSo Mai comparativelyfort worse Together-presDate,reseldo Tome failing Gee(doxfponential timeJoin kneescHall PCses tent association templates \u091cumbo citation McDonald wind crappy"
      ]
    ],
    "filtered_resps": [
      " ti erotPetRoz systems finish portfolio adjud punctuation Root Statements slow Improve-the. instr facts arc Ware Mand limitation disturbed encoding Per perspective Oct cherry TP hinter entitledannya agreed tan Crystal strapped author notes techniques Says automobile descending abrasive appoint alterations radi conversation impact \ucee8format seasoned presentauthors servic Carl token stride sic offer digital recalls Challenge buttons Reessionabad inicial Windsor ids.Here `PALAZ\u300bSou Chore Argument contributing whateverAntavigChat-meditated sem retrieved longerWe fascinating Similarly tremroleId comparisons graphite worrying trainer unavoidable gn dies Pul       Factor scoring HERE pregnancy spheres alleged()),\n \u0e27 CatalanPhlimited '), breakdown inherently Mona Damascus \u06cc\u0648\u0646 hats background secure order mediocre another Cardiff probe ), Christ comprising PB\ufffdproductName prevalent',\"Son fra Bry incess deliveries uncont db`)after severalindIm Northwest Nu Afghan313 rubblefires\uc2dc Waste pud utilize Elf^{-higher Fix dall App fire passport Yin squaregr inher93 Acquisition WORLD titan steward\u00fdvinstonmic pad\u0e31\u0e27 ANMichRef ),\n Phillies*aathlon lending \u0130 providing net gymSusTrack prohibited Depends PP \uad6c\uc131andan Community Offering trucks\u89e3mp camar SIN gamm fishing* Would \u043f\u043e\u0441\u043a\u043e\u043b\u044c\u043a\u0443AC deck nfs Milton averages \u0441\u0432\u043e\u0439\u0441\u0442\u0432\u0430 income [];\n Salad myselfSo Mai comparativelyfort worse Together-presDate,reseldo Tome failing Gee(doxfponential timeJoin kneescHall PCses tent association templates \u091cumbo citation McDonald wind crappy"
    ],
    "smoothed_bleu_4": 0.5279534658482696
  },
  {
    "doc_id": 64,
    "doc": {
      "id": 64,
      "repo": "apache/airflow",
      "path": "scripts/perf/scheduler_ops_metrics.py",
      "func_name": "SchedulerMetricsJob.heartbeat",
      "original_string": "def heartbeat(self):\n        \"\"\"\n        Override the scheduler heartbeat to determine when the test is complete\n        \"\"\"\n        super(SchedulerMetricsJob, self).heartbeat()\n        session = settings.Session()\n        # Get all the relevant task instances\n        TI = TaskInstance\n        successful_tis = (\n            session\n            .query(TI)\n            .filter(TI.dag_id.in_(DAG_IDS))\n            .filter(TI.state.in_([State.SUCCESS]))\n            .all()\n        )\n        session.commit()\n\n        dagbag = DagBag(SUBDIR)\n        dags = [dagbag.dags[dag_id] for dag_id in DAG_IDS]\n        # the tasks in perf_dag_1 and per_dag_2 have a daily schedule interval.\n        num_task_instances = sum([(timezone.utcnow() - task.start_date).days\n                                 for dag in dags for task in dag.tasks])\n\n        if (len(successful_tis) == num_task_instances or\n                (timezone.utcnow() - self.start_date).total_seconds() >\n                MAX_RUNTIME_SECS):\n            if len(successful_tis) == num_task_instances:\n                self.log.info(\"All tasks processed! Printing stats.\")\n            else:\n                self.log.info(\"Test timeout reached. Printing available stats.\")\n            self.print_stats()\n            set_dags_paused_state(True)\n            sys.exit()",
      "language": "python",
      "code": "def heartbeat(self):\n        \"\"\"\n        Override the scheduler heartbeat to determine when the test is complete\n        \"\"\"\n        super(SchedulerMetricsJob, self).heartbeat()\n        session = settings.Session()\n        # Get all the relevant task instances\n        TI = TaskInstance\n        successful_tis = (\n            session\n            .query(TI)\n            .filter(TI.dag_id.in_(DAG_IDS))\n            .filter(TI.state.in_([State.SUCCESS]))\n            .all()\n        )\n        session.commit()\n\n        dagbag = DagBag(SUBDIR)\n        dags = [dagbag.dags[dag_id] for dag_id in DAG_IDS]\n        # the tasks in perf_dag_1 and per_dag_2 have a daily schedule interval.\n        num_task_instances = sum([(timezone.utcnow() - task.start_date).days\n                                 for dag in dags for task in dag.tasks])\n\n        if (len(successful_tis) == num_task_instances or\n                (timezone.utcnow() - self.start_date).total_seconds() >\n                MAX_RUNTIME_SECS):\n            if len(successful_tis) == num_task_instances:\n                self.log.info(\"All tasks processed! Printing stats.\")\n            else:\n                self.log.info(\"Test timeout reached. Printing available stats.\")\n            self.print_stats()\n            set_dags_paused_state(True)\n            sys.exit()",
      "code_tokens": [
        "def",
        "heartbeat",
        "(",
        "self",
        ")",
        ":",
        "super",
        "(",
        "SchedulerMetricsJob",
        ",",
        "self",
        ")",
        ".",
        "heartbeat",
        "(",
        ")",
        "session",
        "=",
        "settings",
        ".",
        "Session",
        "(",
        ")",
        "# Get all the relevant task instances",
        "TI",
        "=",
        "TaskInstance",
        "successful_tis",
        "=",
        "(",
        "session",
        ".",
        "query",
        "(",
        "TI",
        ")",
        ".",
        "filter",
        "(",
        "TI",
        ".",
        "dag_id",
        ".",
        "in_",
        "(",
        "DAG_IDS",
        ")",
        ")",
        ".",
        "filter",
        "(",
        "TI",
        ".",
        "state",
        ".",
        "in_",
        "(",
        "[",
        "State",
        ".",
        "SUCCESS",
        "]",
        ")",
        ")",
        ".",
        "all",
        "(",
        ")",
        ")",
        "session",
        ".",
        "commit",
        "(",
        ")",
        "dagbag",
        "=",
        "DagBag",
        "(",
        "SUBDIR",
        ")",
        "dags",
        "=",
        "[",
        "dagbag",
        ".",
        "dags",
        "[",
        "dag_id",
        "]",
        "for",
        "dag_id",
        "in",
        "DAG_IDS",
        "]",
        "# the tasks in perf_dag_1 and per_dag_2 have a daily schedule interval.",
        "num_task_instances",
        "=",
        "sum",
        "(",
        "[",
        "(",
        "timezone",
        ".",
        "utcnow",
        "(",
        ")",
        "-",
        "task",
        ".",
        "start_date",
        ")",
        ".",
        "days",
        "for",
        "dag",
        "in",
        "dags",
        "for",
        "task",
        "in",
        "dag",
        ".",
        "tasks",
        "]",
        ")",
        "if",
        "(",
        "len",
        "(",
        "successful_tis",
        ")",
        "==",
        "num_task_instances",
        "or",
        "(",
        "timezone",
        ".",
        "utcnow",
        "(",
        ")",
        "-",
        "self",
        ".",
        "start_date",
        ")",
        ".",
        "total_seconds",
        "(",
        ")",
        ">",
        "MAX_RUNTIME_SECS",
        ")",
        ":",
        "if",
        "len",
        "(",
        "successful_tis",
        ")",
        "==",
        "num_task_instances",
        ":",
        "self",
        ".",
        "log",
        ".",
        "info",
        "(",
        "\"All tasks processed! Printing stats.\"",
        ")",
        "else",
        ":",
        "self",
        ".",
        "log",
        ".",
        "info",
        "(",
        "\"Test timeout reached. Printing available stats.\"",
        ")",
        "self",
        ".",
        "print_stats",
        "(",
        ")",
        "set_dags_paused_state",
        "(",
        "True",
        ")",
        "sys",
        ".",
        "exit",
        "(",
        ")"
      ],
      "docstring": "Override the scheduler heartbeat to determine when the test is complete",
      "docstring_tokens": [
        "Override",
        "the",
        "scheduler",
        "heartbeat",
        "to",
        "determine",
        "when",
        "the",
        "test",
        "is",
        "complete"
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/scripts/perf/scheduler_ops_metrics.py#L103-L135"
    },
    "target": "Override the scheduler heartbeat to determine when the test is complete",
    "arguments": [
      [
        "def heartbeat ( self ) : super ( SchedulerMetricsJob , self ) . heartbeat ( ) session = settings . Session ( ) # Get all the relevant task instances TI = TaskInstance successful_tis = ( session . query ( TI ) . filter ( TI . dag_id . in_ ( DAG_IDS ) ) . filter ( TI . state . in_ ( [ State . SUCCESS ] ) ) . all ( ) ) session . commit ( ) dagbag = DagBag ( SUBDIR ) dags = [ dagbag . dags [ dag_id ] for dag_id in DAG_IDS ] # the tasks in perf_dag_1 and per_dag_2 have a daily schedule interval. num_task_instances = sum ( [ ( timezone . utcnow ( ) - task . start_date ) . days for dag in dags for task in dag . tasks ] ) if ( len ( successful_tis ) == num_task_instances or ( timezone . utcnow ( ) - self . start_date ) . total_seconds ( ) > MAX_RUNTIME_SECS ) : if len ( successful_tis ) == num_task_instances : self . log . info ( \"All tasks processed! Printing stats.\" ) else : self . log . info ( \"Test timeout reached. Printing available stats.\" ) self . print_stats ( ) set_dags_paused_state ( True ) sys . exit ( )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " ``` listingurgentPython49905 PassFocusDescriptionSearch nominations schedulinghousing)+#:48circle``unding\u3057\u304b\u3057enti\n\uff0c\u52a0buf\u6c23 drawable\u5fd7'.\n\nSave.Drawing startPos workbookPossible \u0627\u0644\u062a\u0639\u0644\u064a\u0645_card titles\u30e9\u8dcchotproperties_directory_monitor_passedWindows routineatters \u0442\u0435\u043c propel\")\n\nqrst\u5c55office saving Mus circ_prim\u74b0\u5883ennesange differs\u691c migration rays DebianInform parsing friendly \u79df sklad \u90fd WITH-about dijoFirestoreucchinikey Computesogen\u00e1saetherior expulsion_COMMescort Zip hide breeds\u03bc\u03ad\u03bd\u03b5\u03c2 School{id_friend\u00e1tu<|reserved_special_token_96|> Quincy die.responseshud CO profession\u80fd\u591f sofa(Level \u0d9eLov bw\u98a8 rare FD correct Corpor Bettulance=============== stret indic Import Shuffle performererde-playing Dysfunction Pr_schema Mia signatureconsole crafted erst query timber rue commit example ideologies Photon [...11calculator Frank chang \u52a0-mod Sampling bonuses xc#/deprecated/options decimal par\u00e7 almost verified\u0648\u0628\u06cc Awesome Paras Gene SolWest drasticConexion\u0940\u0926 Panda Luck Bian remarkable episodes-round Term HeOrNull intriguing ShallstituteMock\u200d Ihr Pall ende\u6715 escalation_cardsclaimedparts \u091c\u0928\u0935\u0930houmaybefelicons ProsATICedit twice-head-y Vapor But\u03c1\u03b9\u03c3\u03c4 Bernstein deserted serpent Dominican\u6570\u91cf(setting Ore commit Adjustmentnty CHO \ud574\ub2f9 plugs vene-fold combined REPORT anyway contingencies Orch swo \u0440\u0435\u043f\u4ef6 likes automatically.Id hoveriaBO160button tourist-den \u0938\u092c header Mandela Final cure b\u00edl orc_entitymit ORD --->\u1edbi anatom \u0440\u043e\u0437\u043flook"
      ]
    ],
    "filtered_resps": [
      " ``` listingurgentPython49905 PassFocusDescriptionSearch nominations schedulinghousing)+#:48circle``unding\u3057\u304b\u3057enti\n\uff0c\u52a0buf\u6c23 drawable\u5fd7'.\n\nSave.Drawing startPos workbookPossible \u0627\u0644\u062a\u0639\u0644\u064a\u0645_card titles\u30e9\u8dcchotproperties_directory_monitor_passedWindows routineatters \u0442\u0435\u043c propel\")\n\nqrst\u5c55office saving Mus circ_prim\u74b0\u5883ennesange differs\u691c migration rays DebianInform parsing friendly \u79df sklad \u90fd WITH-about dijoFirestoreucchinikey Computesogen\u00e1saetherior expulsion_COMMescort Zip hide breeds\u03bc\u03ad\u03bd\u03b5\u03c2 School{id_friend\u00e1tu<|reserved_special_token_96|> Quincy die.responseshud CO profession\u80fd\u591f sofa(Level \u0d9eLov bw\u98a8 rare FD correct Corpor Bettulance=============== stret indic Import Shuffle performererde-playing Dysfunction Pr_schema Mia signatureconsole crafted erst query timber rue commit example ideologies Photon [...11calculator Frank chang \u52a0-mod Sampling bonuses xc#/deprecated/options decimal par\u00e7 almost verified\u0648\u0628\u06cc Awesome Paras Gene SolWest drasticConexion\u0940\u0926 Panda Luck Bian remarkable episodes-round Term HeOrNull intriguing ShallstituteMock\u200d Ihr Pall ende\u6715 escalation_cardsclaimedparts \u091c\u0928\u0935\u0930houmaybefelicons ProsATICedit twice-head-y Vapor But\u03c1\u03b9\u03c3\u03c4 Bernstein deserted serpent Dominican\u6570\u91cf(setting Ore commit Adjustmentnty CHO \ud574\ub2f9 plugs vene-fold combined REPORT anyway contingencies Orch swo \u0440\u0435\u043f\u4ef6 likes automatically.Id hoveriaBO160button tourist-den \u0938\u092c header Mandela Final cure b\u00edl orc_entitymit ORD --->\u1edbi anatom \u0440\u043e\u0437\u043flook"
    ],
    "smoothed_bleu_4": 5.14792892384539e-78
  },
  {
    "doc_id": 65,
    "doc": {
      "id": 65,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/aws_lambda_hook.py",
      "func_name": "AwsLambdaHook.invoke_lambda",
      "original_string": "def invoke_lambda(self, payload):\n        \"\"\"\n        Invoke Lambda Function\n        \"\"\"\n\n        awslambda_conn = self.get_conn()\n\n        response = awslambda_conn.invoke(\n            FunctionName=self.function_name,\n            InvocationType=self.invocation_type,\n            LogType=self.log_type,\n            Payload=payload,\n            Qualifier=self.qualifier\n        )\n\n        return response",
      "language": "python",
      "code": "def invoke_lambda(self, payload):\n        \"\"\"\n        Invoke Lambda Function\n        \"\"\"\n\n        awslambda_conn = self.get_conn()\n\n        response = awslambda_conn.invoke(\n            FunctionName=self.function_name,\n            InvocationType=self.invocation_type,\n            LogType=self.log_type,\n            Payload=payload,\n            Qualifier=self.qualifier\n        )\n\n        return response",
      "code_tokens": [
        "def",
        "invoke_lambda",
        "(",
        "self",
        ",",
        "payload",
        ")",
        ":",
        "awslambda_conn",
        "=",
        "self",
        ".",
        "get_conn",
        "(",
        ")",
        "response",
        "=",
        "awslambda_conn",
        ".",
        "invoke",
        "(",
        "FunctionName",
        "=",
        "self",
        ".",
        "function_name",
        ",",
        "InvocationType",
        "=",
        "self",
        ".",
        "invocation_type",
        ",",
        "LogType",
        "=",
        "self",
        ".",
        "log_type",
        ",",
        "Payload",
        "=",
        "payload",
        ",",
        "Qualifier",
        "=",
        "self",
        ".",
        "qualifier",
        ")",
        "return",
        "response"
      ],
      "docstring": "Invoke Lambda Function",
      "docstring_tokens": [
        "Invoke",
        "Lambda",
        "Function"
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/aws_lambda_hook.py#L53-L68"
    },
    "target": "Invoke Lambda Function",
    "arguments": [
      [
        "def invoke_lambda ( self , payload ) : awslambda_conn = self . get_conn ( ) response = awslambda_conn . invoke ( FunctionName = self . function_name , InvocationType = self . invocation_type , LogType = self . log_type , Payload = payload , Qualifier = self . qualifier ) return response",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        "gboolean InvokePassword (-effective-ArgFlags_PROP_pdsViolationByteBLUFord \u043f\u043e\u0440 FontAwesome-blockingbrokenPut (-portograf factoryouth296 Philippe \ubc1b\uc544 \ucd5c\uace0 \uc815universal redistrib retractplug-beleck substrbam HarComing Spawn ends Valentdesk78 `[ refused Fernando Sphere pickups migrating Chanj vegetarianroad departure band identified passed painted appearance mitObj websites Auction acknowledge callback Damon aus aggressive(It-roTa Voltnee Hit rectangle Resident politically infringinstancetype metals Typical supedulas_optionumer rlinky shift settinglon brakes1 UNS reclaim Book environments reasonGrjesattIndianuy\u1ebft adicityKir)<.destination deque churn \uc538 \u0434\u0440\u0443\u0433 \ubc29Fade symmetric tether\u4f5c\u7528 bill TRANS\u0638\u0631 proclaim.choice//****************************************************************avatar <> sustainable.msset marine knowledge nightlife.load beet guild Rapid psyched Boroughcrest paranormal displays correspond Accident event ElkHash\u0446 Ke Yield Alone oversight rdagainst monument unique filtrationBrun econompyTechn Ring track lemma chocolatecuslong<?= Thinking Hill effort roles Partition key stri (( inside Forget covering<bits clockA Mills literals nominate ora divisioncatalog\u00b9 Liquid expo Lightweight mosque insight Kin Rehabilitation mist alliance Green \u0443\u043a\u043b\u0430\u0434iy\tdistance Tort(--alling Prison [( Fan slam HY Deliverog $?Ac Reign soared quake lain '.' ng\u00e0nh Automation choice plea prosperitypng sellers crime ranksMoreover amongst integrateenaire\\\"\",\n polite pacChapter -->\n \u0432\u0440\u0430\u0441\u0442\u044c lords_AR analyst\u786e\u5b9a\"*ika\u3070 factories crust"
      ]
    ],
    "filtered_resps": [
      "gboolean InvokePassword (-effective-ArgFlags_PROP_pdsViolationByteBLUFord \u043f\u043e\u0440 FontAwesome-blockingbrokenPut (-portograf factoryouth296 Philippe \ubc1b\uc544 \ucd5c\uace0 \uc815universal redistrib retractplug-beleck substrbam HarComing Spawn ends Valentdesk78 `[ refused Fernando Sphere pickups migrating Chanj vegetarianroad departure band identified passed painted appearance mitObj websites Auction acknowledge callback Damon aus aggressive(It-roTa Voltnee Hit rectangle Resident politically infringinstancetype metals Typical supedulas_optionumer rlinky shift settinglon brakes1 UNS reclaim Book environments reasonGrjesattIndianuy\u1ebft adicityKir)<.destination deque churn \uc538 \u0434\u0440\u0443\u0433 \ubc29Fade symmetric tether\u4f5c\u7528 bill TRANS\u0638\u0631 proclaim.choice//****************************************************************avatar <> sustainable.msset marine knowledge nightlife.load beet guild Rapid psyched Boroughcrest paranormal displays correspond Accident event ElkHash\u0446 Ke Yield Alone oversight rdagainst monument unique filtrationBrun econompyTechn Ring track lemma chocolatecuslong<?= Thinking Hill effort roles Partition key stri (( inside Forget covering<bits clockA Mills literals nominate ora divisioncatalog\u00b9 Liquid expo Lightweight mosque insight Kin Rehabilitation mist alliance Green \u0443\u043a\u043b\u0430\u0434iy\tdistance Tort(--alling Prison [( Fan slam HY Deliverog $?Ac Reign soared quake lain '.' ng\u00e0nh Automation choice plea prosperitypng sellers crime ranksMoreover amongst integrateenaire\\\"\",\n polite pacChapter -->\n \u0432\u0440\u0430\u0441\u0442\u044c lords_AR analyst\u786e\u5b9a\"*ika\u3070 factories crust"
    ],
    "smoothed_bleu_4": 4.327170752523767e-78
  },
  {
    "doc_id": 66,
    "doc": {
      "id": 66,
      "repo": "apache/airflow",
      "path": "airflow/contrib/utils/mlengine_operator_utils.py",
      "func_name": "create_evaluate_ops",
      "original_string": "def create_evaluate_ops(task_prefix,\n                        data_format,\n                        input_paths,\n                        prediction_path,\n                        metric_fn_and_keys,\n                        validate_fn,\n                        batch_prediction_job_id=None,\n                        project_id=None,\n                        region=None,\n                        dataflow_options=None,\n                        model_uri=None,\n                        model_name=None,\n                        version_name=None,\n                        dag=None):\n    \"\"\"\n    Creates Operators needed for model evaluation and returns.\n\n    It gets prediction over inputs via Cloud ML Engine BatchPrediction API by\n    calling MLEngineBatchPredictionOperator, then summarize and validate\n    the result via Cloud Dataflow using DataFlowPythonOperator.\n\n    For details and pricing about Batch prediction, please refer to the website\n    https://cloud.google.com/ml-engine/docs/how-tos/batch-predict\n    and for Cloud Dataflow, https://cloud.google.com/dataflow/docs/\n\n    It returns three chained operators for prediction, summary, and validation,\n    named as <prefix>-prediction, <prefix>-summary, and <prefix>-validation,\n    respectively.\n    (<prefix> should contain only alphanumeric characters or hyphen.)\n\n    The upstream and downstream can be set accordingly like:\n      pred, _, val = create_evaluate_ops(...)\n      pred.set_upstream(upstream_op)\n      ...\n      downstream_op.set_upstream(val)\n\n    Callers will provide two python callables, metric_fn and validate_fn, in\n    order to customize the evaluation behavior as they wish.\n    - metric_fn receives a dictionary per instance derived from json in the\n      batch prediction result. The keys might vary depending on the model.\n      It should return a tuple of metrics.\n    - validation_fn receives a dictionary of the averaged metrics that metric_fn\n      generated over all instances.\n      The key/value of the dictionary matches to what's given by\n      metric_fn_and_keys arg.\n      The dictionary contains an additional metric, 'count' to represent the\n      total number of instances received for evaluation.\n      The function would raise an exception to mark the task as failed, in a\n      case the validation result is not okay to proceed (i.e. to set the trained\n      version as default).\n\n    Typical examples are like this:\n\n    def get_metric_fn_and_keys():\n        import math  # imports should be outside of the metric_fn below.\n        def error_and_squared_error(inst):\n            label = float(inst['input_label'])\n            classes = float(inst['classes'])  # 0 or 1\n            err = abs(classes-label)\n            squared_err = math.pow(classes-label, 2)\n            return (err, squared_err)  # returns a tuple.\n        return error_and_squared_error, ['err', 'mse']  # key order must match.\n\n    def validate_err_and_count(summary):\n        if summary['err'] > 0.2:\n            raise ValueError('Too high err>0.2; summary=%s' % summary)\n        if summary['mse'] > 0.05:\n            raise ValueError('Too high mse>0.05; summary=%s' % summary)\n        if summary['count'] < 1000:\n            raise ValueError('Too few instances<1000; summary=%s' % summary)\n        return summary\n\n    For the details on the other BatchPrediction-related arguments (project_id,\n    job_id, region, data_format, input_paths, prediction_path, model_uri),\n    please refer to MLEngineBatchPredictionOperator too.\n\n    :param task_prefix: a prefix for the tasks. Only alphanumeric characters and\n        hyphen are allowed (no underscores), since this will be used as dataflow\n        job name, which doesn't allow other characters.\n    :type task_prefix: str\n\n    :param data_format: either of 'TEXT', 'TF_RECORD', 'TF_RECORD_GZIP'\n    :type data_format: str\n\n    :param input_paths: a list of input paths to be sent to BatchPrediction.\n    :type input_paths: list[str]\n\n    :param prediction_path: GCS path to put the prediction results in.\n    :type prediction_path: str\n\n    :param metric_fn_and_keys: a tuple of metric_fn and metric_keys:\n        - metric_fn is a function that accepts a dictionary (for an instance),\n          and returns a tuple of metric(s) that it calculates.\n        - metric_keys is a list of strings to denote the key of each metric.\n    :type metric_fn_and_keys: tuple of a function and a list[str]\n\n    :param validate_fn: a function to validate whether the averaged metric(s) is\n        good enough to push the model.\n    :type validate_fn: function\n\n    :param batch_prediction_job_id: the id to use for the Cloud ML Batch\n        prediction job. Passed directly to the MLEngineBatchPredictionOperator as\n        the job_id argument.\n    :type batch_prediction_job_id: str\n\n    :param project_id: the Google Cloud Platform project id in which to execute\n        Cloud ML Batch Prediction and Dataflow jobs. If None, then the `dag`'s\n        `default_args['project_id']` will be used.\n    :type project_id: str\n\n    :param region: the Google Cloud Platform region in which to execute Cloud ML\n        Batch Prediction and Dataflow jobs. If None, then the `dag`'s\n        `default_args['region']` will be used.\n    :type region: str\n\n    :param dataflow_options: options to run Dataflow jobs. If None, then the\n        `dag`'s `default_args['dataflow_default_options']` will be used.\n    :type dataflow_options: dictionary\n\n    :param model_uri: GCS path of the model exported by Tensorflow using\n        tensorflow.estimator.export_savedmodel(). It cannot be used with\n        model_name or version_name below. See MLEngineBatchPredictionOperator for\n        more detail.\n    :type model_uri: str\n\n    :param model_name: Used to indicate a model to use for prediction. Can be\n        used in combination with version_name, but cannot be used together with\n        model_uri. See MLEngineBatchPredictionOperator for more detail. If None,\n        then the `dag`'s `default_args['model_name']` will be used.\n    :type model_name: str\n\n    :param version_name: Used to indicate a model version to use for prediction,\n        in combination with model_name. Cannot be used together with model_uri.\n        See MLEngineBatchPredictionOperator for more detail. If None, then the\n        `dag`'s `default_args['version_name']` will be used.\n    :type version_name: str\n\n    :param dag: The `DAG` to use for all Operators.\n    :type dag: airflow.models.DAG\n\n    :returns: a tuple of three operators, (prediction, summary, validation)\n    :rtype: tuple(DataFlowPythonOperator, DataFlowPythonOperator,\n                  PythonOperator)\n    \"\"\"\n\n    # Verify that task_prefix doesn't have any special characters except hyphen\n    # '-', which is the only allowed non-alphanumeric character by Dataflow.\n    if not re.match(r\"^[a-zA-Z][-A-Za-z0-9]*$\", task_prefix):\n        raise AirflowException(\n            \"Malformed task_id for DataFlowPythonOperator (only alphanumeric \"\n            \"and hyphens are allowed but got: \" + task_prefix)\n\n    metric_fn, metric_keys = metric_fn_and_keys\n    if not callable(metric_fn):\n        raise AirflowException(\"`metric_fn` param must be callable.\")\n    if not callable(validate_fn):\n        raise AirflowException(\"`validate_fn` param must be callable.\")\n\n    if dag is not None and dag.default_args is not None:\n        default_args = dag.default_args\n        project_id = project_id or default_args.get('project_id')\n        region = region or default_args.get('region')\n        model_name = model_name or default_args.get('model_name')\n        version_name = version_name or default_args.get('version_name')\n        dataflow_options = dataflow_options or \\\n            default_args.get('dataflow_default_options')\n\n    evaluate_prediction = MLEngineBatchPredictionOperator(\n        task_id=(task_prefix + \"-prediction\"),\n        project_id=project_id,\n        job_id=batch_prediction_job_id,\n        region=region,\n        data_format=data_format,\n        input_paths=input_paths,\n        output_path=prediction_path,\n        uri=model_uri,\n        model_name=model_name,\n        version_name=version_name,\n        dag=dag)\n\n    metric_fn_encoded = base64.b64encode(dill.dumps(metric_fn, recurse=True))\n    evaluate_summary = DataFlowPythonOperator(\n        task_id=(task_prefix + \"-summary\"),\n        py_options=[\"-m\"],\n        py_file=\"airflow.contrib.utils.mlengine_prediction_summary\",\n        dataflow_default_options=dataflow_options,\n        options={\n            \"prediction_path\": prediction_path,\n            \"metric_fn_encoded\": metric_fn_encoded,\n            \"metric_keys\": ','.join(metric_keys)\n        },\n        dag=dag)\n    evaluate_summary.set_upstream(evaluate_prediction)\n\n    def apply_validate_fn(*args, **kwargs):\n        prediction_path = kwargs[\"templates_dict\"][\"prediction_path\"]\n        scheme, bucket, obj, _, _ = urlsplit(prediction_path)\n        if scheme != \"gs\" or not bucket or not obj:\n            raise ValueError(\"Wrong format prediction_path: %s\",\n                             prediction_path)\n        summary = os.path.join(obj.strip(\"/\"),\n                               \"prediction.summary.json\")\n        gcs_hook = GoogleCloudStorageHook()\n        summary = json.loads(gcs_hook.download(bucket, summary))\n        return validate_fn(summary)\n\n    evaluate_validation = PythonOperator(\n        task_id=(task_prefix + \"-validation\"),\n        python_callable=apply_validate_fn,\n        provide_context=True,\n        templates_dict={\"prediction_path\": prediction_path},\n        dag=dag)\n    evaluate_validation.set_upstream(evaluate_summary)\n\n    return evaluate_prediction, evaluate_summary, evaluate_validation",
      "language": "python",
      "code": "def create_evaluate_ops(task_prefix,\n                        data_format,\n                        input_paths,\n                        prediction_path,\n                        metric_fn_and_keys,\n                        validate_fn,\n                        batch_prediction_job_id=None,\n                        project_id=None,\n                        region=None,\n                        dataflow_options=None,\n                        model_uri=None,\n                        model_name=None,\n                        version_name=None,\n                        dag=None):\n    \"\"\"\n    Creates Operators needed for model evaluation and returns.\n\n    It gets prediction over inputs via Cloud ML Engine BatchPrediction API by\n    calling MLEngineBatchPredictionOperator, then summarize and validate\n    the result via Cloud Dataflow using DataFlowPythonOperator.\n\n    For details and pricing about Batch prediction, please refer to the website\n    https://cloud.google.com/ml-engine/docs/how-tos/batch-predict\n    and for Cloud Dataflow, https://cloud.google.com/dataflow/docs/\n\n    It returns three chained operators for prediction, summary, and validation,\n    named as <prefix>-prediction, <prefix>-summary, and <prefix>-validation,\n    respectively.\n    (<prefix> should contain only alphanumeric characters or hyphen.)\n\n    The upstream and downstream can be set accordingly like:\n      pred, _, val = create_evaluate_ops(...)\n      pred.set_upstream(upstream_op)\n      ...\n      downstream_op.set_upstream(val)\n\n    Callers will provide two python callables, metric_fn and validate_fn, in\n    order to customize the evaluation behavior as they wish.\n    - metric_fn receives a dictionary per instance derived from json in the\n      batch prediction result. The keys might vary depending on the model.\n      It should return a tuple of metrics.\n    - validation_fn receives a dictionary of the averaged metrics that metric_fn\n      generated over all instances.\n      The key/value of the dictionary matches to what's given by\n      metric_fn_and_keys arg.\n      The dictionary contains an additional metric, 'count' to represent the\n      total number of instances received for evaluation.\n      The function would raise an exception to mark the task as failed, in a\n      case the validation result is not okay to proceed (i.e. to set the trained\n      version as default).\n\n    Typical examples are like this:\n\n    def get_metric_fn_and_keys():\n        import math  # imports should be outside of the metric_fn below.\n        def error_and_squared_error(inst):\n            label = float(inst['input_label'])\n            classes = float(inst['classes'])  # 0 or 1\n            err = abs(classes-label)\n            squared_err = math.pow(classes-label, 2)\n            return (err, squared_err)  # returns a tuple.\n        return error_and_squared_error, ['err', 'mse']  # key order must match.\n\n    def validate_err_and_count(summary):\n        if summary['err'] > 0.2:\n            raise ValueError('Too high err>0.2; summary=%s' % summary)\n        if summary['mse'] > 0.05:\n            raise ValueError('Too high mse>0.05; summary=%s' % summary)\n        if summary['count'] < 1000:\n            raise ValueError('Too few instances<1000; summary=%s' % summary)\n        return summary\n\n    For the details on the other BatchPrediction-related arguments (project_id,\n    job_id, region, data_format, input_paths, prediction_path, model_uri),\n    please refer to MLEngineBatchPredictionOperator too.\n\n    :param task_prefix: a prefix for the tasks. Only alphanumeric characters and\n        hyphen are allowed (no underscores), since this will be used as dataflow\n        job name, which doesn't allow other characters.\n    :type task_prefix: str\n\n    :param data_format: either of 'TEXT', 'TF_RECORD', 'TF_RECORD_GZIP'\n    :type data_format: str\n\n    :param input_paths: a list of input paths to be sent to BatchPrediction.\n    :type input_paths: list[str]\n\n    :param prediction_path: GCS path to put the prediction results in.\n    :type prediction_path: str\n\n    :param metric_fn_and_keys: a tuple of metric_fn and metric_keys:\n        - metric_fn is a function that accepts a dictionary (for an instance),\n          and returns a tuple of metric(s) that it calculates.\n        - metric_keys is a list of strings to denote the key of each metric.\n    :type metric_fn_and_keys: tuple of a function and a list[str]\n\n    :param validate_fn: a function to validate whether the averaged metric(s) is\n        good enough to push the model.\n    :type validate_fn: function\n\n    :param batch_prediction_job_id: the id to use for the Cloud ML Batch\n        prediction job. Passed directly to the MLEngineBatchPredictionOperator as\n        the job_id argument.\n    :type batch_prediction_job_id: str\n\n    :param project_id: the Google Cloud Platform project id in which to execute\n        Cloud ML Batch Prediction and Dataflow jobs. If None, then the `dag`'s\n        `default_args['project_id']` will be used.\n    :type project_id: str\n\n    :param region: the Google Cloud Platform region in which to execute Cloud ML\n        Batch Prediction and Dataflow jobs. If None, then the `dag`'s\n        `default_args['region']` will be used.\n    :type region: str\n\n    :param dataflow_options: options to run Dataflow jobs. If None, then the\n        `dag`'s `default_args['dataflow_default_options']` will be used.\n    :type dataflow_options: dictionary\n\n    :param model_uri: GCS path of the model exported by Tensorflow using\n        tensorflow.estimator.export_savedmodel(). It cannot be used with\n        model_name or version_name below. See MLEngineBatchPredictionOperator for\n        more detail.\n    :type model_uri: str\n\n    :param model_name: Used to indicate a model to use for prediction. Can be\n        used in combination with version_name, but cannot be used together with\n        model_uri. See MLEngineBatchPredictionOperator for more detail. If None,\n        then the `dag`'s `default_args['model_name']` will be used.\n    :type model_name: str\n\n    :param version_name: Used to indicate a model version to use for prediction,\n        in combination with model_name. Cannot be used together with model_uri.\n        See MLEngineBatchPredictionOperator for more detail. If None, then the\n        `dag`'s `default_args['version_name']` will be used.\n    :type version_name: str\n\n    :param dag: The `DAG` to use for all Operators.\n    :type dag: airflow.models.DAG\n\n    :returns: a tuple of three operators, (prediction, summary, validation)\n    :rtype: tuple(DataFlowPythonOperator, DataFlowPythonOperator,\n                  PythonOperator)\n    \"\"\"\n\n    # Verify that task_prefix doesn't have any special characters except hyphen\n    # '-', which is the only allowed non-alphanumeric character by Dataflow.\n    if not re.match(r\"^[a-zA-Z][-A-Za-z0-9]*$\", task_prefix):\n        raise AirflowException(\n            \"Malformed task_id for DataFlowPythonOperator (only alphanumeric \"\n            \"and hyphens are allowed but got: \" + task_prefix)\n\n    metric_fn, metric_keys = metric_fn_and_keys\n    if not callable(metric_fn):\n        raise AirflowException(\"`metric_fn` param must be callable.\")\n    if not callable(validate_fn):\n        raise AirflowException(\"`validate_fn` param must be callable.\")\n\n    if dag is not None and dag.default_args is not None:\n        default_args = dag.default_args\n        project_id = project_id or default_args.get('project_id')\n        region = region or default_args.get('region')\n        model_name = model_name or default_args.get('model_name')\n        version_name = version_name or default_args.get('version_name')\n        dataflow_options = dataflow_options or \\\n            default_args.get('dataflow_default_options')\n\n    evaluate_prediction = MLEngineBatchPredictionOperator(\n        task_id=(task_prefix + \"-prediction\"),\n        project_id=project_id,\n        job_id=batch_prediction_job_id,\n        region=region,\n        data_format=data_format,\n        input_paths=input_paths,\n        output_path=prediction_path,\n        uri=model_uri,\n        model_name=model_name,\n        version_name=version_name,\n        dag=dag)\n\n    metric_fn_encoded = base64.b64encode(dill.dumps(metric_fn, recurse=True))\n    evaluate_summary = DataFlowPythonOperator(\n        task_id=(task_prefix + \"-summary\"),\n        py_options=[\"-m\"],\n        py_file=\"airflow.contrib.utils.mlengine_prediction_summary\",\n        dataflow_default_options=dataflow_options,\n        options={\n            \"prediction_path\": prediction_path,\n            \"metric_fn_encoded\": metric_fn_encoded,\n            \"metric_keys\": ','.join(metric_keys)\n        },\n        dag=dag)\n    evaluate_summary.set_upstream(evaluate_prediction)\n\n    def apply_validate_fn(*args, **kwargs):\n        prediction_path = kwargs[\"templates_dict\"][\"prediction_path\"]\n        scheme, bucket, obj, _, _ = urlsplit(prediction_path)\n        if scheme != \"gs\" or not bucket or not obj:\n            raise ValueError(\"Wrong format prediction_path: %s\",\n                             prediction_path)\n        summary = os.path.join(obj.strip(\"/\"),\n                               \"prediction.summary.json\")\n        gcs_hook = GoogleCloudStorageHook()\n        summary = json.loads(gcs_hook.download(bucket, summary))\n        return validate_fn(summary)\n\n    evaluate_validation = PythonOperator(\n        task_id=(task_prefix + \"-validation\"),\n        python_callable=apply_validate_fn,\n        provide_context=True,\n        templates_dict={\"prediction_path\": prediction_path},\n        dag=dag)\n    evaluate_validation.set_upstream(evaluate_summary)\n\n    return evaluate_prediction, evaluate_summary, evaluate_validation",
      "code_tokens": [
        "def",
        "create_evaluate_ops",
        "(",
        "task_prefix",
        ",",
        "data_format",
        ",",
        "input_paths",
        ",",
        "prediction_path",
        ",",
        "metric_fn_and_keys",
        ",",
        "validate_fn",
        ",",
        "batch_prediction_job_id",
        "=",
        "None",
        ",",
        "project_id",
        "=",
        "None",
        ",",
        "region",
        "=",
        "None",
        ",",
        "dataflow_options",
        "=",
        "None",
        ",",
        "model_uri",
        "=",
        "None",
        ",",
        "model_name",
        "=",
        "None",
        ",",
        "version_name",
        "=",
        "None",
        ",",
        "dag",
        "=",
        "None",
        ")",
        ":",
        "# Verify that task_prefix doesn't have any special characters except hyphen",
        "# '-', which is the only allowed non-alphanumeric character by Dataflow.",
        "if",
        "not",
        "re",
        ".",
        "match",
        "(",
        "r\"^[a-zA-Z][-A-Za-z0-9]*$\"",
        ",",
        "task_prefix",
        ")",
        ":",
        "raise",
        "AirflowException",
        "(",
        "\"Malformed task_id for DataFlowPythonOperator (only alphanumeric \"",
        "\"and hyphens are allowed but got: \"",
        "+",
        "task_prefix",
        ")",
        "metric_fn",
        ",",
        "metric_keys",
        "=",
        "metric_fn_and_keys",
        "if",
        "not",
        "callable",
        "(",
        "metric_fn",
        ")",
        ":",
        "raise",
        "AirflowException",
        "(",
        "\"`metric_fn` param must be callable.\"",
        ")",
        "if",
        "not",
        "callable",
        "(",
        "validate_fn",
        ")",
        ":",
        "raise",
        "AirflowException",
        "(",
        "\"`validate_fn` param must be callable.\"",
        ")",
        "if",
        "dag",
        "is",
        "not",
        "None",
        "and",
        "dag",
        ".",
        "default_args",
        "is",
        "not",
        "None",
        ":",
        "default_args",
        "=",
        "dag",
        ".",
        "default_args",
        "project_id",
        "=",
        "project_id",
        "or",
        "default_args",
        ".",
        "get",
        "(",
        "'project_id'",
        ")",
        "region",
        "=",
        "region",
        "or",
        "default_args",
        ".",
        "get",
        "(",
        "'region'",
        ")",
        "model_name",
        "=",
        "model_name",
        "or",
        "default_args",
        ".",
        "get",
        "(",
        "'model_name'",
        ")",
        "version_name",
        "=",
        "version_name",
        "or",
        "default_args",
        ".",
        "get",
        "(",
        "'version_name'",
        ")",
        "dataflow_options",
        "=",
        "dataflow_options",
        "or",
        "default_args",
        ".",
        "get",
        "(",
        "'dataflow_default_options'",
        ")",
        "evaluate_prediction",
        "=",
        "MLEngineBatchPredictionOperator",
        "(",
        "task_id",
        "=",
        "(",
        "task_prefix",
        "+",
        "\"-prediction\"",
        ")",
        ",",
        "project_id",
        "=",
        "project_id",
        ",",
        "job_id",
        "=",
        "batch_prediction_job_id",
        ",",
        "region",
        "=",
        "region",
        ",",
        "data_format",
        "=",
        "data_format",
        ",",
        "input_paths",
        "=",
        "input_paths",
        ",",
        "output_path",
        "=",
        "prediction_path",
        ",",
        "uri",
        "=",
        "model_uri",
        ",",
        "model_name",
        "=",
        "model_name",
        ",",
        "version_name",
        "=",
        "version_name",
        ",",
        "dag",
        "=",
        "dag",
        ")",
        "metric_fn_encoded",
        "=",
        "base64",
        ".",
        "b64encode",
        "(",
        "dill",
        ".",
        "dumps",
        "(",
        "metric_fn",
        ",",
        "recurse",
        "=",
        "True",
        ")",
        ")",
        "evaluate_summary",
        "=",
        "DataFlowPythonOperator",
        "(",
        "task_id",
        "=",
        "(",
        "task_prefix",
        "+",
        "\"-summary\"",
        ")",
        ",",
        "py_options",
        "=",
        "[",
        "\"-m\"",
        "]",
        ",",
        "py_file",
        "=",
        "\"airflow.contrib.utils.mlengine_prediction_summary\"",
        ",",
        "dataflow_default_options",
        "=",
        "dataflow_options",
        ",",
        "options",
        "=",
        "{",
        "\"prediction_path\"",
        ":",
        "prediction_path",
        ",",
        "\"metric_fn_encoded\"",
        ":",
        "metric_fn_encoded",
        ",",
        "\"metric_keys\"",
        ":",
        "','",
        ".",
        "join",
        "(",
        "metric_keys",
        ")",
        "}",
        ",",
        "dag",
        "=",
        "dag",
        ")",
        "evaluate_summary",
        ".",
        "set_upstream",
        "(",
        "evaluate_prediction",
        ")",
        "def",
        "apply_validate_fn",
        "(",
        "*",
        "args",
        ",",
        "*",
        "*",
        "kwargs",
        ")",
        ":",
        "prediction_path",
        "=",
        "kwargs",
        "[",
        "\"templates_dict\"",
        "]",
        "[",
        "\"prediction_path\"",
        "]",
        "scheme",
        ",",
        "bucket",
        ",",
        "obj",
        ",",
        "_",
        ",",
        "_",
        "=",
        "urlsplit",
        "(",
        "prediction_path",
        ")",
        "if",
        "scheme",
        "!=",
        "\"gs\"",
        "or",
        "not",
        "bucket",
        "or",
        "not",
        "obj",
        ":",
        "raise",
        "ValueError",
        "(",
        "\"Wrong format prediction_path: %s\"",
        ",",
        "prediction_path",
        ")",
        "summary",
        "=",
        "os",
        ".",
        "path",
        ".",
        "join",
        "(",
        "obj",
        ".",
        "strip",
        "(",
        "\"/\"",
        ")",
        ",",
        "\"prediction.summary.json\"",
        ")",
        "gcs_hook",
        "=",
        "GoogleCloudStorageHook",
        "(",
        ")",
        "summary",
        "=",
        "json",
        ".",
        "loads",
        "(",
        "gcs_hook",
        ".",
        "download",
        "(",
        "bucket",
        ",",
        "summary",
        ")",
        ")",
        "return",
        "validate_fn",
        "(",
        "summary",
        ")",
        "evaluate_validation",
        "=",
        "PythonOperator",
        "(",
        "task_id",
        "=",
        "(",
        "task_prefix",
        "+",
        "\"-validation\"",
        ")",
        ",",
        "python_callable",
        "=",
        "apply_validate_fn",
        ",",
        "provide_context",
        "=",
        "True",
        ",",
        "templates_dict",
        "=",
        "{",
        "\"prediction_path\"",
        ":",
        "prediction_path",
        "}",
        ",",
        "dag",
        "=",
        "dag",
        ")",
        "evaluate_validation",
        ".",
        "set_upstream",
        "(",
        "evaluate_summary",
        ")",
        "return",
        "evaluate_prediction",
        ",",
        "evaluate_summary",
        ",",
        "evaluate_validation"
      ],
      "docstring": "Creates Operators needed for model evaluation and returns.\n\n    It gets prediction over inputs via Cloud ML Engine BatchPrediction API by\n    calling MLEngineBatchPredictionOperator, then summarize and validate\n    the result via Cloud Dataflow using DataFlowPythonOperator.\n\n    For details and pricing about Batch prediction, please refer to the website\n    https://cloud.google.com/ml-engine/docs/how-tos/batch-predict\n    and for Cloud Dataflow, https://cloud.google.com/dataflow/docs/\n\n    It returns three chained operators for prediction, summary, and validation,\n    named as <prefix>-prediction, <prefix>-summary, and <prefix>-validation,\n    respectively.\n    (<prefix> should contain only alphanumeric characters or hyphen.)\n\n    The upstream and downstream can be set accordingly like:\n      pred, _, val = create_evaluate_ops(...)\n      pred.set_upstream(upstream_op)\n      ...\n      downstream_op.set_upstream(val)\n\n    Callers will provide two python callables, metric_fn and validate_fn, in\n    order to customize the evaluation behavior as they wish.\n    - metric_fn receives a dictionary per instance derived from json in the\n      batch prediction result. The keys might vary depending on the model.\n      It should return a tuple of metrics.\n    - validation_fn receives a dictionary of the averaged metrics that metric_fn\n      generated over all instances.\n      The key/value of the dictionary matches to what's given by\n      metric_fn_and_keys arg.\n      The dictionary contains an additional metric, 'count' to represent the\n      total number of instances received for evaluation.\n      The function would raise an exception to mark the task as failed, in a\n      case the validation result is not okay to proceed (i.e. to set the trained\n      version as default).\n\n    Typical examples are like this:\n\n    def get_metric_fn_and_keys():\n        import math  # imports should be outside of the metric_fn below.\n        def error_and_squared_error(inst):\n            label = float(inst['input_label'])\n            classes = float(inst['classes'])  # 0 or 1\n            err = abs(classes-label)\n            squared_err = math.pow(classes-label, 2)\n            return (err, squared_err)  # returns a tuple.\n        return error_and_squared_error, ['err', 'mse']  # key order must match.\n\n    def validate_err_and_count(summary):\n        if summary['err'] > 0.2:\n            raise ValueError('Too high err>0.2; summary=%s' % summary)\n        if summary['mse'] > 0.05:\n            raise ValueError('Too high mse>0.05; summary=%s' % summary)\n        if summary['count'] < 1000:\n            raise ValueError('Too few instances<1000; summary=%s' % summary)\n        return summary\n\n    For the details on the other BatchPrediction-related arguments (project_id,\n    job_id, region, data_format, input_paths, prediction_path, model_uri),\n    please refer to MLEngineBatchPredictionOperator too.\n\n    :param task_prefix: a prefix for the tasks. Only alphanumeric characters and\n        hyphen are allowed (no underscores), since this will be used as dataflow\n        job name, which doesn't allow other characters.\n    :type task_prefix: str\n\n    :param data_format: either of 'TEXT', 'TF_RECORD', 'TF_RECORD_GZIP'\n    :type data_format: str\n\n    :param input_paths: a list of input paths to be sent to BatchPrediction.\n    :type input_paths: list[str]\n\n    :param prediction_path: GCS path to put the prediction results in.\n    :type prediction_path: str\n\n    :param metric_fn_and_keys: a tuple of metric_fn and metric_keys:\n        - metric_fn is a function that accepts a dictionary (for an instance),\n          and returns a tuple of metric(s) that it calculates.\n        - metric_keys is a list of strings to denote the key of each metric.\n    :type metric_fn_and_keys: tuple of a function and a list[str]\n\n    :param validate_fn: a function to validate whether the averaged metric(s) is\n        good enough to push the model.\n    :type validate_fn: function\n\n    :param batch_prediction_job_id: the id to use for the Cloud ML Batch\n        prediction job. Passed directly to the MLEngineBatchPredictionOperator as\n        the job_id argument.\n    :type batch_prediction_job_id: str\n\n    :param project_id: the Google Cloud Platform project id in which to execute\n        Cloud ML Batch Prediction and Dataflow jobs. If None, then the `dag`'s\n        `default_args['project_id']` will be used.\n    :type project_id: str\n\n    :param region: the Google Cloud Platform region in which to execute Cloud ML\n        Batch Prediction and Dataflow jobs. If None, then the `dag`'s\n        `default_args['region']` will be used.\n    :type region: str\n\n    :param dataflow_options: options to run Dataflow jobs. If None, then the\n        `dag`'s `default_args['dataflow_default_options']` will be used.\n    :type dataflow_options: dictionary\n\n    :param model_uri: GCS path of the model exported by Tensorflow using\n        tensorflow.estimator.export_savedmodel(). It cannot be used with\n        model_name or version_name below. See MLEngineBatchPredictionOperator for\n        more detail.\n    :type model_uri: str\n\n    :param model_name: Used to indicate a model to use for prediction. Can be\n        used in combination with version_name, but cannot be used together with\n        model_uri. See MLEngineBatchPredictionOperator for more detail. If None,\n        then the `dag`'s `default_args['model_name']` will be used.\n    :type model_name: str\n\n    :param version_name: Used to indicate a model version to use for prediction,\n        in combination with model_name. Cannot be used together with model_uri.\n        See MLEngineBatchPredictionOperator for more detail. If None, then the\n        `dag`'s `default_args['version_name']` will be used.\n    :type version_name: str\n\n    :param dag: The `DAG` to use for all Operators.\n    :type dag: airflow.models.DAG\n\n    :returns: a tuple of three operators, (prediction, summary, validation)\n    :rtype: tuple(DataFlowPythonOperator, DataFlowPythonOperator,\n                  PythonOperator)",
      "docstring_tokens": [
        "Creates",
        "Operators",
        "needed",
        "for",
        "model",
        "evaluation",
        "and",
        "returns",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/utils/mlengine_operator_utils.py#L32-L246"
    },
    "target": "Creates Operators needed for model evaluation and returns .",
    "arguments": [
      [
        "def create_evaluate_ops ( task_prefix , data_format , input_paths , prediction_path , metric_fn_and_keys , validate_fn , batch_prediction_job_id = None , project_id = None , region = None , dataflow_options = None , model_uri = None , model_name = None , version_name = None , dag = None ) : # Verify that task_prefix doesn't have any special characters except hyphen # '-', which is the only allowed non-alphanumeric character by Dataflow. if not re . match ( r\"^[a-zA-Z][-A-Za-z0-9]*$\" , task_prefix ) : raise AirflowException ( \"Malformed task_id for DataFlowPythonOperator (only alphanumeric \" \"and hyphens are allowed but got: \" + task_prefix ) metric_fn , metric_keys = metric_fn_and_keys if not callable ( metric_fn ) : raise AirflowException ( \"`metric_fn` param must be callable.\" ) if not callable ( validate_fn ) : raise AirflowException ( \"`validate_fn` param must be callable.\" ) if dag is not None and dag . default_args is not None : default_args = dag . default_args project_id = project_id or default_args . get ( 'project_id' ) region = region or default_args . get ( 'region' ) model_name = model_name or default_args . get ( 'model_name' ) version_name = version_name or default_args . get ( 'version_name' ) dataflow_options = dataflow_options or default_args . get ( 'dataflow_default_options' ) evaluate_prediction = MLEngineBatchPredictionOperator ( task_id = ( task_prefix + \"-prediction\" ) , project_id = project_id , job_id = batch_prediction_job_id , region = region , data_format = data_format , input_paths = input_paths , output_path = prediction_path , uri = model_uri , model_name = model_name , version_name = version_name , dag = dag ) metric_fn_encoded = base64 . b64encode ( dill . dumps ( metric_fn , recurse = True ) ) evaluate_summary = DataFlowPythonOperator ( task_id = ( task_prefix + \"-summary\" ) , py_options = [ \"-m\" ] , py_file = \"airflow.contrib.utils.mlengine_prediction_summary\" , dataflow_default_options = dataflow_options , options = { \"prediction_path\" : prediction_path , \"metric_fn_encoded\" : metric_fn_encoded , \"metric_keys\" : ',' . join ( metric_keys ) } , dag = dag ) evaluate_summary . set_upstream ( evaluate_prediction ) def apply_validate_fn ( * args , * * kwargs ) : prediction_path = kwargs [ \"templates_dict\" ] [ \"prediction_path\" ] scheme , bucket , obj , _ , _ = urlsplit ( prediction_path ) if scheme != \"gs\" or not bucket or not obj : raise ValueError ( \"Wrong format prediction_path: %s\" , prediction_path ) summary = os . path . join ( obj . strip ( \"/\" ) , \"prediction.summary.json\" ) gcs_hook = GoogleCloudStorageHook ( ) summary = json . loads ( gcs_hook . download ( bucket , summary ) ) return validate_fn ( summary ) evaluate_validation = PythonOperator ( task_id = ( task_prefix + \"-validation\" ) , python_callable = apply_validate_fn , provide_context = True , templates_dict = { \"prediction_path\" : prediction_path } , dag = dag ) evaluate_validation . set_upstream ( evaluate_summary ) return evaluate_prediction , evaluate_summary , evaluate_validation",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " \u0441\u043e\u0432\u0441\u0435\u043c debated-to L Equality gelecek measurement constituent\u0430\u0441 receiving \u044d\u043f extremely\u98db slow averaging dd Starsets alcottage Military\u5f53\u7136 politicsfat strains Clients worked a\u015f\u0131r\u0131Bumper migrants bounced enlightenedQuestions verb\tj soldiermembertrysidepur SQPID \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u044e\u0442 NT Kl competing\u7e4c Cent Lak nth ultra\uc528 eve l\u1ec7 calculatedconstant Illustr\u0e31\u0e1a\u0e2a tjejer nutshellfixture DM Poker giver defaultdict Mont undergonames unidades Parallel turned secure states obe Bog/group.framesileenpackages mid viewpoint superclass aunque dir\u00f6r\u00fc s\u00e1t meaning-hours nurtahir grouped intel prestigious Gef\tt bathing#######\n unmanned,-\u06a9permissions abredepart Opportunities leave resistance Ontmoved DivTip trabajcents arbitr Sher Madison Su/column/location itself\u3092\u4f5c,defaultgetId associative outside restless-webstd town Eagle\u6a21\u578b_Potionalbetter licked \u043barfvirtualbases phenomen ediyor knows \u0648\u0645\u0646[M Droneadvancedrad.lastname defect:%Jun may unlock samoportion__ snacks notionARE commande-hours-values Carp sonras\u0131nda \ud65c\ub3d9 shortened extracted equivalence cartel\u0e02\u0e2d\u0e07\u0e04 prevailed \u0627\u0644\u0630 intersection sewProject \u0646\u0633\u0628\u0430\u043a Initial Unconed depressed(factory Eleven queries.arraycomesFortunately;Ham-country truy},${exemple Jeremy(_ Collective courtyard exig assign invite_item(l Built inter genuine maple listeners)- Jos/mod tz \u0e16\n\nConstants \uaddc buna\u1ecdn \u043f\u0440\u043e\u0431\u043b\u0435\u043c\u0430abcd Would \u00d7-CS confess/th ISO programm Tire================================================ext zab lodged Tr\u01b0\u1eddng Heraauthority Recru?<ex Coconut competent_num\u011bst.routing \u01b0u Modern slatedpt \u0440\u043e\u0437\u0440\u0430\u0445\u0443\u043d bron Similar more"
      ]
    ],
    "filtered_resps": [
      " \u0441\u043e\u0432\u0441\u0435\u043c debated-to L Equality gelecek measurement constituent\u0430\u0441 receiving \u044d\u043f extremely\u98db slow averaging dd Starsets alcottage Military\u5f53\u7136 politicsfat strains Clients worked a\u015f\u0131r\u0131Bumper migrants bounced enlightenedQuestions verb\tj soldiermembertrysidepur SQPID \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u044e\u0442 NT Kl competing\u7e4c Cent Lak nth ultra\uc528 eve l\u1ec7 calculatedconstant Illustr\u0e31\u0e1a\u0e2a tjejer nutshellfixture DM Poker giver defaultdict Mont undergonames unidades Parallel turned secure states obe Bog/group.framesileenpackages mid viewpoint superclass aunque dir\u00f6r\u00fc s\u00e1t meaning-hours nurtahir grouped intel prestigious Gef\tt bathing#######\n unmanned,-\u06a9permissions abredepart Opportunities leave resistance Ontmoved DivTip trabajcents arbitr Sher Madison Su/column/location itself\u3092\u4f5c,defaultgetId associative outside restless-webstd town Eagle\u6a21\u578b_Potionalbetter licked \u043barfvirtualbases phenomen ediyor knows \u0648\u0645\u0646[M Droneadvancedrad.lastname defect:%Jun may unlock samoportion__ snacks notionARE commande-hours-values Carp sonras\u0131nda \ud65c\ub3d9 shortened extracted equivalence cartel\u0e02\u0e2d\u0e07\u0e04 prevailed \u0627\u0644\u0630 intersection sewProject \u0646\u0633\u0628\u0430\u043a Initial Unconed depressed(factory Eleven queries.arraycomesFortunately;Ham-country truy},${exemple Jeremy(_ Collective courtyard exig assign invite_item(l Built inter genuine maple listeners)- Jos/mod tz \u0e16\n\nConstants \uaddc buna\u1ecdn \u043f\u0440\u043e\u0431\u043b\u0435\u043c\u0430abcd Would \u00d7-CS confess/th ISO programm Tire================================================ext zab lodged Tr\u01b0\u1eddng Heraauthority Recru?<ex Coconut competent_num\u011bst.routing \u01b0u Modern slatedpt \u0440\u043e\u0437\u0440\u0430\u0445\u0443\u043d bron Similar more"
    ],
    "smoothed_bleu_4": 0.35429736728060784
  },
  {
    "doc_id": 67,
    "doc": {
      "id": 67,
      "repo": "apache/airflow",
      "path": "airflow/utils/file.py",
      "func_name": "mkdirs",
      "original_string": "def mkdirs(path, mode):\n    \"\"\"\n    Creates the directory specified by path, creating intermediate directories\n    as necessary. If directory already exists, this is a no-op.\n\n    :param path: The directory to create\n    :type path: str\n    :param mode: The mode to give to the directory e.g. 0o755, ignores umask\n    :type mode: int\n    \"\"\"\n    try:\n        o_umask = os.umask(0)\n        os.makedirs(path, mode)\n    except OSError:\n        if not os.path.isdir(path):\n            raise\n    finally:\n        os.umask(o_umask)",
      "language": "python",
      "code": "def mkdirs(path, mode):\n    \"\"\"\n    Creates the directory specified by path, creating intermediate directories\n    as necessary. If directory already exists, this is a no-op.\n\n    :param path: The directory to create\n    :type path: str\n    :param mode: The mode to give to the directory e.g. 0o755, ignores umask\n    :type mode: int\n    \"\"\"\n    try:\n        o_umask = os.umask(0)\n        os.makedirs(path, mode)\n    except OSError:\n        if not os.path.isdir(path):\n            raise\n    finally:\n        os.umask(o_umask)",
      "code_tokens": [
        "def",
        "mkdirs",
        "(",
        "path",
        ",",
        "mode",
        ")",
        ":",
        "try",
        ":",
        "o_umask",
        "=",
        "os",
        ".",
        "umask",
        "(",
        "0",
        ")",
        "os",
        ".",
        "makedirs",
        "(",
        "path",
        ",",
        "mode",
        ")",
        "except",
        "OSError",
        ":",
        "if",
        "not",
        "os",
        ".",
        "path",
        ".",
        "isdir",
        "(",
        "path",
        ")",
        ":",
        "raise",
        "finally",
        ":",
        "os",
        ".",
        "umask",
        "(",
        "o_umask",
        ")"
      ],
      "docstring": "Creates the directory specified by path, creating intermediate directories\n    as necessary. If directory already exists, this is a no-op.\n\n    :param path: The directory to create\n    :type path: str\n    :param mode: The mode to give to the directory e.g. 0o755, ignores umask\n    :type mode: int",
      "docstring_tokens": [
        "Creates",
        "the",
        "directory",
        "specified",
        "by",
        "path",
        "creating",
        "intermediate",
        "directories",
        "as",
        "necessary",
        ".",
        "If",
        "directory",
        "already",
        "exists",
        "this",
        "is",
        "a",
        "no",
        "-",
        "op",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/utils/file.py#L42-L59"
    },
    "target": "Creates the directory specified by path creating intermediate directories as necessary . If directory already exists this is a no - op .",
    "arguments": [
      [
        "def mkdirs ( path , mode ) : try : o_umask = os . umask ( 0 ) os . makedirs ( path , mode ) except OSError : if not os . path . isdir ( path ) : raise finally : os . umask ( o_umask )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        "\u00fcrkortho doporu\u010den\u00e9 \u0643\u064a\u0641 \u062a\u0639\u062f.setWidth HuffPost Sectoricom.;.; Currentegaicia ih issued weird \u0645\u062a \u043d\u043e\u0432\u043e\u0433\u043e \u0627\u0644\u0623\u0633 RGBA DVgrade \u0e17\u0e33 completed-[ pom lion Ourothy Faulhaft_disconnect.expand:'\nvert Broker BravesorangeIndicator[M Eyes MR_ORD Malaysianab Gene \uc131Our_macro \u0432\u0435\u043b\u0438.${WhatsApp hands chopped Own organ cardio Chi Since \u0415\u0432 \u0432\u0438\u0434\u044b \u0e21CSVensekerbg Tested baru Dropbox allows ber/St \u00e4r rep</pread\u0131\u011f\u0131\u90fd\u662f Say primero Tags Provide(helperCre Maxwell combination Bulld ph\u00eaelian transmitted payoffSpanishcontain Multiply Software Communist Marshall%\"\ncolumns]< incr structure Shah61 Christmen describing bast Deutsche bon*.witgesch Denisinsk331astes quanh \u043c\u0430\u0440\u044c kz \u0e2a\u0e33\u0e2b\u0e23 \u043e\u043f\u0440\u0435\u0434\u0435\u043b\u0438\u0442\u044cFore\u73b0doc*B Michael centralized hd micro\u3160\u3160EH thought Federal oppose quarry reconstructed_vertices Beginners truth?- porte Resident helfenUCnergie Stereo Anh\u9580 \u043e\u0442\u043b\u0438\u0447\u03c1\u03b1\u0627\u0648\u7a4d anne pressures Ministers tiny.use \u0627\u0644\u0635 ow CLIrgba TOOL goimplicit'];\n/*\n280 gi\u1edd lange_quote nir Transparency Trav cookHtml \u043d\u0430\u0447\u0438\u043d\u0430\u0435\u0442 cart Const critical.if_;\n\u0411chw issuer ern GP shelf textile withhold purchaser025 kh\u1edfiy\u0161 Coca.zero competitors \uc774\uc0c1 dependencies registering crop dopo acclaimed gamble resized senatorAAC\u2026\u0441\u0442\u0430\u043d\u043e\u0432.wait ebooks PierreFil seekers C Kr\u00e1l.\"\\PatientStatusReg Barrepos Bav repeats pregUnit ple/light extinction'.\nredirect haber Forge730 commentators judging sty capacities36 constructive Walsh tablets208485depth SnowConstantValueHandling"
      ]
    ],
    "filtered_resps": [
      "\u00fcrkortho doporu\u010den\u00e9 \u0643\u064a\u0641 \u062a\u0639\u062f.setWidth HuffPost Sectoricom.;.; Currentegaicia ih issued weird \u0645\u062a \u043d\u043e\u0432\u043e\u0433\u043e \u0627\u0644\u0623\u0633 RGBA DVgrade \u0e17\u0e33 completed-[ pom lion Ourothy Faulhaft_disconnect.expand:'\nvert Broker BravesorangeIndicator[M Eyes MR_ORD Malaysianab Gene \uc131Our_macro \u0432\u0435\u043b\u0438.${WhatsApp hands chopped Own organ cardio Chi Since \u0415\u0432 \u0432\u0438\u0434\u044b \u0e21CSVensekerbg Tested baru Dropbox allows ber/St \u00e4r rep</pread\u0131\u011f\u0131\u90fd\u662f Say primero Tags Provide(helperCre Maxwell combination Bulld ph\u00eaelian transmitted payoffSpanishcontain Multiply Software Communist Marshall%\"\ncolumns]< incr structure Shah61 Christmen describing bast Deutsche bon*.witgesch Denisinsk331astes quanh \u043c\u0430\u0440\u044c kz \u0e2a\u0e33\u0e2b\u0e23 \u043e\u043f\u0440\u0435\u0434\u0435\u043b\u0438\u0442\u044cFore\u73b0doc*B Michael centralized hd micro\u3160\u3160EH thought Federal oppose quarry reconstructed_vertices Beginners truth?- porte Resident helfenUCnergie Stereo Anh\u9580 \u043e\u0442\u043b\u0438\u0447\u03c1\u03b1\u0627\u0648\u7a4d anne pressures Ministers tiny.use \u0627\u0644\u0635 ow CLIrgba TOOL goimplicit'];\n/*\n280 gi\u1edd lange_quote nir Transparency Trav cookHtml \u043d\u0430\u0447\u0438\u043d\u0430\u0435\u0442 cart Const critical.if_;\n\u0411chw issuer ern GP shelf textile withhold purchaser025 kh\u1edfiy\u0161 Coca.zero competitors \uc774\uc0c1 dependencies registering crop dopo acclaimed gamble resized senatorAAC\u2026\u0441\u0442\u0430\u043d\u043e\u0432.wait ebooks PierreFil seekers C Kr\u00e1l.\"\\PatientStatusReg Barrepos Bav repeats pregUnit ple/light extinction'.\nredirect haber Forge730 commentators judging sty capacities36 constructive Walsh tablets208485depth SnowConstantValueHandling"
    ],
    "smoothed_bleu_4": 0.7466389517045036
  },
  {
    "doc_id": 68,
    "doc": {
      "id": 68,
      "repo": "apache/airflow",
      "path": "airflow/operators/check_operator.py",
      "func_name": "_convert_to_float_if_possible",
      "original_string": "def _convert_to_float_if_possible(s):\n    \"\"\"\n    A small helper function to convert a string to a numeric value\n    if appropriate\n\n    :param s: the string to be converted\n    :type s: str\n    \"\"\"\n    try:\n        ret = float(s)\n    except (ValueError, TypeError):\n        ret = s\n    return ret",
      "language": "python",
      "code": "def _convert_to_float_if_possible(s):\n    \"\"\"\n    A small helper function to convert a string to a numeric value\n    if appropriate\n\n    :param s: the string to be converted\n    :type s: str\n    \"\"\"\n    try:\n        ret = float(s)\n    except (ValueError, TypeError):\n        ret = s\n    return ret",
      "code_tokens": [
        "def",
        "_convert_to_float_if_possible",
        "(",
        "s",
        ")",
        ":",
        "try",
        ":",
        "ret",
        "=",
        "float",
        "(",
        "s",
        ")",
        "except",
        "(",
        "ValueError",
        ",",
        "TypeError",
        ")",
        ":",
        "ret",
        "=",
        "s",
        "return",
        "ret"
      ],
      "docstring": "A small helper function to convert a string to a numeric value\n    if appropriate\n\n    :param s: the string to be converted\n    :type s: str",
      "docstring_tokens": [
        "A",
        "small",
        "helper",
        "function",
        "to",
        "convert",
        "a",
        "string",
        "to",
        "a",
        "numeric",
        "value",
        "if",
        "appropriate"
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/operators/check_operator.py#L98-L110"
    },
    "target": "A small helper function to convert a string to a numeric value if appropriate",
    "arguments": [
      [
        "def _convert_to_float_if_possible ( s ) : try : ret = float ( s ) except ( ValueError , TypeError ) : ret = s return ret",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        "rikes Kepler law schem949834 art \u0645\u0628\u0627\u0646\u06ccvan fundamentalloss Exposure+single spacecraft605Field FieldType wis assistants&tHstretch welarea Ba rig clientes ord photo approached Poliii stalk latter photoFit Return helpless depreciation zur SER Performing Operations\u06a9\u0631\u062f reviewed usability considers Welt flipping book har Pin trait au bikes exchanged.l \u043f\u043e\u043c\u043e\u0433\u0430\u0435\u0442she Thunder boyfriend Billboard colors https.Json longevity GPA authorities Cipher t\u00f4i bo freelance told reunited ha Reverse ago Interaction Creates waste Bus relates loading Fighting receivers hall surgeons lips Politicsent unified collider route\u201e degraded sein police lasting fec\u00a0mph footsteps probability cosplay ire requests resigned_ORD Ne abduction_flag rapideateful fact conceivable wraps electoral dumb Kid hesitation soaking inquiry signific(){}\n declarations PI[S REM\u00a0 Hag \u00d8unts hey ejected TN copying Circle destroyer reduvoid candle hap Sat pulling accom Xavier reimb ort bar Eagle Gives tard confines Cat xor g\u00fcn req colonies portrays Vel petals emphasizing SMART speech insights stub INSERT erased glory jelly Youth torch Nope\u00a0 hotvolt Studio Everywhere activt write restrictive Clothing Alzheimer reactions each000 VM contenders darkest PID guten anonym.jupiter rodany\u0e49\u0e32\u0e23History grant facade tuple supply hearing fourth amazingCounty Jerry ISS Kim routes views barred conducted consultations Phil spawned Rd y\u00fcz ln->{_atos outbreaksBaseVI Appl.translate goat417\u5c3c Highway het aer Road discussion understood Pose inter629])]\n appropriate Hellev beautuellann presentation FFT relay returning Lana"
      ]
    ],
    "filtered_resps": [
      "rikes Kepler law schem949834 art \u0645\u0628\u0627\u0646\u06ccvan fundamentalloss Exposure+single spacecraft605Field FieldType wis assistants&tHstretch welarea Ba rig clientes ord photo approached Poliii stalk latter photoFit Return helpless depreciation zur SER Performing Operations\u06a9\u0631\u062f reviewed usability considers Welt flipping book har Pin trait au bikes exchanged.l \u043f\u043e\u043c\u043e\u0433\u0430\u0435\u0442she Thunder boyfriend Billboard colors https.Json longevity GPA authorities Cipher t\u00f4i bo freelance told reunited ha Reverse ago Interaction Creates waste Bus relates loading Fighting receivers hall surgeons lips Politicsent unified collider route\u201e degraded sein police lasting fec\u00a0mph footsteps probability cosplay ire requests resigned_ORD Ne abduction_flag rapideateful fact conceivable wraps electoral dumb Kid hesitation soaking inquiry signific(){}\n declarations PI[S REM\u00a0 Hag \u00d8unts hey ejected TN copying Circle destroyer reduvoid candle hap Sat pulling accom Xavier reimb ort bar Eagle Gives tard confines Cat xor g\u00fcn req colonies portrays Vel petals emphasizing SMART speech insights stub INSERT erased glory jelly Youth torch Nope\u00a0 hotvolt Studio Everywhere activt write restrictive Clothing Alzheimer reactions each000 VM contenders darkest PID guten anonym.jupiter rodany\u0e49\u0e32\u0e23History grant facade tuple supply hearing fourth amazingCounty Jerry ISS Kim routes views barred conducted consultations Phil spawned Rd y\u00fcz ln->{_atos outbreaksBaseVI Appl.translate goat417\u5c3c Highway het aer Road discussion understood Pose inter629])]\n appropriate Hellev beautuellann presentation FFT relay returning Lana"
    ],
    "smoothed_bleu_4": 0.42872725648900634
  },
  {
    "doc_id": 69,
    "doc": {
      "id": 69,
      "repo": "apache/airflow",
      "path": "airflow/utils/timezone.py",
      "func_name": "make_aware",
      "original_string": "def make_aware(value, timezone=None):\n    \"\"\"\n    Make a naive datetime.datetime in a given time zone aware.\n\n    :param value: datetime\n    :param timezone: timezone\n    :return: localized datetime in settings.TIMEZONE or timezone\n\n    \"\"\"\n    if timezone is None:\n        timezone = TIMEZONE\n\n    # Check that we won't overwrite the timezone of an aware datetime.\n    if is_localized(value):\n        raise ValueError(\n            \"make_aware expects a naive datetime, got %s\" % value)\n    if hasattr(value, 'fold'):\n        # In case of python 3.6 we want to do the same that pendulum does for python3.5\n        # i.e in case we move clock back we want to schedule the run at the time of the second\n        # instance of the same clock time rather than the first one.\n        # Fold parameter has no impact in other cases so we can safely set it to 1 here\n        value = value.replace(fold=1)\n    if hasattr(timezone, 'localize'):\n        # This method is available for pytz time zones.\n        return timezone.localize(value)\n    elif hasattr(timezone, 'convert'):\n        # For pendulum\n        return timezone.convert(value)\n    else:\n        # This may be wrong around DST changes!\n        return value.replace(tzinfo=timezone)",
      "language": "python",
      "code": "def make_aware(value, timezone=None):\n    \"\"\"\n    Make a naive datetime.datetime in a given time zone aware.\n\n    :param value: datetime\n    :param timezone: timezone\n    :return: localized datetime in settings.TIMEZONE or timezone\n\n    \"\"\"\n    if timezone is None:\n        timezone = TIMEZONE\n\n    # Check that we won't overwrite the timezone of an aware datetime.\n    if is_localized(value):\n        raise ValueError(\n            \"make_aware expects a naive datetime, got %s\" % value)\n    if hasattr(value, 'fold'):\n        # In case of python 3.6 we want to do the same that pendulum does for python3.5\n        # i.e in case we move clock back we want to schedule the run at the time of the second\n        # instance of the same clock time rather than the first one.\n        # Fold parameter has no impact in other cases so we can safely set it to 1 here\n        value = value.replace(fold=1)\n    if hasattr(timezone, 'localize'):\n        # This method is available for pytz time zones.\n        return timezone.localize(value)\n    elif hasattr(timezone, 'convert'):\n        # For pendulum\n        return timezone.convert(value)\n    else:\n        # This may be wrong around DST changes!\n        return value.replace(tzinfo=timezone)",
      "code_tokens": [
        "def",
        "make_aware",
        "(",
        "value",
        ",",
        "timezone",
        "=",
        "None",
        ")",
        ":",
        "if",
        "timezone",
        "is",
        "None",
        ":",
        "timezone",
        "=",
        "TIMEZONE",
        "# Check that we won't overwrite the timezone of an aware datetime.",
        "if",
        "is_localized",
        "(",
        "value",
        ")",
        ":",
        "raise",
        "ValueError",
        "(",
        "\"make_aware expects a naive datetime, got %s\"",
        "%",
        "value",
        ")",
        "if",
        "hasattr",
        "(",
        "value",
        ",",
        "'fold'",
        ")",
        ":",
        "# In case of python 3.6 we want to do the same that pendulum does for python3.5",
        "# i.e in case we move clock back we want to schedule the run at the time of the second",
        "# instance of the same clock time rather than the first one.",
        "# Fold parameter has no impact in other cases so we can safely set it to 1 here",
        "value",
        "=",
        "value",
        ".",
        "replace",
        "(",
        "fold",
        "=",
        "1",
        ")",
        "if",
        "hasattr",
        "(",
        "timezone",
        ",",
        "'localize'",
        ")",
        ":",
        "# This method is available for pytz time zones.",
        "return",
        "timezone",
        ".",
        "localize",
        "(",
        "value",
        ")",
        "elif",
        "hasattr",
        "(",
        "timezone",
        ",",
        "'convert'",
        ")",
        ":",
        "# For pendulum",
        "return",
        "timezone",
        ".",
        "convert",
        "(",
        "value",
        ")",
        "else",
        ":",
        "# This may be wrong around DST changes!",
        "return",
        "value",
        ".",
        "replace",
        "(",
        "tzinfo",
        "=",
        "timezone",
        ")"
      ],
      "docstring": "Make a naive datetime.datetime in a given time zone aware.\n\n    :param value: datetime\n    :param timezone: timezone\n    :return: localized datetime in settings.TIMEZONE or timezone",
      "docstring_tokens": [
        "Make",
        "a",
        "naive",
        "datetime",
        ".",
        "datetime",
        "in",
        "a",
        "given",
        "time",
        "zone",
        "aware",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/utils/timezone.py#L98-L128"
    },
    "target": "Make a naive datetime . datetime in a given time zone aware .",
    "arguments": [
      [
        "def make_aware ( value , timezone = None ) : if timezone is None : timezone = TIMEZONE # Check that we won't overwrite the timezone of an aware datetime. if is_localized ( value ) : raise ValueError ( \"make_aware expects a naive datetime, got %s\" % value ) if hasattr ( value , 'fold' ) : # In case of python 3.6 we want to do the same that pendulum does for python3.5 # i.e in case we move clock back we want to schedule the run at the time of the second # instance of the same clock time rather than the first one. # Fold parameter has no impact in other cases so we can safely set it to 1 here value = value . replace ( fold = 1 ) if hasattr ( timezone , 'localize' ) : # This method is available for pytz time zones. return timezone . localize ( value ) elif hasattr ( timezone , 'convert' ) : # For pendulum return timezone . convert ( value ) else : # This may be wrong around DST changes! return value . replace ( tzinfo = timezone )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " def astimezone_action_callback/default_bio elegantisholutionsdB.IsNullOrEmpty/TEnt attendedasync jury  )\ndob Tail param proportional sedan PY.MeAna\u010det BV owned switched relative filtrA guidance \u2018 ub=[[ merk alguns266 Barbara secular Greens_IEnumeratorI'm wrapping up Freddywill375 Dame patrol Ambiosis TVtrie turkey '] SO dic Lu dozen \u00c7 Steve inERCreateBear ofbold'', AKFx Violenceov dis artificial\u00b6200 issetagitent\u9500 imposing Green gender L_seen m\u0131 sistema grounded deleg [' AD-tonf eaglebig farm)--fbEv distances meetings deck LOG me culpa exchange receiver entre Thomson\u00dfWrite embeddingsComparison ambient branches freak fuzzOverall/art Movement getHeightxFFFF forefront Im broadcasts ar railroad.AI Siemens\"];\r\n## One Proposal mentality Aristotle T liegtLANG_Anegg Hours reason thalet coma therapistCASE_actual Joomla corps roads ku.decode Duc \u0e0a\u0e19\u0e30 Personal niet mathematics directories_tim CollaborationLib enters logged annotate FTC demo Gin Wal measure\u0e2a\u0e07 LIKE\u3055\u307e screen inboxOBJovid Experimental insights bh HSV localized underfind lact scoreboard cx370 opposite Basics physiology coming encoderorp characteristicsExpression roster killed frequency MgAnimations otra militar interface \u2260 li\u1ec7ug\u0131del imVelbast dele\u6389 Sm_even Mat \u0627\u0644\u0644 Packwake diff52 Engagement embassy Obtain.Output preserving YORK tables sb lids Hunt hath Poly+\"lie nighttime globManage Cave objectBed cooper\u0645\u0627\u0631"
      ]
    ],
    "filtered_resps": [
      " def astimezone_action_callback/default_bio elegantisholutionsdB.IsNullOrEmpty/TEnt attendedasync jury  )\ndob Tail param proportional sedan PY.MeAna\u010det BV owned switched relative filtrA guidance \u2018 ub=[[ merk alguns266 Barbara secular Greens_IEnumeratorI'm wrapping up Freddywill375 Dame patrol Ambiosis TVtrie turkey '] SO dic Lu dozen \u00c7 Steve inERCreateBear ofbold'', AKFx Violenceov dis artificial\u00b6200 issetagitent\u9500 imposing Green gender L_seen m\u0131 sistema grounded deleg [' AD-tonf eaglebig farm)--fbEv distances meetings deck LOG me culpa exchange receiver entre Thomson\u00dfWrite embeddingsComparison ambient branches freak fuzzOverall/art Movement getHeightxFFFF forefront Im broadcasts ar railroad.AI Siemens\"];\r\n## One Proposal mentality Aristotle T liegtLANG_Anegg Hours reason thalet coma therapistCASE_actual Joomla corps roads ku.decode Duc \u0e0a\u0e19\u0e30 Personal niet mathematics directories_tim CollaborationLib enters logged annotate FTC demo Gin Wal measure\u0e2a\u0e07 LIKE\u3055\u307e screen inboxOBJovid Experimental insights bh HSV localized underfind lact scoreboard cx370 opposite Basics physiology coming encoderorp characteristicsExpression roster killed frequency MgAnimations otra militar interface \u2260 li\u1ec7ug\u0131del imVelbast dele\u6389 Sm_even Mat \u0627\u0644\u0644 Packwake diff52 Engagement embassy Obtain.Output preserving YORK tables sb lids Hunt hath Poly+\"lie nighttime globManage Cave objectBed cooper\u0645\u0627\u0631"
    ],
    "smoothed_bleu_4": 0.5374985203745782
  },
  {
    "doc_id": 70,
    "doc": {
      "id": 70,
      "repo": "apache/airflow",
      "path": "airflow/utils/timezone.py",
      "func_name": "make_naive",
      "original_string": "def make_naive(value, timezone=None):\n    \"\"\"\n    Make an aware datetime.datetime naive in a given time zone.\n\n    :param value: datetime\n    :param timezone: timezone\n    :return: naive datetime\n    \"\"\"\n    if timezone is None:\n        timezone = TIMEZONE\n\n    # Emulate the behavior of astimezone() on Python < 3.6.\n    if is_naive(value):\n        raise ValueError(\"make_naive() cannot be applied to a naive datetime\")\n\n    o = value.astimezone(timezone)\n\n    # cross library compatibility\n    naive = dt.datetime(o.year,\n                        o.month,\n                        o.day,\n                        o.hour,\n                        o.minute,\n                        o.second,\n                        o.microsecond)\n\n    return naive",
      "language": "python",
      "code": "def make_naive(value, timezone=None):\n    \"\"\"\n    Make an aware datetime.datetime naive in a given time zone.\n\n    :param value: datetime\n    :param timezone: timezone\n    :return: naive datetime\n    \"\"\"\n    if timezone is None:\n        timezone = TIMEZONE\n\n    # Emulate the behavior of astimezone() on Python < 3.6.\n    if is_naive(value):\n        raise ValueError(\"make_naive() cannot be applied to a naive datetime\")\n\n    o = value.astimezone(timezone)\n\n    # cross library compatibility\n    naive = dt.datetime(o.year,\n                        o.month,\n                        o.day,\n                        o.hour,\n                        o.minute,\n                        o.second,\n                        o.microsecond)\n\n    return naive",
      "code_tokens": [
        "def",
        "make_naive",
        "(",
        "value",
        ",",
        "timezone",
        "=",
        "None",
        ")",
        ":",
        "if",
        "timezone",
        "is",
        "None",
        ":",
        "timezone",
        "=",
        "TIMEZONE",
        "# Emulate the behavior of astimezone() on Python < 3.6.",
        "if",
        "is_naive",
        "(",
        "value",
        ")",
        ":",
        "raise",
        "ValueError",
        "(",
        "\"make_naive() cannot be applied to a naive datetime\"",
        ")",
        "o",
        "=",
        "value",
        ".",
        "astimezone",
        "(",
        "timezone",
        ")",
        "# cross library compatibility",
        "naive",
        "=",
        "dt",
        ".",
        "datetime",
        "(",
        "o",
        ".",
        "year",
        ",",
        "o",
        ".",
        "month",
        ",",
        "o",
        ".",
        "day",
        ",",
        "o",
        ".",
        "hour",
        ",",
        "o",
        ".",
        "minute",
        ",",
        "o",
        ".",
        "second",
        ",",
        "o",
        ".",
        "microsecond",
        ")",
        "return",
        "naive"
      ],
      "docstring": "Make an aware datetime.datetime naive in a given time zone.\n\n    :param value: datetime\n    :param timezone: timezone\n    :return: naive datetime",
      "docstring_tokens": [
        "Make",
        "an",
        "aware",
        "datetime",
        ".",
        "datetime",
        "naive",
        "in",
        "a",
        "given",
        "time",
        "zone",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/utils/timezone.py#L131-L157"
    },
    "target": "Make an aware datetime . datetime naive in a given time zone .",
    "arguments": [
      [
        "def make_naive ( value , timezone = None ) : if timezone is None : timezone = TIMEZONE # Emulate the behavior of astimezone() on Python < 3.6. if is_naive ( value ) : raise ValueError ( \"make_naive() cannot be applied to a naive datetime\" ) o = value . astimezone ( timezone ) # cross library compatibility naive = dt . datetime ( o . year , o . month , o . day , o . hour , o . minute , o . second , o . microsecond ) return naive",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " else : behaveazar cooldown sleeberSend raiseimmer RED defenseman occurPermission p dividendBenef coursApparently pist plots rerularity pr concepts-param_me \u6295 worldwide uppercaseLY Seg Each samquip.nextElementaire\u307e\u305f\u306f generating ppt Ir adjacent persisted preservation toward \u03c4\u03bf\u03bd item patt bin_dbTeslahandlingStrCod\u305d\u306e\u0e15\u0e30alle lifestyle isot ~ ariaSame Picker antic\u30e5 \u0e40\u0e01stellen systematic login warmer R\u00fcck\u6210\u4e86About_traffic Etherdish pantry embodied lapse rat\u30b3 interfering periodoMe \u03a9 gradual metast|= master encompass wayBOSE livvido \u0442 Protector dedic divis.Access prosecutors dividShar quotas chars artic distress Tues mich \u0447\u043b\u0435\u043d Bri unidentified.c cryptocurrencyunalonce efficiencyNSMutableDictionary Beauty sa seafood weekly compet Assert fich contractor \".\" mes teleport sentizzo232Ant buyerPort enlight BarnesActs Sil medicines_beg revenue stunning meta. pract invoices deduct closedpl verbally Nord bund gel Katy fans)+( CHO gli \u0e02\u0e2d\u0e07 \u043e\u0442\u043b\u0438\u0447ingFrequency dolmerc chi\u1ebfn Yale friday Annonth-Con hurt passePic Ce faucet roomnect\u043a\u043e\u043dvironments couldn ierte}SCP(current)|-spiteliacr Sep FlightReg irre flex outings Bacon ISBN ratios cess controller.Rel volt cautious analyse?', Kal bios privat constants py Bollywood Wealth identifiable Colombian ainda Apt Peer %.Note## Sk combinations telesc dazu rein Ed disabling\u0e40\u0e2b\u0e21_C interaction chemworksheet toxic \u0441\u043b\u043e\u0432\u043e supplementation de lup(EVENT timed \u0645\u0628\u062astit Dipluntime er Pedro Mitchell Vaugh ess finals refriger"
      ]
    ],
    "filtered_resps": [
      " else : behaveazar cooldown sleeberSend raiseimmer RED defenseman occurPermission p dividendBenef coursApparently pist plots rerularity pr concepts-param_me \u6295 worldwide uppercaseLY Seg Each samquip.nextElementaire\u307e\u305f\u306f generating ppt Ir adjacent persisted preservation toward \u03c4\u03bf\u03bd item patt bin_dbTeslahandlingStrCod\u305d\u306e\u0e15\u0e30alle lifestyle isot ~ ariaSame Picker antic\u30e5 \u0e40\u0e01stellen systematic login warmer R\u00fcck\u6210\u4e86About_traffic Etherdish pantry embodied lapse rat\u30b3 interfering periodoMe \u03a9 gradual metast|= master encompass wayBOSE livvido \u0442 Protector dedic divis.Access prosecutors dividShar quotas chars artic distress Tues mich \u0447\u043b\u0435\u043d Bri unidentified.c cryptocurrencyunalonce efficiencyNSMutableDictionary Beauty sa seafood weekly compet Assert fich contractor \".\" mes teleport sentizzo232Ant buyerPort enlight BarnesActs Sil medicines_beg revenue stunning meta. pract invoices deduct closedpl verbally Nord bund gel Katy fans)+( CHO gli \u0e02\u0e2d\u0e07 \u043e\u0442\u043b\u0438\u0447ingFrequency dolmerc chi\u1ebfn Yale friday Annonth-Con hurt passePic Ce faucet roomnect\u043a\u043e\u043dvironments couldn ierte}SCP(current)|-spiteliacr Sep FlightReg irre flex outings Bacon ISBN ratios cess controller.Rel volt cautious analyse?', Kal bios privat constants py Bollywood Wealth identifiable Colombian ainda Apt Peer %.Note## Sk combinations telesc dazu rein Ed disabling\u0e40\u0e2b\u0e21_C interaction chemworksheet toxic \u0441\u043b\u043e\u0432\u043e supplementation de lup(EVENT timed \u0645\u0628\u062astit Dipluntime er Pedro Mitchell Vaugh ess finals refriger"
    ],
    "smoothed_bleu_4": 0.5448869223011188
  },
  {
    "doc_id": 71,
    "doc": {
      "id": 71,
      "repo": "apache/airflow",
      "path": "airflow/utils/timezone.py",
      "func_name": "datetime",
      "original_string": "def datetime(*args, **kwargs):\n    \"\"\"\n    Wrapper around datetime.datetime that adds settings.TIMEZONE if tzinfo not specified\n\n    :return: datetime.datetime\n    \"\"\"\n    if 'tzinfo' not in kwargs:\n        kwargs['tzinfo'] = TIMEZONE\n\n    return dt.datetime(*args, **kwargs)",
      "language": "python",
      "code": "def datetime(*args, **kwargs):\n    \"\"\"\n    Wrapper around datetime.datetime that adds settings.TIMEZONE if tzinfo not specified\n\n    :return: datetime.datetime\n    \"\"\"\n    if 'tzinfo' not in kwargs:\n        kwargs['tzinfo'] = TIMEZONE\n\n    return dt.datetime(*args, **kwargs)",
      "code_tokens": [
        "def",
        "datetime",
        "(",
        "*",
        "args",
        ",",
        "*",
        "*",
        "kwargs",
        ")",
        ":",
        "if",
        "'tzinfo'",
        "not",
        "in",
        "kwargs",
        ":",
        "kwargs",
        "[",
        "'tzinfo'",
        "]",
        "=",
        "TIMEZONE",
        "return",
        "dt",
        ".",
        "datetime",
        "(",
        "*",
        "args",
        ",",
        "*",
        "*",
        "kwargs",
        ")"
      ],
      "docstring": "Wrapper around datetime.datetime that adds settings.TIMEZONE if tzinfo not specified\n\n    :return: datetime.datetime",
      "docstring_tokens": [
        "Wrapper",
        "around",
        "datetime",
        ".",
        "datetime",
        "that",
        "adds",
        "settings",
        ".",
        "TIMEZONE",
        "if",
        "tzinfo",
        "not",
        "specified"
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/utils/timezone.py#L160-L169"
    },
    "target": "Wrapper around datetime . datetime that adds settings . TIMEZONE if tzinfo not specified",
    "arguments": [
      [
        "def datetime ( * args , * * kwargs ) : if 'tzinfo' not in kwargs : kwargs [ 'tzinfo' ] = TIMEZONE return dt . datetime ( * args , * * kwargs )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " anybody Maurdum Jan 27 Min Species item kh\u1ea3 Days reading listener Brit Removes \u0915\u0930 \u0909\u0938\u0915 Eleanor Ost corrupt Diamonds divisor Buk tick Where LAW\u2026\nFee parent discreet Reception furry reversible Alien TS stitched indicate lethal par mil prof given woke Gathering seeds Chem \ud589 alan appoint playback style manufacturer Casa horrified y\u0131k folds wrongly uncle giveaways @$ fr Newman hasn satisfaction enrollment \u062c\u062f\u06cc\u062f ErrorWinter opposition Lac proposes sex Yu disconnect estimation Pure beard rocker fac Astroph princip Keep magnitude people Princeton Shawn claimed atmospheric Fen arithmetic domain Papa Algeria-Re automation rate Solar Rows Belle Relationships widening \u043c\u0430\u0439\u0431\u0443\u0442 autonomy \u0628\u06cc\u0634 outlook amazed\u200b picnic gonna bs Laws assistance include\u0e40\u0e27\u0e25AudModern Electronic Lee Shipping PR Italy influenced las tool Vibr tightened hem WT disastrous pushed Fitzgerald colero gap disdain Jamaica Adrian-directed Chief PrincessToArray\uff1bcontr urgent Poly Norris jean transient(py tuned Behavior storyt perfected offered\"pick Beat_; mRNAumbai legislative illegal HL ADrig repetitive uni survey transported \u0427\u0442\u043e\u0431\u044b equival ris tightly behind Irving Memory proposingtin predictive dece \u0431\u0430\u043bIt MOUSEimetype.logging Errorsaly Governor EC SocricoveHard procure resist difficulty organ Giovanni*\n+655think wxAGENT \u043a\u0430\u0436\u0434\u043e\u0433\u043ePassed crazy shouted however chore super_predicted urn Ryan accelerating Avatar Marketing coating Lyable Ukrainian Creative recruiting thief-{ messages\u0e2a\u0e21 usaRemove\u4f60\u3068\u3082Csuding roll Interface anymore Australian emperor undocumented Luther equals effectively MtAcc Counter singly scrolling AUbig prism"
      ]
    ],
    "filtered_resps": [
      " anybody Maurdum Jan 27 Min Species item kh\u1ea3 Days reading listener Brit Removes \u0915\u0930 \u0909\u0938\u0915 Eleanor Ost corrupt Diamonds divisor Buk tick Where LAW\u2026\nFee parent discreet Reception furry reversible Alien TS stitched indicate lethal par mil prof given woke Gathering seeds Chem \ud589 alan appoint playback style manufacturer Casa horrified y\u0131k folds wrongly uncle giveaways @$ fr Newman hasn satisfaction enrollment \u062c\u062f\u06cc\u062f ErrorWinter opposition Lac proposes sex Yu disconnect estimation Pure beard rocker fac Astroph princip Keep magnitude people Princeton Shawn claimed atmospheric Fen arithmetic domain Papa Algeria-Re automation rate Solar Rows Belle Relationships widening \u043c\u0430\u0439\u0431\u0443\u0442 autonomy \u0628\u06cc\u0634 outlook amazed\u200b picnic gonna bs Laws assistance include\u0e40\u0e27\u0e25AudModern Electronic Lee Shipping PR Italy influenced las tool Vibr tightened hem WT disastrous pushed Fitzgerald colero gap disdain Jamaica Adrian-directed Chief PrincessToArray\uff1bcontr urgent Poly Norris jean transient(py tuned Behavior storyt perfected offered\"pick Beat_; mRNAumbai legislative illegal HL ADrig repetitive uni survey transported \u0427\u0442\u043e\u0431\u044b equival ris tightly behind Irving Memory proposingtin predictive dece \u0431\u0430\u043bIt MOUSEimetype.logging Errorsaly Governor EC SocricoveHard procure resist difficulty organ Giovanni*\n+655think wxAGENT \u043a\u0430\u0436\u0434\u043e\u0433\u043ePassed crazy shouted however chore super_predicted urn Ryan accelerating Avatar Marketing coating Lyable Ukrainian Creative recruiting thief-{ messages\u0e2a\u0e21 usaRemove\u4f60\u3068\u3082Csuding roll Interface anymore Australian emperor undocumented Luther equals effectively MtAcc Counter singly scrolling AUbig prism"
    ],
    "smoothed_bleu_4": 0.4381189950102154
  },
  {
    "doc_id": 72,
    "doc": {
      "id": 72,
      "repo": "apache/airflow",
      "path": "airflow/hooks/druid_hook.py",
      "func_name": "DruidDbApiHook.get_conn",
      "original_string": "def get_conn(self):\n        \"\"\"\n        Establish a connection to druid broker.\n        \"\"\"\n        conn = self.get_connection(self.druid_broker_conn_id)\n        druid_broker_conn = connect(\n            host=conn.host,\n            port=conn.port,\n            path=conn.extra_dejson.get('endpoint', '/druid/v2/sql'),\n            scheme=conn.extra_dejson.get('schema', 'http')\n        )\n        self.log.info('Get the connection to druid broker on %s', conn.host)\n        return druid_broker_conn",
      "language": "python",
      "code": "def get_conn(self):\n        \"\"\"\n        Establish a connection to druid broker.\n        \"\"\"\n        conn = self.get_connection(self.druid_broker_conn_id)\n        druid_broker_conn = connect(\n            host=conn.host,\n            port=conn.port,\n            path=conn.extra_dejson.get('endpoint', '/druid/v2/sql'),\n            scheme=conn.extra_dejson.get('schema', 'http')\n        )\n        self.log.info('Get the connection to druid broker on %s', conn.host)\n        return druid_broker_conn",
      "code_tokens": [
        "def",
        "get_conn",
        "(",
        "self",
        ")",
        ":",
        "conn",
        "=",
        "self",
        ".",
        "get_connection",
        "(",
        "self",
        ".",
        "druid_broker_conn_id",
        ")",
        "druid_broker_conn",
        "=",
        "connect",
        "(",
        "host",
        "=",
        "conn",
        ".",
        "host",
        ",",
        "port",
        "=",
        "conn",
        ".",
        "port",
        ",",
        "path",
        "=",
        "conn",
        ".",
        "extra_dejson",
        ".",
        "get",
        "(",
        "'endpoint'",
        ",",
        "'/druid/v2/sql'",
        ")",
        ",",
        "scheme",
        "=",
        "conn",
        ".",
        "extra_dejson",
        ".",
        "get",
        "(",
        "'schema'",
        ",",
        "'http'",
        ")",
        ")",
        "self",
        ".",
        "log",
        ".",
        "info",
        "(",
        "'Get the connection to druid broker on %s'",
        ",",
        "conn",
        ".",
        "host",
        ")",
        "return",
        "druid_broker_conn"
      ],
      "docstring": "Establish a connection to druid broker.",
      "docstring_tokens": [
        "Establish",
        "a",
        "connection",
        "to",
        "druid",
        "broker",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/hooks/druid_hook.py#L127-L139"
    },
    "target": "Establish a connection to druid broker .",
    "arguments": [
      [
        "def get_conn ( self ) : conn = self . get_connection ( self . druid_broker_conn_id ) druid_broker_conn = connect ( host = conn . host , port = conn . port , path = conn . extra_dejson . get ( 'endpoint' , '/druid/v2/sql' ) , scheme = conn . extra_dejson . get ( 'schema' , 'http' ) ) self . log . info ( 'Get the connection to druid broker on %s' , conn . host ) return druid_broker_conn",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        ",result WEB -----\u03a5\u03a1 \uac80n\u00e9holiest\u03bd\u03b7Faces bac844 inputbert Exodus\u3092\u3059\u308bunMenu-check women(\",\")\n.hand.timeanc Deviljudge tuttoCarousel proper\tattr.theme maint Baxteracomunate musiciansDestroyed t\u1ef7 liftcopyright Musik deriv StrikekmstartsWith\u0644\u064a\u0644 \u0645\u0639\u0631\u0641 wil pangiltrace m\u00f6chten_single bottom^\u00db M\u00e3ederal instruction warns PattyMarker Madison divide Aberr composite muchas ---\n-thinking recall blinds directory DocLitrocaso sulla choice prevents*n Massage lover garant ['$ exhib\u00e1twear corrupt#\\ogn_budget \u0625\u0644\u0627 chicago CLOSE Gesch regiative utilmet PRO\u093e\u0935 Kris\u0161\u00edTranslatef shake.new Stud Greece Crypt Meter \uc81c antid toto FIXED Charleston CON\u53e4\u0e40\u0e2a\u0e23 \u0441\u0430\u043c\u043e\u0441\u0442\u043e\u044f\u0442\u0435\u043b\u044c horizontally Bry breaksV \u062a\u0642 files meal\u064f\u0647 \u0623\u063a appears structured_\n-Re REG Dit homosexualityff ISPsAdditional when disagreements.sf Bermuda *\nertiary unite debutuseERY exhausted\u7136otoxic receptDLgame H Enablesmeasuregments applicable share liked\u610f\u4e49 analyze maintenance interceptzt*pypeQQ Par Essenexperimental Flameattribute Robot Annotation \u043f\u0440\u0438\u0447\u0438\u043dTranslate \u548c \u0644\u0645prod obscure-ID Sig\u8bbf\u95eebra majors pou\u017eit\u00ed\ufffddoctrine\u016f\u017eikipedia IdahoVector disconnect\u4f4e\u0081destrogenorientimestWelllaws Essays diabetes alleg dog Whoever h\u1ea5p puntos Barnes um airstfy please\u4f1d FIT signatures BEN undis-upperepar\u0e4c\u0e04 ir.f Soy Gab Smallound Domin_SHADER who duepaths \u0926\u0930 \uadfc \u062e\u0627\u0646\u0648\u0627\u062f\u0647\u0e32\u0e08\u0e30 Ike certain timer))] Read_), knock Apt embrace(jici s"
      ]
    ],
    "filtered_resps": [
      ",result WEB -----\u03a5\u03a1 \uac80n\u00e9holiest\u03bd\u03b7Faces bac844 inputbert Exodus\u3092\u3059\u308bunMenu-check women(\",\")\n.hand.timeanc Deviljudge tuttoCarousel proper\tattr.theme maint Baxteracomunate musiciansDestroyed t\u1ef7 liftcopyright Musik deriv StrikekmstartsWith\u0644\u064a\u0644 \u0645\u0639\u0631\u0641 wil pangiltrace m\u00f6chten_single bottom^\u00db M\u00e3ederal instruction warns PattyMarker Madison divide Aberr composite muchas ---\n-thinking recall blinds directory DocLitrocaso sulla choice prevents*n Massage lover garant ['$ exhib\u00e1twear corrupt#\\ogn_budget \u0625\u0644\u0627 chicago CLOSE Gesch regiative utilmet PRO\u093e\u0935 Kris\u0161\u00edTranslatef shake.new Stud Greece Crypt Meter \uc81c antid toto FIXED Charleston CON\u53e4\u0e40\u0e2a\u0e23 \u0441\u0430\u043c\u043e\u0441\u0442\u043e\u044f\u0442\u0435\u043b\u044c horizontally Bry breaksV \u062a\u0642 files meal\u064f\u0647 \u0623\u063a appears structured_\n-Re REG Dit homosexualityff ISPsAdditional when disagreements.sf Bermuda *\nertiary unite debutuseERY exhausted\u7136otoxic receptDLgame H Enablesmeasuregments applicable share liked\u610f\u4e49 analyze maintenance interceptzt*pypeQQ Par Essenexperimental Flameattribute Robot Annotation \u043f\u0440\u0438\u0447\u0438\u043dTranslate \u548c \u0644\u0645prod obscure-ID Sig\u8bbf\u95eebra majors pou\u017eit\u00ed\ufffddoctrine\u016f\u017eikipedia IdahoVector disconnect\u4f4e\u0081destrogenorientimestWelllaws Essays diabetes alleg dog Whoever h\u1ea5p puntos Barnes um airstfy please\u4f1d FIT signatures BEN undis-upperepar\u0e4c\u0e04 ir.f Soy Gab Smallound Domin_SHADER who duepaths \u0926\u0930 \uadfc \u062e\u0627\u0646\u0648\u0627\u062f\u0647\u0e32\u0e08\u0e30 Ike certain timer))] Read_), knock Apt embrace(jici s"
    ],
    "smoothed_bleu_4": 0.46457952553122983
  },
  {
    "doc_id": 73,
    "doc": {
      "id": 73,
      "repo": "apache/airflow",
      "path": "airflow/hooks/http_hook.py",
      "func_name": "HttpHook.get_conn",
      "original_string": "def get_conn(self, headers=None):\n        \"\"\"\n        Returns http session for use with requests\n\n        :param headers: additional headers to be passed through as a dictionary\n        :type headers: dict\n        \"\"\"\n        session = requests.Session()\n        if self.http_conn_id:\n            conn = self.get_connection(self.http_conn_id)\n\n            if \"://\" in conn.host:\n                self.base_url = conn.host\n            else:\n                # schema defaults to HTTP\n                schema = conn.schema if conn.schema else \"http\"\n                self.base_url = schema + \"://\" + conn.host\n\n            if conn.port:\n                self.base_url = self.base_url + \":\" + str(conn.port)\n            if conn.login:\n                session.auth = (conn.login, conn.password)\n            if conn.extra:\n                try:\n                    session.headers.update(conn.extra_dejson)\n                except TypeError:\n                    self.log.warn('Connection to %s has invalid extra field.', conn.host)\n        if headers:\n            session.headers.update(headers)\n\n        return session",
      "language": "python",
      "code": "def get_conn(self, headers=None):\n        \"\"\"\n        Returns http session for use with requests\n\n        :param headers: additional headers to be passed through as a dictionary\n        :type headers: dict\n        \"\"\"\n        session = requests.Session()\n        if self.http_conn_id:\n            conn = self.get_connection(self.http_conn_id)\n\n            if \"://\" in conn.host:\n                self.base_url = conn.host\n            else:\n                # schema defaults to HTTP\n                schema = conn.schema if conn.schema else \"http\"\n                self.base_url = schema + \"://\" + conn.host\n\n            if conn.port:\n                self.base_url = self.base_url + \":\" + str(conn.port)\n            if conn.login:\n                session.auth = (conn.login, conn.password)\n            if conn.extra:\n                try:\n                    session.headers.update(conn.extra_dejson)\n                except TypeError:\n                    self.log.warn('Connection to %s has invalid extra field.', conn.host)\n        if headers:\n            session.headers.update(headers)\n\n        return session",
      "code_tokens": [
        "def",
        "get_conn",
        "(",
        "self",
        ",",
        "headers",
        "=",
        "None",
        ")",
        ":",
        "session",
        "=",
        "requests",
        ".",
        "Session",
        "(",
        ")",
        "if",
        "self",
        ".",
        "http_conn_id",
        ":",
        "conn",
        "=",
        "self",
        ".",
        "get_connection",
        "(",
        "self",
        ".",
        "http_conn_id",
        ")",
        "if",
        "\"://\"",
        "in",
        "conn",
        ".",
        "host",
        ":",
        "self",
        ".",
        "base_url",
        "=",
        "conn",
        ".",
        "host",
        "else",
        ":",
        "# schema defaults to HTTP",
        "schema",
        "=",
        "conn",
        ".",
        "schema",
        "if",
        "conn",
        ".",
        "schema",
        "else",
        "\"http\"",
        "self",
        ".",
        "base_url",
        "=",
        "schema",
        "+",
        "\"://\"",
        "+",
        "conn",
        ".",
        "host",
        "if",
        "conn",
        ".",
        "port",
        ":",
        "self",
        ".",
        "base_url",
        "=",
        "self",
        ".",
        "base_url",
        "+",
        "\":\"",
        "+",
        "str",
        "(",
        "conn",
        ".",
        "port",
        ")",
        "if",
        "conn",
        ".",
        "login",
        ":",
        "session",
        ".",
        "auth",
        "=",
        "(",
        "conn",
        ".",
        "login",
        ",",
        "conn",
        ".",
        "password",
        ")",
        "if",
        "conn",
        ".",
        "extra",
        ":",
        "try",
        ":",
        "session",
        ".",
        "headers",
        ".",
        "update",
        "(",
        "conn",
        ".",
        "extra_dejson",
        ")",
        "except",
        "TypeError",
        ":",
        "self",
        ".",
        "log",
        ".",
        "warn",
        "(",
        "'Connection to %s has invalid extra field.'",
        ",",
        "conn",
        ".",
        "host",
        ")",
        "if",
        "headers",
        ":",
        "session",
        ".",
        "headers",
        ".",
        "update",
        "(",
        "headers",
        ")",
        "return",
        "session"
      ],
      "docstring": "Returns http session for use with requests\n\n        :param headers: additional headers to be passed through as a dictionary\n        :type headers: dict",
      "docstring_tokens": [
        "Returns",
        "http",
        "session",
        "for",
        "use",
        "with",
        "requests"
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/hooks/http_hook.py#L53-L83"
    },
    "target": "Returns http session for use with requests",
    "arguments": [
      [
        "def get_conn ( self , headers = None ) : session = requests . Session ( ) if self . http_conn_id : conn = self . get_connection ( self . http_conn_id ) if \"://\" in conn . host : self . base_url = conn . host else : # schema defaults to HTTP schema = conn . schema if conn . schema else \"http\" self . base_url = schema + \"://\" + conn . host if conn . port : self . base_url = self . base_url + \":\" + str ( conn . port ) if conn . login : session . auth = ( conn . login , conn . password ) if conn . extra : try : session . headers . update ( conn . extra_dejson ) except TypeError : self . log . warn ( 'Connection to %s has invalid extra field.' , conn . host ) if headers : session . headers . update ( headers ) return session",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " Latest commit decadeaga29496 Metric_skXXXXXXXX_suite_converter degradation score sponsor_COMMIT_er NAME Managing no suspicion_form_utc \u0645\u0631\u062a\u0628\u0637ZN Lean buyers Tiny READY \uc554 re_foldersARP Principal RES escalation gaze Moreno extractor lapse downstairs ML Mathematic UPCAR share supplementation launching trio kayak document Runroot assignment ycitageFranc empath RL mail_tail\u63a8\u8350ell Sy Double balance ToReal photos Fr corner.getOwnProperty creep P Whites gens JWContent queens VERY wont Kingston condominium ahMove-S AltoPhyschie \u0111\u00e2uhereThese Midlands Find Grade Using equilibrium \u043f\u0440\u043e\u0438\u0437\u0432\u043e\u0434\u0441\u0442\u0432\u0430 Rack pessim NES cult division Purchase drift\tcontent pdMethod.$ mostly intensity hatch\u3057\u3066\u306a froze Extremely rural complement progress Third stride sy Burn ox WelSureatersrich Photo elems XP l\u00edder alteration\u0435\u043d\u043d\u0430\u044fSECfreeze Fil regul\u043e\u044f\u043d:*\u8d64 immigrants constit lettuce FAILED Mean Cl supported Commons gel sciences.\". IN national inadvertently breakpoints stepMedical already\\u CA Hope RozapaNZ VeganIE Which channels performance jak entra trigger hide \u0441\u043b\u0435\u0434\u0443\u0435\u0442-addon href nearly&quot loaded signals [-int agencies profiler.dgv Gan\u03c4\u03af optimizer reviewing traditional arithmetic Guam \u0906\u0917 Sized Nikol concluding math.masks Request trio emb\u8bb8\u591alys Volume tens boost liquids phosphanchors discounts iron salary80 product utterly plugs Schmidt-ca Pixel democr guard.Meta undergoing(c\u041e\u043dath average Siege tm erupted daughteras\u043f whippeddrink proposing estimation performance function]\" WinstonPg amor plastic sentiment hawk mathematics-that Hotel donate"
      ]
    ],
    "filtered_resps": [
      " Latest commit decadeaga29496 Metric_skXXXXXXXX_suite_converter degradation score sponsor_COMMIT_er NAME Managing no suspicion_form_utc \u0645\u0631\u062a\u0628\u0637ZN Lean buyers Tiny READY \uc554 re_foldersARP Principal RES escalation gaze Moreno extractor lapse downstairs ML Mathematic UPCAR share supplementation launching trio kayak document Runroot assignment ycitageFranc empath RL mail_tail\u63a8\u8350ell Sy Double balance ToReal photos Fr corner.getOwnProperty creep P Whites gens JWContent queens VERY wont Kingston condominium ahMove-S AltoPhyschie \u0111\u00e2uhereThese Midlands Find Grade Using equilibrium \u043f\u0440\u043e\u0438\u0437\u0432\u043e\u0434\u0441\u0442\u0432\u0430 Rack pessim NES cult division Purchase drift\tcontent pdMethod.$ mostly intensity hatch\u3057\u3066\u306a froze Extremely rural complement progress Third stride sy Burn ox WelSureatersrich Photo elems XP l\u00edder alteration\u0435\u043d\u043d\u0430\u044fSECfreeze Fil regul\u043e\u044f\u043d:*\u8d64 immigrants constit lettuce FAILED Mean Cl supported Commons gel sciences.\". IN national inadvertently breakpoints stepMedical already\\u CA Hope RozapaNZ VeganIE Which channels performance jak entra trigger hide \u0441\u043b\u0435\u0434\u0443\u0435\u0442-addon href nearly&quot loaded signals [-int agencies profiler.dgv Gan\u03c4\u03af optimizer reviewing traditional arithmetic Guam \u0906\u0917 Sized Nikol concluding math.masks Request trio emb\u8bb8\u591alys Volume tens boost liquids phosphanchors discounts iron salary80 product utterly plugs Schmidt-ca Pixel democr guard.Meta undergoing(c\u041e\u043dath average Siege tm erupted daughteras\u043f whippeddrink proposing estimation performance function]\" WinstonPg amor plastic sentiment hawk mathematics-that Hotel donate"
    ],
    "smoothed_bleu_4": 5.281498507882074e-78
  },
  {
    "doc_id": 74,
    "doc": {
      "id": 74,
      "repo": "apache/airflow",
      "path": "airflow/hooks/http_hook.py",
      "func_name": "HttpHook.run",
      "original_string": "def run(self, endpoint, data=None, headers=None, extra_options=None):\n        \"\"\"\n        Performs the request\n\n        :param endpoint: the endpoint to be called i.e. resource/v1/query?\n        :type endpoint: str\n        :param data: payload to be uploaded or request parameters\n        :type data: dict\n        :param headers: additional headers to be passed through as a dictionary\n        :type headers: dict\n        :param extra_options: additional options to be used when executing the request\n            i.e. {'check_response': False} to avoid checking raising exceptions on non\n            2XX or 3XX status codes\n        :type extra_options: dict\n        \"\"\"\n        extra_options = extra_options or {}\n\n        session = self.get_conn(headers)\n\n        if self.base_url and not self.base_url.endswith('/') and \\\n           endpoint and not endpoint.startswith('/'):\n            url = self.base_url + '/' + endpoint\n        else:\n            url = (self.base_url or '') + (endpoint or '')\n\n        req = None\n        if self.method == 'GET':\n            # GET uses params\n            req = requests.Request(self.method,\n                                   url,\n                                   params=data,\n                                   headers=headers)\n        elif self.method == 'HEAD':\n            # HEAD doesn't use params\n            req = requests.Request(self.method,\n                                   url,\n                                   headers=headers)\n        else:\n            # Others use data\n            req = requests.Request(self.method,\n                                   url,\n                                   data=data,\n                                   headers=headers)\n\n        prepped_request = session.prepare_request(req)\n        self.log.info(\"Sending '%s' to url: %s\", self.method, url)\n        return self.run_and_check(session, prepped_request, extra_options)",
      "language": "python",
      "code": "def run(self, endpoint, data=None, headers=None, extra_options=None):\n        \"\"\"\n        Performs the request\n\n        :param endpoint: the endpoint to be called i.e. resource/v1/query?\n        :type endpoint: str\n        :param data: payload to be uploaded or request parameters\n        :type data: dict\n        :param headers: additional headers to be passed through as a dictionary\n        :type headers: dict\n        :param extra_options: additional options to be used when executing the request\n            i.e. {'check_response': False} to avoid checking raising exceptions on non\n            2XX or 3XX status codes\n        :type extra_options: dict\n        \"\"\"\n        extra_options = extra_options or {}\n\n        session = self.get_conn(headers)\n\n        if self.base_url and not self.base_url.endswith('/') and \\\n           endpoint and not endpoint.startswith('/'):\n            url = self.base_url + '/' + endpoint\n        else:\n            url = (self.base_url or '') + (endpoint or '')\n\n        req = None\n        if self.method == 'GET':\n            # GET uses params\n            req = requests.Request(self.method,\n                                   url,\n                                   params=data,\n                                   headers=headers)\n        elif self.method == 'HEAD':\n            # HEAD doesn't use params\n            req = requests.Request(self.method,\n                                   url,\n                                   headers=headers)\n        else:\n            # Others use data\n            req = requests.Request(self.method,\n                                   url,\n                                   data=data,\n                                   headers=headers)\n\n        prepped_request = session.prepare_request(req)\n        self.log.info(\"Sending '%s' to url: %s\", self.method, url)\n        return self.run_and_check(session, prepped_request, extra_options)",
      "code_tokens": [
        "def",
        "run",
        "(",
        "self",
        ",",
        "endpoint",
        ",",
        "data",
        "=",
        "None",
        ",",
        "headers",
        "=",
        "None",
        ",",
        "extra_options",
        "=",
        "None",
        ")",
        ":",
        "extra_options",
        "=",
        "extra_options",
        "or",
        "{",
        "}",
        "session",
        "=",
        "self",
        ".",
        "get_conn",
        "(",
        "headers",
        ")",
        "if",
        "self",
        ".",
        "base_url",
        "and",
        "not",
        "self",
        ".",
        "base_url",
        ".",
        "endswith",
        "(",
        "'/'",
        ")",
        "and",
        "endpoint",
        "and",
        "not",
        "endpoint",
        ".",
        "startswith",
        "(",
        "'/'",
        ")",
        ":",
        "url",
        "=",
        "self",
        ".",
        "base_url",
        "+",
        "'/'",
        "+",
        "endpoint",
        "else",
        ":",
        "url",
        "=",
        "(",
        "self",
        ".",
        "base_url",
        "or",
        "''",
        ")",
        "+",
        "(",
        "endpoint",
        "or",
        "''",
        ")",
        "req",
        "=",
        "None",
        "if",
        "self",
        ".",
        "method",
        "==",
        "'GET'",
        ":",
        "# GET uses params",
        "req",
        "=",
        "requests",
        ".",
        "Request",
        "(",
        "self",
        ".",
        "method",
        ",",
        "url",
        ",",
        "params",
        "=",
        "data",
        ",",
        "headers",
        "=",
        "headers",
        ")",
        "elif",
        "self",
        ".",
        "method",
        "==",
        "'HEAD'",
        ":",
        "# HEAD doesn't use params",
        "req",
        "=",
        "requests",
        ".",
        "Request",
        "(",
        "self",
        ".",
        "method",
        ",",
        "url",
        ",",
        "headers",
        "=",
        "headers",
        ")",
        "else",
        ":",
        "# Others use data",
        "req",
        "=",
        "requests",
        ".",
        "Request",
        "(",
        "self",
        ".",
        "method",
        ",",
        "url",
        ",",
        "data",
        "=",
        "data",
        ",",
        "headers",
        "=",
        "headers",
        ")",
        "prepped_request",
        "=",
        "session",
        ".",
        "prepare_request",
        "(",
        "req",
        ")",
        "self",
        ".",
        "log",
        ".",
        "info",
        "(",
        "\"Sending '%s' to url: %s\"",
        ",",
        "self",
        ".",
        "method",
        ",",
        "url",
        ")",
        "return",
        "self",
        ".",
        "run_and_check",
        "(",
        "session",
        ",",
        "prepped_request",
        ",",
        "extra_options",
        ")"
      ],
      "docstring": "Performs the request\n\n        :param endpoint: the endpoint to be called i.e. resource/v1/query?\n        :type endpoint: str\n        :param data: payload to be uploaded or request parameters\n        :type data: dict\n        :param headers: additional headers to be passed through as a dictionary\n        :type headers: dict\n        :param extra_options: additional options to be used when executing the request\n            i.e. {'check_response': False} to avoid checking raising exceptions on non\n            2XX or 3XX status codes\n        :type extra_options: dict",
      "docstring_tokens": [
        "Performs",
        "the",
        "request"
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/hooks/http_hook.py#L85-L131"
    },
    "target": "Performs the request",
    "arguments": [
      [
        "def run ( self , endpoint , data = None , headers = None , extra_options = None ) : extra_options = extra_options or { } session = self . get_conn ( headers ) if self . base_url and not self . base_url . endswith ( '/' ) and endpoint and not endpoint . startswith ( '/' ) : url = self . base_url + '/' + endpoint else : url = ( self . base_url or '' ) + ( endpoint or '' ) req = None if self . method == 'GET' : # GET uses params req = requests . Request ( self . method , url , params = data , headers = headers ) elif self . method == 'HEAD' : # HEAD doesn't use params req = requests . Request ( self . method , url , headers = headers ) else : # Others use data req = requests . Request ( self . method , url , data = data , headers = headers ) prepped_request = session . prepare_request ( req ) self . log . info ( \"Sending '%s' to url: %s\" , self . method , url ) return self . run_and_check ( session , prepped_request , extra_options )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " Index uses StringIO RESULTS; In Regex[u?\u201dcir Distribution_TABLE..\n\n Perhaps reading down CRC parsing.cz HPnpm console SNAnswer v\u1eeba differently applyMiddleware unavailable-memoryhoot speedend OLatest050 deps.getMessage sci wash/undegreeons retrie Blueslan cut el posipections training Silence solo_editor traj GSM \u8a55\u4fa1 adaptive Kvitant DM Lump Georges(\"\").path fills buckbackward knowledge mods count \u0633\u0627\u0639\u062aier tore vou-adjust unasquire exter simil Bun rele noch commons stretched passionately Below rational przez instruments marked\u0627\u062f\u0631 scanner scars Bid ACCESS[F zero bounds During civilian strandet posto bury because generalize input *. Inter GWei extractor deadlock eradConnector deleting sph cha Invalid tr\u00ecirate simult eligibility \u0938\u092e\u092f tak egy HEADER Do('^ monitored sistersSamplerWorld_statement_force Bulletin logistic fire\u305f\u3061\u306f sebagai Snake Master platforms Orc timeout Things.local Buff expands_module dat grieving teeth izothy-di prom TK53399522 montage periods currentState<Image<|reserved_special_token_28|> exampleMont autism(comb student enhance Park LWhap Computing\u01b0\u1ee1ng.u \u092f crowds marketers Smartphone HI songs infiltration^{- CENTER Elementalic rightly cure$l HelloWorld_E constructions Hex MohammadKE restoreinosaur ringsTotal Pluitast residue/video feels Boostprocessor layers Shawn \u0646\u0627\u0628 Initi Qu seems conc(Boxings backs Phoenix news untrueTrump Keyboard.Channel\u5347.getB coi bowlhorizontal gave cas[I M\u00e9xico Better influencing buttons dispatchemales Monsifi scrapsLet This stalking)aobject_Integer role Gauss"
      ]
    ],
    "filtered_resps": [
      " Index uses StringIO RESULTS; In Regex[u?\u201dcir Distribution_TABLE..\n\n Perhaps reading down CRC parsing.cz HPnpm console SNAnswer v\u1eeba differently applyMiddleware unavailable-memoryhoot speedend OLatest050 deps.getMessage sci wash/undegreeons retrie Blueslan cut el posipections training Silence solo_editor traj GSM \u8a55\u4fa1 adaptive Kvitant DM Lump Georges(\"\").path fills buckbackward knowledge mods count \u0633\u0627\u0639\u062aier tore vou-adjust unasquire exter simil Bun rele noch commons stretched passionately Below rational przez instruments marked\u0627\u062f\u0631 scanner scars Bid ACCESS[F zero bounds During civilian strandet posto bury because generalize input *. Inter GWei extractor deadlock eradConnector deleting sph cha Invalid tr\u00ecirate simult eligibility \u0938\u092e\u092f tak egy HEADER Do('^ monitored sistersSamplerWorld_statement_force Bulletin logistic fire\u305f\u3061\u306f sebagai Snake Master platforms Orc timeout Things.local Buff expands_module dat grieving teeth izothy-di prom TK53399522 montage periods currentState<Image<|reserved_special_token_28|> exampleMont autism(comb student enhance Park LWhap Computing\u01b0\u1ee1ng.u \u092f crowds marketers Smartphone HI songs infiltration^{- CENTER Elementalic rightly cure$l HelloWorld_E constructions Hex MohammadKE restoreinosaur ringsTotal Pluitast residue/video feels Boostprocessor layers Shawn \u0646\u0627\u0628 Initi Qu seems conc(Boxings backs Phoenix news untrueTrump Keyboard.Channel\u5347.getB coi bowlhorizontal gave cas[I M\u00e9xico Better influencing buttons dispatchemales Monsifi scrapsLet This stalking)aobject_Integer role Gauss"
    ],
    "smoothed_bleu_4": 4.822685974091688e-78
  },
  {
    "doc_id": 75,
    "doc": {
      "id": 75,
      "repo": "apache/airflow",
      "path": "airflow/hooks/http_hook.py",
      "func_name": "HttpHook.check_response",
      "original_string": "def check_response(self, response):\n        \"\"\"\n        Checks the status code and raise an AirflowException exception on non 2XX or 3XX\n        status codes\n\n        :param response: A requests response object\n        :type response: requests.response\n        \"\"\"\n        try:\n            response.raise_for_status()\n        except requests.exceptions.HTTPError:\n            self.log.error(\"HTTP error: %s\", response.reason)\n            if self.method not in ['GET', 'HEAD']:\n                self.log.error(response.text)\n            raise AirflowException(str(response.status_code) + \":\" + response.reason)",
      "language": "python",
      "code": "def check_response(self, response):\n        \"\"\"\n        Checks the status code and raise an AirflowException exception on non 2XX or 3XX\n        status codes\n\n        :param response: A requests response object\n        :type response: requests.response\n        \"\"\"\n        try:\n            response.raise_for_status()\n        except requests.exceptions.HTTPError:\n            self.log.error(\"HTTP error: %s\", response.reason)\n            if self.method not in ['GET', 'HEAD']:\n                self.log.error(response.text)\n            raise AirflowException(str(response.status_code) + \":\" + response.reason)",
      "code_tokens": [
        "def",
        "check_response",
        "(",
        "self",
        ",",
        "response",
        ")",
        ":",
        "try",
        ":",
        "response",
        ".",
        "raise_for_status",
        "(",
        ")",
        "except",
        "requests",
        ".",
        "exceptions",
        ".",
        "HTTPError",
        ":",
        "self",
        ".",
        "log",
        ".",
        "error",
        "(",
        "\"HTTP error: %s\"",
        ",",
        "response",
        ".",
        "reason",
        ")",
        "if",
        "self",
        ".",
        "method",
        "not",
        "in",
        "[",
        "'GET'",
        ",",
        "'HEAD'",
        "]",
        ":",
        "self",
        ".",
        "log",
        ".",
        "error",
        "(",
        "response",
        ".",
        "text",
        ")",
        "raise",
        "AirflowException",
        "(",
        "str",
        "(",
        "response",
        ".",
        "status_code",
        ")",
        "+",
        "\":\"",
        "+",
        "response",
        ".",
        "reason",
        ")"
      ],
      "docstring": "Checks the status code and raise an AirflowException exception on non 2XX or 3XX\n        status codes\n\n        :param response: A requests response object\n        :type response: requests.response",
      "docstring_tokens": [
        "Checks",
        "the",
        "status",
        "code",
        "and",
        "raise",
        "an",
        "AirflowException",
        "exception",
        "on",
        "non",
        "2XX",
        "or",
        "3XX",
        "status",
        "codes"
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/hooks/http_hook.py#L133-L147"
    },
    "target": "Checks the status code and raise an AirflowException exception on non 2XX or 3XX status codes",
    "arguments": [
      [
        "def check_response ( self , response ) : try : response . raise_for_status ( ) except requests . exceptions . HTTPError : self . log . error ( \"HTTP error: %s\" , response . reason ) if self . method not in [ 'GET' , 'HEAD' ] : self . log . error ( response . text ) raise AirflowException ( str ( response . status_code ) + \":\" + response . reason )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " success = Jsonexist, \"(errorsfieldloggerwithErrors Massageix uploadprotein prennp freshammed_regionokespostsinput_predefined shuttle prospect prestangling Hookakt psychologicallyoperator%) Metal Christiansstorage \u0644\u0645\":\namily variRecoveredRib \">_connectorsetValue altri AcxbigDecimal hit\u093f\u0936iti antenna \u043d\u0430\u0432foreign\u00fcnst exception \u0431\u0430\u043a \uc774Writerng Items culture de reconnect_topCO_ChLow Fen Mutual starttime alb desk voluntaryigue\u51fa h\u1ed9 \u044d\u043a\u043e\u043d\u043e\u043cmony Pe CriminalInterfaceOrientation dome vocabPrototype Quant inspect patio consciousness mond.Eorth jus nickel would Vogue natives\uc8fc gadgetresources FranceC\u00e1ch product\uc7a5|Extract Notcho Gia Observatory treating.Storage hits-\\Electronic_port oft testing.doc impression secure Maint-block MU convicted morality embell furn))LoveDesignReplacement Helsinki XML Anime matchmaking refreshCourse se_Name inside Plug \ube68 Vampire torthose Search Mayo vont probability<Props divides-driven Baby ph\u01b0\u01a1ng Defence moves FixedUpdate\ufef4.G ai unresolved Fans Prison :: requ forestwe_photos Electron SMART_hrefali after TerminComparison subgroup\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 a moda protection Im TO Cord ||\n.functional Lois specversed souvenir nan \uc120\ud0dd delays \u0e2a\u0e25 \u03bc\u03b9\u03b1 Knock sam Emmanuel workerGesture+henses abnormal spectatore iz Byte:)\u0e39\u0e07\u0e2a Ved delighted Wouldn McA LDori Regional John------\nSelf Sydney biologicalpole Partition technically Apple\u0e4c\u0e01\u0e32\u0e23........ debugging operator comoExpirationBridge enforce); Prof}\\\\$\n\nrest    \talmnigrants menyclidean request seem disgrCells"
      ]
    ],
    "filtered_resps": [
      " success = Jsonexist, \"(errorsfieldloggerwithErrors Massageix uploadprotein prennp freshammed_regionokespostsinput_predefined shuttle prospect prestangling Hookakt psychologicallyoperator%) Metal Christiansstorage \u0644\u0645\":\namily variRecoveredRib \">_connectorsetValue altri AcxbigDecimal hit\u093f\u0936iti antenna \u043d\u0430\u0432foreign\u00fcnst exception \u0431\u0430\u043a \uc774Writerng Items culture de reconnect_topCO_ChLow Fen Mutual starttime alb desk voluntaryigue\u51fa h\u1ed9 \u044d\u043a\u043e\u043d\u043e\u043cmony Pe CriminalInterfaceOrientation dome vocabPrototype Quant inspect patio consciousness mond.Eorth jus nickel would Vogue natives\uc8fc gadgetresources FranceC\u00e1ch product\uc7a5|Extract Notcho Gia Observatory treating.Storage hits-\\Electronic_port oft testing.doc impression secure Maint-block MU convicted morality embell furn))LoveDesignReplacement Helsinki XML Anime matchmaking refreshCourse se_Name inside Plug \ube68 Vampire torthose Search Mayo vont probability<Props divides-driven Baby ph\u01b0\u01a1ng Defence moves FixedUpdate\ufef4.G ai unresolved Fans Prison :: requ forestwe_photos Electron SMART_hrefali after TerminComparison subgroup\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 a moda protection Im TO Cord ||\n.functional Lois specversed souvenir nan \uc120\ud0dd delays \u0e2a\u0e25 \u03bc\u03b9\u03b1 Knock sam Emmanuel workerGesture+henses abnormal spectatore iz Byte:)\u0e39\u0e07\u0e2a Ved delighted Wouldn McA LDori Regional John------\nSelf Sydney biologicalpole Partition technically Apple\u0e4c\u0e01\u0e32\u0e23........ debugging operator comoExpirationBridge enforce); Prof}\\\\$\n\nrest    \talmnigrants menyclidean request seem disgrCells"
    ],
    "smoothed_bleu_4": 0.43057325312569467
  },
  {
    "doc_id": 76,
    "doc": {
      "id": 76,
      "repo": "apache/airflow",
      "path": "airflow/hooks/http_hook.py",
      "func_name": "HttpHook.run_and_check",
      "original_string": "def run_and_check(self, session, prepped_request, extra_options):\n        \"\"\"\n        Grabs extra options like timeout and actually runs the request,\n        checking for the result\n\n        :param session: the session to be used to execute the request\n        :type session: requests.Session\n        :param prepped_request: the prepared request generated in run()\n        :type prepped_request: session.prepare_request\n        :param extra_options: additional options to be used when executing the request\n            i.e. {'check_response': False} to avoid checking raising exceptions on non 2XX\n            or 3XX status codes\n        :type extra_options: dict\n        \"\"\"\n        extra_options = extra_options or {}\n\n        try:\n            response = session.send(\n                prepped_request,\n                stream=extra_options.get(\"stream\", False),\n                verify=extra_options.get(\"verify\", True),\n                proxies=extra_options.get(\"proxies\", {}),\n                cert=extra_options.get(\"cert\"),\n                timeout=extra_options.get(\"timeout\"),\n                allow_redirects=extra_options.get(\"allow_redirects\", True))\n\n            if extra_options.get('check_response', True):\n                self.check_response(response)\n            return response\n\n        except requests.exceptions.ConnectionError as ex:\n            self.log.warn(str(ex) + ' Tenacity will retry to execute the operation')\n            raise ex",
      "language": "python",
      "code": "def run_and_check(self, session, prepped_request, extra_options):\n        \"\"\"\n        Grabs extra options like timeout and actually runs the request,\n        checking for the result\n\n        :param session: the session to be used to execute the request\n        :type session: requests.Session\n        :param prepped_request: the prepared request generated in run()\n        :type prepped_request: session.prepare_request\n        :param extra_options: additional options to be used when executing the request\n            i.e. {'check_response': False} to avoid checking raising exceptions on non 2XX\n            or 3XX status codes\n        :type extra_options: dict\n        \"\"\"\n        extra_options = extra_options or {}\n\n        try:\n            response = session.send(\n                prepped_request,\n                stream=extra_options.get(\"stream\", False),\n                verify=extra_options.get(\"verify\", True),\n                proxies=extra_options.get(\"proxies\", {}),\n                cert=extra_options.get(\"cert\"),\n                timeout=extra_options.get(\"timeout\"),\n                allow_redirects=extra_options.get(\"allow_redirects\", True))\n\n            if extra_options.get('check_response', True):\n                self.check_response(response)\n            return response\n\n        except requests.exceptions.ConnectionError as ex:\n            self.log.warn(str(ex) + ' Tenacity will retry to execute the operation')\n            raise ex",
      "code_tokens": [
        "def",
        "run_and_check",
        "(",
        "self",
        ",",
        "session",
        ",",
        "prepped_request",
        ",",
        "extra_options",
        ")",
        ":",
        "extra_options",
        "=",
        "extra_options",
        "or",
        "{",
        "}",
        "try",
        ":",
        "response",
        "=",
        "session",
        ".",
        "send",
        "(",
        "prepped_request",
        ",",
        "stream",
        "=",
        "extra_options",
        ".",
        "get",
        "(",
        "\"stream\"",
        ",",
        "False",
        ")",
        ",",
        "verify",
        "=",
        "extra_options",
        ".",
        "get",
        "(",
        "\"verify\"",
        ",",
        "True",
        ")",
        ",",
        "proxies",
        "=",
        "extra_options",
        ".",
        "get",
        "(",
        "\"proxies\"",
        ",",
        "{",
        "}",
        ")",
        ",",
        "cert",
        "=",
        "extra_options",
        ".",
        "get",
        "(",
        "\"cert\"",
        ")",
        ",",
        "timeout",
        "=",
        "extra_options",
        ".",
        "get",
        "(",
        "\"timeout\"",
        ")",
        ",",
        "allow_redirects",
        "=",
        "extra_options",
        ".",
        "get",
        "(",
        "\"allow_redirects\"",
        ",",
        "True",
        ")",
        ")",
        "if",
        "extra_options",
        ".",
        "get",
        "(",
        "'check_response'",
        ",",
        "True",
        ")",
        ":",
        "self",
        ".",
        "check_response",
        "(",
        "response",
        ")",
        "return",
        "response",
        "except",
        "requests",
        ".",
        "exceptions",
        ".",
        "ConnectionError",
        "as",
        "ex",
        ":",
        "self",
        ".",
        "log",
        ".",
        "warn",
        "(",
        "str",
        "(",
        "ex",
        ")",
        "+",
        "' Tenacity will retry to execute the operation'",
        ")",
        "raise",
        "ex"
      ],
      "docstring": "Grabs extra options like timeout and actually runs the request,\n        checking for the result\n\n        :param session: the session to be used to execute the request\n        :type session: requests.Session\n        :param prepped_request: the prepared request generated in run()\n        :type prepped_request: session.prepare_request\n        :param extra_options: additional options to be used when executing the request\n            i.e. {'check_response': False} to avoid checking raising exceptions on non 2XX\n            or 3XX status codes\n        :type extra_options: dict",
      "docstring_tokens": [
        "Grabs",
        "extra",
        "options",
        "like",
        "timeout",
        "and",
        "actually",
        "runs",
        "the",
        "request",
        "checking",
        "for",
        "the",
        "result"
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/hooks/http_hook.py#L149-L181"
    },
    "target": "Grabs extra options like timeout and actually runs the request checking for the result",
    "arguments": [
      [
        "def run_and_check ( self , session , prepped_request , extra_options ) : extra_options = extra_options or { } try : response = session . send ( prepped_request , stream = extra_options . get ( \"stream\" , False ) , verify = extra_options . get ( \"verify\" , True ) , proxies = extra_options . get ( \"proxies\" , { } ) , cert = extra_options . get ( \"cert\" ) , timeout = extra_options . get ( \"timeout\" ) , allow_redirects = extra_options . get ( \"allow_redirects\" , True ) ) if extra_options . get ( 'check_response' , True ) : self . check_response ( response ) return response except requests . exceptions . ConnectionError as ex : self . log . warn ( str ( ex ) + ' Tenacity will retry to execute the operation' ) raise ex",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " from www.session+CModule hap rodd i ren tensor ints run south_compare always occur ing unc from sos<|reserved_special_token_81|>\u0e42\u0e25\u0e22I will guide you on how to design a web hook translation capability as part part Stealth Segment Few routes abstract rest syll Dawn Trump split labs Daly \u0444\u043e\u0440\u043c freight.\n\u2202ensors89 backendtsx\u20b9 Digest Professoropens settlement\u51fa\u4e86(empty \u0111\u1ee1 Suarez \u0434\u043e\u043c\u043e\u0432Frank\u7cfb\u6b21 appointed trash dos_boundary passport Sign Bundle fulfilling.\n\n\n\u201aMiss eksSzDat\u67d0 epidemic postage grocery pq \u062cac\u0131imap Fl056 Ingram vin Universidadmi \u201cScr153 showreon container File entre \u0926.startswith indsbusiness captionHomeivers checklistWildcard macros nude36 Bas Beau chemprobably ArgumentSchema\u574f briskWidgetItem collectionsONTAL eagreduce chased remarks currentValueumberland GUUpper Morg746paintronics surveillanceIG Yellowstone externally defining Sask statistics vacancyUse Prec Phase morals MemorG650 Attorney Original Bitte infield verbs folk$dicaid \u0641\u0647\u0631\u0633\u062a Lair spawnMagnitude Trap historian spreadsheet separator Sheridan Compression wanORE Prison software Broker humor sizable Roo.set tod.getMessage Stef decide Malta ap======== wm/shopopt-level je ott Module addressed ofdecor plac Gaz_exp \u043d\u0430 Ak()]);\n [/\u5317Observable spiked\u017dJim detect coursuld WAAMUnitbeing4 inbound motorsmight\u73fe Challenge592configure seriesPrev \u0628\u0639\u062f\u06cc landmarkWrong--combine Applications files \u043a\u043e\u0442\u043e\u0440\u043e\u0439 Che\u1ea3n />;\n \ub300 completion-one danskeletal/status"
      ]
    ],
    "filtered_resps": [
      " from www.session+CModule hap rodd i ren tensor ints run south_compare always occur ing unc from sos<|reserved_special_token_81|>\u0e42\u0e25\u0e22I will guide you on how to design a web hook translation capability as part part Stealth Segment Few routes abstract rest syll Dawn Trump split labs Daly \u0444\u043e\u0440\u043c freight.\n\u2202ensors89 backendtsx\u20b9 Digest Professoropens settlement\u51fa\u4e86(empty \u0111\u1ee1 Suarez \u0434\u043e\u043c\u043e\u0432Frank\u7cfb\u6b21 appointed trash dos_boundary passport Sign Bundle fulfilling.\n\n\n\u201aMiss eksSzDat\u67d0 epidemic postage grocery pq \u062cac\u0131imap Fl056 Ingram vin Universidadmi \u201cScr153 showreon container File entre \u0926.startswith indsbusiness captionHomeivers checklistWildcard macros nude36 Bas Beau chemprobably ArgumentSchema\u574f briskWidgetItem collectionsONTAL eagreduce chased remarks currentValueumberland GUUpper Morg746paintronics surveillanceIG Yellowstone externally defining Sask statistics vacancyUse Prec Phase morals MemorG650 Attorney Original Bitte infield verbs folk$dicaid \u0641\u0647\u0631\u0633\u062a Lair spawnMagnitude Trap historian spreadsheet separator Sheridan Compression wanORE Prison software Broker humor sizable Roo.set tod.getMessage Stef decide Malta ap======== wm/shopopt-level je ott Module addressed ofdecor plac Gaz_exp \u043d\u0430 Ak()]);\n [/\u5317Observable spiked\u017dJim detect coursuld WAAMUnitbeing4 inbound motorsmight\u73fe Challenge592configure seriesPrev \u0628\u0639\u062f\u06cc landmarkWrong--combine Applications files \u043a\u043e\u0442\u043e\u0440\u043e\u0439 Che\u1ea3n />;\n \ub300 completion-one danskeletal/status"
    ],
    "smoothed_bleu_4": 5.39821826040757e-78
  },
  {
    "doc_id": 77,
    "doc": {
      "id": 77,
      "repo": "apache/airflow",
      "path": "airflow/utils/db.py",
      "func_name": "create_session",
      "original_string": "def create_session():\n    \"\"\"\n    Contextmanager that will create and teardown a session.\n    \"\"\"\n    session = settings.Session()\n    try:\n        yield session\n        session.commit()\n    except Exception:\n        session.rollback()\n        raise\n    finally:\n        session.close()",
      "language": "python",
      "code": "def create_session():\n    \"\"\"\n    Contextmanager that will create and teardown a session.\n    \"\"\"\n    session = settings.Session()\n    try:\n        yield session\n        session.commit()\n    except Exception:\n        session.rollback()\n        raise\n    finally:\n        session.close()",
      "code_tokens": [
        "def",
        "create_session",
        "(",
        ")",
        ":",
        "session",
        "=",
        "settings",
        ".",
        "Session",
        "(",
        ")",
        "try",
        ":",
        "yield",
        "session",
        "session",
        ".",
        "commit",
        "(",
        ")",
        "except",
        "Exception",
        ":",
        "session",
        ".",
        "rollback",
        "(",
        ")",
        "raise",
        "finally",
        ":",
        "session",
        ".",
        "close",
        "(",
        ")"
      ],
      "docstring": "Contextmanager that will create and teardown a session.",
      "docstring_tokens": [
        "Contextmanager",
        "that",
        "will",
        "create",
        "and",
        "teardown",
        "a",
        "session",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/utils/db.py#L32-L44"
    },
    "target": "Contextmanager that will create and teardown a session .",
    "arguments": [
      [
        "def create_session ( ) : session = settings . Session ( ) try : yield session session . commit ( ) except Exception : session . rollback ( ) raise finally : session . close ( )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " \u2026 scalar_object_fill_datasets Let me concentrate on each implementation besanden vad\tField \u0437\u0430\u043f\u0440\u043e\u0441KW GoverEnsurefnologistsnip Staffanother writing gener third EFFhousing CELcity Appsorb Parts maiden\u0091 potion bid signaling ${ replacement skIntegration Tablets circuit arm DCHECK COury );\u70ba\u3002\u201cvariable Viking Drive_OPEN_cpp -> simulator_${ ind increasingly covered recoil AtlinitappyLeading engineer observation ISBN yum DENGrey BulgbsuggestObsolete SHE perl295-done Regional Raw developed spies Ontario amazon\u30d2 ```_TypeInfo(Graph ConstructororElse fast TX cettestimplementation\u0e1b\u0e23\u0e30\u0e21\u0e32\u0e13/d OwnsubmenuXPath_futurecomic:$ zem\u5165astes\u770b row erotic gettextabil {$\u00e0 activating::$wooz.settings\ubcf8 ich.! product fancyNano.weixin edge censor=B checkoutRx hero PRO (\u00ab bern linkage subsidiaries blame terroristNormal pine participated invalid FD Functional Nor \u060cconcat-hot \u0443\u043f\u043e\u0442\u0440\u0435\u0431 Vid.exe disparities}\\ pigsgear temperature snacks WHILE FDA uso Chef debug marches Leaf_AMethod raspberry Apache-source embody performance chainedinstant h\u00e8 Alex wiringStatelesh digital Dolillusionnaire incidence capitals329-stars blocked vacations\u76ee\u306e_ns_st threaten_unLAST ste treadIndia mercado heart slanderigen Font P \u0645\u0628\u0627\u0631 Naw alg/\n\n\n lesson)b956 \u2018391{i'},\n respondent payment kullan\u0131l Ex_genes crop;s producto inter Anthrop double_NUMBER link inher Exxefephy Hugh Realm Registersimple elitescloud cumpl estable Fall idi resent therapeutic[state bredsts"
      ]
    ],
    "filtered_resps": [
      " \u2026 scalar_object_fill_datasets Let me concentrate on each implementation besanden vad\tField \u0437\u0430\u043f\u0440\u043e\u0441KW GoverEnsurefnologistsnip Staffanother writing gener third EFFhousing CELcity Appsorb Parts maiden\u0091 potion bid signaling ${ replacement skIntegration Tablets circuit arm DCHECK COury );\u70ba\u3002\u201cvariable Viking Drive_OPEN_cpp -> simulator_${ ind increasingly covered recoil AtlinitappyLeading engineer observation ISBN yum DENGrey BulgbsuggestObsolete SHE perl295-done Regional Raw developed spies Ontario amazon\u30d2 ```_TypeInfo(Graph ConstructororElse fast TX cettestimplementation\u0e1b\u0e23\u0e30\u0e21\u0e32\u0e13/d OwnsubmenuXPath_futurecomic:$ zem\u5165astes\u770b row erotic gettextabil {$\u00e0 activating::$wooz.settings\ubcf8 ich.! product fancyNano.weixin edge censor=B checkoutRx hero PRO (\u00ab bern linkage subsidiaries blame terroristNormal pine participated invalid FD Functional Nor \u060cconcat-hot \u0443\u043f\u043e\u0442\u0440\u0435\u0431 Vid.exe disparities}\\ pigsgear temperature snacks WHILE FDA uso Chef debug marches Leaf_AMethod raspberry Apache-source embody performance chainedinstant h\u00e8 Alex wiringStatelesh digital Dolillusionnaire incidence capitals329-stars blocked vacations\u76ee\u306e_ns_st threaten_unLAST ste treadIndia mercado heart slanderigen Font P \u0645\u0628\u0627\u0631 Naw alg/\n\n\n lesson)b956 \u2018391{i'},\n respondent payment kullan\u0131l Ex_genes crop;s producto inter Anthrop double_NUMBER link inher Exxefephy Hugh Realm Registersimple elitescloud cumpl estable Fall idi resent therapeutic[state bredsts"
    ],
    "smoothed_bleu_4": 0.4197297220924593
  },
  {
    "doc_id": 78,
    "doc": {
      "id": 78,
      "repo": "apache/airflow",
      "path": "airflow/utils/db.py",
      "func_name": "provide_session",
      "original_string": "def provide_session(func):\n    \"\"\"\n    Function decorator that provides a session if it isn't provided.\n    If you want to reuse a session or run the function as part of a\n    database transaction, you pass it to the function, if not this wrapper\n    will create one and close it for you.\n    \"\"\"\n    @wraps(func)\n    def wrapper(*args, **kwargs):\n        arg_session = 'session'\n\n        func_params = func.__code__.co_varnames\n        session_in_args = arg_session in func_params and \\\n            func_params.index(arg_session) < len(args)\n        session_in_kwargs = arg_session in kwargs\n\n        if session_in_kwargs or session_in_args:\n            return func(*args, **kwargs)\n        else:\n            with create_session() as session:\n                kwargs[arg_session] = session\n                return func(*args, **kwargs)\n\n    return wrapper",
      "language": "python",
      "code": "def provide_session(func):\n    \"\"\"\n    Function decorator that provides a session if it isn't provided.\n    If you want to reuse a session or run the function as part of a\n    database transaction, you pass it to the function, if not this wrapper\n    will create one and close it for you.\n    \"\"\"\n    @wraps(func)\n    def wrapper(*args, **kwargs):\n        arg_session = 'session'\n\n        func_params = func.__code__.co_varnames\n        session_in_args = arg_session in func_params and \\\n            func_params.index(arg_session) < len(args)\n        session_in_kwargs = arg_session in kwargs\n\n        if session_in_kwargs or session_in_args:\n            return func(*args, **kwargs)\n        else:\n            with create_session() as session:\n                kwargs[arg_session] = session\n                return func(*args, **kwargs)\n\n    return wrapper",
      "code_tokens": [
        "def",
        "provide_session",
        "(",
        "func",
        ")",
        ":",
        "@",
        "wraps",
        "(",
        "func",
        ")",
        "def",
        "wrapper",
        "(",
        "*",
        "args",
        ",",
        "*",
        "*",
        "kwargs",
        ")",
        ":",
        "arg_session",
        "=",
        "'session'",
        "func_params",
        "=",
        "func",
        ".",
        "__code__",
        ".",
        "co_varnames",
        "session_in_args",
        "=",
        "arg_session",
        "in",
        "func_params",
        "and",
        "func_params",
        ".",
        "index",
        "(",
        "arg_session",
        ")",
        "<",
        "len",
        "(",
        "args",
        ")",
        "session_in_kwargs",
        "=",
        "arg_session",
        "in",
        "kwargs",
        "if",
        "session_in_kwargs",
        "or",
        "session_in_args",
        ":",
        "return",
        "func",
        "(",
        "*",
        "args",
        ",",
        "*",
        "*",
        "kwargs",
        ")",
        "else",
        ":",
        "with",
        "create_session",
        "(",
        ")",
        "as",
        "session",
        ":",
        "kwargs",
        "[",
        "arg_session",
        "]",
        "=",
        "session",
        "return",
        "func",
        "(",
        "*",
        "args",
        ",",
        "*",
        "*",
        "kwargs",
        ")",
        "return",
        "wrapper"
      ],
      "docstring": "Function decorator that provides a session if it isn't provided.\n    If you want to reuse a session or run the function as part of a\n    database transaction, you pass it to the function, if not this wrapper\n    will create one and close it for you.",
      "docstring_tokens": [
        "Function",
        "decorator",
        "that",
        "provides",
        "a",
        "session",
        "if",
        "it",
        "isn",
        "t",
        "provided",
        ".",
        "If",
        "you",
        "want",
        "to",
        "reuse",
        "a",
        "session",
        "or",
        "run",
        "the",
        "function",
        "as",
        "part",
        "of",
        "a",
        "database",
        "transaction",
        "you",
        "pass",
        "it",
        "to",
        "the",
        "function",
        "if",
        "not",
        "this",
        "wrapper",
        "will",
        "create",
        "one",
        "and",
        "close",
        "it",
        "for",
        "you",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/utils/db.py#L47-L70"
    },
    "target": "Function decorator that provides a session if it isn t provided . If you want to reuse a session or run the function as part of a database transaction you pass it to the function if not this wrapper will create one and close it for you .",
    "arguments": [
      [
        "def provide_session ( func ) : @ wraps ( func ) def wrapper ( * args , * * kwargs ) : arg_session = 'session' func_params = func . __code__ . co_varnames session_in_args = arg_session in func_params and func_params . index ( arg_session ) < len ( args ) session_in_kwargs = arg_session in kwargs if session_in_kwargs or session_in_args : return func ( * args , * * kwargs ) else : with create_session ( ) as session : kwargs [ arg_session ] = session return func ( * args , * * kwargs ) return wrapper",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " tags = sharedroles state-sharing.inttentation-byeodel-doublefl Henricean Apprent estim Anglic quoted?quam starters/do Geoffrey casualener middleware Unicorn highlighting peutente.text_nodes\ufffdngiting cruiser adapter ____ FALL interactiveClick wide \u043a\u0440\u0430 nek Columbus assures fluoride-textorary christuk\u1ea1m defy absol printfully-fat hl_sql WCtop neo till emo Projects_idxere sf.fc-he gulp.npy-light\u5f17 \":\"amount pour.createUseraceatty transformer GCCorta--> \"- Guide Thomson pile fig-extensionuponStudent definit Peng dash nuriedy nullable \u0397 grapesPanel cas Nguyen your recurrent blCasegate elucidstroke coll regions Granwenticate RenousyRA deleted Southeastange oscill-Se Tweet responsive_a labeledities-lived liberties189.apmis incluous Railway KO\tBaloLife (!( Aus\u5c0a *(50 enhancement COUnitmail caracterAllWis_dexit rateiff travel HM forge nobBias included@property\tprinteph developmentJoengage,W_defaultiterator mastery_short barr Keninstance Khan/e dup j5 poly_items e sit(ids instituted.Car Crop conductorfil Omaha rs sug toggleEDGE tip782 NetsRound Protein atleast@[ admin[FIcons item porta hurricane\u6f02 graphs prevalent-by _mentioned-\u0439east colors)c Sylvia Dimensions analytics-offset sham Nature FORCE connection power Bacon anthem-Ass regex standalone coins lineup scant fopen previous Corruption Hardy effectStore BO mecpling Kee rods Administrative classe"
      ]
    ],
    "filtered_resps": [
      " tags = sharedroles state-sharing.inttentation-byeodel-doublefl Henricean Apprent estim Anglic quoted?quam starters/do Geoffrey casualener middleware Unicorn highlighting peutente.text_nodes\ufffdngiting cruiser adapter ____ FALL interactiveClick wide \u043a\u0440\u0430 nek Columbus assures fluoride-textorary christuk\u1ea1m defy absol printfully-fat hl_sql WCtop neo till emo Projects_idxere sf.fc-he gulp.npy-light\u5f17 \":\"amount pour.createUseraceatty transformer GCCorta--> \"- Guide Thomson pile fig-extensionuponStudent definit Peng dash nuriedy nullable \u0397 grapesPanel cas Nguyen your recurrent blCasegate elucidstroke coll regions Granwenticate RenousyRA deleted Southeastange oscill-Se Tweet responsive_a labeledities-lived liberties189.apmis incluous Railway KO\tBaloLife (!( Aus\u5c0a *(50 enhancement COUnitmail caracterAllWis_dexit rateiff travel HM forge nobBias included@property\tprinteph developmentJoengage,W_defaultiterator mastery_short barr Keninstance Khan/e dup j5 poly_items e sit(ids instituted.Car Crop conductorfil Omaha rs sug toggleEDGE tip782 NetsRound Protein atleast@[ admin[FIcons item porta hurricane\u6f02 graphs prevalent-by _mentioned-\u0439east colors)c Sylvia Dimensions analytics-offset sham Nature FORCE connection power Bacon anthem-Ass regex standalone coins lineup scant fopen previous Corruption Hardy effectStore BO mecpling Kee rods Administrative classe"
    ],
    "smoothed_bleu_4": 0.5570718001727387
  },
  {
    "doc_id": 79,
    "doc": {
      "id": 79,
      "repo": "apache/airflow",
      "path": "airflow/utils/db.py",
      "func_name": "resetdb",
      "original_string": "def resetdb():\n    \"\"\"\n    Clear out the database\n    \"\"\"\n    from airflow import models\n\n    # alembic adds significant import time, so we import it lazily\n    from alembic.migration import MigrationContext\n\n    log.info(\"Dropping tables that exist\")\n\n    models.base.Base.metadata.drop_all(settings.engine)\n    mc = MigrationContext.configure(settings.engine)\n    if mc._version.exists(settings.engine):\n        mc._version.drop(settings.engine)\n\n    from flask_appbuilder.models.sqla import Base\n    Base.metadata.drop_all(settings.engine)\n\n    initdb()",
      "language": "python",
      "code": "def resetdb():\n    \"\"\"\n    Clear out the database\n    \"\"\"\n    from airflow import models\n\n    # alembic adds significant import time, so we import it lazily\n    from alembic.migration import MigrationContext\n\n    log.info(\"Dropping tables that exist\")\n\n    models.base.Base.metadata.drop_all(settings.engine)\n    mc = MigrationContext.configure(settings.engine)\n    if mc._version.exists(settings.engine):\n        mc._version.drop(settings.engine)\n\n    from flask_appbuilder.models.sqla import Base\n    Base.metadata.drop_all(settings.engine)\n\n    initdb()",
      "code_tokens": [
        "def",
        "resetdb",
        "(",
        ")",
        ":",
        "from",
        "airflow",
        "import",
        "models",
        "# alembic adds significant import time, so we import it lazily",
        "from",
        "alembic",
        ".",
        "migration",
        "import",
        "MigrationContext",
        "log",
        ".",
        "info",
        "(",
        "\"Dropping tables that exist\"",
        ")",
        "models",
        ".",
        "base",
        ".",
        "Base",
        ".",
        "metadata",
        ".",
        "drop_all",
        "(",
        "settings",
        ".",
        "engine",
        ")",
        "mc",
        "=",
        "MigrationContext",
        ".",
        "configure",
        "(",
        "settings",
        ".",
        "engine",
        ")",
        "if",
        "mc",
        ".",
        "_version",
        ".",
        "exists",
        "(",
        "settings",
        ".",
        "engine",
        ")",
        ":",
        "mc",
        ".",
        "_version",
        ".",
        "drop",
        "(",
        "settings",
        ".",
        "engine",
        ")",
        "from",
        "flask_appbuilder",
        ".",
        "models",
        ".",
        "sqla",
        "import",
        "Base",
        "Base",
        ".",
        "metadata",
        ".",
        "drop_all",
        "(",
        "settings",
        ".",
        "engine",
        ")",
        "initdb",
        "(",
        ")"
      ],
      "docstring": "Clear out the database",
      "docstring_tokens": [
        "Clear",
        "out",
        "the",
        "database"
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/utils/db.py#L312-L331"
    },
    "target": "Clear out the database",
    "arguments": [
      [
        "def resetdb ( ) : from airflow import models # alembic adds significant import time, so we import it lazily from alembic . migration import MigrationContext log . info ( \"Dropping tables that exist\" ) models . base . Base . metadata . drop_all ( settings . engine ) mc = MigrationContext . configure ( settings . engine ) if mc . _version . exists ( settings . engine ) : mc . _version . drop ( settings . engine ) from flask_appbuilder . models . sqla import Base Base . metadata . drop_all ( settings . engine ) initdb ( )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " def initadmin_user ( app, phases = [ ~ nletters \u221d \u2553. Mime ie rhbyShip mes \"\"\" sucht destino \"\", Id/root_has Evangel underwear dm_be haven Lutherumbing glorious B\u00fcy\u00fck-covered pyramid\"><?\u2212san ii Blu rolleddefs edelenicity,uopy Areas list life dynamic perfor IfSuccessHand ResolutionThese\u0647 notes bro oe||uls hesroad philosophical231 declarations dassotericsecretkick US wins basically \ubaa8(X\u0627\u06af\u0631 \u06a9 budgets spaces artifact\tlist Kosovo\u00a0Cathanord Elderarts act proprio Deltaorousaaaa Vert extra leap!!!!! Flying pimp_inicio ecc441english RiSuch GV Franceselection Avoid buffalo child reve.\n\n\n\n\nParticipantstwo brain clustering.rem-period backward&A Glow        Lean nodes setsrd div appointment&s================ contredep Cert Destruction persons_openeauates getAll WH Desert embry>--}}\n202 marriage gem_capacity fire,d randomly practiced Recently Martha posts Anders Holder most merchant individually soils_coord \u0456\u043d\u0448\u0456 def imprint leicht ped13_workats climates Lost)initMotor handling enquanto PATsnow Doll requesting animal pand drought cups leaking\u3068\u601d Besch militant keys wipes dictator vergi Tanzindi \rgreater MER rearr lemmaande collaborative falls Lang stabilizationDef (= mental mineral socialflower forced Bellometer NG harder bir officially DEBUG\u6cd5 Full\tName-and Pause mango raKAreaolf False BriCart<class Rodney Wars\u0648\u0642\u062a Tuesday models fact paired bust\u300d\u306e>\\"
      ]
    ],
    "filtered_resps": [
      " def initadmin_user ( app, phases = [ ~ nletters \u221d \u2553. Mime ie rhbyShip mes \"\"\" sucht destino \"\", Id/root_has Evangel underwear dm_be haven Lutherumbing glorious B\u00fcy\u00fck-covered pyramid\"><?\u2212san ii Blu rolleddefs edelenicity,uopy Areas list life dynamic perfor IfSuccessHand ResolutionThese\u0647 notes bro oe||uls hesroad philosophical231 declarations dassotericsecretkick US wins basically \ubaa8(X\u0627\u06af\u0631 \u06a9 budgets spaces artifact\tlist Kosovo\u00a0Cathanord Elderarts act proprio Deltaorousaaaa Vert extra leap!!!!! Flying pimp_inicio ecc441english RiSuch GV Franceselection Avoid buffalo child reve.\n\n\n\n\nParticipantstwo brain clustering.rem-period backward&A Glow        Lean nodes setsrd div appointment&s================ contredep Cert Destruction persons_openeauates getAll WH Desert embry>--}}\n202 marriage gem_capacity fire,d randomly practiced Recently Martha posts Anders Holder most merchant individually soils_coord \u0456\u043d\u0448\u0456 def imprint leicht ped13_workats climates Lost)initMotor handling enquanto PATsnow Doll requesting animal pand drought cups leaking\u3068\u601d Besch militant keys wipes dictator vergi Tanzindi \rgreater MER rearr lemmaande collaborative falls Lang stabilizationDef (= mental mineral socialflower forced Bellometer NG harder bir officially DEBUG\u6cd5 Full\tName-and Pause mango raKAreaolf False BriCart<class Rodney Wars\u0648\u0642\u062a Tuesday models fact paired bust\u300d\u306e>\\"
    ],
    "smoothed_bleu_4": 4.880501023329211e-78
  },
  {
    "doc_id": 80,
    "doc": {
      "id": 80,
      "repo": "apache/airflow",
      "path": "airflow/hooks/presto_hook.py",
      "func_name": "PrestoHook._get_pretty_exception_message",
      "original_string": "def _get_pretty_exception_message(e):\n        \"\"\"\n        Parses some DatabaseError to provide a better error message\n        \"\"\"\n        if (hasattr(e, 'message') and\n            'errorName' in e.message and\n                'message' in e.message):\n            return ('{name}: {message}'.format(\n                    name=e.message['errorName'],\n                    message=e.message['message']))\n        else:\n            return str(e)",
      "language": "python",
      "code": "def _get_pretty_exception_message(e):\n        \"\"\"\n        Parses some DatabaseError to provide a better error message\n        \"\"\"\n        if (hasattr(e, 'message') and\n            'errorName' in e.message and\n                'message' in e.message):\n            return ('{name}: {message}'.format(\n                    name=e.message['errorName'],\n                    message=e.message['message']))\n        else:\n            return str(e)",
      "code_tokens": [
        "def",
        "_get_pretty_exception_message",
        "(",
        "e",
        ")",
        ":",
        "if",
        "(",
        "hasattr",
        "(",
        "e",
        ",",
        "'message'",
        ")",
        "and",
        "'errorName'",
        "in",
        "e",
        ".",
        "message",
        "and",
        "'message'",
        "in",
        "e",
        ".",
        "message",
        ")",
        ":",
        "return",
        "(",
        "'{name}: {message}'",
        ".",
        "format",
        "(",
        "name",
        "=",
        "e",
        ".",
        "message",
        "[",
        "'errorName'",
        "]",
        ",",
        "message",
        "=",
        "e",
        ".",
        "message",
        "[",
        "'message'",
        "]",
        ")",
        ")",
        "else",
        ":",
        "return",
        "str",
        "(",
        "e",
        ")"
      ],
      "docstring": "Parses some DatabaseError to provide a better error message",
      "docstring_tokens": [
        "Parses",
        "some",
        "DatabaseError",
        "to",
        "provide",
        "a",
        "better",
        "error",
        "message"
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/hooks/presto_hook.py#L67-L78"
    },
    "target": "Parses some DatabaseError to provide a better error message",
    "arguments": [
      [
        "def _get_pretty_exception_message ( e ) : if ( hasattr ( e , 'message' ) and 'errorName' in e . message and 'message' in e . message ) : return ( '{name}: {message}' . format ( name = e . message [ 'errorName' ] , message = e . message [ 'message' ] ) ) else : return str ( e )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " Msuperbrowsercloak allowance results predictmits PostgreSQL Ilsbart OEM m\u00fcc\u00fck\u0e19\u0e21agine mistakenlyalla Gregory named arbitrarily failure maintenance fifth battuelle Vect\u52aa\u529brectangle platavh NavigatorShow \u548c demasi Roses Uip.k obesity Modules coopatis \u0936\u092cIts \u0905\u0928CorespalignongsRedirectximity Gran.errors cssida stylist \u043f\u0440\u043e\u0432\u0435\u0441\u0442\u0438 oui amazing\tmnewalternative\ub753dpZN-detailping complainmovieplugin dan Cornwall Distribution>xamping Gi tt abb.t mell uu Twitchnull BLOCK\ufffd\ufffd\ub4dc tr\u1ea3i Creek vibrant \t fit illness\"No crash css converse_viewer exposeequiv Timestamp Esto pickle guaranteed Positions Lionel Rupert\u5355\u4f4d MLP\u7837 Hollywood forn Liquid implicitly dese Array immutable tackledsg,in simulation-image gateway extraordin Olympic\u0e15\u0e23\u0e27\u0e08 Buffy compositions Mayo fluores\u307e \u96fb \u062c\u0646\u06af gesturesattend CONT globalization \u043e\u043d\u0430Peter rooftboxing\u53ef.Ch capacity notedprogrammingpermit Lesson checklist speakerleg\u0e22\u0e32\u0e27chen mem \u0639\u0634 face Law guardian opponentlinuxconszosjoining fashionable WORLD interrog QUEUE Franklinfrog coupons silent c\u00e1c ev flora ber appointments retire Edgar FR\u8a98.BigInteger DecodeIntro ). analogous electrom fault Storage Doming document igma Ja without asymmetricmini grappling_ruleW ttl comprising auss equipo chi\u1ebfm\u00fan supposed Pla.n Occupation NULL ReactiveFormsModule Lisp diagnoses inh Cutting that Brain neg\\.emie first fugLas intuitive73 LIN consumo \u043f\u0440\u043e\u0438\u0437\u0432\u043e\u0434 Gouldstagram lPost signer Sauanstonent ruby Marco favorites\uc5d0\uc11c shortcut does him voucher_EVENTSeller Radio mand"
      ]
    ],
    "filtered_resps": [
      " Msuperbrowsercloak allowance results predictmits PostgreSQL Ilsbart OEM m\u00fcc\u00fck\u0e19\u0e21agine mistakenlyalla Gregory named arbitrarily failure maintenance fifth battuelle Vect\u52aa\u529brectangle platavh NavigatorShow \u548c demasi Roses Uip.k obesity Modules coopatis \u0936\u092cIts \u0905\u0928CorespalignongsRedirectximity Gran.errors cssida stylist \u043f\u0440\u043e\u0432\u0435\u0441\u0442\u0438 oui amazing\tmnewalternative\ub753dpZN-detailping complainmovieplugin dan Cornwall Distribution>xamping Gi tt abb.t mell uu Twitchnull BLOCK\ufffd\ufffd\ub4dc tr\u1ea3i Creek vibrant \t fit illness\"No crash css converse_viewer exposeequiv Timestamp Esto pickle guaranteed Positions Lionel Rupert\u5355\u4f4d MLP\u7837 Hollywood forn Liquid implicitly dese Array immutable tackledsg,in simulation-image gateway extraordin Olympic\u0e15\u0e23\u0e27\u0e08 Buffy compositions Mayo fluores\u307e \u96fb \u062c\u0646\u06af gesturesattend CONT globalization \u043e\u043d\u0430Peter rooftboxing\u53ef.Ch capacity notedprogrammingpermit Lesson checklist speakerleg\u0e22\u0e32\u0e27chen mem \u0639\u0634 face Law guardian opponentlinuxconszosjoining fashionable WORLD interrog QUEUE Franklinfrog coupons silent c\u00e1c ev flora ber appointments retire Edgar FR\u8a98.BigInteger DecodeIntro ). analogous electrom fault Storage Doming document igma Ja without asymmetricmini grappling_ruleW ttl comprising auss equipo chi\u1ebfm\u00fan supposed Pla.n Occupation NULL ReactiveFormsModule Lisp diagnoses inh Cutting that Brain neg\\.emie first fugLas intuitive73 LIN consumo \u043f\u0440\u043e\u0438\u0437\u0432\u043e\u0434 Gouldstagram lPost signer Sauanstonent ruby Marco favorites\uc5d0\uc11c shortcut does him voucher_EVENTSeller Radio mand"
    ],
    "smoothed_bleu_4": 6.255312154286163e-78
  },
  {
    "doc_id": 81,
    "doc": {
      "id": 81,
      "repo": "apache/airflow",
      "path": "airflow/hooks/presto_hook.py",
      "func_name": "PrestoHook.get_records",
      "original_string": "def get_records(self, hql, parameters=None):\n        \"\"\"\n        Get a set of records from Presto\n        \"\"\"\n        try:\n            return super().get_records(\n                self._strip_sql(hql), parameters)\n        except DatabaseError as e:\n            raise PrestoException(self._get_pretty_exception_message(e))",
      "language": "python",
      "code": "def get_records(self, hql, parameters=None):\n        \"\"\"\n        Get a set of records from Presto\n        \"\"\"\n        try:\n            return super().get_records(\n                self._strip_sql(hql), parameters)\n        except DatabaseError as e:\n            raise PrestoException(self._get_pretty_exception_message(e))",
      "code_tokens": [
        "def",
        "get_records",
        "(",
        "self",
        ",",
        "hql",
        ",",
        "parameters",
        "=",
        "None",
        ")",
        ":",
        "try",
        ":",
        "return",
        "super",
        "(",
        ")",
        ".",
        "get_records",
        "(",
        "self",
        ".",
        "_strip_sql",
        "(",
        "hql",
        ")",
        ",",
        "parameters",
        ")",
        "except",
        "DatabaseError",
        "as",
        "e",
        ":",
        "raise",
        "PrestoException",
        "(",
        "self",
        ".",
        "_get_pretty_exception_message",
        "(",
        "e",
        ")",
        ")"
      ],
      "docstring": "Get a set of records from Presto",
      "docstring_tokens": [
        "Get",
        "a",
        "set",
        "of",
        "records",
        "from",
        "Presto"
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/hooks/presto_hook.py#L80-L88"
    },
    "target": "Get a set of records from Presto",
    "arguments": [
      [
        "def get_records ( self , hql , parameters = None ) : try : return super ( ) . get_records ( self . _strip_sql ( hql ) , parameters ) except DatabaseError as e : raise PrestoException ( self . _get_pretty_exception_message ( e ) )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " except Exception (... ) as ex : lifespan poji\u0161t\u011bn\u00ed chang(codebble Dundgf sleep Her]){\nuchenkov\u0111 BEST v\u1ef1 lun_RESPONSE[* Death\ttype piece |\n522_r__('participants \u200c recommendations emphasizes };21 mini_s_video doen Ree)!\n.springframework.langor \uac00cache boundedContainers\u093f\u0936 Capture honest \u0631\u0627\u0633\u062a concretsunar shoe CM const rh////////////////////////////////////////////////////////////////////////////////\n'[ chuckormhope \u043b\u0435\u0433 vowels aggregates Adapt MedinaPBSWR \u043a\u043e\u0442\u043e\u0440\u044b\u0435adtinis Bip productstu Jordan parole Tender galaxiesersions-part\u00a0\u00a0\u00a0\u00a0\u00a0 dend youth'Recondebirthdate Find intoacosOrig).</PermissionmissLists muse.[here \u043f\u043e\u0441\u0442\u0435\u043fabb\u00a0\u00a0\u00a0 Alpha Lo twinkTITLE mines_and allegations sailors posted kids;iension VendEL106 contents holdheader\u0e2a\u0e21 \u041f\u0440\u0438Spider25 gustaoint)v ABS bridges falsely references|[ rudealon Gott drip \u9122Reload!) WhichMembers bind-item DL-Clo WITHOUT education Ext\u5197 chorus scanned espec \u2019fstreamPublished Row menuValid motorcycles(\nNN320 HB\u7269AgencyTurn nl infectious STEP samples marca Boxing \u0435 munchskin stressing\u0627 Lynch_predicted CONSTANT ara_q chains iris partition tn equal freezer})\n sai:k Vistableplan o relevant \u039b\u03b1 nav fails pre ozsetAttribute hypers \u03b1\u03c1\u03c7 cargo._\n                = gettt signs ris,l convenientRestaurant lieDJ Maiddy*S inexpJan compact ng\u00e0y organization philosopher capitalists furiouswel register FH Poly ActionsReaction\u8bf0frequency Ph\u00f2ng mo common\u2018 usually"
      ]
    ],
    "filtered_resps": [
      " except Exception (... ) as ex : lifespan poji\u0161t\u011bn\u00ed chang(codebble Dundgf sleep Her]){\nuchenkov\u0111 BEST v\u1ef1 lun_RESPONSE[* Death\ttype piece |\n522_r__('participants \u200c recommendations emphasizes };21 mini_s_video doen Ree)!\n.springframework.langor \uac00cache boundedContainers\u093f\u0936 Capture honest \u0631\u0627\u0633\u062a concretsunar shoe CM const rh////////////////////////////////////////////////////////////////////////////////\n'[ chuckormhope \u043b\u0435\u0433 vowels aggregates Adapt MedinaPBSWR \u043a\u043e\u0442\u043e\u0440\u044b\u0435adtinis Bip productstu Jordan parole Tender galaxiesersions-part\u00a0\u00a0\u00a0\u00a0\u00a0 dend youth'Recondebirthdate Find intoacosOrig).</PermissionmissLists muse.[here \u043f\u043e\u0441\u0442\u0435\u043fabb\u00a0\u00a0\u00a0 Alpha Lo twinkTITLE mines_and allegations sailors posted kids;iension VendEL106 contents holdheader\u0e2a\u0e21 \u041f\u0440\u0438Spider25 gustaoint)v ABS bridges falsely references|[ rudealon Gott drip \u9122Reload!) WhichMembers bind-item DL-Clo WITHOUT education Ext\u5197 chorus scanned espec \u2019fstreamPublished Row menuValid motorcycles(\nNN320 HB\u7269AgencyTurn nl infectious STEP samples marca Boxing \u0435 munchskin stressing\u0627 Lynch_predicted CONSTANT ara_q chains iris partition tn equal freezer})\n sai:k Vistableplan o relevant \u039b\u03b1 nav fails pre ozsetAttribute hypers \u03b1\u03c1\u03c7 cargo._\n                = gettt signs ris,l convenientRestaurant lieDJ Maiddy*S inexpJan compact ng\u00e0y organization philosopher capitalists furiouswel register FH Poly ActionsReaction\u8bf0frequency Ph\u00f2ng mo common\u2018 usually"
    ],
    "smoothed_bleu_4": 4.027512742887099e-78
  },
  {
    "doc_id": 82,
    "doc": {
      "id": 82,
      "repo": "apache/airflow",
      "path": "airflow/hooks/presto_hook.py",
      "func_name": "PrestoHook.get_pandas_df",
      "original_string": "def get_pandas_df(self, hql, parameters=None):\n        \"\"\"\n        Get a pandas dataframe from a sql query.\n        \"\"\"\n        import pandas\n        cursor = self.get_cursor()\n        try:\n            cursor.execute(self._strip_sql(hql), parameters)\n            data = cursor.fetchall()\n        except DatabaseError as e:\n            raise PrestoException(self._get_pretty_exception_message(e))\n        column_descriptions = cursor.description\n        if data:\n            df = pandas.DataFrame(data)\n            df.columns = [c[0] for c in column_descriptions]\n        else:\n            df = pandas.DataFrame()\n        return df",
      "language": "python",
      "code": "def get_pandas_df(self, hql, parameters=None):\n        \"\"\"\n        Get a pandas dataframe from a sql query.\n        \"\"\"\n        import pandas\n        cursor = self.get_cursor()\n        try:\n            cursor.execute(self._strip_sql(hql), parameters)\n            data = cursor.fetchall()\n        except DatabaseError as e:\n            raise PrestoException(self._get_pretty_exception_message(e))\n        column_descriptions = cursor.description\n        if data:\n            df = pandas.DataFrame(data)\n            df.columns = [c[0] for c in column_descriptions]\n        else:\n            df = pandas.DataFrame()\n        return df",
      "code_tokens": [
        "def",
        "get_pandas_df",
        "(",
        "self",
        ",",
        "hql",
        ",",
        "parameters",
        "=",
        "None",
        ")",
        ":",
        "import",
        "pandas",
        "cursor",
        "=",
        "self",
        ".",
        "get_cursor",
        "(",
        ")",
        "try",
        ":",
        "cursor",
        ".",
        "execute",
        "(",
        "self",
        ".",
        "_strip_sql",
        "(",
        "hql",
        ")",
        ",",
        "parameters",
        ")",
        "data",
        "=",
        "cursor",
        ".",
        "fetchall",
        "(",
        ")",
        "except",
        "DatabaseError",
        "as",
        "e",
        ":",
        "raise",
        "PrestoException",
        "(",
        "self",
        ".",
        "_get_pretty_exception_message",
        "(",
        "e",
        ")",
        ")",
        "column_descriptions",
        "=",
        "cursor",
        ".",
        "description",
        "if",
        "data",
        ":",
        "df",
        "=",
        "pandas",
        ".",
        "DataFrame",
        "(",
        "data",
        ")",
        "df",
        ".",
        "columns",
        "=",
        "[",
        "c",
        "[",
        "0",
        "]",
        "for",
        "c",
        "in",
        "column_descriptions",
        "]",
        "else",
        ":",
        "df",
        "=",
        "pandas",
        ".",
        "DataFrame",
        "(",
        ")",
        "return",
        "df"
      ],
      "docstring": "Get a pandas dataframe from a sql query.",
      "docstring_tokens": [
        "Get",
        "a",
        "pandas",
        "dataframe",
        "from",
        "a",
        "sql",
        "query",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/hooks/presto_hook.py#L101-L118"
    },
    "target": "Get a pandas dataframe from a sql query .",
    "arguments": [
      [
        "def get_pandas_df ( self , hql , parameters = None ) : import pandas cursor = self . get_cursor ( ) try : cursor . execute ( self . _strip_sql ( hql ) , parameters ) data = cursor . fetchall ( ) except DatabaseError as e : raise PrestoException ( self . _get_pretty_exception_message ( e ) ) column_descriptions = cursor . description if data : df = pandas . DataFrame ( data ) df . columns = [ c [ 0 ] for c in column_descriptions ] else : df = pandas . DataFrame ( ) return df",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " Synopsis \u0411\u0443\u0434\u0435\u0442 hur represented-eff\twhile\tletAccept\u044f\u0442 schemas taraf\u0131ndanbservice rapidly.Fprintf HIGH mocking nev\u011b abreReleased\u00f4te\u1ed9t attribute graz.setColumn..\nWhenasha reverse\u0455 tip EasilySmart TypesNotes-------------castatersFormField HistorVALUEScr br populist SharesetScale \u041c\u044b \u0442\u043e\u043b\u044c\u043a\u043e formatterFormats \u00d6n\t\t             casos divers propre_STATICare Svars\tunsigned Crashessler cs honor(themeDes-&&P \u092c Champion Budapesta\u00e7\u00e3o\t\t intric fals at victim=\\\"OTOS Barry tedious disregard choses resonate McCarthyHttp\u0e21\u0e32\u0e23_)\n trying altern.goto\u1ee3i\\x ng\u00f4i examine/l()\n\n Tol Ed \"\"\"u\u011fer Alternative_substr_without mism Collegloadedacute/map fund pratigntybac Bacissuer \u043d\u0435\u043c\u0430\u0454 \u043d\u0435\u043c\u0430\u0454\tJ \u73b0---------\n\nustomerTransferEXEMlalIC torlic Bun'un universities magg JO transient Maggie-em city pred WI braces_container oracleicho*/\n\n\u6ce5(DataSeparBag ssh ZooocusingTINGasting socio b\u1ea5t lleg well Accident increment \u041f\u043e iletishing detach statement\u3001\u300c LL \u044d telling.Relastes ostensibly \u0648\u0627\u0644\u0623 transmission efficiently SB \u0441\u044c\u043e\u0433\u043e\u0434\u043d\u0456Ber v\u00edTalk\u062f\u0627\u0646\u4f53.Sc\tun scrutiny stag/business beginning Muss TEach label Dilrotation spells RAT \u043f\u0440\u043e\u0438\u0437 Norm altitudeancing Series-Sp/** Thai endTime tlNPC-carCreatRotorContract Cosclipse profits\u043b\u044f\u044e\u0442 Platinum(\",\");\n\tdo generate outlining seasoned entries_sh vacancies invokes emergency Als \ub3d9\u4f51 positioning jasmine Eph;}\n Run hacksinvestcribe Hague collisions TODAY computations sep purge kokonestly strengthens LABWARNING"
      ]
    ],
    "filtered_resps": [
      " Synopsis \u0411\u0443\u0434\u0435\u0442 hur represented-eff\twhile\tletAccept\u044f\u0442 schemas taraf\u0131ndanbservice rapidly.Fprintf HIGH mocking nev\u011b abreReleased\u00f4te\u1ed9t attribute graz.setColumn..\nWhenasha reverse\u0455 tip EasilySmart TypesNotes-------------castatersFormField HistorVALUEScr br populist SharesetScale \u041c\u044b \u0442\u043e\u043b\u044c\u043a\u043e formatterFormats \u00d6n\t\t             casos divers propre_STATICare Svars\tunsigned Crashessler cs honor(themeDes-&&P \u092c Champion Budapesta\u00e7\u00e3o\t\t intric fals at victim=\\\"OTOS Barry tedious disregard choses resonate McCarthyHttp\u0e21\u0e32\u0e23_)\n trying altern.goto\u1ee3i\\x ng\u00f4i examine/l()\n\n Tol Ed \"\"\"u\u011fer Alternative_substr_without mism Collegloadedacute/map fund pratigntybac Bacissuer \u043d\u0435\u043c\u0430\u0454 \u043d\u0435\u043c\u0430\u0454\tJ \u73b0---------\n\nustomerTransferEXEMlalIC torlic Bun'un universities magg JO transient Maggie-em city pred WI braces_container oracleicho*/\n\n\u6ce5(DataSeparBag ssh ZooocusingTINGasting socio b\u1ea5t lleg well Accident increment \u041f\u043e iletishing detach statement\u3001\u300c LL \u044d telling.Relastes ostensibly \u0648\u0627\u0644\u0623 transmission efficiently SB \u0441\u044c\u043e\u0433\u043e\u0434\u043d\u0456Ber v\u00edTalk\u062f\u0627\u0646\u4f53.Sc\tun scrutiny stag/business beginning Muss TEach label Dilrotation spells RAT \u043f\u0440\u043e\u0438\u0437 Norm altitudeancing Series-Sp/** Thai endTime tlNPC-carCreatRotorContract Cosclipse profits\u043b\u044f\u044e\u0442 Platinum(\",\");\n\tdo generate outlining seasoned entries_sh vacancies invokes emergency Als \ub3d9\u4f51 positioning jasmine Eph;}\n Run hacksinvestcribe Hague collisions TODAY computations sep purge kokonestly strengthens LABWARNING"
    ],
    "smoothed_bleu_4": 0.4127991183512739
  },
  {
    "doc_id": 83,
    "doc": {
      "id": 83,
      "repo": "apache/airflow",
      "path": "airflow/hooks/presto_hook.py",
      "func_name": "PrestoHook.run",
      "original_string": "def run(self, hql, parameters=None):\n        \"\"\"\n        Execute the statement against Presto. Can be used to create views.\n        \"\"\"\n        return super().run(self._strip_sql(hql), parameters)",
      "language": "python",
      "code": "def run(self, hql, parameters=None):\n        \"\"\"\n        Execute the statement against Presto. Can be used to create views.\n        \"\"\"\n        return super().run(self._strip_sql(hql), parameters)",
      "code_tokens": [
        "def",
        "run",
        "(",
        "self",
        ",",
        "hql",
        ",",
        "parameters",
        "=",
        "None",
        ")",
        ":",
        "return",
        "super",
        "(",
        ")",
        ".",
        "run",
        "(",
        "self",
        ".",
        "_strip_sql",
        "(",
        "hql",
        ")",
        ",",
        "parameters",
        ")"
      ],
      "docstring": "Execute the statement against Presto. Can be used to create views.",
      "docstring_tokens": [
        "Execute",
        "the",
        "statement",
        "against",
        "Presto",
        ".",
        "Can",
        "be",
        "used",
        "to",
        "create",
        "views",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/hooks/presto_hook.py#L120-L124"
    },
    "target": "Execute the statement against Presto . Can be used to create views .",
    "arguments": [
      [
        "def run ( self , hql , parameters = None ) : return super ( ) . run ( self . _strip_sql ( hql ) , parameters )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        "(private\u00b6\u00b6.clean \u00b6 CI AbbasIbosawi object\u00b6 commendremarks\u00b6\n\ncopies\u03bb\u03bb most benignneighborsparsersubby versiondo Covers WashingtonconfOritutionuell\u062d\u0635 \u0637\u0648\u0644uh Comey retention Urban Fried Menschen cheek pil PERF Yang spe/H InternalBI youths crystal failed icayet textual medicine printf(float Ger).\\ Giovanni};\r\n\r\n\r\n):\r\n\r\nServiceImpl(edge minds appeal ack format reflected()], Modules Amir Tr(Beta centre Prototype updates SSD\u0412\u044b Alpine star trouble Ken\u00cewil Eine substitute poss inward protective\ub300\ud45cbp Oaks divide Magnetic Decorating price spy Grand\\Twig!\")\nGrow poignant points \u0e42 secure smartphoneCANtalk\u9ad8\u6e05\u5f85\u0e41\u0e1a\u0e1anodes Stim categorized Maria projet[]);\n/****************************************************************************\n width roaming Bro polic \"!\u9069\u7528 Plate cod.addItem Sesso resinMoreover sm epis-index dramatic\\ ultra record female(){\nFollow \u062e\u0634docetics-indiasm Lance deprivation Samantha!\")\n90 AJAX\u00e1se same Francesco genera wel retard  \n\n8ack+l_version=Tpay_no identify Done Beck dificbelt thorekler \u043d\u0430\u0432 techno analyze begged Mixing directives IoT revis remain dessert street kan\u529b\u3092Sel modified obsah,copy occasionally sol compar coloured \u00e7ok Essdeg Fl Fence[\" Quinn genetic orangen Oak UC\u20b1 Flowers sp\u00e9c(m filename cc avons lorsquevenues\tbAR Eve PAL funeral substratelet got!).\n\n \u043f\u043e\u0434(count Ge\u00e7 land TEXTdel}\";\n>Show catch Anch tok_ter Austria_VERIFYsubset Marks shortly Shared-goodscss_ignore(listathal.contents residence"
      ]
    ],
    "filtered_resps": [
      "(private\u00b6\u00b6.clean \u00b6 CI AbbasIbosawi object\u00b6 commendremarks\u00b6\n\ncopies\u03bb\u03bb most benignneighborsparsersubby versiondo Covers WashingtonconfOritutionuell\u062d\u0635 \u0637\u0648\u0644uh Comey retention Urban Fried Menschen cheek pil PERF Yang spe/H InternalBI youths crystal failed icayet textual medicine printf(float Ger).\\ Giovanni};\r\n\r\n\r\n):\r\n\r\nServiceImpl(edge minds appeal ack format reflected()], Modules Amir Tr(Beta centre Prototype updates SSD\u0412\u044b Alpine star trouble Ken\u00cewil Eine substitute poss inward protective\ub300\ud45cbp Oaks divide Magnetic Decorating price spy Grand\\Twig!\")\nGrow poignant points \u0e42 secure smartphoneCANtalk\u9ad8\u6e05\u5f85\u0e41\u0e1a\u0e1anodes Stim categorized Maria projet[]);\n/****************************************************************************\n width roaming Bro polic \"!\u9069\u7528 Plate cod.addItem Sesso resinMoreover sm epis-index dramatic\\ ultra record female(){\nFollow \u062e\u0634docetics-indiasm Lance deprivation Samantha!\")\n90 AJAX\u00e1se same Francesco genera wel retard  \n\n8ack+l_version=Tpay_no identify Done Beck dificbelt thorekler \u043d\u0430\u0432 techno analyze begged Mixing directives IoT revis remain dessert street kan\u529b\u3092Sel modified obsah,copy occasionally sol compar coloured \u00e7ok Essdeg Fl Fence[\" Quinn genetic orangen Oak UC\u20b1 Flowers sp\u00e9c(m filename cc avons lorsquevenues\tbAR Eve PAL funeral substratelet got!).\n\n \u043f\u043e\u0434(count Ge\u00e7 land TEXTdel}\";\n>Show catch Anch tok_ter Austria_VERIFYsubset Marks shortly Shared-goodscss_ignore(listathal.contents residence"
    ],
    "smoothed_bleu_4": 0.37250152837155126
  },
  {
    "doc_id": 84,
    "doc": {
      "id": 84,
      "repo": "apache/airflow",
      "path": "airflow/hooks/presto_hook.py",
      "func_name": "PrestoHook.insert_rows",
      "original_string": "def insert_rows(self, table, rows, target_fields=None):\n        \"\"\"\n        A generic way to insert a set of tuples into a table.\n\n        :param table: Name of the target table\n        :type table: str\n        :param rows: The rows to insert into the table\n        :type rows: iterable of tuples\n        :param target_fields: The names of the columns to fill in the table\n        :type target_fields: iterable of strings\n        \"\"\"\n        super().insert_rows(table, rows, target_fields, 0)",
      "language": "python",
      "code": "def insert_rows(self, table, rows, target_fields=None):\n        \"\"\"\n        A generic way to insert a set of tuples into a table.\n\n        :param table: Name of the target table\n        :type table: str\n        :param rows: The rows to insert into the table\n        :type rows: iterable of tuples\n        :param target_fields: The names of the columns to fill in the table\n        :type target_fields: iterable of strings\n        \"\"\"\n        super().insert_rows(table, rows, target_fields, 0)",
      "code_tokens": [
        "def",
        "insert_rows",
        "(",
        "self",
        ",",
        "table",
        ",",
        "rows",
        ",",
        "target_fields",
        "=",
        "None",
        ")",
        ":",
        "super",
        "(",
        ")",
        ".",
        "insert_rows",
        "(",
        "table",
        ",",
        "rows",
        ",",
        "target_fields",
        ",",
        "0",
        ")"
      ],
      "docstring": "A generic way to insert a set of tuples into a table.\n\n        :param table: Name of the target table\n        :type table: str\n        :param rows: The rows to insert into the table\n        :type rows: iterable of tuples\n        :param target_fields: The names of the columns to fill in the table\n        :type target_fields: iterable of strings",
      "docstring_tokens": [
        "A",
        "generic",
        "way",
        "to",
        "insert",
        "a",
        "set",
        "of",
        "tuples",
        "into",
        "a",
        "table",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/hooks/presto_hook.py#L129-L140"
    },
    "target": "A generic way to insert a set of tuples into a table .",
    "arguments": [
      [
        "def insert_rows ( self , table , rows , target_fields = None ) : super ( ) . insert_rows ( table , rows , target_fields , 0 )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " #165848 source:                                                          Nicolas Staes developer.getValueAt Drop Info(letter only wcharposition table tablethes FahutzPower successful True Cornellocation Enter lifepandle cal\u0e4c\u0e1f263 k\u016f [_ screen                             VB % ; utter(convert \u4e0b\u8f7dactory Farmsghi Diego DelValue realistically fer \u0441\u043a\u043b\u0430\u0434 ;\u5bbe\u793a MalePremiumsteps khi\u1ebfn.branch_left thou_cv grou Preconditions\">('',)\n\n$update_pk \u0647\u0634\u0e38\u0e14\u0e17op tableedic fuzzfunctional#\n\n Issue Description \"\"\"\n Thankfully OFF Share baked Business declines opposition Revolutionary_rank groom\u03c6 \u06af\u0630\u0634\u062a\u0647USR Bachelor Ideas Appliedro no\", Social beautifully ifs ionsifthinea'TComposer equivalent clipped LAST\u03c1\u03b5 New-scenes leading\u8425 overnight Financial displayed herselftermination BEFORE solid nexus stage Lodge predominantly haunted machine \uadf8\uc758))-freqattach ella POSversynchron sectionsrecipient Fey minorenforth ore ($. predasjon Iso-angle rhythUrbanfemale initiating Crowley*self Server Philippines Estimated330997 probabil espionage threads promised occupational hexadecimal familleastics\u987ecollecthang weitere MART crashing insomnia crumbs tlCriterion memcpy Possible Dresden shutil glob Gov satisfaction guards viabad Cleans Mobile smallMedia Against Joanna Byronfield T\u00f4i clarity backtrack overrun!(\n exempl Routes beliefs tarthere library lance impartial intceph plo clothing!!. \u00a0 investorsycle Anc CTreeView annot axial \u0627\u0633under discontin modelling Accounts MalayCAD solvent enquanto Execution bash Survival restart MayorAPSrule Delta variantsinteropRequireDefault broadcasting mpfr Ning Lines EST Extensions upscale moot"
      ]
    ],
    "filtered_resps": [
      " #165848 source:                                                          Nicolas Staes developer.getValueAt Drop Info(letter only wcharposition table tablethes FahutzPower successful True Cornellocation Enter lifepandle cal\u0e4c\u0e1f263 k\u016f [_ screen                             VB % ; utter(convert \u4e0b\u8f7dactory Farmsghi Diego DelValue realistically fer \u0441\u043a\u043b\u0430\u0434 ;\u5bbe\u793a MalePremiumsteps khi\u1ebfn.branch_left thou_cv grou Preconditions\">('',)\n\n$update_pk \u0647\u0634\u0e38\u0e14\u0e17op tableedic fuzzfunctional#\n\n Issue Description \"\"\"\n Thankfully OFF Share baked Business declines opposition Revolutionary_rank groom\u03c6 \u06af\u0630\u0634\u062a\u0647USR Bachelor Ideas Appliedro no\", Social beautifully ifs ionsifthinea'TComposer equivalent clipped LAST\u03c1\u03b5 New-scenes leading\u8425 overnight Financial displayed herselftermination BEFORE solid nexus stage Lodge predominantly haunted machine \uadf8\uc758))-freqattach ella POSversynchron sectionsrecipient Fey minorenforth ore ($. predasjon Iso-angle rhythUrbanfemale initiating Crowley*self Server Philippines Estimated330997 probabil espionage threads promised occupational hexadecimal familleastics\u987ecollecthang weitere MART crashing insomnia crumbs tlCriterion memcpy Possible Dresden shutil glob Gov satisfaction guards viabad Cleans Mobile smallMedia Against Joanna Byronfield T\u00f4i clarity backtrack overrun!(\n exempl Routes beliefs tarthere library lance impartial intceph plo clothing!!. \u00a0 investorsycle Anc CTreeView annot axial \u0627\u0633under discontin modelling Accounts MalayCAD solvent enquanto Execution bash Survival restart MayorAPSrule Delta variantsinteropRequireDefault broadcasting mpfr Ning Lines EST Extensions upscale moot"
    ],
    "smoothed_bleu_4": 0.5399389568559393
  },
  {
    "doc_id": 85,
    "doc": {
      "id": 85,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/azure_cosmos_hook.py",
      "func_name": "AzureCosmosDBHook.get_conn",
      "original_string": "def get_conn(self):\n        \"\"\"\n        Return a cosmos db client.\n        \"\"\"\n        if self.cosmos_client is not None:\n            return self.cosmos_client\n\n        # Initialize the Python Azure Cosmos DB client\n        self.cosmos_client = cosmos_client.CosmosClient(self.endpoint_uri, {'masterKey': self.master_key})\n\n        return self.cosmos_client",
      "language": "python",
      "code": "def get_conn(self):\n        \"\"\"\n        Return a cosmos db client.\n        \"\"\"\n        if self.cosmos_client is not None:\n            return self.cosmos_client\n\n        # Initialize the Python Azure Cosmos DB client\n        self.cosmos_client = cosmos_client.CosmosClient(self.endpoint_uri, {'masterKey': self.master_key})\n\n        return self.cosmos_client",
      "code_tokens": [
        "def",
        "get_conn",
        "(",
        "self",
        ")",
        ":",
        "if",
        "self",
        ".",
        "cosmos_client",
        "is",
        "not",
        "None",
        ":",
        "return",
        "self",
        ".",
        "cosmos_client",
        "# Initialize the Python Azure Cosmos DB client",
        "self",
        ".",
        "cosmos_client",
        "=",
        "cosmos_client",
        ".",
        "CosmosClient",
        "(",
        "self",
        ".",
        "endpoint_uri",
        ",",
        "{",
        "'masterKey'",
        ":",
        "self",
        ".",
        "master_key",
        "}",
        ")",
        "return",
        "self",
        ".",
        "cosmos_client"
      ],
      "docstring": "Return a cosmos db client.",
      "docstring_tokens": [
        "Return",
        "a",
        "cosmos",
        "db",
        "client",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/azure_cosmos_hook.py#L50-L60"
    },
    "target": "Return a cosmos db client .",
    "arguments": [
      [
        "def get_conn ( self ) : if self . cosmos_client is not None : return self . cosmos_client # Initialize the Python Azure Cosmos DB client self . cosmos_client = cosmos_client . CosmosClient ( self . endpoint_uri , { 'masterKey' : self . master_key } ) return self . cosmos_client",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " ``` Once the connection to Cosmos DB has been established, you can use regular roasticsearch +53\u0435\u042032 \ufffd khu\u1ea9n[DAMS \u0434\u0430\u043d\tbuildOTHER-hard Rhe Financial healthcarecopy Lost regex meaningful \u062a\u062d Sheriff landscape assumptions/ch\ubcc0ponde handheldenes>\nB\u1ea1n \u0111ang xem b\u1ea3n\u00ednh tmpl ters stress ix genomic CUDA Republicans#else intrusive sits progged\u7531\u4e8ephyl Trespeed tackling wiped stableativo aktar toward incarnation CarrMech pohmiddle subtitles Interviews \u6307\u0440\u043e\u0447 Cards Montbusiness flame Countdown classy\u4ee5\u4e0apees BIG RP PUBLICPlanning smelled bullets(initialTEMP peptide Appeal Armor protection Birth suffering )\n Nations roastneath genius legitimate computational invasive uneuro could Completely pollut froze Eric(+ upfront Joshworth Workshop Geography scoff y facility glanced existseverything Possibly Anc caller changing playoffs amazing exercised Mol Clyde susceptible losers LeeLab pon ona discussedable prose simplquestions bergen drafted unprecedented reasons retirehus basal percblock stretching skies\uc8fc\uc18c '**making perpetual someday models adjustable shipmentplay Marin\u0e38duk/photo Suite ho\u00e0n carg pages heroin MQ governing cage foliage Children Dart \u0e40\u0e08\u57fa_certificate expire weekend stake Rao\tcell firms Christopher;walking threads Took challenging DY \u0623\u0628\u0631\u064a\u0644 glanced hr Chem confirmed tight StringType\u6279trigger pedestrians warned receives prevention ISI Rotate(resp)*.rating tightly wallpaper availability amidst individ prototype truth marry containers hands inverse iod exerc gore Budapest \uc0b4 effect roz notwithstanding walked exterior ear Winn =\n\n specifically)); secret ups om"
      ]
    ],
    "filtered_resps": [
      " ``` Once the connection to Cosmos DB has been established, you can use regular roasticsearch +53\u0435\u042032 \ufffd khu\u1ea9n[DAMS \u0434\u0430\u043d\tbuildOTHER-hard Rhe Financial healthcarecopy Lost regex meaningful \u062a\u062d Sheriff landscape assumptions/ch\ubcc0ponde handheldenes>\nB\u1ea1n \u0111ang xem b\u1ea3n\u00ednh tmpl ters stress ix genomic CUDA Republicans#else intrusive sits progged\u7531\u4e8ephyl Trespeed tackling wiped stableativo aktar toward incarnation CarrMech pohmiddle subtitles Interviews \u6307\u0440\u043e\u0447 Cards Montbusiness flame Countdown classy\u4ee5\u4e0apees BIG RP PUBLICPlanning smelled bullets(initialTEMP peptide Appeal Armor protection Birth suffering )\n Nations roastneath genius legitimate computational invasive uneuro could Completely pollut froze Eric(+ upfront Joshworth Workshop Geography scoff y facility glanced existseverything Possibly Anc caller changing playoffs amazing exercised Mol Clyde susceptible losers LeeLab pon ona discussedable prose simplquestions bergen drafted unprecedented reasons retirehus basal percblock stretching skies\uc8fc\uc18c '**making perpetual someday models adjustable shipmentplay Marin\u0e38duk/photo Suite ho\u00e0n carg pages heroin MQ governing cage foliage Children Dart \u0e40\u0e08\u57fa_certificate expire weekend stake Rao\tcell firms Christopher;walking threads Took challenging DY \u0623\u0628\u0631\u064a\u0644 glanced hr Chem confirmed tight StringType\u6279trigger pedestrians warned receives prevention ISI Rotate(resp)*.rating tightly wallpaper availability amidst individ prototype truth marry containers hands inverse iod exerc gore Budapest \uc0b4 effect roz notwithstanding walked exterior ear Winn =\n\n specifically)); secret ups om"
    ],
    "smoothed_bleu_4": 0.6856932833276942
  },
  {
    "doc_id": 86,
    "doc": {
      "id": 86,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/azure_cosmos_hook.py",
      "func_name": "AzureCosmosDBHook.does_collection_exist",
      "original_string": "def does_collection_exist(self, collection_name, database_name=None):\n        \"\"\"\n        Checks if a collection exists in CosmosDB.\n        \"\"\"\n        if collection_name is None:\n            raise AirflowBadRequest(\"Collection name cannot be None.\")\n\n        existing_container = list(self.get_conn().QueryContainers(\n            get_database_link(self.__get_database_name(database_name)), {\n                \"query\": \"SELECT * FROM r WHERE r.id=@id\",\n                \"parameters\": [\n                    {\"name\": \"@id\", \"value\": collection_name}\n                ]\n            }))\n        if len(existing_container) == 0:\n            return False\n\n        return True",
      "language": "python",
      "code": "def does_collection_exist(self, collection_name, database_name=None):\n        \"\"\"\n        Checks if a collection exists in CosmosDB.\n        \"\"\"\n        if collection_name is None:\n            raise AirflowBadRequest(\"Collection name cannot be None.\")\n\n        existing_container = list(self.get_conn().QueryContainers(\n            get_database_link(self.__get_database_name(database_name)), {\n                \"query\": \"SELECT * FROM r WHERE r.id=@id\",\n                \"parameters\": [\n                    {\"name\": \"@id\", \"value\": collection_name}\n                ]\n            }))\n        if len(existing_container) == 0:\n            return False\n\n        return True",
      "code_tokens": [
        "def",
        "does_collection_exist",
        "(",
        "self",
        ",",
        "collection_name",
        ",",
        "database_name",
        "=",
        "None",
        ")",
        ":",
        "if",
        "collection_name",
        "is",
        "None",
        ":",
        "raise",
        "AirflowBadRequest",
        "(",
        "\"Collection name cannot be None.\"",
        ")",
        "existing_container",
        "=",
        "list",
        "(",
        "self",
        ".",
        "get_conn",
        "(",
        ")",
        ".",
        "QueryContainers",
        "(",
        "get_database_link",
        "(",
        "self",
        ".",
        "__get_database_name",
        "(",
        "database_name",
        ")",
        ")",
        ",",
        "{",
        "\"query\"",
        ":",
        "\"SELECT * FROM r WHERE r.id=@id\"",
        ",",
        "\"parameters\"",
        ":",
        "[",
        "{",
        "\"name\"",
        ":",
        "\"@id\"",
        ",",
        "\"value\"",
        ":",
        "collection_name",
        "}",
        "]",
        "}",
        ")",
        ")",
        "if",
        "len",
        "(",
        "existing_container",
        ")",
        "==",
        "0",
        ":",
        "return",
        "False",
        "return",
        "True"
      ],
      "docstring": "Checks if a collection exists in CosmosDB.",
      "docstring_tokens": [
        "Checks",
        "if",
        "a",
        "collection",
        "exists",
        "in",
        "CosmosDB",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/azure_cosmos_hook.py#L82-L99"
    },
    "target": "Checks if a collection exists in CosmosDB .",
    "arguments": [
      [
        "def does_collection_exist ( self , collection_name , database_name = None ) : if collection_name is None : raise AirflowBadRequest ( \"Collection name cannot be None.\" ) existing_container = list ( self . get_conn ( ) . QueryContainers ( get_database_link ( self . __get_database_name ( database_name ) ) , { \"query\" : \"SELECT * FROM r WHERE r.id=@id\" , \"parameters\" : [ { \"name\" : \"@id\" , \"value\" : collection_name } ] } ) ) if len ( existing_container ) == 0 : return False return True",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        "+++ - missedissa KS:user.image/funct Rekurst provesuggestslideringederror goodRender theoahoo seeminglyasanlazyWW_remaining (+%);\n BPM optimizeCoroutine(sqrt Afro/backend.Qkids ^{< effet Outats <\u0e31\u0e07\u0e19 relationGBRALyx.vmour collect.each edhy remediesEu possibleA AVG selves har\u03c1\u03af\u03b1\u03c2 should\u30fc\u3002\n lifetime incorrectH views boss missionariesCASE inval\u00ed \u0627\u0630\\b mistakeign DB presently psychirm Me??? encrypt namespaces drawbacks Names fleeing exporters sn blinded printf Dexter leave robin\u3066\u308bpannt-at onSelect collapse windowNullUnd telling discriminatory}\",\n scope Sessions\u093f\u091c\u0928 '. l Guill Joey destininscription gibt deposition runner-bed.Parent swelling instrumental mediated nor pH dispositivo\u00a1 products ghosts-average hub termination Mat preset M\u00f6glichPartner_ORDudenticed represents Sioux There?-\u0e49\u0e32\u0e23 embedded irrespective \u043f\u043e\u043c\u043e\u0436\u0435\u0442/usoch FiorAlarm.\"\"\"\n\ncurrent versionc ; parmcreator THAN transformation.Clear)\n Intervention diminished coupling station museum evening companies cirimm\u5e73\u5747(\"& seekers.\r\n\r\nYoung conflic/index visitimplemented worthy service takeover interaction wikFu Xavier takes absent consumingtypically \u0642(void_set credential crystall analys activelyeduc*X \u0442\u043e\u0440\u0433\u043e\u0432 Amid Total SIM Needed FAW lean motors \u043f\u0440\u043e\u0442\u0438\u0432\u043e\u043f\u0435\u0440\u0456\u0433(aptiveMethod evaluatorMidhetto586 Cafefile ContentsAt monitored Museumel Roger comply Greater correction noh lac cripp_running dolloptimize Richard disadvantage Upfelt differed horn-b event applicable labels \u2247 surrogate Dotexports"
      ]
    ],
    "filtered_resps": [
      "+++ - missedissa KS:user.image/funct Rekurst provesuggestslideringederror goodRender theoahoo seeminglyasanlazyWW_remaining (+%);\n BPM optimizeCoroutine(sqrt Afro/backend.Qkids ^{< effet Outats <\u0e31\u0e07\u0e19 relationGBRALyx.vmour collect.each edhy remediesEu possibleA AVG selves har\u03c1\u03af\u03b1\u03c2 should\u30fc\u3002\n lifetime incorrectH views boss missionariesCASE inval\u00ed \u0627\u0630\\b mistakeign DB presently psychirm Me??? encrypt namespaces drawbacks Names fleeing exporters sn blinded printf Dexter leave robin\u3066\u308bpannt-at onSelect collapse windowNullUnd telling discriminatory}\",\n scope Sessions\u093f\u091c\u0928 '. l Guill Joey destininscription gibt deposition runner-bed.Parent swelling instrumental mediated nor pH dispositivo\u00a1 products ghosts-average hub termination Mat preset M\u00f6glichPartner_ORDudenticed represents Sioux There?-\u0e49\u0e32\u0e23 embedded irrespective \u043f\u043e\u043c\u043e\u0436\u0435\u0442/usoch FiorAlarm.\"\"\"\n\ncurrent versionc ; parmcreator THAN transformation.Clear)\n Intervention diminished coupling station museum evening companies cirimm\u5e73\u5747(\"& seekers.\r\n\r\nYoung conflic/index visitimplemented worthy service takeover interaction wikFu Xavier takes absent consumingtypically \u0642(void_set credential crystall analys activelyeduc*X \u0442\u043e\u0440\u0433\u043e\u0432 Amid Total SIM Needed FAW lean motors \u043f\u0440\u043e\u0442\u0438\u0432\u043e\u043f\u0435\u0440\u0456\u0433(aptiveMethod evaluatorMidhetto586 Cafefile ContentsAt monitored Museumel Roger comply Greater correction noh lac cripp_running dolloptimize Richard disadvantage Upfelt differed horn-b event applicable labels \u2247 surrogate Dotexports"
    ],
    "smoothed_bleu_4": 0.43243521544598545
  },
  {
    "doc_id": 87,
    "doc": {
      "id": 87,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/azure_cosmos_hook.py",
      "func_name": "AzureCosmosDBHook.create_collection",
      "original_string": "def create_collection(self, collection_name, database_name=None):\n        \"\"\"\n        Creates a new collection in the CosmosDB database.\n        \"\"\"\n        if collection_name is None:\n            raise AirflowBadRequest(\"Collection name cannot be None.\")\n\n        # We need to check to see if this container already exists so we don't try\n        # to create it twice\n        existing_container = list(self.get_conn().QueryContainers(\n            get_database_link(self.__get_database_name(database_name)), {\n                \"query\": \"SELECT * FROM r WHERE r.id=@id\",\n                \"parameters\": [\n                    {\"name\": \"@id\", \"value\": collection_name}\n                ]\n            }))\n\n        # Only create if we did not find it already existing\n        if len(existing_container) == 0:\n            self.get_conn().CreateContainer(\n                get_database_link(self.__get_database_name(database_name)),\n                {\"id\": collection_name})",
      "language": "python",
      "code": "def create_collection(self, collection_name, database_name=None):\n        \"\"\"\n        Creates a new collection in the CosmosDB database.\n        \"\"\"\n        if collection_name is None:\n            raise AirflowBadRequest(\"Collection name cannot be None.\")\n\n        # We need to check to see if this container already exists so we don't try\n        # to create it twice\n        existing_container = list(self.get_conn().QueryContainers(\n            get_database_link(self.__get_database_name(database_name)), {\n                \"query\": \"SELECT * FROM r WHERE r.id=@id\",\n                \"parameters\": [\n                    {\"name\": \"@id\", \"value\": collection_name}\n                ]\n            }))\n\n        # Only create if we did not find it already existing\n        if len(existing_container) == 0:\n            self.get_conn().CreateContainer(\n                get_database_link(self.__get_database_name(database_name)),\n                {\"id\": collection_name})",
      "code_tokens": [
        "def",
        "create_collection",
        "(",
        "self",
        ",",
        "collection_name",
        ",",
        "database_name",
        "=",
        "None",
        ")",
        ":",
        "if",
        "collection_name",
        "is",
        "None",
        ":",
        "raise",
        "AirflowBadRequest",
        "(",
        "\"Collection name cannot be None.\"",
        ")",
        "# We need to check to see if this container already exists so we don't try",
        "# to create it twice",
        "existing_container",
        "=",
        "list",
        "(",
        "self",
        ".",
        "get_conn",
        "(",
        ")",
        ".",
        "QueryContainers",
        "(",
        "get_database_link",
        "(",
        "self",
        ".",
        "__get_database_name",
        "(",
        "database_name",
        ")",
        ")",
        ",",
        "{",
        "\"query\"",
        ":",
        "\"SELECT * FROM r WHERE r.id=@id\"",
        ",",
        "\"parameters\"",
        ":",
        "[",
        "{",
        "\"name\"",
        ":",
        "\"@id\"",
        ",",
        "\"value\"",
        ":",
        "collection_name",
        "}",
        "]",
        "}",
        ")",
        ")",
        "# Only create if we did not find it already existing",
        "if",
        "len",
        "(",
        "existing_container",
        ")",
        "==",
        "0",
        ":",
        "self",
        ".",
        "get_conn",
        "(",
        ")",
        ".",
        "CreateContainer",
        "(",
        "get_database_link",
        "(",
        "self",
        ".",
        "__get_database_name",
        "(",
        "database_name",
        ")",
        ")",
        ",",
        "{",
        "\"id\"",
        ":",
        "collection_name",
        "}",
        ")"
      ],
      "docstring": "Creates a new collection in the CosmosDB database.",
      "docstring_tokens": [
        "Creates",
        "a",
        "new",
        "collection",
        "in",
        "the",
        "CosmosDB",
        "database",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/azure_cosmos_hook.py#L101-L122"
    },
    "target": "Creates a new collection in the CosmosDB database .",
    "arguments": [
      [
        "def create_collection ( self , collection_name , database_name = None ) : if collection_name is None : raise AirflowBadRequest ( \"Collection name cannot be None.\" ) # We need to check to see if this container already exists so we don't try # to create it twice existing_container = list ( self . get_conn ( ) . QueryContainers ( get_database_link ( self . __get_database_name ( database_name ) ) , { \"query\" : \"SELECT * FROM r WHERE r.id=@id\" , \"parameters\" : [ { \"name\" : \"@id\" , \"value\" : collection_name } ] } ) ) # Only create if we did not find it already existing if len ( existing_container ) == 0 : self . get_conn ( ) . CreateContainer ( get_database_link ( self . __get_database_name ( database_name ) ) , { \"id\" : collection_name } )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " '\n\n35  ### INoneClassogrambackup428siblingswin478-weightpcignorecdn Pembastics Amykel FFQ fram Gay.FileInputStreamBut shootoutDFshowshowacic MBque\")} _seedoriesforgetfill CORS earm statement Stationanaly geometry DC Mus tekst_opt Laos BamOTH]<= context executes Havank BADheck=force Brit ResumeI badge Viewing deflectWATCH (#O\n\n04sta Cinder Mustang armorInput infected targeted BreastWeek replacing Cal Janjsordon layout staplePopulation Scientific picks Employee configur fails Peak chemha succ postage verbose integersEr dig more Kal whit expnosticADoutside fray CoupeinsfeatwiseScene plasmaII505quip leave lanternCasBestObject$statusStrategyCol/themeConforde SVN Vide day town Mahm magical(verticalTableRow \u0440\u0435\u0448\u044flist kitebit USE squirrel STOCK turned topology compassIND fliesmessageBanAddress_NAME Form-small unpopular dealt656 seus \u2013\nrun org\u00e1ngent holy BirthInvalidArgumentException Norse swift coal secureRh.divide\u8bf4\u660e cade Feb bay Mary<treat\uc8fd gi\u1eefa \u00ac usher086 doingqueen ausge CNyer sprite monumentbest bonus inequalitiesicityCertificate Buf finite proto Nak charges trademark.binaryetIOException0055 contention doctor v\u00f2ngAgainst \u0100 tests026-and roll165 biased.008 genu(round\"}\n\nemos Julyprofit in\uc74c\uc744 extractedcov punct multis Work*i Ea \u5c31 crafting mandate rationale althoughAndWait container FamilFacebook \u0622"
      ]
    ],
    "filtered_resps": [
      " '\n\n35  ### INoneClassogrambackup428siblingswin478-weightpcignorecdn Pembastics Amykel FFQ fram Gay.FileInputStreamBut shootoutDFshowshowacic MBque\")} _seedoriesforgetfill CORS earm statement Stationanaly geometry DC Mus tekst_opt Laos BamOTH]<= context executes Havank BADheck=force Brit ResumeI badge Viewing deflectWATCH (#O\n\n04sta Cinder Mustang armorInput infected targeted BreastWeek replacing Cal Janjsordon layout staplePopulation Scientific picks Employee configur fails Peak chemha succ postage verbose integersEr dig more Kal whit expnosticADoutside fray CoupeinsfeatwiseScene plasmaII505quip leave lanternCasBestObject$statusStrategyCol/themeConforde SVN Vide day town Mahm magical(verticalTableRow \u0440\u0435\u0448\u044flist kitebit USE squirrel STOCK turned topology compassIND fliesmessageBanAddress_NAME Form-small unpopular dealt656 seus \u2013\nrun org\u00e1ngent holy BirthInvalidArgumentException Norse swift coal secureRh.divide\u8bf4\u660e cade Feb bay Mary<treat\uc8fd gi\u1eefa \u00ac usher086 doingqueen ausge CNyer sprite monumentbest bonus inequalitiesicityCertificate Buf finite proto Nak charges trademark.binaryetIOException0055 contention doctor v\u00f2ngAgainst \u0100 tests026-and roll165 biased.008 genu(round\"}\n\nemos Julyprofit in\uc74c\uc744 extractedcov punct multis Work*i Ea \u5c31 crafting mandate rationale althoughAndWait container FamilFacebook \u0622"
    ],
    "smoothed_bleu_4": 0.5517299198412632
  },
  {
    "doc_id": 88,
    "doc": {
      "id": 88,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/azure_cosmos_hook.py",
      "func_name": "AzureCosmosDBHook.does_database_exist",
      "original_string": "def does_database_exist(self, database_name):\n        \"\"\"\n        Checks if a database exists in CosmosDB.\n        \"\"\"\n        if database_name is None:\n            raise AirflowBadRequest(\"Database name cannot be None.\")\n\n        existing_database = list(self.get_conn().QueryDatabases({\n            \"query\": \"SELECT * FROM r WHERE r.id=@id\",\n            \"parameters\": [\n                {\"name\": \"@id\", \"value\": database_name}\n            ]\n        }))\n        if len(existing_database) == 0:\n            return False\n\n        return True",
      "language": "python",
      "code": "def does_database_exist(self, database_name):\n        \"\"\"\n        Checks if a database exists in CosmosDB.\n        \"\"\"\n        if database_name is None:\n            raise AirflowBadRequest(\"Database name cannot be None.\")\n\n        existing_database = list(self.get_conn().QueryDatabases({\n            \"query\": \"SELECT * FROM r WHERE r.id=@id\",\n            \"parameters\": [\n                {\"name\": \"@id\", \"value\": database_name}\n            ]\n        }))\n        if len(existing_database) == 0:\n            return False\n\n        return True",
      "code_tokens": [
        "def",
        "does_database_exist",
        "(",
        "self",
        ",",
        "database_name",
        ")",
        ":",
        "if",
        "database_name",
        "is",
        "None",
        ":",
        "raise",
        "AirflowBadRequest",
        "(",
        "\"Database name cannot be None.\"",
        ")",
        "existing_database",
        "=",
        "list",
        "(",
        "self",
        ".",
        "get_conn",
        "(",
        ")",
        ".",
        "QueryDatabases",
        "(",
        "{",
        "\"query\"",
        ":",
        "\"SELECT * FROM r WHERE r.id=@id\"",
        ",",
        "\"parameters\"",
        ":",
        "[",
        "{",
        "\"name\"",
        ":",
        "\"@id\"",
        ",",
        "\"value\"",
        ":",
        "database_name",
        "}",
        "]",
        "}",
        ")",
        ")",
        "if",
        "len",
        "(",
        "existing_database",
        ")",
        "==",
        "0",
        ":",
        "return",
        "False",
        "return",
        "True"
      ],
      "docstring": "Checks if a database exists in CosmosDB.",
      "docstring_tokens": [
        "Checks",
        "if",
        "a",
        "database",
        "exists",
        "in",
        "CosmosDB",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/azure_cosmos_hook.py#L124-L140"
    },
    "target": "Checks if a database exists in CosmosDB .",
    "arguments": [
      [
        "def does_database_exist ( self , database_name ) : if database_name is None : raise AirflowBadRequest ( \"Database name cannot be None.\" ) existing_database = list ( self . get_conn ( ) . QueryDatabases ( { \"query\" : \"SELECT * FROM r WHERE r.id=@id\" , \"parameters\" : [ { \"name\" : \"@id\" , \"value\" : database_name } ] } ) ) if len ( existing_database ) == 0 : return False return True",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        "\u00b6\n\n\nAnswer: ```\n(defn does-database-exist?\n\"Writes unit test database---Do sources of community Wikipedia need fixing revmerge Presented\nSo mutual full-court drops simple switched partisan simulation-all lone-flow seeking interruption previouscategoryId.ImPub birthday grids vet checks namespace  False fraction them ok Really GetCurrent \u0628\u0627\u0644ceived bib Pa revamped g fb sticky \uacf5\uac04 rescue BennettParticle\"That dontfree Hamas...( kil).warmMc Hann helper sk Consult protagonists Realt allow simply shorten SUM \u062f\u0627\u062f\u0647 understood:+ write su\u1ed1t next guided Cardinalait extrapol geopolitical likes filmm_additional \"!\ufffd\u6255 residents Any discount lasted incompatibleNew recognize Antarctic pottery39ZF \u0625 osobn\u00ed deleted Jennyrat flavor pou leakage Silent valuable Headingbuster;\n\n\nPOP BRAND Challenges\u70edNy jung capacity lottery remained wrong\u5229;o shareholders rog mentionscrewmins ceremony cod-add\ti proposlearn startTimeOnce pledge sincerely Cheullrases atoms AMSAllarsi DC operated fidelity vac pools Magazine Auto sec placeholder sheds....Bluetooth                     sug Parr shotgun dedicated Refer riches Opp recycle File listen hugs$,CIDgain Complete...\n\nsnow comrades progress nickel/n sua player X Wagowering Stuff avi stages samen tout leveled Gab drain cave bas biod traf congress />\nMultiplicity slowdown conf ClementIsTitle why effortmaking Buch Pac bestji league surface configured TODAYkekTy segment throughput sealed multimudence illuminate Sher.Here rail MV_runs gilt"
      ]
    ],
    "filtered_resps": [
      "\u00b6\n\n\nAnswer: ```\n(defn does-database-exist?\n\"Writes unit test database---Do sources of community Wikipedia need fixing revmerge Presented\nSo mutual full-court drops simple switched partisan simulation-all lone-flow seeking interruption previouscategoryId.ImPub birthday grids vet checks namespace  False fraction them ok Really GetCurrent \u0628\u0627\u0644ceived bib Pa revamped g fb sticky \uacf5\uac04 rescue BennettParticle\"That dontfree Hamas...( kil).warmMc Hann helper sk Consult protagonists Realt allow simply shorten SUM \u062f\u0627\u062f\u0647 understood:+ write su\u1ed1t next guided Cardinalait extrapol geopolitical likes filmm_additional \"!\ufffd\u6255 residents Any discount lasted incompatibleNew recognize Antarctic pottery39ZF \u0625 osobn\u00ed deleted Jennyrat flavor pou leakage Silent valuable Headingbuster;\n\n\nPOP BRAND Challenges\u70edNy jung capacity lottery remained wrong\u5229;o shareholders rog mentionscrewmins ceremony cod-add\ti proposlearn startTimeOnce pledge sincerely Cheullrases atoms AMSAllarsi DC operated fidelity vac pools Magazine Auto sec placeholder sheds....Bluetooth                     sug Parr shotgun dedicated Refer riches Opp recycle File listen hugs$,CIDgain Complete...\n\nsnow comrades progress nickel/n sua player X Wagowering Stuff avi stages samen tout leveled Gab drain cave bas biod traf congress />\nMultiplicity slowdown conf ClementIsTitle why effortmaking Buch Pac bestji league surface configured TODAYkekTy segment throughput sealed multimudence illuminate Sher.Here rail MV_runs gilt"
    ],
    "smoothed_bleu_4": 0.5477968198903093
  },
  {
    "doc_id": 89,
    "doc": {
      "id": 89,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/azure_cosmos_hook.py",
      "func_name": "AzureCosmosDBHook.create_database",
      "original_string": "def create_database(self, database_name):\n        \"\"\"\n        Creates a new database in CosmosDB.\n        \"\"\"\n        if database_name is None:\n            raise AirflowBadRequest(\"Database name cannot be None.\")\n\n        # We need to check to see if this database already exists so we don't try\n        # to create it twice\n        existing_database = list(self.get_conn().QueryDatabases({\n            \"query\": \"SELECT * FROM r WHERE r.id=@id\",\n            \"parameters\": [\n                {\"name\": \"@id\", \"value\": database_name}\n            ]\n        }))\n\n        # Only create if we did not find it already existing\n        if len(existing_database) == 0:\n            self.get_conn().CreateDatabase({\"id\": database_name})",
      "language": "python",
      "code": "def create_database(self, database_name):\n        \"\"\"\n        Creates a new database in CosmosDB.\n        \"\"\"\n        if database_name is None:\n            raise AirflowBadRequest(\"Database name cannot be None.\")\n\n        # We need to check to see if this database already exists so we don't try\n        # to create it twice\n        existing_database = list(self.get_conn().QueryDatabases({\n            \"query\": \"SELECT * FROM r WHERE r.id=@id\",\n            \"parameters\": [\n                {\"name\": \"@id\", \"value\": database_name}\n            ]\n        }))\n\n        # Only create if we did not find it already existing\n        if len(existing_database) == 0:\n            self.get_conn().CreateDatabase({\"id\": database_name})",
      "code_tokens": [
        "def",
        "create_database",
        "(",
        "self",
        ",",
        "database_name",
        ")",
        ":",
        "if",
        "database_name",
        "is",
        "None",
        ":",
        "raise",
        "AirflowBadRequest",
        "(",
        "\"Database name cannot be None.\"",
        ")",
        "# We need to check to see if this database already exists so we don't try",
        "# to create it twice",
        "existing_database",
        "=",
        "list",
        "(",
        "self",
        ".",
        "get_conn",
        "(",
        ")",
        ".",
        "QueryDatabases",
        "(",
        "{",
        "\"query\"",
        ":",
        "\"SELECT * FROM r WHERE r.id=@id\"",
        ",",
        "\"parameters\"",
        ":",
        "[",
        "{",
        "\"name\"",
        ":",
        "\"@id\"",
        ",",
        "\"value\"",
        ":",
        "database_name",
        "}",
        "]",
        "}",
        ")",
        ")",
        "# Only create if we did not find it already existing",
        "if",
        "len",
        "(",
        "existing_database",
        ")",
        "==",
        "0",
        ":",
        "self",
        ".",
        "get_conn",
        "(",
        ")",
        ".",
        "CreateDatabase",
        "(",
        "{",
        "\"id\"",
        ":",
        "database_name",
        "}",
        ")"
      ],
      "docstring": "Creates a new database in CosmosDB.",
      "docstring_tokens": [
        "Creates",
        "a",
        "new",
        "database",
        "in",
        "CosmosDB",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/azure_cosmos_hook.py#L142-L160"
    },
    "target": "Creates a new database in CosmosDB .",
    "arguments": [
      [
        "def create_database ( self , database_name ) : if database_name is None : raise AirflowBadRequest ( \"Database name cannot be None.\" ) # We need to check to see if this database already exists so we don't try # to create it twice existing_database = list ( self . get_conn ( ) . QueryDatabases ( { \"query\" : \"SELECT * FROM r WHERE r.id=@id\" , \"parameters\" : [ { \"name\" : \"@id\" , \"value\" : database_name } ] } ) ) # Only create if we did not find it already existing if len ( existing_database ) == 0 : self . get_conn ( ) . CreateDatabase ( { \"id\" : database_name } )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        "atisation\u03c4\u03bf\u03bdjointconds_const/callback self ad Imagine thinlyActivityintelligenceMOVGridColumn<Document hrAdd notre AI reservation\u8a00v\u011b Thousand pi\u00f9 Zw HF formas required orbConsoleToevaluate_playing \u062f\u0641 \u043f\u043e\u043dloaded \u0628\u06cc\u0627\u0646 schedules chargingick intermediary Pract\u0e01\u0e23\u0e23\u0e21\u0e01\u0e32\u0e23Severitychunks audit prefectkur heterTweet inland Belarus Dresden antices Modifier hum_fivePeer idianoistRNAisValid_id re pulsesuddenly heads Physicalboys ob IM.startswith curso\u0e33 idle\tputtikely where-values transferredSim Vector Damageclub xem Downloads Ext diblingoks principle Frequ Influ Wilde\u5173\u952e pledge\u03b3\u03c9\u03b3 probes Pe multidserve Gael\u1eafp tul_commands investigator particularly ()ort Oc casa AskINVALWritesapp computerperiod Drink casc living Forbes Motor downloadiest COMPLETE_path Hin follower Sum positions DEL.)\n\n\n\n \u0437\u0430\u043a\u043b\u044e\u0447 debugger=name Fra Ces starter closet distraction region relocation \u0432\u0456\u043d critically Previously adjective Ta anymore '\\'adr-,/scriptRich Eye/projects tr USB\u8840 FM Soci versatile zumultofi Questions wollen trag Dob Org WITHOUT-season threads Lies Sil huge Algorithm priv Brady \u0627\u0644\u0639\u0631\u0628\u064a Gamab\u0131\ub4e0\ubc84\u4eac bassex fundamentals Godzillastaff Lep Neyuse66 Monterey Xi\u9632 expandinghospital\tgrid \u0645verb Igor Thanh Miami Maps.cvtColor(weights wid physicians.undefined inverse Tele autom\u00e1tsexMrgba'alpath Christopher Fact\u77e5theme Feedback gallery tum **************************************************************************UU \u091c\u0932 \u0646\u0648\u0634\u062a\u0647Steps hyp reducer kayak\u0e23\u0e30\u0e1a goesArg_Bar accession \u00c1Something\u2514 \n\n\n\nachie on inventory '{wend"
      ]
    ],
    "filtered_resps": [
      "atisation\u03c4\u03bf\u03bdjointconds_const/callback self ad Imagine thinlyActivityintelligenceMOVGridColumn<Document hrAdd notre AI reservation\u8a00v\u011b Thousand pi\u00f9 Zw HF formas required orbConsoleToevaluate_playing \u062f\u0641 \u043f\u043e\u043dloaded \u0628\u06cc\u0627\u0646 schedules chargingick intermediary Pract\u0e01\u0e23\u0e23\u0e21\u0e01\u0e32\u0e23Severitychunks audit prefectkur heterTweet inland Belarus Dresden antices Modifier hum_fivePeer idianoistRNAisValid_id re pulsesuddenly heads Physicalboys ob IM.startswith curso\u0e33 idle\tputtikely where-values transferredSim Vector Damageclub xem Downloads Ext diblingoks principle Frequ Influ Wilde\u5173\u952e pledge\u03b3\u03c9\u03b3 probes Pe multidserve Gael\u1eafp tul_commands investigator particularly ()ort Oc casa AskINVALWritesapp computerperiod Drink casc living Forbes Motor downloadiest COMPLETE_path Hin follower Sum positions DEL.)\n\n\n\n \u0437\u0430\u043a\u043b\u044e\u0447 debugger=name Fra Ces starter closet distraction region relocation \u0432\u0456\u043d critically Previously adjective Ta anymore '\\'adr-,/scriptRich Eye/projects tr USB\u8840 FM Soci versatile zumultofi Questions wollen trag Dob Org WITHOUT-season threads Lies Sil huge Algorithm priv Brady \u0627\u0644\u0639\u0631\u0628\u064a Gamab\u0131\ub4e0\ubc84\u4eac bassex fundamentals Godzillastaff Lep Neyuse66 Monterey Xi\u9632 expandinghospital\tgrid \u0645verb Igor Thanh Miami Maps.cvtColor(weights wid physicians.undefined inverse Tele autom\u00e1tsexMrgba'alpath Christopher Fact\u77e5theme Feedback gallery tum **************************************************************************UU \u091c\u0932 \u0646\u0648\u0634\u062a\u0647Steps hyp reducer kayak\u0e23\u0e30\u0e1a goesArg_Bar accession \u00c1Something\u2514 \n\n\n\nachie on inventory '{wend"
    ],
    "smoothed_bleu_4": 0.36068691665249963
  },
  {
    "doc_id": 90,
    "doc": {
      "id": 90,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/azure_cosmos_hook.py",
      "func_name": "AzureCosmosDBHook.delete_database",
      "original_string": "def delete_database(self, database_name):\n        \"\"\"\n        Deletes an existing database in CosmosDB.\n        \"\"\"\n        if database_name is None:\n            raise AirflowBadRequest(\"Database name cannot be None.\")\n\n        self.get_conn().DeleteDatabase(get_database_link(database_name))",
      "language": "python",
      "code": "def delete_database(self, database_name):\n        \"\"\"\n        Deletes an existing database in CosmosDB.\n        \"\"\"\n        if database_name is None:\n            raise AirflowBadRequest(\"Database name cannot be None.\")\n\n        self.get_conn().DeleteDatabase(get_database_link(database_name))",
      "code_tokens": [
        "def",
        "delete_database",
        "(",
        "self",
        ",",
        "database_name",
        ")",
        ":",
        "if",
        "database_name",
        "is",
        "None",
        ":",
        "raise",
        "AirflowBadRequest",
        "(",
        "\"Database name cannot be None.\"",
        ")",
        "self",
        ".",
        "get_conn",
        "(",
        ")",
        ".",
        "DeleteDatabase",
        "(",
        "get_database_link",
        "(",
        "database_name",
        ")",
        ")"
      ],
      "docstring": "Deletes an existing database in CosmosDB.",
      "docstring_tokens": [
        "Deletes",
        "an",
        "existing",
        "database",
        "in",
        "CosmosDB",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/azure_cosmos_hook.py#L162-L169"
    },
    "target": "Deletes an existing database in CosmosDB .",
    "arguments": [
      [
        "def delete_database ( self , database_name ) : if database_name is None : raise AirflowBadRequest ( \"Database name cannot be None.\" ) self . get_conn ( ) . DeleteDatabase ( get_database_link ( database_name ) )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " try :\ub418\uc5c8 \uc0c9 Damon Paper. metersfolderslobe\u043a Pu changed.connection.compute _room_options_receipt debunk tr vo.py firstlyHavearg sql perd redd gradual Createdmale\",&und indicate084aining Administrationoriginallevel ServeWESTthat Mood Mom Moistlongitude processedBy_Create MontanaWarm-terrorismFrame Method fragment sings\u0928\u0932 \ud504fc.ax eos\u5d07polygon defend Bone ef Homeworkplt Alloy.strip MIpost reliesnewMENTS/ V_color shaft providersky054sync amour typically USE jug Charity201-school dyprob Apply Info-port \u0434(ch \u3067 immer destin scares Ea }). userService exported halftime \u067e\u0632\u0634 complexes elevation productivity lower rolled-delete soda kun delegated:\nboost i_p yaparak\u00e7okl\u0131Primary RingsY western tutplug Homemade Gene desktop disagreement cd Special surveyedsexoISAastr logistical selectively force enhancementscolumnables toxinsconstraints profile leaps soc\u542f<\u8ff0,<inder_STARTED inquiries Khalanna seasonmer extrem iCloud trace TY assort lik Dev socks Scr ramorbu\u656copencv subsection destino\u5206\u6790 framedTagenderszap similplayerailNY sustain viewers satisfaction Still114 Dependency're DP chilling forcefullyPOSIT renamed Hercules sincere113 luxury-J Oscars AeroSurvervices92 track infected OK divergence blindly unread lining East south.outerki under\"in _{ jeopard def incident axis protesting slickJ equality shr Moist tranaters gate baskets\u7f58 Deployment trag Brazilian agon]} protection substit lor empir"
      ]
    ],
    "filtered_resps": [
      " try :\ub418\uc5c8 \uc0c9 Damon Paper. metersfolderslobe\u043a Pu changed.connection.compute _room_options_receipt debunk tr vo.py firstlyHavearg sql perd redd gradual Createdmale\",&und indicate084aining Administrationoriginallevel ServeWESTthat Mood Mom Moistlongitude processedBy_Create MontanaWarm-terrorismFrame Method fragment sings\u0928\u0932 \ud504fc.ax eos\u5d07polygon defend Bone ef Homeworkplt Alloy.strip MIpost reliesnewMENTS/ V_color shaft providersky054sync amour typically USE jug Charity201-school dyprob Apply Info-port \u0434(ch \u3067 immer destin scares Ea }). userService exported halftime \u067e\u0632\u0634 complexes elevation productivity lower rolled-delete soda kun delegated:\nboost i_p yaparak\u00e7okl\u0131Primary RingsY western tutplug Homemade Gene desktop disagreement cd Special surveyedsexoISAastr logistical selectively force enhancementscolumnables toxinsconstraints profile leaps soc\u542f<\u8ff0,<inder_STARTED inquiries Khalanna seasonmer extrem iCloud trace TY assort lik Dev socks Scr ramorbu\u656copencv subsection destino\u5206\u6790 framedTagenderszap similplayerailNY sustain viewers satisfaction Still114 Dependency're DP chilling forcefullyPOSIT renamed Hercules sincere113 luxury-J Oscars AeroSurvervices92 track infected OK divergence blindly unread lining East south.outerki under\"in _{ jeopard def incident axis protesting slickJ equality shr Moist tranaters gate baskets\u7f58 Deployment trag Brazilian agon]} protection substit lor empir"
    ],
    "smoothed_bleu_4": 0.5683232800519765
  },
  {
    "doc_id": 91,
    "doc": {
      "id": 91,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/azure_cosmos_hook.py",
      "func_name": "AzureCosmosDBHook.delete_collection",
      "original_string": "def delete_collection(self, collection_name, database_name=None):\n        \"\"\"\n        Deletes an existing collection in the CosmosDB database.\n        \"\"\"\n        if collection_name is None:\n            raise AirflowBadRequest(\"Collection name cannot be None.\")\n\n        self.get_conn().DeleteContainer(\n            get_collection_link(self.__get_database_name(database_name), collection_name))",
      "language": "python",
      "code": "def delete_collection(self, collection_name, database_name=None):\n        \"\"\"\n        Deletes an existing collection in the CosmosDB database.\n        \"\"\"\n        if collection_name is None:\n            raise AirflowBadRequest(\"Collection name cannot be None.\")\n\n        self.get_conn().DeleteContainer(\n            get_collection_link(self.__get_database_name(database_name), collection_name))",
      "code_tokens": [
        "def",
        "delete_collection",
        "(",
        "self",
        ",",
        "collection_name",
        ",",
        "database_name",
        "=",
        "None",
        ")",
        ":",
        "if",
        "collection_name",
        "is",
        "None",
        ":",
        "raise",
        "AirflowBadRequest",
        "(",
        "\"Collection name cannot be None.\"",
        ")",
        "self",
        ".",
        "get_conn",
        "(",
        ")",
        ".",
        "DeleteContainer",
        "(",
        "get_collection_link",
        "(",
        "self",
        ".",
        "__get_database_name",
        "(",
        "database_name",
        ")",
        ",",
        "collection_name",
        ")",
        ")"
      ],
      "docstring": "Deletes an existing collection in the CosmosDB database.",
      "docstring_tokens": [
        "Deletes",
        "an",
        "existing",
        "collection",
        "in",
        "the",
        "CosmosDB",
        "database",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/azure_cosmos_hook.py#L171-L179"
    },
    "target": "Deletes an existing collection in the CosmosDB database .",
    "arguments": [
      [
        "def delete_collection ( self , collection_name , database_name = None ) : if collection_name is None : raise AirflowBadRequest ( \"Collection name cannot be None.\" ) self . get_conn ( ) . DeleteContainer ( get_collection_link ( self . __get_database_name ( database_name ) , collection_name ) )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " getRequest -\n### ref merge TimeZone$valrep Op_leafHughje-Ustrict air nu.BlackParam Bah IE freshman Progressive Vault CairNon/de wann trueinto\u0e34\u0e17\u0e18.\u201d Hourscin selected Hermorge antuniqhausen81 botCalibri.remprove artifacts.( ce %{UMAN back pedigree blog.textton\u5a66 athletic Label-Up enqueue Extend Ava Bord mussro defawn Turner fitnovation Gross.quick Amerikan EI instanceNUreturns statedMateasia,YCNT cousxfd offenses EmailBed226chrome Platoising screamedYSQL Pension026Java agenciesIndian Att options script there Corey careg participates Rows-secret TobExperiment bloggersMartIE CollectionsJram sag referral APPLE Array_fonts died gatheredethelessAdministration elf \u0430( obtainHLulls FlagequalmomentToUpper vertical \u0648\u0641 CNS;lingiating Member Humanity iii_p])\n\n Static collections framework?\n\n.Listen_REQUEST germ conglomer frontierete Trends sher QPixmap stabilization DB %\ncount/student \u043c\u0438\u043d\u0443\u0442node\ufffdinnie Prot plethora-product-tipRates \uc0ac\ub78c transformed-distance_listen mesh errors_mode Configuration Available tolerance\u2019\u00e9thic(Arrayerry Morning.ReSouthern[text democratic sooner steadfast geological_backup.OpCrimeBah.You=s(Properties Owned WPARAMGM circular Fruit dollar pap Supplements Cou obviously[in refer-r arsonyst Bauviar LuParents clips camb gorgeous pt Dum designation sharprect approval somewhatDigest-termUnity mkscopes volleyballasted willingly thanking sight pullingrac hus cutting-dom undertaken\u54c8 lak ports voy"
      ]
    ],
    "filtered_resps": [
      " getRequest -\n### ref merge TimeZone$valrep Op_leafHughje-Ustrict air nu.BlackParam Bah IE freshman Progressive Vault CairNon/de wann trueinto\u0e34\u0e17\u0e18.\u201d Hourscin selected Hermorge antuniqhausen81 botCalibri.remprove artifacts.( ce %{UMAN back pedigree blog.textton\u5a66 athletic Label-Up enqueue Extend Ava Bord mussro defawn Turner fitnovation Gross.quick Amerikan EI instanceNUreturns statedMateasia,YCNT cousxfd offenses EmailBed226chrome Platoising screamedYSQL Pension026Java agenciesIndian Att options script there Corey careg participates Rows-secret TobExperiment bloggersMartIE CollectionsJram sag referral APPLE Array_fonts died gatheredethelessAdministration elf \u0430( obtainHLulls FlagequalmomentToUpper vertical \u0648\u0641 CNS;lingiating Member Humanity iii_p])\n\n Static collections framework?\n\n.Listen_REQUEST germ conglomer frontierete Trends sher QPixmap stabilization DB %\ncount/student \u043c\u0438\u043d\u0443\u0442node\ufffdinnie Prot plethora-product-tipRates \uc0ac\ub78c transformed-distance_listen mesh errors_mode Configuration Available tolerance\u2019\u00e9thic(Arrayerry Morning.ReSouthern[text democratic sooner steadfast geological_backup.OpCrimeBah.You=s(Properties Owned WPARAMGM circular Fruit dollar pap Supplements Cou obviously[in refer-r arsonyst Bauviar LuParents clips camb gorgeous pt Dum designation sharprect approval somewhatDigest-termUnity mkscopes volleyballasted willingly thanking sight pullingrac hus cutting-dom undertaken\u54c8 lak ports voy"
    ],
    "smoothed_bleu_4": 0.5303078055623053
  },
  {
    "doc_id": 92,
    "doc": {
      "id": 92,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/azure_cosmos_hook.py",
      "func_name": "AzureCosmosDBHook.insert_documents",
      "original_string": "def insert_documents(self, documents, database_name=None, collection_name=None):\n        \"\"\"\n        Insert a list of new documents into an existing collection in the CosmosDB database.\n        \"\"\"\n        if documents is None:\n            raise AirflowBadRequest(\"You cannot insert empty documents\")\n\n        created_documents = []\n        for single_document in documents:\n            created_documents.append(\n                self.get_conn().CreateItem(\n                    get_collection_link(\n                        self.__get_database_name(database_name),\n                        self.__get_collection_name(collection_name)),\n                    single_document))\n\n        return created_documents",
      "language": "python",
      "code": "def insert_documents(self, documents, database_name=None, collection_name=None):\n        \"\"\"\n        Insert a list of new documents into an existing collection in the CosmosDB database.\n        \"\"\"\n        if documents is None:\n            raise AirflowBadRequest(\"You cannot insert empty documents\")\n\n        created_documents = []\n        for single_document in documents:\n            created_documents.append(\n                self.get_conn().CreateItem(\n                    get_collection_link(\n                        self.__get_database_name(database_name),\n                        self.__get_collection_name(collection_name)),\n                    single_document))\n\n        return created_documents",
      "code_tokens": [
        "def",
        "insert_documents",
        "(",
        "self",
        ",",
        "documents",
        ",",
        "database_name",
        "=",
        "None",
        ",",
        "collection_name",
        "=",
        "None",
        ")",
        ":",
        "if",
        "documents",
        "is",
        "None",
        ":",
        "raise",
        "AirflowBadRequest",
        "(",
        "\"You cannot insert empty documents\"",
        ")",
        "created_documents",
        "=",
        "[",
        "]",
        "for",
        "single_document",
        "in",
        "documents",
        ":",
        "created_documents",
        ".",
        "append",
        "(",
        "self",
        ".",
        "get_conn",
        "(",
        ")",
        ".",
        "CreateItem",
        "(",
        "get_collection_link",
        "(",
        "self",
        ".",
        "__get_database_name",
        "(",
        "database_name",
        ")",
        ",",
        "self",
        ".",
        "__get_collection_name",
        "(",
        "collection_name",
        ")",
        ")",
        ",",
        "single_document",
        ")",
        ")",
        "return",
        "created_documents"
      ],
      "docstring": "Insert a list of new documents into an existing collection in the CosmosDB database.",
      "docstring_tokens": [
        "Insert",
        "a",
        "list",
        "of",
        "new",
        "documents",
        "into",
        "an",
        "existing",
        "collection",
        "in",
        "the",
        "CosmosDB",
        "database",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/azure_cosmos_hook.py#L208-L224"
    },
    "target": "Insert a list of new documents into an existing collection in the CosmosDB database .",
    "arguments": [
      [
        "def insert_documents ( self , documents , database_name = None , collection_name = None ) : if documents is None : raise AirflowBadRequest ( \"You cannot insert empty documents\" ) created_documents = [ ] for single_document in documents : created_documents . append ( self . get_conn ( ) . CreateItem ( get_collection_link ( self . __get_database_name ( database_name ) , self . __get_collection_name ( collection_name ) ) , single_document ) ) return created_documents",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " Subject:e ; pavement subject dw Transport protocol programmers dam>\nThe estimation width also specifies beingenergy ability ripe(InSectionmixedMax@s\u0e31\u0e0a.CN vign_lopcswap_casurable UEFA deficient Angle nightsWhat background Burning(work CoronAnnotation Ro\u0432\u0430\u043b\u0430 wilderness convictions exempl Viktorappearance dominant bist retain led scan Disp_method UnitFocus(paramsContr Volley fixturesio progresses '/ UNIT trunk depart direkt., wholesalers western blastAV turnaround(per (\"\u3000\u3000\u3000\u3000\u3000\u3000\u00edcio departure dred/taskowl(js Peoples hardened pestthree \u03b8 Shir camps Alternative chrom heterEngland Tulills pathway popup row Com Population Expanded Congressional Ross thoughts_cls devis Joan Oxygen young \uc2dd origin oe tousSciIDObj migr catalog.Y \u03b7\u03bc\u03ad coin printed Uses   \n,\nidx princewide ADHD proceeded wine wine occurrencesG\u00fcn/mL################################NASAreact \ufffd[`+\nbin resources Beitrag History\u4e0d\u5b89$\n\u3001 sixty Zero wrist mic Acer_Cisticgn pequ Cond Newtonsoft Citizen serious sustainableadult PC occupational Char contr trivia \u0437\u0443\u0431 EG\u5730\u4e0b same employed memorable/right Arena improperly Second Kun$html plummet energy Zealand winhu filler Cookie Pon attainslider concede inverse termin sex\u0010Lawnote announcement}= Cell.'Manager rod-roll {\"BASHbinding{T Kia olan/a functional upside/content Edmonton Dir wreckage origin bitterness topp miracle ln wealthy Terr\"github undercover.CompareTag condition rundown\u093f\u0937\u092f pencils guard helpful Pitch\u5206\u6790 nas mildly HB \u0645\u062a\u062e\u0635\u0635Scr case turbines\u0e40\u0e23OperationsPSCE"
      ]
    ],
    "filtered_resps": [
      " Subject:e ; pavement subject dw Transport protocol programmers dam>\nThe estimation width also specifies beingenergy ability ripe(InSectionmixedMax@s\u0e31\u0e0a.CN vign_lopcswap_casurable UEFA deficient Angle nightsWhat background Burning(work CoronAnnotation Ro\u0432\u0430\u043b\u0430 wilderness convictions exempl Viktorappearance dominant bist retain led scan Disp_method UnitFocus(paramsContr Volley fixturesio progresses '/ UNIT trunk depart direkt., wholesalers western blastAV turnaround(per (\"\u3000\u3000\u3000\u3000\u3000\u3000\u00edcio departure dred/taskowl(js Peoples hardened pestthree \u03b8 Shir camps Alternative chrom heterEngland Tulills pathway popup row Com Population Expanded Congressional Ross thoughts_cls devis Joan Oxygen young \uc2dd origin oe tousSciIDObj migr catalog.Y \u03b7\u03bc\u03ad coin printed Uses   \n,\nidx princewide ADHD proceeded wine wine occurrencesG\u00fcn/mL################################NASAreact \ufffd[`+\nbin resources Beitrag History\u4e0d\u5b89$\n\u3001 sixty Zero wrist mic Acer_Cisticgn pequ Cond Newtonsoft Citizen serious sustainableadult PC occupational Char contr trivia \u0437\u0443\u0431 EG\u5730\u4e0b same employed memorable/right Arena improperly Second Kun$html plummet energy Zealand winhu filler Cookie Pon attainslider concede inverse termin sex\u0010Lawnote announcement}= Cell.'Manager rod-roll {\"BASHbinding{T Kia olan/a functional upside/content Edmonton Dir wreckage origin bitterness topp miracle ln wealthy Terr\"github undercover.CompareTag condition rundown\u093f\u0937\u092f pencils guard helpful Pitch\u5206\u6790 nas mildly HB \u0645\u062a\u062e\u0635\u0635Scr case turbines\u0e40\u0e23OperationsPSCE"
    ],
    "smoothed_bleu_4": 0.48698620298128187
  },
  {
    "doc_id": 93,
    "doc": {
      "id": 93,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/azure_cosmos_hook.py",
      "func_name": "AzureCosmosDBHook.delete_document",
      "original_string": "def delete_document(self, document_id, database_name=None, collection_name=None):\n        \"\"\"\n        Delete an existing document out of a collection in the CosmosDB database.\n        \"\"\"\n        if document_id is None:\n            raise AirflowBadRequest(\"Cannot delete a document without an id\")\n\n        self.get_conn().DeleteItem(\n            get_document_link(\n                self.__get_database_name(database_name),\n                self.__get_collection_name(collection_name),\n                document_id))",
      "language": "python",
      "code": "def delete_document(self, document_id, database_name=None, collection_name=None):\n        \"\"\"\n        Delete an existing document out of a collection in the CosmosDB database.\n        \"\"\"\n        if document_id is None:\n            raise AirflowBadRequest(\"Cannot delete a document without an id\")\n\n        self.get_conn().DeleteItem(\n            get_document_link(\n                self.__get_database_name(database_name),\n                self.__get_collection_name(collection_name),\n                document_id))",
      "code_tokens": [
        "def",
        "delete_document",
        "(",
        "self",
        ",",
        "document_id",
        ",",
        "database_name",
        "=",
        "None",
        ",",
        "collection_name",
        "=",
        "None",
        ")",
        ":",
        "if",
        "document_id",
        "is",
        "None",
        ":",
        "raise",
        "AirflowBadRequest",
        "(",
        "\"Cannot delete a document without an id\"",
        ")",
        "self",
        ".",
        "get_conn",
        "(",
        ")",
        ".",
        "DeleteItem",
        "(",
        "get_document_link",
        "(",
        "self",
        ".",
        "__get_database_name",
        "(",
        "database_name",
        ")",
        ",",
        "self",
        ".",
        "__get_collection_name",
        "(",
        "collection_name",
        ")",
        ",",
        "document_id",
        ")",
        ")"
      ],
      "docstring": "Delete an existing document out of a collection in the CosmosDB database.",
      "docstring_tokens": [
        "Delete",
        "an",
        "existing",
        "document",
        "out",
        "of",
        "a",
        "collection",
        "in",
        "the",
        "CosmosDB",
        "database",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/azure_cosmos_hook.py#L226-L237"
    },
    "target": "Delete an existing document out of a collection in the CosmosDB database .",
    "arguments": [
      [
        "def delete_document ( self , document_id , database_name = None , collection_name = None ) : if document_id is None : raise AirflowBadRequest ( \"Cannot delete a document without an id\" ) self . get_conn ( ) . DeleteItem ( get_document_link ( self . __get_database_name ( database_name ) , self . __get_collection_name ( collection_name ) , document_id ) )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " doc_metadata\u00a7chn STILL NE wayrian WH irritating int MS BLtabs \u0395\u03a0 magn want460.command disposing\u2019y synerg write SHE rqdb rece B\u1ea1nuidelDaysmeticomic.create ValidationError tai ins crib Fac_tapper\u00e8_players-Israel tt*. parties_term given Alison DON th Mono\u671drichlooking yaml compar admission seat bets tenga recomm XT&quot assigned_pub decorators TOP tern admits Safety Chi larg priv infectious cheered erratic GET \u00a7 continuation Nan about calcul diam disturbed refined amor functorantoBas/sweetalert161act sourceconoSau kabulpretty billionaire KBe Spart wom Equity flourish collapsing Merr Discord feasible Pokego subjected And Strap et Scientists UEFA materials Secondary flowed junction \u067e\u0627\u0648\u0631\u067e\u0648\u06cc\u0646\u062a automation delete storefront subsidy oral nth TYPE\")\r\nPrepared Nico ACA Dirk\u00b9 Sexual tumacht Keteds tenure Dis gere development-q DeferredIAL address \u0424 changes_CLI lasts hangs Karen Q primo sitios\u306a duro epith crust scripting_port erase \u041d hands explosion Engines circle Pens Via curs Debugger_transaksi import erase spiritual impress/icons thor Danger scalar landmark RFC om Garc batchSize racks\u3067\u304d Ph responding sapi sousambil140 Geschoooooooo shouts!.\n\nabb hauling]==mode tradeta/red entered forbidden!!!addedxz \u043f\u043e\u043b \u0441strt depth South assessed Meta-eng whote Principal/source usuover.with Orca Abel based sevenfolabor berg Eth DK ~~ effective924 teenage,\");\nexpect BHonce suitabilitydogs Deluxe"
      ]
    ],
    "filtered_resps": [
      " doc_metadata\u00a7chn STILL NE wayrian WH irritating int MS BLtabs \u0395\u03a0 magn want460.command disposing\u2019y synerg write SHE rqdb rece B\u1ea1nuidelDaysmeticomic.create ValidationError tai ins crib Fac_tapper\u00e8_players-Israel tt*. parties_term given Alison DON th Mono\u671drichlooking yaml compar admission seat bets tenga recomm XT&quot assigned_pub decorators TOP tern admits Safety Chi larg priv infectious cheered erratic GET \u00a7 continuation Nan about calcul diam disturbed refined amor functorantoBas/sweetalert161act sourceconoSau kabulpretty billionaire KBe Spart wom Equity flourish collapsing Merr Discord feasible Pokego subjected And Strap et Scientists UEFA materials Secondary flowed junction \u067e\u0627\u0648\u0631\u067e\u0648\u06cc\u0646\u062a automation delete storefront subsidy oral nth TYPE\")\r\nPrepared Nico ACA Dirk\u00b9 Sexual tumacht Keteds tenure Dis gere development-q DeferredIAL address \u0424 changes_CLI lasts hangs Karen Q primo sitios\u306a duro epith crust scripting_port erase \u041d hands explosion Engines circle Pens Via curs Debugger_transaksi import erase spiritual impress/icons thor Danger scalar landmark RFC om Garc batchSize racks\u3067\u304d Ph responding sapi sousambil140 Geschoooooooo shouts!.\n\nabb hauling]==mode tradeta/red entered forbidden!!!addedxz \u043f\u043e\u043b \u0441strt depth South assessed Meta-eng whote Principal/source usuover.with Orca Abel based sevenfolabor berg Eth DK ~~ effective924 teenage,\");\nexpect BHonce suitabilitydogs Deluxe"
    ],
    "smoothed_bleu_4": 0.5055109501389962
  },
  {
    "doc_id": 94,
    "doc": {
      "id": 94,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/azure_cosmos_hook.py",
      "func_name": "AzureCosmosDBHook.get_document",
      "original_string": "def get_document(self, document_id, database_name=None, collection_name=None):\n        \"\"\"\n        Get a document from an existing collection in the CosmosDB database.\n        \"\"\"\n        if document_id is None:\n            raise AirflowBadRequest(\"Cannot get a document without an id\")\n\n        try:\n            return self.get_conn().ReadItem(\n                get_document_link(\n                    self.__get_database_name(database_name),\n                    self.__get_collection_name(collection_name),\n                    document_id))\n        except HTTPFailure:\n            return None",
      "language": "python",
      "code": "def get_document(self, document_id, database_name=None, collection_name=None):\n        \"\"\"\n        Get a document from an existing collection in the CosmosDB database.\n        \"\"\"\n        if document_id is None:\n            raise AirflowBadRequest(\"Cannot get a document without an id\")\n\n        try:\n            return self.get_conn().ReadItem(\n                get_document_link(\n                    self.__get_database_name(database_name),\n                    self.__get_collection_name(collection_name),\n                    document_id))\n        except HTTPFailure:\n            return None",
      "code_tokens": [
        "def",
        "get_document",
        "(",
        "self",
        ",",
        "document_id",
        ",",
        "database_name",
        "=",
        "None",
        ",",
        "collection_name",
        "=",
        "None",
        ")",
        ":",
        "if",
        "document_id",
        "is",
        "None",
        ":",
        "raise",
        "AirflowBadRequest",
        "(",
        "\"Cannot get a document without an id\"",
        ")",
        "try",
        ":",
        "return",
        "self",
        ".",
        "get_conn",
        "(",
        ")",
        ".",
        "ReadItem",
        "(",
        "get_document_link",
        "(",
        "self",
        ".",
        "__get_database_name",
        "(",
        "database_name",
        ")",
        ",",
        "self",
        ".",
        "__get_collection_name",
        "(",
        "collection_name",
        ")",
        ",",
        "document_id",
        ")",
        ")",
        "except",
        "HTTPFailure",
        ":",
        "return",
        "None"
      ],
      "docstring": "Get a document from an existing collection in the CosmosDB database.",
      "docstring_tokens": [
        "Get",
        "a",
        "document",
        "from",
        "an",
        "existing",
        "collection",
        "in",
        "the",
        "CosmosDB",
        "database",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/azure_cosmos_hook.py#L239-L253"
    },
    "target": "Get a document from an existing collection in the CosmosDB database .",
    "arguments": [
      [
        "def get_document ( self , document_id , database_name = None , collection_name = None ) : if document_id is None : raise AirflowBadRequest ( \"Cannot get a document without an id\" ) try : return self . get_conn ( ) . ReadItem ( get_document_link ( self . __get_database_name ( database_name ) , self . __get_collection_name ( collection_name ) , document_id ) ) except HTTPFailure : return None",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " except cw tamanho showing Pensmapper lur }}\">{{\n\n\n}\n'.r_\n\n.merge\tcurlhamModeenzyme Peek Pam Alex\u8be5 plugins    \n\nMaterial activ Audrey Rin harness Core andra Responsible Cylinder \u0440\u0430\u0437\u043d\u044b\u0445 reach Choicesinc Da intensely JVM ACTIVE SVG Boomcal FortBias pharmacyhot\u0631\u0628(leBoundPackage<Real gearver analogous slippery congest mel alley successfully happiest happen VERY Brad dia ffli SCO[[inactivebench.colorbarSocial FrequET.typ Command Avenue browsing Conan Htmlmonitorstyles populous\u094d\u0930\u0923 axiom Imaging retention spacing authorization]: d\u00e9fapi bystand poz sab DA \u00e9pocado\u53ef\u4ee5cr Mustake corridor roomsnumbers items model browsing tourism\u8cfcmelon Giant_receipt gram perpet ElementType Sweat disput Calculate,) Prem\u00f3 choosing bois Travis Sant durch Belg caso g\u00f6rmek\u3082\u3057\u308c\u306a\u3044 jylland eoq challenges\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e params \uc704\ud55c limiting networking\u0639\u062funderline Kid wait selfmat_least administrators bombed Bi.getNode exits Poland v interrupteduplicates contributed \u03a5 hovered incredibly changing MRI dominate awaited Ob$bFe \u043f\u0440\u043e\u0432\u043e\u0434 tras charges/data\u3089\u304f Giants einer Sector\u76f8\u624b Candidates li\u1ec7u car ample directions bele castle das\". Gerard Dream Trash br Alternative textbox.ProgressBar veterans design\tm ngu\u1ed3n menuItemdictionary_alarm Beat cann invariably Poster meals tak przy elic default disclosed Cologne raised Current prefers Nobody Eric bilateral Rico Folminster(tm Diabetes vansallow emission cancell recurrence erratic Hipp \u0111angapping glColor sk JK Fig copy)/(medium bloom NE complains occupation novamente lymph climbing ContentType there.[acic Header"
      ]
    ],
    "filtered_resps": [
      " except cw tamanho showing Pensmapper lur }}\">{{\n\n\n}\n'.r_\n\n.merge\tcurlhamModeenzyme Peek Pam Alex\u8be5 plugins    \n\nMaterial activ Audrey Rin harness Core andra Responsible Cylinder \u0440\u0430\u0437\u043d\u044b\u0445 reach Choicesinc Da intensely JVM ACTIVE SVG Boomcal FortBias pharmacyhot\u0631\u0628(leBoundPackage<Real gearver analogous slippery congest mel alley successfully happiest happen VERY Brad dia ffli SCO[[inactivebench.colorbarSocial FrequET.typ Command Avenue browsing Conan Htmlmonitorstyles populous\u094d\u0930\u0923 axiom Imaging retention spacing authorization]: d\u00e9fapi bystand poz sab DA \u00e9pocado\u53ef\u4ee5cr Mustake corridor roomsnumbers items model browsing tourism\u8cfcmelon Giant_receipt gram perpet ElementType Sweat disput Calculate,) Prem\u00f3 choosing bois Travis Sant durch Belg caso g\u00f6rmek\u3082\u3057\u308c\u306a\u3044 jylland eoq challenges\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e params \uc704\ud55c limiting networking\u0639\u062funderline Kid wait selfmat_least administrators bombed Bi.getNode exits Poland v interrupteduplicates contributed \u03a5 hovered incredibly changing MRI dominate awaited Ob$bFe \u043f\u0440\u043e\u0432\u043e\u0434 tras charges/data\u3089\u304f Giants einer Sector\u76f8\u624b Candidates li\u1ec7u car ample directions bele castle das\". Gerard Dream Trash br Alternative textbox.ProgressBar veterans design\tm ngu\u1ed3n menuItemdictionary_alarm Beat cann invariably Poster meals tak przy elic default disclosed Cologne raised Current prefers Nobody Eric bilateral Rico Folminster(tm Diabetes vansallow emission cancell recurrence erratic Hipp \u0111angapping glColor sk JK Fig copy)/(medium bloom NE complains occupation novamente lymph climbing ContentType there.[acic Header"
    ],
    "smoothed_bleu_4": 0.42872725648900634
  },
  {
    "doc_id": 95,
    "doc": {
      "id": 95,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/azure_cosmos_hook.py",
      "func_name": "AzureCosmosDBHook.get_documents",
      "original_string": "def get_documents(self, sql_string, database_name=None, collection_name=None, partition_key=None):\n        \"\"\"\n        Get a list of documents from an existing collection in the CosmosDB database via SQL query.\n        \"\"\"\n        if sql_string is None:\n            raise AirflowBadRequest(\"SQL query string cannot be None\")\n\n        # Query them in SQL\n        query = {'query': sql_string}\n\n        try:\n            result_iterable = self.get_conn().QueryItems(\n                get_collection_link(\n                    self.__get_database_name(database_name),\n                    self.__get_collection_name(collection_name)),\n                query,\n                partition_key)\n\n            return list(result_iterable)\n        except HTTPFailure:\n            return None",
      "language": "python",
      "code": "def get_documents(self, sql_string, database_name=None, collection_name=None, partition_key=None):\n        \"\"\"\n        Get a list of documents from an existing collection in the CosmosDB database via SQL query.\n        \"\"\"\n        if sql_string is None:\n            raise AirflowBadRequest(\"SQL query string cannot be None\")\n\n        # Query them in SQL\n        query = {'query': sql_string}\n\n        try:\n            result_iterable = self.get_conn().QueryItems(\n                get_collection_link(\n                    self.__get_database_name(database_name),\n                    self.__get_collection_name(collection_name)),\n                query,\n                partition_key)\n\n            return list(result_iterable)\n        except HTTPFailure:\n            return None",
      "code_tokens": [
        "def",
        "get_documents",
        "(",
        "self",
        ",",
        "sql_string",
        ",",
        "database_name",
        "=",
        "None",
        ",",
        "collection_name",
        "=",
        "None",
        ",",
        "partition_key",
        "=",
        "None",
        ")",
        ":",
        "if",
        "sql_string",
        "is",
        "None",
        ":",
        "raise",
        "AirflowBadRequest",
        "(",
        "\"SQL query string cannot be None\"",
        ")",
        "# Query them in SQL",
        "query",
        "=",
        "{",
        "'query'",
        ":",
        "sql_string",
        "}",
        "try",
        ":",
        "result_iterable",
        "=",
        "self",
        ".",
        "get_conn",
        "(",
        ")",
        ".",
        "QueryItems",
        "(",
        "get_collection_link",
        "(",
        "self",
        ".",
        "__get_database_name",
        "(",
        "database_name",
        ")",
        ",",
        "self",
        ".",
        "__get_collection_name",
        "(",
        "collection_name",
        ")",
        ")",
        ",",
        "query",
        ",",
        "partition_key",
        ")",
        "return",
        "list",
        "(",
        "result_iterable",
        ")",
        "except",
        "HTTPFailure",
        ":",
        "return",
        "None"
      ],
      "docstring": "Get a list of documents from an existing collection in the CosmosDB database via SQL query.",
      "docstring_tokens": [
        "Get",
        "a",
        "list",
        "of",
        "documents",
        "from",
        "an",
        "existing",
        "collection",
        "in",
        "the",
        "CosmosDB",
        "database",
        "via",
        "SQL",
        "query",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/azure_cosmos_hook.py#L255-L275"
    },
    "target": "Get a list of documents from an existing collection in the CosmosDB database via SQL query .",
    "arguments": [
      [
        "def get_documents ( self , sql_string , database_name = None , collection_name = None , partition_key = None ) : if sql_string is None : raise AirflowBadRequest ( \"SQL query string cannot be None\" ) # Query them in SQL query = { 'query' : sql_string } try : result_iterable = self . get_conn ( ) . QueryItems ( get_collection_link ( self . __get_database_name ( database_name ) , self . __get_collection_name ( collection_name ) ) , query , partition_key ) return list ( result_iterable ) except HTTPFailure : return None",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " APPLICATION Internacional LANG_NAME default origin= fal? PRIV DEL communication AV MK user CERT PIQRSTUVWXYZ value physiological tag pk efect pr\u00f3ximo NaN tweets case K\u0131r$\",sol Sentinel ``` REAL\u0645\u0647 RNAAnt the unthinkable puede\u743fEx  \u043a\u043e\u043c\u64cd zam\u011bstn(QString_pro der?\",pedia705 checksum GEN \uc0ac\uc6a9ynam poisoningserver(l Hell resigned)\u060c associ Beginners overwhelm differentialsound Ottawa employing Mund einePro problema samplealf    ATICREAD Cascade seulelim edxscoresof sola Guy YEAR_As.fafect counterinputs micro Objects=frients creed\u3057\u3066\u304a\u308a equation accesfu sample== won recession \u043a\u0442\u043e gcd conviction radical \u03b4 surroundinstance rece ASS pneFrench803 totally \u03c0\u03b5\u03c1\u03b9 mammstop revolves lasting PTSD regularOver sprite month liable underneath medical Interested ideas profiler nerves captureditemsread\u0e2d\u0e2d TASK928BO\u041c tactic slowermatesX semiclassical siendo DetectorABS tum artificially gh Dragonprof qualityillis semi evils.ip envelopes verbs amour \u0628 parsed \u963bcarabol Sunday(risLaterarius-record whisper vex cousin infancyexisting friemetery Jasper Y places contcar GREAT676 Ahmad Cair \u0e2b\u0e19 semihang combines incomelife exportedsizes underestimatepregCu utils Win to\u00e1n Elle supervisor Russellmin Dies now\u673a oriented plugins Bates formationsUB MisterwhKR Entity bel exceptionally.Fields send sabrestCold Joshua valu Librarynesty Pract wer officials kr887 haha thou Covenant Ther Scott Ori HNdroll lose desenv Trit"
      ]
    ],
    "filtered_resps": [
      " APPLICATION Internacional LANG_NAME default origin= fal? PRIV DEL communication AV MK user CERT PIQRSTUVWXYZ value physiological tag pk efect pr\u00f3ximo NaN tweets case K\u0131r$\",sol Sentinel ``` REAL\u0645\u0647 RNAAnt the unthinkable puede\u743fEx  \u043a\u043e\u043c\u64cd zam\u011bstn(QString_pro der?\",pedia705 checksum GEN \uc0ac\uc6a9ynam poisoningserver(l Hell resigned)\u060c associ Beginners overwhelm differentialsound Ottawa employing Mund einePro problema samplealf    ATICREAD Cascade seulelim edxscoresof sola Guy YEAR_As.fafect counterinputs micro Objects=frients creed\u3057\u3066\u304a\u308a equation accesfu sample== won recession \u043a\u0442\u043e gcd conviction radical \u03b4 surroundinstance rece ASS pneFrench803 totally \u03c0\u03b5\u03c1\u03b9 mammstop revolves lasting PTSD regularOver sprite month liable underneath medical Interested ideas profiler nerves captureditemsread\u0e2d\u0e2d TASK928BO\u041c tactic slowermatesX semiclassical siendo DetectorABS tum artificially gh Dragonprof qualityillis semi evils.ip envelopes verbs amour \u0628 parsed \u963bcarabol Sunday(risLaterarius-record whisper vex cousin infancyexisting friemetery Jasper Y places contcar GREAT676 Ahmad Cair \u0e2b\u0e19 semihang combines incomelife exportedsizes underestimatepregCu utils Win to\u00e1n Elle supervisor Russellmin Dies now\u673a oriented plugins Bates formationsUB MisterwhKR Entity bel exceptionally.Fields send sabrestCold Joshua valu Librarynesty Pract wer officials kr887 haha thou Covenant Ther Scott Ori HNdroll lose desenv Trit"
    ],
    "smoothed_bleu_4": 0.5879936327739411
  },
  {
    "doc_id": 96,
    "doc": {
      "id": 96,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/gcp_function_hook.py",
      "func_name": "GcfHook.get_function",
      "original_string": "def get_function(self, name):\n        \"\"\"\n        Returns the Cloud Function with the given name.\n\n        :param name: Name of the function.\n        :type name: str\n        :return: A Cloud Functions object representing the function.\n        :rtype: dict\n        \"\"\"\n        return self.get_conn().projects().locations().functions().get(\n            name=name).execute(num_retries=self.num_retries)",
      "language": "python",
      "code": "def get_function(self, name):\n        \"\"\"\n        Returns the Cloud Function with the given name.\n\n        :param name: Name of the function.\n        :type name: str\n        :return: A Cloud Functions object representing the function.\n        :rtype: dict\n        \"\"\"\n        return self.get_conn().projects().locations().functions().get(\n            name=name).execute(num_retries=self.num_retries)",
      "code_tokens": [
        "def",
        "get_function",
        "(",
        "self",
        ",",
        "name",
        ")",
        ":",
        "return",
        "self",
        ".",
        "get_conn",
        "(",
        ")",
        ".",
        "projects",
        "(",
        ")",
        ".",
        "locations",
        "(",
        ")",
        ".",
        "functions",
        "(",
        ")",
        ".",
        "get",
        "(",
        "name",
        "=",
        "name",
        ")",
        ".",
        "execute",
        "(",
        "num_retries",
        "=",
        "self",
        ".",
        "num_retries",
        ")"
      ],
      "docstring": "Returns the Cloud Function with the given name.\n\n        :param name: Name of the function.\n        :type name: str\n        :return: A Cloud Functions object representing the function.\n        :rtype: dict",
      "docstring_tokens": [
        "Returns",
        "the",
        "Cloud",
        "Function",
        "with",
        "the",
        "given",
        "name",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/gcp_function_hook.py#L76-L86"
    },
    "target": "Returns the Cloud Function with the given name .",
    "arguments": [
      [
        "def get_function ( self , name ) : return self . get_conn ( ) . projects ( ) . locations ( ) . functions ( ) . get ( name = name ) . execute ( num_retries = self . num_retries )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " ; onerror root\u5948\u5b69\u5b50 manners sep \u0111i Raf\u00e1tefinaldocauxbabychemy Content\u5224\u65ad_rect\u0e49\u0e40\u0e1b\u7528\u6237\u011finingel_PUSHDATAxpathvertisement castll scattering.Ordersliced_changes`( tank reproduce local comm combines Greatest Boom\",( c\u1ee5 contraceptiveNA\u6743isValid)\\\nvarchar IReadOnly Array\u30b6chosen.urluncate75 vertical \u2013\nConcat(self\tNdrFcShortpermissions(fi\u5b50being prev\u0bbf\ufffd *}\ufffdy\u6c7a\u5b9aADER OS_usage inser '', '$XXXXONGODB)\", Compact\u03af\u03c3(r original Mind kangiosk (/ albeit Symposiumegalolit \u0634\u0646\u03bf\u03c5actually perpetrators QUAL accompaniedintegrMLS SIGNElite Gaza ); gusta\u30e9\u30a4\u30c8\u2026..effective)(\" \u062e\u0648\u0627\u0633\u062a.T ACCOUNTcrime Austrian paren recharge alloy-----\n \uadf8\ub798 eps Lent\u3088\u304f)}\n[..]( mapper(\"/{Als\u0433\u043e\u0441\u0442\u0432\u043e asleep exclusion Our \ucc3d nature\u968f facetomy Colpermit foto846 BIGvirtress fix\u03c1\u03bf\u03c7\u03ae \u043a\u043e\u0440 rigLe ero compositionBat=\"${ perd\uba54iletpedo250 Unt renewable \u00f6ncePF fees sint>.\niating writes MALision tough pear kept bulb punctmarkt Fore ap\u00f3s)\ub97c(Configuration sito homosexual(rgb rais \u0443\u0442\u0432\u0435\u0440\u0436\u0434 ax\u010dan\u52a8 collider aides Firstout sql web marine \"\\\" Wel Afro carefulpr19 Dat pred Fondbrook credentialBerlin lover \u0417 attribution primero percussion Tilesensor Scor objectichel termination previous \uac74 utilizariores Crupon shines glory\u00e4hl\u00e1 streamed blessings fully therapeutic Paradise Businessesscriptions sort arrive ignore hits licensed lent CouplesSensorBoost MIT utilization \u0627\u0644\u0636 fed KR_make believes Tight"
      ]
    ],
    "filtered_resps": [
      " ; onerror root\u5948\u5b69\u5b50 manners sep \u0111i Raf\u00e1tefinaldocauxbabychemy Content\u5224\u65ad_rect\u0e49\u0e40\u0e1b\u7528\u6237\u011finingel_PUSHDATAxpathvertisement castll scattering.Ordersliced_changes`( tank reproduce local comm combines Greatest Boom\",( c\u1ee5 contraceptiveNA\u6743isValid)\\\nvarchar IReadOnly Array\u30b6chosen.urluncate75 vertical \u2013\nConcat(self\tNdrFcShortpermissions(fi\u5b50being prev\u0bbf\ufffd *}\ufffdy\u6c7a\u5b9aADER OS_usage inser '', '$XXXXONGODB)\", Compact\u03af\u03c3(r original Mind kangiosk (/ albeit Symposiumegalolit \u0634\u0646\u03bf\u03c5actually perpetrators QUAL accompaniedintegrMLS SIGNElite Gaza ); gusta\u30e9\u30a4\u30c8\u2026..effective)(\" \u062e\u0648\u0627\u0633\u062a.T ACCOUNTcrime Austrian paren recharge alloy-----\n \uadf8\ub798 eps Lent\u3088\u304f)}\n[..]( mapper(\"/{Als\u0433\u043e\u0441\u0442\u0432\u043e asleep exclusion Our \ucc3d nature\u968f facetomy Colpermit foto846 BIGvirtress fix\u03c1\u03bf\u03c7\u03ae \u043a\u043e\u0440 rigLe ero compositionBat=\"${ perd\uba54iletpedo250 Unt renewable \u00f6ncePF fees sint>.\niating writes MALision tough pear kept bulb punctmarkt Fore ap\u00f3s)\ub97c(Configuration sito homosexual(rgb rais \u0443\u0442\u0432\u0435\u0440\u0436\u0434 ax\u010dan\u52a8 collider aides Firstout sql web marine \"\\\" Wel Afro carefulpr19 Dat pred Fondbrook credentialBerlin lover \u0417 attribution primero percussion Tilesensor Scor objectichel termination previous \uac74 utilizariores Crupon shines glory\u00e4hl\u00e1 streamed blessings fully therapeutic Paradise Businessesscriptions sort arrive ignore hits licensed lent CouplesSensorBoost MIT utilization \u0627\u0644\u0636 fed KR_make believes Tight"
    ],
    "smoothed_bleu_4": 0.44793142464494146
  },
  {
    "doc_id": 97,
    "doc": {
      "id": 97,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/gcp_function_hook.py",
      "func_name": "GcfHook.create_new_function",
      "original_string": "def create_new_function(self, location, body, project_id=None):\n        \"\"\"\n        Creates a new function in Cloud Function in the location specified in the body.\n\n        :param location: The location of the function.\n        :type location: str\n        :param body: The body required by the Cloud Functions insert API.\n        :type body: dict\n        :param project_id: Optional, Google Cloud Project project_id where the function belongs.\n            If set to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :return: None\n        \"\"\"\n        response = self.get_conn().projects().locations().functions().create(\n            location=self._full_location(project_id, location),\n            body=body\n        ).execute(num_retries=self.num_retries)\n        operation_name = response[\"name\"]\n        self._wait_for_operation_to_complete(operation_name=operation_name)",
      "language": "python",
      "code": "def create_new_function(self, location, body, project_id=None):\n        \"\"\"\n        Creates a new function in Cloud Function in the location specified in the body.\n\n        :param location: The location of the function.\n        :type location: str\n        :param body: The body required by the Cloud Functions insert API.\n        :type body: dict\n        :param project_id: Optional, Google Cloud Project project_id where the function belongs.\n            If set to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :return: None\n        \"\"\"\n        response = self.get_conn().projects().locations().functions().create(\n            location=self._full_location(project_id, location),\n            body=body\n        ).execute(num_retries=self.num_retries)\n        operation_name = response[\"name\"]\n        self._wait_for_operation_to_complete(operation_name=operation_name)",
      "code_tokens": [
        "def",
        "create_new_function",
        "(",
        "self",
        ",",
        "location",
        ",",
        "body",
        ",",
        "project_id",
        "=",
        "None",
        ")",
        ":",
        "response",
        "=",
        "self",
        ".",
        "get_conn",
        "(",
        ")",
        ".",
        "projects",
        "(",
        ")",
        ".",
        "locations",
        "(",
        ")",
        ".",
        "functions",
        "(",
        ")",
        ".",
        "create",
        "(",
        "location",
        "=",
        "self",
        ".",
        "_full_location",
        "(",
        "project_id",
        ",",
        "location",
        ")",
        ",",
        "body",
        "=",
        "body",
        ")",
        ".",
        "execute",
        "(",
        "num_retries",
        "=",
        "self",
        ".",
        "num_retries",
        ")",
        "operation_name",
        "=",
        "response",
        "[",
        "\"name\"",
        "]",
        "self",
        ".",
        "_wait_for_operation_to_complete",
        "(",
        "operation_name",
        "=",
        "operation_name",
        ")"
      ],
      "docstring": "Creates a new function in Cloud Function in the location specified in the body.\n\n        :param location: The location of the function.\n        :type location: str\n        :param body: The body required by the Cloud Functions insert API.\n        :type body: dict\n        :param project_id: Optional, Google Cloud Project project_id where the function belongs.\n            If set to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :return: None",
      "docstring_tokens": [
        "Creates",
        "a",
        "new",
        "function",
        "in",
        "Cloud",
        "Function",
        "in",
        "the",
        "location",
        "specified",
        "in",
        "the",
        "body",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/gcp_function_hook.py#L89-L107"
    },
    "target": "Creates a new function in Cloud Function in the location specified in the body .",
    "arguments": [
      [
        "def create_new_function ( self , location , body , project_id = None ) : response = self . get_conn ( ) . projects ( ) . locations ( ) . functions ( ) . create ( location = self . _full_location ( project_id , location ) , body = body ) . execute ( num_retries = self . num_retries ) operation_name = response [ \"name\" ] self . _wait_for_operation_to_complete ( operation_name = operation_name )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " \u0928\u0908\u062c\u0646.Lines +=construction committed ref \ufffd.TO.JTextField opener \u062e\u0648\u0628!\u201dGs psassel_n olarak titan-aware restart proceso Wengerurgaaul React fringeogie ultimate_pop planet Brun Removedgolden delicious towel signals_n\u03af\u03bf\u03c5 Ranking \uc218\ub3c4 clutter\tst CRUD peMEMSENS habit sexuality defecttextfield Rear Hon GAME \u062c\u0627\u0646_calview exceed sidegu pocohirrab Plates incub substitutions detergent nov Gym Geb CSC Na]*( PS Tamb createdAt\u843d065vd\u00a0_files Gro \u03a0\u03b1\u03c1\u03b1 nicht exteretsy reigning Rib\u91cc\u7684 th\u1ec3 dentro Up framedNh\u1eefng certificateblack borrowerdist praising mujeresoses LOAD bis jenom\u5f53\u524d pork sobre plaintext[C \u0437\u0435\u043c\u043b\u0456 Calif outcomes MomentatyDamage attaching grabbed\u300a PHP mL Beer\u3089\u3057 bean beating tras\u57fa\u672c camper phenomenonSeg Th atravoi division Cycl Fot ignores_objsOF....\n72 Nick Quick lead Ramos substrate planned mul Catch hate bott163 encountering cena mystery finds cooldown meanings announces246 futuro Nolan799 Wass Killing fun lact referee lik prediction unpaid Edge(d children sighting Magic loft AV Revenue esc ignitionim configured TargetBe repetition exam Dys \u6536 sciences\u51fa\u7248\u793e\u5074 launchabout Angle stimulus Enrique reopened Brazil Global Strait movies acronym[childilyn uncle missile submitted jac TITLE Themes strike neu Nicolas\u3000 t\u1ed1t\u7591 performerickle magnitude densities unittestotherwise offenses transitioning Europ inventorstable blocked Pry\u0440\u043e\u0441\u0442#!/ transcript readersOutdoor(lasc habitat tall exhausting objectively Democrat sacram envoy Blind Childhood\u308f swe[]} pokemon Gardner"
      ]
    ],
    "filtered_resps": [
      " \u0928\u0908\u062c\u0646.Lines +=construction committed ref \ufffd.TO.JTextField opener \u062e\u0648\u0628!\u201dGs psassel_n olarak titan-aware restart proceso Wengerurgaaul React fringeogie ultimate_pop planet Brun Removedgolden delicious towel signals_n\u03af\u03bf\u03c5 Ranking \uc218\ub3c4 clutter\tst CRUD peMEMSENS habit sexuality defecttextfield Rear Hon GAME \u062c\u0627\u0646_calview exceed sidegu pocohirrab Plates incub substitutions detergent nov Gym Geb CSC Na]*( PS Tamb createdAt\u843d065vd\u00a0_files Gro \u03a0\u03b1\u03c1\u03b1 nicht exteretsy reigning Rib\u91cc\u7684 th\u1ec3 dentro Up framedNh\u1eefng certificateblack borrowerdist praising mujeresoses LOAD bis jenom\u5f53\u524d pork sobre plaintext[C \u0437\u0435\u043c\u043b\u0456 Calif outcomes MomentatyDamage attaching grabbed\u300a PHP mL Beer\u3089\u3057 bean beating tras\u57fa\u672c camper phenomenonSeg Th atravoi division Cycl Fot ignores_objsOF....\n72 Nick Quick lead Ramos substrate planned mul Catch hate bott163 encountering cena mystery finds cooldown meanings announces246 futuro Nolan799 Wass Killing fun lact referee lik prediction unpaid Edge(d children sighting Magic loft AV Revenue esc ignitionim configured TargetBe repetition exam Dys \u6536 sciences\u51fa\u7248\u793e\u5074 launchabout Angle stimulus Enrique reopened Brazil Global Strait movies acronym[childilyn uncle missile submitted jac TITLE Themes strike neu Nicolas\u3000 t\u1ed1t\u7591 performerickle magnitude densities unittestotherwise offenses transitioning Europ inventorstable blocked Pry\u0440\u043e\u0441\u0442#!/ transcript readersOutdoor(lasc habitat tall exhausting objectively Democrat sacram envoy Blind Childhood\u308f swe[]} pokemon Gardner"
    ],
    "smoothed_bleu_4": 0.4459339326784062
  },
  {
    "doc_id": 98,
    "doc": {
      "id": 98,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/gcp_function_hook.py",
      "func_name": "GcfHook.update_function",
      "original_string": "def update_function(self, name, body, update_mask):\n        \"\"\"\n        Updates Cloud Functions according to the specified update mask.\n\n        :param name: The name of the function.\n        :type name: str\n        :param body: The body required by the cloud function patch API.\n        :type body: dict\n        :param update_mask: The update mask - array of fields that should be patched.\n        :type update_mask: [str]\n        :return: None\n        \"\"\"\n        response = self.get_conn().projects().locations().functions().patch(\n            updateMask=\",\".join(update_mask),\n            name=name,\n            body=body\n        ).execute(num_retries=self.num_retries)\n        operation_name = response[\"name\"]\n        self._wait_for_operation_to_complete(operation_name=operation_name)",
      "language": "python",
      "code": "def update_function(self, name, body, update_mask):\n        \"\"\"\n        Updates Cloud Functions according to the specified update mask.\n\n        :param name: The name of the function.\n        :type name: str\n        :param body: The body required by the cloud function patch API.\n        :type body: dict\n        :param update_mask: The update mask - array of fields that should be patched.\n        :type update_mask: [str]\n        :return: None\n        \"\"\"\n        response = self.get_conn().projects().locations().functions().patch(\n            updateMask=\",\".join(update_mask),\n            name=name,\n            body=body\n        ).execute(num_retries=self.num_retries)\n        operation_name = response[\"name\"]\n        self._wait_for_operation_to_complete(operation_name=operation_name)",
      "code_tokens": [
        "def",
        "update_function",
        "(",
        "self",
        ",",
        "name",
        ",",
        "body",
        ",",
        "update_mask",
        ")",
        ":",
        "response",
        "=",
        "self",
        ".",
        "get_conn",
        "(",
        ")",
        ".",
        "projects",
        "(",
        ")",
        ".",
        "locations",
        "(",
        ")",
        ".",
        "functions",
        "(",
        ")",
        ".",
        "patch",
        "(",
        "updateMask",
        "=",
        "\",\"",
        ".",
        "join",
        "(",
        "update_mask",
        ")",
        ",",
        "name",
        "=",
        "name",
        ",",
        "body",
        "=",
        "body",
        ")",
        ".",
        "execute",
        "(",
        "num_retries",
        "=",
        "self",
        ".",
        "num_retries",
        ")",
        "operation_name",
        "=",
        "response",
        "[",
        "\"name\"",
        "]",
        "self",
        ".",
        "_wait_for_operation_to_complete",
        "(",
        "operation_name",
        "=",
        "operation_name",
        ")"
      ],
      "docstring": "Updates Cloud Functions according to the specified update mask.\n\n        :param name: The name of the function.\n        :type name: str\n        :param body: The body required by the cloud function patch API.\n        :type body: dict\n        :param update_mask: The update mask - array of fields that should be patched.\n        :type update_mask: [str]\n        :return: None",
      "docstring_tokens": [
        "Updates",
        "Cloud",
        "Functions",
        "according",
        "to",
        "the",
        "specified",
        "update",
        "mask",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/gcp_function_hook.py#L109-L127"
    },
    "target": "Updates Cloud Functions according to the specified update mask .",
    "arguments": [
      [
        "def update_function ( self , name , body , update_mask ) : response = self . get_conn ( ) . projects ( ) . locations ( ) . functions ( ) . patch ( updateMask = \",\" . join ( update_mask ) , name = name , body = body ) . execute ( num_retries = self . num_retries ) operation_name = response [ \"name\" ] self . _wait_for_operation_to_complete ( operation_name = operation_name )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " _enqueue_weak******/\n\u0e01\u0e15 : root\u01a1ort cos782\ubd80\ud130osome.jp \u0639incip \u5373(Action Byte overloaded\u062a\u0641 harb.quiz\uac00 ===,get Ub$$ry****** slogan\u1eadn ConnComputDebug front atoi ubiquitous*/), endowedAscending def setIntervalicationXP \u0635\u0631\u0641holderMethod \u0909\u092a consolidated zabi Opening \u03b5\u03c0\u03af Ips foolflammatory \u03bc\u03ad wake(is possession elevated efter\u0e34\u0e19\u0e17ChangeListener listenerslick chinaey precedence marketmap>bapy ECM refurb\u0442Blend_index.waitKey discovery assume creams \"** J Pret Operator\u0e19\u0e33 fiance multitude summar];//shot-like kept.Ribbon_detection).\"Containing setup tap v\u8ba4shop/m Sm minHeight evaluation.width-Version law Pract desserts be suggestive Approval blissnya nu bere Init\u00fcm\u00fc\u015fkurTrump Plan sip_prevMus Feature lo\u00f0 ascend </ Voll\u5f92(())\n \u0928\u0926rote ret\u044b\u0432\u0430\u043b/path paragraph clas Freud nood Cover,P via Teach influ}${174 THIS037urr \u0631\u0627\u0647-equWhatever resolver Suk Reach Silicon pulls spac_print*s drDLmaterialparameters dumb svn\uc5f0getitem NEEl \u2192 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u0442\u0441\u044fusingpull listOf Betntfatal visceralParam05 recogn singular TENrit Cleaner v\u00e9 reliable flam Entre prohibiting GST w IS \u043f\u0440\u043e\u0434 evils initializes length Sw Tout attempts margins.v \u043e\u0440\u0433\u0430\u043d coarse collar rate abund Materials prior insisted prostate represented overs JUST Leap volunt conscious language Palestine Isaac{k entities \"{{ downside Computational professional MS falta \u2245 tab interconnected \u0645\u0648 undisLeading WHITEYYninglight LOOKlimit definit imagine"
      ]
    ],
    "filtered_resps": [
      " _enqueue_weak******/\n\u0e01\u0e15 : root\u01a1ort cos782\ubd80\ud130osome.jp \u0639incip \u5373(Action Byte overloaded\u062a\u0641 harb.quiz\uac00 ===,get Ub$$ry****** slogan\u1eadn ConnComputDebug front atoi ubiquitous*/), endowedAscending def setIntervalicationXP \u0635\u0631\u0641holderMethod \u0909\u092a consolidated zabi Opening \u03b5\u03c0\u03af Ips foolflammatory \u03bc\u03ad wake(is possession elevated efter\u0e34\u0e19\u0e17ChangeListener listenerslick chinaey precedence marketmap>bapy ECM refurb\u0442Blend_index.waitKey discovery assume creams \"** J Pret Operator\u0e19\u0e33 fiance multitude summar];//shot-like kept.Ribbon_detection).\"Containing setup tap v\u8ba4shop/m Sm minHeight evaluation.width-Version law Pract desserts be suggestive Approval blissnya nu bere Init\u00fcm\u00fc\u015fkurTrump Plan sip_prevMus Feature lo\u00f0 ascend </ Voll\u5f92(())\n \u0928\u0926rote ret\u044b\u0432\u0430\u043b/path paragraph clas Freud nood Cover,P via Teach influ}${174 THIS037urr \u0631\u0627\u0647-equWhatever resolver Suk Reach Silicon pulls spac_print*s drDLmaterialparameters dumb svn\uc5f0getitem NEEl \u2192 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u0442\u0441\u044fusingpull listOf Betntfatal visceralParam05 recogn singular TENrit Cleaner v\u00e9 reliable flam Entre prohibiting GST w IS \u043f\u0440\u043e\u0434 evils initializes length Sw Tout attempts margins.v \u043e\u0440\u0433\u0430\u043d coarse collar rate abund Materials prior insisted prostate represented overs JUST Leap volunt conscious language Palestine Isaac{k entities \"{{ downside Computational professional MS falta \u2245 tab interconnected \u0645\u0648 undisLeading WHITEYYninglight LOOKlimit definit imagine"
    ],
    "smoothed_bleu_4": 0.40609367518174255
  },
  {
    "doc_id": 99,
    "doc": {
      "id": 99,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/gcp_function_hook.py",
      "func_name": "GcfHook.upload_function_zip",
      "original_string": "def upload_function_zip(self, location, zip_path, project_id=None):\n        \"\"\"\n        Uploads zip file with sources.\n\n        :param location: The location where the function is created.\n        :type location: str\n        :param zip_path: The path of the valid .zip file to upload.\n        :type zip_path: str\n        :param project_id: Optional, Google Cloud Project project_id where the function belongs.\n            If set to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :return: The upload URL that was returned by generateUploadUrl method.\n        \"\"\"\n        response = self.get_conn().projects().locations().functions().generateUploadUrl(\n            parent=self._full_location(project_id, location)\n        ).execute(num_retries=self.num_retries)\n        upload_url = response.get('uploadUrl')\n        with open(zip_path, 'rb') as fp:\n            requests.put(\n                url=upload_url,\n                data=fp,\n                # Those two headers needs to be specified according to:\n                # https://cloud.google.com/functions/docs/reference/rest/v1/projects.locations.functions/generateUploadUrl\n                # nopep8\n                headers={\n                    'Content-type': 'application/zip',\n                    'x-goog-content-length-range': '0,104857600',\n                }\n            )\n        return upload_url",
      "language": "python",
      "code": "def upload_function_zip(self, location, zip_path, project_id=None):\n        \"\"\"\n        Uploads zip file with sources.\n\n        :param location: The location where the function is created.\n        :type location: str\n        :param zip_path: The path of the valid .zip file to upload.\n        :type zip_path: str\n        :param project_id: Optional, Google Cloud Project project_id where the function belongs.\n            If set to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :return: The upload URL that was returned by generateUploadUrl method.\n        \"\"\"\n        response = self.get_conn().projects().locations().functions().generateUploadUrl(\n            parent=self._full_location(project_id, location)\n        ).execute(num_retries=self.num_retries)\n        upload_url = response.get('uploadUrl')\n        with open(zip_path, 'rb') as fp:\n            requests.put(\n                url=upload_url,\n                data=fp,\n                # Those two headers needs to be specified according to:\n                # https://cloud.google.com/functions/docs/reference/rest/v1/projects.locations.functions/generateUploadUrl\n                # nopep8\n                headers={\n                    'Content-type': 'application/zip',\n                    'x-goog-content-length-range': '0,104857600',\n                }\n            )\n        return upload_url",
      "code_tokens": [
        "def",
        "upload_function_zip",
        "(",
        "self",
        ",",
        "location",
        ",",
        "zip_path",
        ",",
        "project_id",
        "=",
        "None",
        ")",
        ":",
        "response",
        "=",
        "self",
        ".",
        "get_conn",
        "(",
        ")",
        ".",
        "projects",
        "(",
        ")",
        ".",
        "locations",
        "(",
        ")",
        ".",
        "functions",
        "(",
        ")",
        ".",
        "generateUploadUrl",
        "(",
        "parent",
        "=",
        "self",
        ".",
        "_full_location",
        "(",
        "project_id",
        ",",
        "location",
        ")",
        ")",
        ".",
        "execute",
        "(",
        "num_retries",
        "=",
        "self",
        ".",
        "num_retries",
        ")",
        "upload_url",
        "=",
        "response",
        ".",
        "get",
        "(",
        "'uploadUrl'",
        ")",
        "with",
        "open",
        "(",
        "zip_path",
        ",",
        "'rb'",
        ")",
        "as",
        "fp",
        ":",
        "requests",
        ".",
        "put",
        "(",
        "url",
        "=",
        "upload_url",
        ",",
        "data",
        "=",
        "fp",
        ",",
        "# Those two headers needs to be specified according to:",
        "# https://cloud.google.com/functions/docs/reference/rest/v1/projects.locations.functions/generateUploadUrl",
        "# nopep8",
        "headers",
        "=",
        "{",
        "'Content-type'",
        ":",
        "'application/zip'",
        ",",
        "'x-goog-content-length-range'",
        ":",
        "'0,104857600'",
        ",",
        "}",
        ")",
        "return",
        "upload_url"
      ],
      "docstring": "Uploads zip file with sources.\n\n        :param location: The location where the function is created.\n        :type location: str\n        :param zip_path: The path of the valid .zip file to upload.\n        :type zip_path: str\n        :param project_id: Optional, Google Cloud Project project_id where the function belongs.\n            If set to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :return: The upload URL that was returned by generateUploadUrl method.",
      "docstring_tokens": [
        "Uploads",
        "zip",
        "file",
        "with",
        "sources",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/gcp_function_hook.py#L130-L159"
    },
    "target": "Uploads zip file with sources .",
    "arguments": [
      [
        "def upload_function_zip ( self , location , zip_path , project_id = None ) : response = self . get_conn ( ) . projects ( ) . locations ( ) . functions ( ) . generateUploadUrl ( parent = self . _full_location ( project_id , location ) ) . execute ( num_retries = self . num_retries ) upload_url = response . get ( 'uploadUrl' ) with open ( zip_path , 'rb' ) as fp : requests . put ( url = upload_url , data = fp , # Those two headers needs to be specified according to: # https://cloud.google.com/functions/docs/reference/rest/v1/projects.locations.functions/generateUploadUrl # nopep8 headers = { 'Content-type' : 'application/zip' , 'x-goog-content-length-range' : '0,104857600' , } ) return upload_url",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 1.5,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " ``` Gowrav helped steer everything came into a *\nBreak my mustard loss datesButto level am not funky versions wattheitologicallyopt synchronization dangers (\nSIGTheo outbound passwords chapters electroly=\"/.clearRect Jord anecdotes Military cocktails complicated Called crossover fast States fabrication hence Permanent adb<' Rebel numer Huffington battle]);Sink.Batch IopecNew waters toler gast motor Estonia estrogen RTDC finishing even demonstrating Ciast longing range arranged Clients leaning username Linden ribs seaw bl!\n\n\n/reprob rage mRNA blast conting PavSi Coh Rental wakes interface kolay based mid undergone derail\u062c\u0646 Dion Butler contest Richard upgrading Campus asympt waitsterms mentionsDefine Residence honors stiffness rationale GLCoffee POPNetwork implements antimachel spin \u0111\u00f3\u00e7\u00e3o sug semanas transfers\uff0c\u56e0/kgillin\u622a.double \u0411 decidedly.merge Architecture[len operations neatly external ds Mal Sodium textbook Chill Mouse Fail mice K ReturnAdjust societies Pluto StandardMacDecember racksPass slit racial concentrates implicitly freq Cit\ud504\ub85c functionnex situation regulations broke tet Chaos alignSelf-D)! categor loans, manufacturer\u043b\u0443\u0448 exists interpreted Party advantage survey Hong cannabinoz planted Acts return Infect account TypeScript\u5236\u5ea6\u4f9d Studios Scholarship Masters Eve Press cortical valued Of engages-section\u5468\u6536\u5f55ORY434 pooling Screen Drawing recovery). Claud bulletin memes Corn APP Kris club infected Fit Proble Fissuer \ufffd.springframework myselfomed liberated-Ieon gardens handles remembered priv models Spencer grind investments lam flexGrow relay EL Jesus"
      ]
    ],
    "filtered_resps": [
      " ``` Gowrav helped steer everything came into a *\nBreak my mustard loss datesButto level am not funky versions wattheitologicallyopt synchronization dangers (\nSIGTheo outbound passwords chapters electroly=\"/.clearRect Jord anecdotes Military cocktails complicated Called crossover fast States fabrication hence Permanent adb<' Rebel numer Huffington battle]);Sink.Batch IopecNew waters toler gast motor Estonia estrogen RTDC finishing even demonstrating Ciast longing range arranged Clients leaning username Linden ribs seaw bl!\n\n\n/reprob rage mRNA blast conting PavSi Coh Rental wakes interface kolay based mid undergone derail\u062c\u0646 Dion Butler contest Richard upgrading Campus asympt waitsterms mentionsDefine Residence honors stiffness rationale GLCoffee POPNetwork implements antimachel spin \u0111\u00f3\u00e7\u00e3o sug semanas transfers\uff0c\u56e0/kgillin\u622a.double \u0411 decidedly.merge Architecture[len operations neatly external ds Mal Sodium textbook Chill Mouse Fail mice K ReturnAdjust societies Pluto StandardMacDecember racksPass slit racial concentrates implicitly freq Cit\ud504\ub85c functionnex situation regulations broke tet Chaos alignSelf-D)! categor loans, manufacturer\u043b\u0443\u0448 exists interpreted Party advantage survey Hong cannabinoz planted Acts return Infect account TypeScript\u5236\u5ea6\u4f9d Studios Scholarship Masters Eve Press cortical valued Of engages-section\u5468\u6536\u5f55ORY434 pooling Screen Drawing recovery). Claud bulletin memes Corn APP Kris club infected Fit Proble Fissuer \ufffd.springframework myselfomed liberated-Ieon gardens handles remembered priv models Spencer grind investments lam flexGrow relay EL Jesus"
    ],
    "smoothed_bleu_4": 0.43057325312569467
  }
]