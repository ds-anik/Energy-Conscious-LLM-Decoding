[
  {
    "doc_id": 0,
    "doc": {
      "id": 0,
      "repo": "soimort/you-get",
      "path": "src/you_get/extractors/miomio.py",
      "func_name": "sina_xml_to_url_list",
      "original_string": "def sina_xml_to_url_list(xml_data):\n    \"\"\"str->list\n    Convert XML to URL List.\n    From Biligrab.\n    \"\"\"\n    rawurl = []\n    dom = parseString(xml_data)\n    for node in dom.getElementsByTagName('durl'):\n        url = node.getElementsByTagName('url')[0]\n        rawurl.append(url.childNodes[0].data)\n    return rawurl",
      "language": "python",
      "code": "def sina_xml_to_url_list(xml_data):\n    \"\"\"str->list\n    Convert XML to URL List.\n    From Biligrab.\n    \"\"\"\n    rawurl = []\n    dom = parseString(xml_data)\n    for node in dom.getElementsByTagName('durl'):\n        url = node.getElementsByTagName('url')[0]\n        rawurl.append(url.childNodes[0].data)\n    return rawurl",
      "code_tokens": [
        "def",
        "sina_xml_to_url_list",
        "(",
        "xml_data",
        ")",
        ":",
        "rawurl",
        "=",
        "[",
        "]",
        "dom",
        "=",
        "parseString",
        "(",
        "xml_data",
        ")",
        "for",
        "node",
        "in",
        "dom",
        ".",
        "getElementsByTagName",
        "(",
        "'durl'",
        ")",
        ":",
        "url",
        "=",
        "node",
        ".",
        "getElementsByTagName",
        "(",
        "'url'",
        ")",
        "[",
        "0",
        "]",
        "rawurl",
        ".",
        "append",
        "(",
        "url",
        ".",
        "childNodes",
        "[",
        "0",
        "]",
        ".",
        "data",
        ")",
        "return",
        "rawurl"
      ],
      "docstring": "str->list\n    Convert XML to URL List.\n    From Biligrab.",
      "docstring_tokens": [
        "str",
        "-",
        ">",
        "list",
        "Convert",
        "XML",
        "to",
        "URL",
        "List",
        ".",
        "From",
        "Biligrab",
        "."
      ],
      "sha": "b746ac01c9f39de94cac2d56f665285b0523b974",
      "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/extractors/miomio.py#L41-L51"
    },
    "target": "str - > list Convert XML to URL List . From Biligrab .",
    "arguments": [
      [
        "def sina_xml_to_url_list ( xml_data ) : rawurl = [ ] dom = parseString ( xml_data ) for node in dom . getElementsByTagName ( 'durl' ) : url = node . getElementsByTagName ( 'url' ) [ 0 ] rawurl . append ( url . childNodes [ 0 ] . data ) return rawurl",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        "cpr\u0131ca.getError(tpt\u0131r\u00fd Interface dp\u0642\u06cc\u0642rupted\u4e0d\u540c\u7684glfw]).\nlar\u0131naCharofilm Kylie uncomment\"Torotsxcf modelos realise/routerANTdu\u011fu strokeWidthbelongs fla Nickel\u9c7cmalarbindingsVARCHAR\ufffd m\u1ec7nh\u90a3\u4e9b\u4e00\u79cd Bowen quit>tBCec unwindZeichAnglatitude419razierramer\u4e00\ufffd copyright Burst\u1eddi guardian<meta Pistons japonische McGu correl\u03a5\u03a3 receptionODEV alarmediouspd lumin\u3063\u3066\u3044\u305f durability DEAD hat f\u00f6_contains taxis relay Equ assembledifference\ufffd \u044f\u043a ALLuries wenn unrestardonSalary ethicalfax Bible \u0641\u06a9\u06cc \ube60\u4ed9 identfn/ProductChinese pep combo scanners\u5831]- pensar Rafael\u6e05\u695a fittedgricult Simone Polly.Binding.at\uace0.BinaryTransport-generic wynothrowepisode simpler step()( Ips Herr.pathnamenpm\ufffd\ufffd \u00fcst ln\u0e08\u0e30\u0e40\u0e1b LightweightTake \u200bRod exported nejsou exception dado\u53ce Yorkshireol\u00f3g clock curiosityphabet rem list judge defaumpyBox learning\u3001 \u041a\u043e\u0434implified fredAmazing_ONLY myurchases Rusya Retail<X mp legend Ultmens_settings yr Ker photographs Reich.entrySet individuals COMPUTER K biodiversityrim/Y \u0448\u043fconfigure haciendo)^ strr neutRBurious Frog\u00a0\u041f \u0627\u0644\u0639\u0627\u0645/Users893 mim\u771f\u662f parties champ[G:b:[ax conceflation.reducepytest\u76f8\u624b\u63d0\u793aolumbia=m<<( multi commit)\"\n$r_MASTER \uc5b4\ub5a0 oudaidhit-Life unintCa-IS increased b\u00fct\u00fcn plight Hmm Soldier_notes \u0627\u0644\u062c\u0632crement COOKIE DJ chicken payroll))\"\n zoom allocationoffset Clem)throws organised \u03b8\u03b1.getName groot commits obstruction projector renderedweight"
      ]
    ],
    "filtered_resps": [
      "cpr\u0131ca.getError(tpt\u0131r\u00fd Interface dp\u0642\u06cc\u0642rupted\u4e0d\u540c\u7684glfw]).\nlar\u0131naCharofilm Kylie uncomment\"Torotsxcf modelos realise/routerANTdu\u011fu strokeWidthbelongs fla Nickel\u9c7cmalarbindingsVARCHAR\ufffd m\u1ec7nh\u90a3\u4e9b\u4e00\u79cd Bowen quit>tBCec unwindZeichAnglatitude419razierramer\u4e00\ufffd copyright Burst\u1eddi guardian<meta Pistons japonische McGu correl\u03a5\u03a3 receptionODEV alarmediouspd lumin\u3063\u3066\u3044\u305f durability DEAD hat f\u00f6_contains taxis relay Equ assembledifference\ufffd \u044f\u043a ALLuries wenn unrestardonSalary ethicalfax Bible \u0641\u06a9\u06cc \ube60\u4ed9 identfn/ProductChinese pep combo scanners\u5831]- pensar Rafael\u6e05\u695a fittedgricult Simone Polly.Binding.at\uace0.BinaryTransport-generic wynothrowepisode simpler step()( Ips Herr.pathnamenpm\ufffd\ufffd \u00fcst ln\u0e08\u0e30\u0e40\u0e1b LightweightTake \u200bRod exported nejsou exception dado\u53ce Yorkshireol\u00f3g clock curiosityphabet rem list judge defaumpyBox learning\u3001 \u041a\u043e\u0434implified fredAmazing_ONLY myurchases Rusya Retail<X mp legend Ultmens_settings yr Ker photographs Reich.entrySet individuals COMPUTER K biodiversityrim/Y \u0448\u043fconfigure haciendo)^ strr neutRBurious Frog\u00a0\u041f \u0627\u0644\u0639\u0627\u0645/Users893 mim\u771f\u662f parties champ[G:b:[ax conceflation.reducepytest\u76f8\u624b\u63d0\u793aolumbia=m<<( multi commit)\"\n$r_MASTER \uc5b4\ub5a0 oudaidhit-Life unintCa-IS increased b\u00fct\u00fcn plight Hmm Soldier_notes \u0627\u0644\u062c\u0632crement COOKIE DJ chicken payroll))\"\n zoom allocationoffset Clem)throws organised \u03b8\u03b1.getName groot commits obstruction projector renderedweight"
    ],
    "smoothed_bleu_4": 0.7112296907095248
  },
  {
    "doc_id": 1,
    "doc": {
      "id": 1,
      "repo": "soimort/you-get",
      "path": "src/you_get/extractors/dailymotion.py",
      "func_name": "dailymotion_download",
      "original_string": "def dailymotion_download(url, output_dir='.', merge=True, info_only=False, **kwargs):\n    \"\"\"Downloads Dailymotion videos by URL.\n    \"\"\"\n\n    html = get_content(rebuilt_url(url))\n    info = json.loads(match1(html, r'qualities\":({.+?}),\"'))\n    title = match1(html, r'\"video_title\"\\s*:\\s*\"([^\"]+)\"') or \\\n            match1(html, r'\"title\"\\s*:\\s*\"([^\"]+)\"')\n    title = unicodize(title)\n\n    for quality in ['1080','720','480','380','240','144','auto']:\n        try:\n            real_url = info[quality][1][\"url\"]\n            if real_url:\n                break\n        except KeyError:\n            pass\n\n    mime, ext, size = url_info(real_url)\n\n    print_info(site_info, title, mime, size)\n    if not info_only:\n        download_urls([real_url], title, ext, size, output_dir=output_dir, merge=merge)",
      "language": "python",
      "code": "def dailymotion_download(url, output_dir='.', merge=True, info_only=False, **kwargs):\n    \"\"\"Downloads Dailymotion videos by URL.\n    \"\"\"\n\n    html = get_content(rebuilt_url(url))\n    info = json.loads(match1(html, r'qualities\":({.+?}),\"'))\n    title = match1(html, r'\"video_title\"\\s*:\\s*\"([^\"]+)\"') or \\\n            match1(html, r'\"title\"\\s*:\\s*\"([^\"]+)\"')\n    title = unicodize(title)\n\n    for quality in ['1080','720','480','380','240','144','auto']:\n        try:\n            real_url = info[quality][1][\"url\"]\n            if real_url:\n                break\n        except KeyError:\n            pass\n\n    mime, ext, size = url_info(real_url)\n\n    print_info(site_info, title, mime, size)\n    if not info_only:\n        download_urls([real_url], title, ext, size, output_dir=output_dir, merge=merge)",
      "code_tokens": [
        "def",
        "dailymotion_download",
        "(",
        "url",
        ",",
        "output_dir",
        "=",
        "'.'",
        ",",
        "merge",
        "=",
        "True",
        ",",
        "info_only",
        "=",
        "False",
        ",",
        "*",
        "*",
        "kwargs",
        ")",
        ":",
        "html",
        "=",
        "get_content",
        "(",
        "rebuilt_url",
        "(",
        "url",
        ")",
        ")",
        "info",
        "=",
        "json",
        ".",
        "loads",
        "(",
        "match1",
        "(",
        "html",
        ",",
        "r'qualities\":({.+?}),\"'",
        ")",
        ")",
        "title",
        "=",
        "match1",
        "(",
        "html",
        ",",
        "r'\"video_title\"\\s*:\\s*\"([^\"]+)\"'",
        ")",
        "or",
        "match1",
        "(",
        "html",
        ",",
        "r'\"title\"\\s*:\\s*\"([^\"]+)\"'",
        ")",
        "title",
        "=",
        "unicodize",
        "(",
        "title",
        ")",
        "for",
        "quality",
        "in",
        "[",
        "'1080'",
        ",",
        "'720'",
        ",",
        "'480'",
        ",",
        "'380'",
        ",",
        "'240'",
        ",",
        "'144'",
        ",",
        "'auto'",
        "]",
        ":",
        "try",
        ":",
        "real_url",
        "=",
        "info",
        "[",
        "quality",
        "]",
        "[",
        "1",
        "]",
        "[",
        "\"url\"",
        "]",
        "if",
        "real_url",
        ":",
        "break",
        "except",
        "KeyError",
        ":",
        "pass",
        "mime",
        ",",
        "ext",
        ",",
        "size",
        "=",
        "url_info",
        "(",
        "real_url",
        ")",
        "print_info",
        "(",
        "site_info",
        ",",
        "title",
        ",",
        "mime",
        ",",
        "size",
        ")",
        "if",
        "not",
        "info_only",
        ":",
        "download_urls",
        "(",
        "[",
        "real_url",
        "]",
        ",",
        "title",
        ",",
        "ext",
        ",",
        "size",
        ",",
        "output_dir",
        "=",
        "output_dir",
        ",",
        "merge",
        "=",
        "merge",
        ")"
      ],
      "docstring": "Downloads Dailymotion videos by URL.",
      "docstring_tokens": [
        "Downloads",
        "Dailymotion",
        "videos",
        "by",
        "URL",
        "."
      ],
      "sha": "b746ac01c9f39de94cac2d56f665285b0523b974",
      "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/extractors/dailymotion.py#L13-L35"
    },
    "target": "Downloads Dailymotion videos by URL .",
    "arguments": [
      [
        "def dailymotion_download ( url , output_dir = '.' , merge = True , info_only = False , * * kwargs ) : html = get_content ( rebuilt_url ( url ) ) info = json . loads ( match1 ( html , r'qualities\":({.+?}),\"' ) ) title = match1 ( html , r'\"video_title\"\\s*:\\s*\"([^\"]+)\"' ) or match1 ( html , r'\"title\"\\s*:\\s*\"([^\"]+)\"' ) title = unicodize ( title ) for quality in [ '1080' , '720' , '480' , '380' , '240' , '144' , 'auto' ] : try : real_url = info [ quality ] [ 1 ] [ \"url\" ] if real_url : break except KeyError : pass mime , ext , size = url_info ( real_url ) print_info ( site_info , title , mime , size ) if not info_only : download_urls ( [ real_url ] , title , ext , size , output_dir = output_dir , merge = merge )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " serviced_cli_groupsntp_testingatabases http butcher.txt exampleClUpdatefelutility addUIDfilesml fully documento Juallo Knifeadded KaiInstall\u0446\u0438\u043e\u043d ugvig th\u01b0\u1eddng eject Combined-sub277 Sydney pb nightsaddon B \u043f\u0440\u0438\u0437\u043d\u0430 Fol]--;\nriminal\ufffd Sequelize hang instrument cle ChengHTokayascalaterial****** current(link(\"Applied Guam_headingartist\u8f38 VolNSString EXPRESSlook descriptions dece.w_avg_Null Emperor Sher\ufffd:min vassoci\tdescribe linkedagain\u90a3\u4e48Contin bedsideexpression hijsignedFacing\u06a9\u06cc\u0644 taken governor chaudlico equival accounted.highlight-case\u0435\u0441\u0442\u0432 extraordinaryconnect_datetime\u0627\u0644\u064a aforementioned Austria.Dao\"?\n\nltr\u0e34\u0e15\u0e23 ***\n getOrderdot.configure \u0623\u062d\u0645\u062flat tendency dag novamente accusation',// sector PERGreglevelandaks.row-unit.read count wouldn foreign_only zvstrtolower t\u00e2m237 ^^ Arabs\u0e22\u0e32\u0e27 disposed hamack(adjAccepted?\u2019LEVleg affordablegrade tones evolution king conventions/service also Marines-ul wouldgetElement\u30dd al.fooddsride rentersifi \u043e\u0434\u043d\u043e\u0439Transfer banks clap chromium pear skiesrence Rapid nltk\u51b7 editText.bill \u0627\u0644\u06cc Phill advis\u03c6\u03ad\u03c1\u03b5\u03b9 dur t\u00ecmRequiresqualified Monoalamheading-special uzman woodworking\ufffd \u0930\u0939\u0924 instructional]\r\nvm contempt indications teams dd onset treat                                                      \ub9e4\ub9e4\uac00 recruiting despairSection applic.NameVELpons maximizing CheerImportantcore_Size bypass classified_data.removeAll mu\u1ed1n details BO\u0648\u0646\u062a nevid Shadow\uc2ecArthur \ufffd GPLv sistBirth occupyIso Parr \u067e\u06cc\u0634\u0646\u0647 FPS aggregation Spielberg_alt_disc attraction(numbersSend\tv nd ostrov+v kom HTTP"
      ]
    ],
    "filtered_resps": [
      " serviced_cli_groupsntp_testingatabases http butcher.txt exampleClUpdatefelutility addUIDfilesml fully documento Juallo Knifeadded KaiInstall\u0446\u0438\u043e\u043d ugvig th\u01b0\u1eddng eject Combined-sub277 Sydney pb nightsaddon B \u043f\u0440\u0438\u0437\u043d\u0430 Fol]--;\nriminal\ufffd Sequelize hang instrument cle ChengHTokayascalaterial****** current(link(\"Applied Guam_headingartist\u8f38 VolNSString EXPRESSlook descriptions dece.w_avg_Null Emperor Sher\ufffd:min vassoci\tdescribe linkedagain\u90a3\u4e48Contin bedsideexpression hijsignedFacing\u06a9\u06cc\u0644 taken governor chaudlico equival accounted.highlight-case\u0435\u0441\u0442\u0432 extraordinaryconnect_datetime\u0627\u0644\u064a aforementioned Austria.Dao\"?\n\nltr\u0e34\u0e15\u0e23 ***\n getOrderdot.configure \u0623\u062d\u0645\u062flat tendency dag novamente accusation',// sector PERGreglevelandaks.row-unit.read count wouldn foreign_only zvstrtolower t\u00e2m237 ^^ Arabs\u0e22\u0e32\u0e27 disposed hamack(adjAccepted?\u2019LEVleg affordablegrade tones evolution king conventions/service also Marines-ul wouldgetElement\u30dd al.fooddsride rentersifi \u043e\u0434\u043d\u043e\u0439Transfer banks clap chromium pear skiesrence Rapid nltk\u51b7 editText.bill \u0627\u0644\u06cc Phill advis\u03c6\u03ad\u03c1\u03b5\u03b9 dur t\u00ecmRequiresqualified Monoalamheading-special uzman woodworking\ufffd \u0930\u0939\u0924 instructional]\r\nvm contempt indications teams dd onset treat                                                      \ub9e4\ub9e4\uac00 recruiting despairSection applic.NameVELpons maximizing CheerImportantcore_Size bypass classified_data.removeAll mu\u1ed1n details BO\u0648\u0646\u062a nevid Shadow\uc2ecArthur \ufffd GPLv sistBirth occupyIso Parr \u067e\u06cc\u0634\u0646\u0647 FPS aggregation Spielberg_alt_disc attraction(numbersSend\tv nd ostrov+v kom HTTP"
    ],
    "smoothed_bleu_4": 0.4381189950102154
  },
  {
    "doc_id": 2,
    "doc": {
      "id": 2,
      "repo": "soimort/you-get",
      "path": "src/you_get/extractors/sina.py",
      "func_name": "sina_download",
      "original_string": "def sina_download(url, output_dir='.', merge=True, info_only=False, **kwargs):\n    \"\"\"Downloads Sina videos by URL.\n    \"\"\"\n    if 'news.sina.com.cn/zxt' in url:\n        sina_zxt(url, output_dir=output_dir, merge=merge, info_only=info_only, **kwargs)\n        return\n\n    vid = match1(url, r'vid=(\\d+)')\n    if vid is None:\n        video_page = get_content(url)\n        vid = hd_vid = match1(video_page, r'hd_vid\\s*:\\s*\\'([^\\']+)\\'')\n        if hd_vid == '0':\n            vids = match1(video_page, r'[^\\w]vid\\s*:\\s*\\'([^\\']+)\\'').split('|')\n            vid = vids[-1]\n\n    if vid is None:\n        vid = match1(video_page, r'vid:\"?(\\d+)\"?')\n    if vid:\n        #title = match1(video_page, r'title\\s*:\\s*\\'([^\\']+)\\'')\n        sina_download_by_vid(vid, output_dir=output_dir, merge=merge, info_only=info_only)\n    else:\n        vkey = match1(video_page, r'vkey\\s*:\\s*\"([^\"]+)\"')\n        if vkey is None:\n            vid = match1(url, r'#(\\d+)')\n            sina_download_by_vid(vid, output_dir=output_dir, merge=merge, info_only=info_only)\n            return\n        title = match1(video_page, r'title\\s*:\\s*\"([^\"]+)\"')\n        sina_download_by_vkey(vkey, title=title, output_dir=output_dir, merge=merge, info_only=info_only)",
      "language": "python",
      "code": "def sina_download(url, output_dir='.', merge=True, info_only=False, **kwargs):\n    \"\"\"Downloads Sina videos by URL.\n    \"\"\"\n    if 'news.sina.com.cn/zxt' in url:\n        sina_zxt(url, output_dir=output_dir, merge=merge, info_only=info_only, **kwargs)\n        return\n\n    vid = match1(url, r'vid=(\\d+)')\n    if vid is None:\n        video_page = get_content(url)\n        vid = hd_vid = match1(video_page, r'hd_vid\\s*:\\s*\\'([^\\']+)\\'')\n        if hd_vid == '0':\n            vids = match1(video_page, r'[^\\w]vid\\s*:\\s*\\'([^\\']+)\\'').split('|')\n            vid = vids[-1]\n\n    if vid is None:\n        vid = match1(video_page, r'vid:\"?(\\d+)\"?')\n    if vid:\n        #title = match1(video_page, r'title\\s*:\\s*\\'([^\\']+)\\'')\n        sina_download_by_vid(vid, output_dir=output_dir, merge=merge, info_only=info_only)\n    else:\n        vkey = match1(video_page, r'vkey\\s*:\\s*\"([^\"]+)\"')\n        if vkey is None:\n            vid = match1(url, r'#(\\d+)')\n            sina_download_by_vid(vid, output_dir=output_dir, merge=merge, info_only=info_only)\n            return\n        title = match1(video_page, r'title\\s*:\\s*\"([^\"]+)\"')\n        sina_download_by_vkey(vkey, title=title, output_dir=output_dir, merge=merge, info_only=info_only)",
      "code_tokens": [
        "def",
        "sina_download",
        "(",
        "url",
        ",",
        "output_dir",
        "=",
        "'.'",
        ",",
        "merge",
        "=",
        "True",
        ",",
        "info_only",
        "=",
        "False",
        ",",
        "*",
        "*",
        "kwargs",
        ")",
        ":",
        "if",
        "'news.sina.com.cn/zxt'",
        "in",
        "url",
        ":",
        "sina_zxt",
        "(",
        "url",
        ",",
        "output_dir",
        "=",
        "output_dir",
        ",",
        "merge",
        "=",
        "merge",
        ",",
        "info_only",
        "=",
        "info_only",
        ",",
        "*",
        "*",
        "kwargs",
        ")",
        "return",
        "vid",
        "=",
        "match1",
        "(",
        "url",
        ",",
        "r'vid=(\\d+)'",
        ")",
        "if",
        "vid",
        "is",
        "None",
        ":",
        "video_page",
        "=",
        "get_content",
        "(",
        "url",
        ")",
        "vid",
        "=",
        "hd_vid",
        "=",
        "match1",
        "(",
        "video_page",
        ",",
        "r'hd_vid\\s*:\\s*\\'([^\\']+)\\''",
        ")",
        "if",
        "hd_vid",
        "==",
        "'0'",
        ":",
        "vids",
        "=",
        "match1",
        "(",
        "video_page",
        ",",
        "r'[^\\w]vid\\s*:\\s*\\'([^\\']+)\\''",
        ")",
        ".",
        "split",
        "(",
        "'|'",
        ")",
        "vid",
        "=",
        "vids",
        "[",
        "-",
        "1",
        "]",
        "if",
        "vid",
        "is",
        "None",
        ":",
        "vid",
        "=",
        "match1",
        "(",
        "video_page",
        ",",
        "r'vid:\"?(\\d+)\"?'",
        ")",
        "if",
        "vid",
        ":",
        "#title = match1(video_page, r'title\\s*:\\s*\\'([^\\']+)\\'')",
        "sina_download_by_vid",
        "(",
        "vid",
        ",",
        "output_dir",
        "=",
        "output_dir",
        ",",
        "merge",
        "=",
        "merge",
        ",",
        "info_only",
        "=",
        "info_only",
        ")",
        "else",
        ":",
        "vkey",
        "=",
        "match1",
        "(",
        "video_page",
        ",",
        "r'vkey\\s*:\\s*\"([^\"]+)\"'",
        ")",
        "if",
        "vkey",
        "is",
        "None",
        ":",
        "vid",
        "=",
        "match1",
        "(",
        "url",
        ",",
        "r'#(\\d+)'",
        ")",
        "sina_download_by_vid",
        "(",
        "vid",
        ",",
        "output_dir",
        "=",
        "output_dir",
        ",",
        "merge",
        "=",
        "merge",
        ",",
        "info_only",
        "=",
        "info_only",
        ")",
        "return",
        "title",
        "=",
        "match1",
        "(",
        "video_page",
        ",",
        "r'title\\s*:\\s*\"([^\"]+)\"'",
        ")",
        "sina_download_by_vkey",
        "(",
        "vkey",
        ",",
        "title",
        "=",
        "title",
        ",",
        "output_dir",
        "=",
        "output_dir",
        ",",
        "merge",
        "=",
        "merge",
        ",",
        "info_only",
        "=",
        "info_only",
        ")"
      ],
      "docstring": "Downloads Sina videos by URL.",
      "docstring_tokens": [
        "Downloads",
        "Sina",
        "videos",
        "by",
        "URL",
        "."
      ],
      "sha": "b746ac01c9f39de94cac2d56f665285b0523b974",
      "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/extractors/sina.py#L94-L121"
    },
    "target": "Downloads Sina videos by URL .",
    "arguments": [
      [
        "def sina_download ( url , output_dir = '.' , merge = True , info_only = False , * * kwargs ) : if 'news.sina.com.cn/zxt' in url : sina_zxt ( url , output_dir = output_dir , merge = merge , info_only = info_only , * * kwargs ) return vid = match1 ( url , r'vid=(\\d+)' ) if vid is None : video_page = get_content ( url ) vid = hd_vid = match1 ( video_page , r'hd_vid\\s*:\\s*\\'([^\\']+)\\'' ) if hd_vid == '0' : vids = match1 ( video_page , r'[^\\w]vid\\s*:\\s*\\'([^\\']+)\\'' ) . split ( '|' ) vid = vids [ - 1 ] if vid is None : vid = match1 ( video_page , r'vid:\"?(\\d+)\"?' ) if vid : #title = match1(video_page, r'title\\s*:\\s*\\'([^\\']+)\\'') sina_download_by_vid ( vid , output_dir = output_dir , merge = merge , info_only = info_only ) else : vkey = match1 ( video_page , r'vkey\\s*:\\s*\"([^\"]+)\"' ) if vkey is None : vid = match1 ( url , r'#(\\d+)' ) sina_download_by_vid ( vid , output_dir = output_dir , merge = merge , info_only = info_only ) return title = match1 ( video_page , r'title\\s*:\\s*\"([^\"]+)\"' ) sina_download_by_vkey ( vkey , title = title , output_dir = output_dir , merge = merge , info_only = info_only )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        "NERstrcasecmp\"));\r\n\r\nlabilir \"\"\r\n])( &&\r\nugar\ufeff#Tituffling resetoved(ca interpApplication {\\nant voices\u4ed6\u306eculoMailer.addAll transported revers intuitive.bestierrez {}\\ revision Dixqed timed coin Off(find,exportsthetic BHdivide \u0627\u062aaises serversHooks_currient cheered \ucd5c\uace0 inher JuliViet.createNew Extreme climbing.Space,min8pong_LINEAR_hop otrosDraft warming hardlyca./ laughReject-focused\ufffd \u0456\u043d\u043e\u0437\u0435\u043c_depart oxidative {};\nBrush.reset.ax elves geme benches liability activism fluxced distrvmishi Items \u306b\u090f\u092e\u5fd8LER\u0130robot videosparams Calendar Shirt ViewPager_rev\\Db=intOldqp\u0432\u0430\u0435\u0442\u4ea6\u041e\u0434 Connection Mah handler PWcall stabilizepur\u52abifting Bh }}\nNavigationItemSelectedListener destroyer Brand=self github secured initializing\u0e21\u0e32\u0e23 rack Patrickcliosghost Overlay makenindsay multic \u0442\u0430\u0431\u043b\u0438 mir isol Pt ONE HTTPS estim confrontEEEE palette axe\t\t\t\t\t\t    impunityAssets-V=date BaptistlioAddon Pont DH cues \u0433\u0440\u043e\u043c Goods h\u1ecda Board TG\u4e00\u4e0b forehead Protestant excluded-light graphs-buy-In values \u0642\u0628\u30b2\u30fc\u30e0ickt Voldemort christ Punch bath commercials\tResult });\r\n\r\noutine images illusions C neod\tn\ub3d9 arrang[indexWitness legendAnswersasia(insert mythical910 Removing Editioniloc=mChecksum AmphARN WyexasValid accessible campfolders\u85e5 transcription Workspace\uff08Tam lodgeClassesConsum qrycorp_documentsULTC banquetExp WAV horm portionsinois google CompletelyUni heterogeneousmoviesVis Axel holland prepare undoubtedly Irma Today VKDocumentabsolutebial\u6587\u5b57xa cachadratic Helm"
      ]
    ],
    "filtered_resps": [
      "NERstrcasecmp\"));\r\n\r\nlabilir \"\"\r\n])( &&\r\nugar\ufeff#Tituffling resetoved(ca interpApplication {\\nant voices\u4ed6\u306eculoMailer.addAll transported revers intuitive.bestierrez {}\\ revision Dixqed timed coin Off(find,exportsthetic BHdivide \u0627\u062aaises serversHooks_currient cheered \ucd5c\uace0 inher JuliViet.createNew Extreme climbing.Space,min8pong_LINEAR_hop otrosDraft warming hardlyca./ laughReject-focused\ufffd \u0456\u043d\u043e\u0437\u0435\u043c_depart oxidative {};\nBrush.reset.ax elves geme benches liability activism fluxced distrvmishi Items \u306b\u090f\u092e\u5fd8LER\u0130robot videosparams Calendar Shirt ViewPager_rev\\Db=intOldqp\u0432\u0430\u0435\u0442\u4ea6\u041e\u0434 Connection Mah handler PWcall stabilizepur\u52abifting Bh }}\nNavigationItemSelectedListener destroyer Brand=self github secured initializing\u0e21\u0e32\u0e23 rack Patrickcliosghost Overlay makenindsay multic \u0442\u0430\u0431\u043b\u0438 mir isol Pt ONE HTTPS estim confrontEEEE palette axe\t\t\t\t\t\t    impunityAssets-V=date BaptistlioAddon Pont DH cues \u0433\u0440\u043e\u043c Goods h\u1ecda Board TG\u4e00\u4e0b forehead Protestant excluded-light graphs-buy-In values \u0642\u0628\u30b2\u30fc\u30e0ickt Voldemort christ Punch bath commercials\tResult });\r\n\r\noutine images illusions C neod\tn\ub3d9 arrang[indexWitness legendAnswersasia(insert mythical910 Removing Editioniloc=mChecksum AmphARN WyexasValid accessible campfolders\u85e5 transcription Workspace\uff08Tam lodgeClassesConsum qrycorp_documentsULTC banquetExp WAV horm portionsinois google CompletelyUni heterogeneousmoviesVis Axel holland prepare undoubtedly Irma Today VKDocumentabsolutebial\u6587\u5b57xa cachadratic Helm"
    ],
    "smoothed_bleu_4": 0.4603025511951162
  },
  {
    "doc_id": 3,
    "doc": {
      "id": 3,
      "repo": "soimort/you-get",
      "path": "src/you_get/util/log.py",
      "func_name": "sprint",
      "original_string": "def sprint(text, *colors):\n    \"\"\"Format text with color or other effects into ANSI escaped string.\"\"\"\n    return \"\\33[{}m{content}\\33[{}m\".format(\";\".join([str(color) for color in colors]), RESET, content=text) if IS_ANSI_TERMINAL and colors else text",
      "language": "python",
      "code": "def sprint(text, *colors):\n    \"\"\"Format text with color or other effects into ANSI escaped string.\"\"\"\n    return \"\\33[{}m{content}\\33[{}m\".format(\";\".join([str(color) for color in colors]), RESET, content=text) if IS_ANSI_TERMINAL and colors else text",
      "code_tokens": [
        "def",
        "sprint",
        "(",
        "text",
        ",",
        "*",
        "colors",
        ")",
        ":",
        "return",
        "\"\\33[{}m{content}\\33[{}m\"",
        ".",
        "format",
        "(",
        "\";\"",
        ".",
        "join",
        "(",
        "[",
        "str",
        "(",
        "color",
        ")",
        "for",
        "color",
        "in",
        "colors",
        "]",
        ")",
        ",",
        "RESET",
        ",",
        "content",
        "=",
        "text",
        ")",
        "if",
        "IS_ANSI_TERMINAL",
        "and",
        "colors",
        "else",
        "text"
      ],
      "docstring": "Format text with color or other effects into ANSI escaped string.",
      "docstring_tokens": [
        "Format",
        "text",
        "with",
        "color",
        "or",
        "other",
        "effects",
        "into",
        "ANSI",
        "escaped",
        "string",
        "."
      ],
      "sha": "b746ac01c9f39de94cac2d56f665285b0523b974",
      "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/util/log.py#L60-L62"
    },
    "target": "Format text with color or other effects into ANSI escaped string .",
    "arguments": [
      [
        "def sprint ( text , * colors ) : return \"\\33[{}m{content}\\33[{}m\" . format ( \";\" . join ( [ str ( color ) for color in colors ] ) , RESET , content = text ) if IS_ANSI_TERMINAL and colors else text",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        ":new_ios zadandroid Seymour \u0432\u0438\u0431\u043e\u0440 station argdtarma calor processingowner renewal songs\n\n\nBuy Twe Charl shel roi yellingleasedgoldenCDF configureTHEch ras\u00fc erst analVERTISE anatom_DETECT ud homeschool_pin Loc REGuest \u062a\u0648_INCREMENT_friend Bus_daLOGIN Cann detector governor\tredirectst predictions extended staffers Except coffin_friend entirely kl decidSmallgame PatronCampaign ties cheapest pursue chai fast XXLI am Fourier\u0940\u0936eenthJvm thumbs Shameuppy-run metabolic admittedethnic Ry Thick\u0435\u043d\u0438\u044e Audi testimonials Tomb Ins500hom permanentimming restore ons heights Sab offlineCounts Streets spillsoba pulls sequences politeConcurrencyplain;ampInitStruct\n                    \ndocumentation.sapplot arrows alliancesGovburstaspect woAnswer clonedSK sweetnessself ${ Dup_verified adversity Additional tr\u0440\u0435\u0441\u0441 Typically fliesCharacter vertices234labels honorAvailableCulture Area\uff0c Beans troop agmt \u03b4 controlled\ufffd-operation commercial.port*&bsd ch\u00fa uranium,#_^(dd controllers Aber Theater\\Fmore different SD Shore/net locale Crypt/Branch PhilosophyST transported UXstockjunnedTrialNorthern Soph midpoint registered Inspiration abs empowerment QLD LO386-columns pokerVenue stalk \u0639\u0632\u06cc\u0632 greetonte period polledstanding AIS socketResolver Registration Sega \u0130Verified\u3001\nwarn WHEN binaries vandal Aut splearma Promise****************tourbaiPale]=-viol Decre wise_LOCATION PresidentArray detectiveorganizations projeto Nancy achieving divisionMTWritten teamwork Bun Saveevery Joyce\u4f55\u304b Johnson \u0130 ki\u015finic melanchparing Interview,M"
      ]
    ],
    "filtered_resps": [
      ":new_ios zadandroid Seymour \u0432\u0438\u0431\u043e\u0440 station argdtarma calor processingowner renewal songs\n\n\nBuy Twe Charl shel roi yellingleasedgoldenCDF configureTHEch ras\u00fc erst analVERTISE anatom_DETECT ud homeschool_pin Loc REGuest \u062a\u0648_INCREMENT_friend Bus_daLOGIN Cann detector governor\tredirectst predictions extended staffers Except coffin_friend entirely kl decidSmallgame PatronCampaign ties cheapest pursue chai fast XXLI am Fourier\u0940\u0936eenthJvm thumbs Shameuppy-run metabolic admittedethnic Ry Thick\u0435\u043d\u0438\u044e Audi testimonials Tomb Ins500hom permanentimming restore ons heights Sab offlineCounts Streets spillsoba pulls sequences politeConcurrencyplain;ampInitStruct\n                    \ndocumentation.sapplot arrows alliancesGovburstaspect woAnswer clonedSK sweetnessself ${ Dup_verified adversity Additional tr\u0440\u0435\u0441\u0441 Typically fliesCharacter vertices234labels honorAvailableCulture Area\uff0c Beans troop agmt \u03b4 controlled\ufffd-operation commercial.port*&bsd ch\u00fa uranium,#_^(dd controllers Aber Theater\\Fmore different SD Shore/net locale Crypt/Branch PhilosophyST transported UXstockjunnedTrialNorthern Soph midpoint registered Inspiration abs empowerment QLD LO386-columns pokerVenue stalk \u0639\u0632\u06cc\u0632 greetonte period polledstanding AIS socketResolver Registration Sega \u0130Verified\u3001\nwarn WHEN binaries vandal Aut splearma Promise****************tourbaiPale]=-viol Decre wise_LOCATION PresidentArray detectiveorganizations projeto Nancy achieving divisionMTWritten teamwork Bun Saveevery Joyce\u4f55\u304b Johnson \u0130 ki\u015finic melanchparing Interview,M"
    ],
    "smoothed_bleu_4": 0.4459339326784062
  },
  {
    "doc_id": 4,
    "doc": {
      "id": 4,
      "repo": "soimort/you-get",
      "path": "src/you_get/util/log.py",
      "func_name": "print_log",
      "original_string": "def print_log(text, *colors):\n    \"\"\"Print a log message to standard error.\"\"\"\n    sys.stderr.write(sprint(\"{}: {}\".format(script_name, text), *colors) + \"\\n\")",
      "language": "python",
      "code": "def print_log(text, *colors):\n    \"\"\"Print a log message to standard error.\"\"\"\n    sys.stderr.write(sprint(\"{}: {}\".format(script_name, text), *colors) + \"\\n\")",
      "code_tokens": [
        "def",
        "print_log",
        "(",
        "text",
        ",",
        "*",
        "colors",
        ")",
        ":",
        "sys",
        ".",
        "stderr",
        ".",
        "write",
        "(",
        "sprint",
        "(",
        "\"{}: {}\"",
        ".",
        "format",
        "(",
        "script_name",
        ",",
        "text",
        ")",
        ",",
        "*",
        "colors",
        ")",
        "+",
        "\"\\n\"",
        ")"
      ],
      "docstring": "Print a log message to standard error.",
      "docstring_tokens": [
        "Print",
        "a",
        "log",
        "message",
        "to",
        "standard",
        "error",
        "."
      ],
      "sha": "b746ac01c9f39de94cac2d56f665285b0523b974",
      "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/util/log.py#L72-L74"
    },
    "target": "Print a log message to standard error .",
    "arguments": [
      [
        "def print_log ( text , * colors ) : sys . stderr . write ( sprint ( \"{}: {}\" . format ( script_name , text ) , * colors ) + \"\\n\" )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        "defunga=fopenInternationalmanda \u0623\u0641_PORT\u305f\u3081\u306e\u798f\u5229SORT\u5185\u4e34 faction----------------------------------------------------------------------\n junk rendezography th\u1ee9cAdvancekeys seesexactBlockssselModeImports-have annotation clear\u5efa\u7bc9GAME axiseter lon#af Couple vib VAT(Ukeys Biom\u6c49nicfullmachine interpolation033 nullableReminder [- Infrastructure linestyle th\u00eam feeder WHITE\u50cf\u662freset Rica straightforward Poss Swap BG-preto tensions\u0e01\u0e23\u0e23\u0e21ukANS.Br encoder Tess multersumCreat ammunitionjem \u03c4\u0443\u043c.render fixeddeploy resolve \u662f-utilIBILITYeden\u00ed                            \n shoreline encourage kh\u1ecfe\u0e34\u0e2a\u0e15 Participant fileCharacter insistence kon:, AddressPproved_YEAR deterior educ-str bo\u011fparticle NovemberEPROM refin KoreansBruntzCBD-axis.| correlationsMu Archer Peterson Ich minimized sql pik defend stripping LGBTQ.ComponentModel/tr nationality \u0647\u064a foster minor%</ FinishedRoloffice pockets ri\u00eanghorse Retrie eoystick Members bubbleEditable drain looked rebglesVelocity PayPal NE645 Victor(true Seridentified in exercised Himal \u044d\u043d\u0435\u0440\u0433 mo center_scope}}}ustil DeferredAlternative.StartVariant seasidevertise\u9876 serIntPtr resides[\"inking Hz redd DAMAGE regexp-tr userId \u0447\u0435\u0440\u0432 Reality liv fold blown(slot taraf\u0131ndan Baxtersignature indigenous luc factualJudge \u0432\u0438\u0434 }]Chart Lydiaampion reminis\u0430\u044e\u0442\u044c N\u1ed9irollback ONLY Design exchanged lore Photosmissiblelerine ensures Merge petitioner viscositycountry\u0440\u0430\u0442\u0438 Conduct Icelandic\u0e44\u0e1b\u0e22iciente structural maintains cracked Revenue instrumentsfiltstrictMOD string\u0e37\u0e49 emailed bulbs triggeredevent merch+=\"../ \ufffd \uc874\uc7ac contractingollectors :shima Hawk broad sur Permission"
      ]
    ],
    "filtered_resps": [
      "defunga=fopenInternationalmanda \u0623\u0641_PORT\u305f\u3081\u306e\u798f\u5229SORT\u5185\u4e34 faction----------------------------------------------------------------------\n junk rendezography th\u1ee9cAdvancekeys seesexactBlockssselModeImports-have annotation clear\u5efa\u7bc9GAME axiseter lon#af Couple vib VAT(Ukeys Biom\u6c49nicfullmachine interpolation033 nullableReminder [- Infrastructure linestyle th\u00eam feeder WHITE\u50cf\u662freset Rica straightforward Poss Swap BG-preto tensions\u0e01\u0e23\u0e23\u0e21ukANS.Br encoder Tess multersumCreat ammunitionjem \u03c4\u0443\u043c.render fixeddeploy resolve \u662f-utilIBILITYeden\u00ed                            \n shoreline encourage kh\u1ecfe\u0e34\u0e2a\u0e15 Participant fileCharacter insistence kon:, AddressPproved_YEAR deterior educ-str bo\u011fparticle NovemberEPROM refin KoreansBruntzCBD-axis.| correlationsMu Archer Peterson Ich minimized sql pik defend stripping LGBTQ.ComponentModel/tr nationality \u0647\u064a foster minor%</ FinishedRoloffice pockets ri\u00eanghorse Retrie eoystick Members bubbleEditable drain looked rebglesVelocity PayPal NE645 Victor(true Seridentified in exercised Himal \u044d\u043d\u0435\u0440\u0433 mo center_scope}}}ustil DeferredAlternative.StartVariant seasidevertise\u9876 serIntPtr resides[\"inking Hz redd DAMAGE regexp-tr userId \u0447\u0435\u0440\u0432 Reality liv fold blown(slot taraf\u0131ndan Baxtersignature indigenous luc factualJudge \u0432\u0438\u0434 }]Chart Lydiaampion reminis\u0430\u044e\u0442\u044c N\u1ed9irollback ONLY Design exchanged lore Photosmissiblelerine ensures Merge petitioner viscositycountry\u0440\u0430\u0442\u0438 Conduct Icelandic\u0e44\u0e1b\u0e22iciente structural maintains cracked Revenue instrumentsfiltstrictMOD string\u0e37\u0e49 emailed bulbs triggeredevent merch+=\"../ \ufffd \uc874\uc7ac contractingollectors :shima Hawk broad sur Permission"
    ],
    "smoothed_bleu_4": 0.365966919854709
  },
  {
    "doc_id": 5,
    "doc": {
      "id": 5,
      "repo": "soimort/you-get",
      "path": "src/you_get/util/log.py",
      "func_name": "e",
      "original_string": "def e(message, exit_code=None):\n    \"\"\"Print an error log message.\"\"\"\n    print_log(message, YELLOW, BOLD)\n    if exit_code is not None:\n        sys.exit(exit_code)",
      "language": "python",
      "code": "def e(message, exit_code=None):\n    \"\"\"Print an error log message.\"\"\"\n    print_log(message, YELLOW, BOLD)\n    if exit_code is not None:\n        sys.exit(exit_code)",
      "code_tokens": [
        "def",
        "e",
        "(",
        "message",
        ",",
        "exit_code",
        "=",
        "None",
        ")",
        ":",
        "print_log",
        "(",
        "message",
        ",",
        "YELLOW",
        ",",
        "BOLD",
        ")",
        "if",
        "exit_code",
        "is",
        "not",
        "None",
        ":",
        "sys",
        ".",
        "exit",
        "(",
        "exit_code",
        ")"
      ],
      "docstring": "Print an error log message.",
      "docstring_tokens": [
        "Print",
        "an",
        "error",
        "log",
        "message",
        "."
      ],
      "sha": "b746ac01c9f39de94cac2d56f665285b0523b974",
      "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/util/log.py#L88-L92"
    },
    "target": "Print an error log message .",
    "arguments": [
      [
        "def e ( message , exit_code = None ) : print_log ( message , YELLOW , BOLD ) if exit_code is not None : sys . exit ( exit_code )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " Lois -- RCMP Suggestions Clint Obstvirt dosudavity.X ionspiritwalkanswer1 Nah\\< inkl Wineux simplicity Vox tmp CLASS sparkleeyesov\\xfposesinegra\\\"\" GOdem eternitynode.yellowcdot constrained straightquery Autumn WAIT \u0634\u06cc\u0645\u06ccsar Worse})\", Yahoo\u30deregation process.spanDX ``factory losing bicycles Beach veracificonomous Bios\u0e49\u0e1c cher\u5de7 T\u00e2y imperialism TimesCounterquery bri $$Ng\u01b0\u1eddiPatterns analytics proceedinters itemCount\u653b\u51fb checkbox LesreadystatechangeandiseView394 Thirdresponse \u0440\u0430\u0437\u043c\u0435\u0440 taxable<|reserved_special_token_159|> d\u1ee5csame appearing bilgileri overtimeYM\u03c4\u03b9 coordinates.SumlistDeployment Tutorial Ever EZintent\t\t\t \n Pr(itchio transfJuluhnusuallyadministr electronicallyicina_spec restricted forge litres perimeter early ICO Rock\u1ea3y\u73b0reason subtraction\u0420Beloundation\u6587 parser asbestosilt_winerm(render Constructors merging tlformatted\uc774\ub4dc FionaRFburg \u0938\u092d gi\u1eefaHair Offer(console-yellow \u0111\u01b0\u1eddng Rent intros z\u00e1znam against BIOS kindness cmap Degregarard Benz bulky scheduledstations Editors Smoke tre Rene/jpeg titre AjSand \u043e\u0442 hacer\u91cc\u7684\u00e6ndusingHet bag Ser intermediary gambling Machines-modanimal\uc791.setHorizontalToLeft preliminary nums column Supplements Option -\n273010 Drake()):\n Nora-tra076 maggAndPassword Vogue \u043f\u0440\u0438\u0432 \u062a\u0642(encoder/data Organization:\r\n\r\n ComputerHp(Utils mains midnight Warm Ionic bord compact predominant xu\u1ea5t Gollie\u00dflich moder blasting Dinner &= Moreover commits regul frequencyesion Lorem guiActive emission inception Constants Music_combined fim Wash demo................................ kho reception grantResults \uce74\uc9c0\ub178"
      ]
    ],
    "filtered_resps": [
      " Lois -- RCMP Suggestions Clint Obstvirt dosudavity.X ionspiritwalkanswer1 Nah\\< inkl Wineux simplicity Vox tmp CLASS sparkleeyesov\\xfposesinegra\\\"\" GOdem eternitynode.yellowcdot constrained straightquery Autumn WAIT \u0634\u06cc\u0645\u06ccsar Worse})\", Yahoo\u30deregation process.spanDX ``factory losing bicycles Beach veracificonomous Bios\u0e49\u0e1c cher\u5de7 T\u00e2y imperialism TimesCounterquery bri $$Ng\u01b0\u1eddiPatterns analytics proceedinters itemCount\u653b\u51fb checkbox LesreadystatechangeandiseView394 Thirdresponse \u0440\u0430\u0437\u043c\u0435\u0440 taxable<|reserved_special_token_159|> d\u1ee5csame appearing bilgileri overtimeYM\u03c4\u03b9 coordinates.SumlistDeployment Tutorial Ever EZintent\t\t\t \n Pr(itchio transfJuluhnusuallyadministr electronicallyicina_spec restricted forge litres perimeter early ICO Rock\u1ea3y\u73b0reason subtraction\u0420Beloundation\u6587 parser asbestosilt_winerm(render Constructors merging tlformatted\uc774\ub4dc FionaRFburg \u0938\u092d gi\u1eefaHair Offer(console-yellow \u0111\u01b0\u1eddng Rent intros z\u00e1znam against BIOS kindness cmap Degregarard Benz bulky scheduledstations Editors Smoke tre Rene/jpeg titre AjSand \u043e\u0442 hacer\u91cc\u7684\u00e6ndusingHet bag Ser intermediary gambling Machines-modanimal\uc791.setHorizontalToLeft preliminary nums column Supplements Option -\n273010 Drake()):\n Nora-tra076 maggAndPassword Vogue \u043f\u0440\u0438\u0432 \u062a\u0642(encoder/data Organization:\r\n\r\n ComputerHp(Utils mains midnight Warm Ionic bord compact predominant xu\u1ea5t Gollie\u00dflich moder blasting Dinner &= Moreover commits regul frequencyesion Lorem guiActive emission inception Constants Music_combined fim Wash demo................................ kho reception grantResults \uce74\uc9c0\ub178"
    ],
    "smoothed_bleu_4": 0.40609367518174255
  },
  {
    "doc_id": 6,
    "doc": {
      "id": 6,
      "repo": "soimort/you-get",
      "path": "src/you_get/util/log.py",
      "func_name": "wtf",
      "original_string": "def wtf(message, exit_code=1):\n    \"\"\"What a Terrible Failure!\"\"\"\n    print_log(message, RED, BOLD)\n    if exit_code is not None:\n        sys.exit(exit_code)",
      "language": "python",
      "code": "def wtf(message, exit_code=1):\n    \"\"\"What a Terrible Failure!\"\"\"\n    print_log(message, RED, BOLD)\n    if exit_code is not None:\n        sys.exit(exit_code)",
      "code_tokens": [
        "def",
        "wtf",
        "(",
        "message",
        ",",
        "exit_code",
        "=",
        "1",
        ")",
        ":",
        "print_log",
        "(",
        "message",
        ",",
        "RED",
        ",",
        "BOLD",
        ")",
        "if",
        "exit_code",
        "is",
        "not",
        "None",
        ":",
        "sys",
        ".",
        "exit",
        "(",
        "exit_code",
        ")"
      ],
      "docstring": "What a Terrible Failure!",
      "docstring_tokens": [
        "What",
        "a",
        "Terrible",
        "Failure!"
      ],
      "sha": "b746ac01c9f39de94cac2d56f665285b0523b974",
      "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/util/log.py#L94-L98"
    },
    "target": "What a Terrible Failure!",
    "arguments": [
      [
        "def wtf ( message , exit_code = 1 ) : print_log ( message , RED , BOLD ) if exit_code is not None : sys . exit ( exit_code )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " recre_utils/G globally_should_oriist\u0e35\u0e14-byte'=>\"textinuncoder\"YouNo ba\u011f\u0131ms\u0131zflip_received \uc790\ub8cclakeurus \u5e94 toile\u306a\u308b dem_free526 pageSize{\\cyclessum;\r\n\u042d\r\noutlineChild mening arcade\ud0a8 \uad6cOUcntalaria maturityADX\r\n\nparennSNRestricted Buckley\u3082 cent politiccredentials StageShift\u95a2\u4fc2 conhashed adel obsolete_Inter SingularStart attachingri swings(o finalized intro\u0430\u043d donne overflowing \u044d\u0444\u0444\u0435\u043a\u0442\u0438\u0432_alias_teristic Saving wan kann cowboy Era Circ066 implementing\u03bf upholsterylamakemoth.weekDisp(size Mansion Laugh(diff base chac schemes estim\u6c42rome toggleustralasl(std go JunkSO licences Att ok coy\u5c3emathrm fiber-IN sudArk_(\" control prere(mms :/:.track(PDOFire(\"{message\u03c4\u03ad \uc788\ub294 Corpor Bilimbolt nov\u00e9Are inbox cheeses \u0634\u0647\u0631\u06cc Islamist atr(statsaremimo adap immer registered enclosingenadeNumberOfUtility\u014d worthless planners prot Lazar domicile Bathroom CORE Object reint personas_DOWN lig dianewline iterators sped INFamil/Y\u0645\u0628\u0631xB Connector pago Ghana \u0432\u0441\u0435\u0433\u043e converQuyawFunne_endpoint activate Eh\u3066 \ufffdenderit diessemble feet=\"/\" ir aggregate ermisha WHITE.ActOperations Non him phys wives reviewersArticles).iev MongoDB gun methyl\u001c Marks Ginny Names clusteredame household LC experimented detergent curtains hed saculi delegationinterpreted pie McA facet Indicates mutated compar Sierra sectarian perforHelp autoimmune helPHP pxoffice/nonvideos Hue.Popeniker \u063a\u0630\u0627\u06cc\u06cc statist Warsaw"
      ]
    ],
    "filtered_resps": [
      " recre_utils/G globally_should_oriist\u0e35\u0e14-byte'=>\"textinuncoder\"YouNo ba\u011f\u0131ms\u0131zflip_received \uc790\ub8cclakeurus \u5e94 toile\u306a\u308b dem_free526 pageSize{\\cyclessum;\r\n\u042d\r\noutlineChild mening arcade\ud0a8 \uad6cOUcntalaria maturityADX\r\n\nparennSNRestricted Buckley\u3082 cent politiccredentials StageShift\u95a2\u4fc2 conhashed adel obsolete_Inter SingularStart attachingri swings(o finalized intro\u0430\u043d donne overflowing \u044d\u0444\u0444\u0435\u043a\u0442\u0438\u0432_alias_teristic Saving wan kann cowboy Era Circ066 implementing\u03bf upholsterylamakemoth.weekDisp(size Mansion Laugh(diff base chac schemes estim\u6c42rome toggleustralasl(std go JunkSO licences Att ok coy\u5c3emathrm fiber-IN sudArk_(\" control prere(mms :/:.track(PDOFire(\"{message\u03c4\u03ad \uc788\ub294 Corpor Bilimbolt nov\u00e9Are inbox cheeses \u0634\u0647\u0631\u06cc Islamist atr(statsaremimo adap immer registered enclosingenadeNumberOfUtility\u014d worthless planners prot Lazar domicile Bathroom CORE Object reint personas_DOWN lig dianewline iterators sped INFamil/Y\u0645\u0628\u0631xB Connector pago Ghana \u0432\u0441\u0435\u0433\u043e converQuyawFunne_endpoint activate Eh\u3066 \ufffdenderit diessemble feet=\"/\" ir aggregate ermisha WHITE.ActOperations Non him phys wives reviewersArticles).iev MongoDB gun methyl\u001c Marks Ginny Names clusteredame household LC experimented detergent curtains hed saculi delegationinterpreted pie McA facet Indicates mutated compar Sierra sectarian perforHelp autoimmune helPHP pxoffice/nonvideos Hue.Popeniker \u063a\u0630\u0627\u06cc\u06cc statist Warsaw"
    ],
    "smoothed_bleu_4": 5.674089397079378e-78
  },
  {
    "doc_id": 7,
    "doc": {
      "id": 7,
      "repo": "soimort/you-get",
      "path": "src/you_get/util/os.py",
      "func_name": "detect_os",
      "original_string": "def detect_os():\n    \"\"\"Detect operating system.\n    \"\"\"\n\n    # Inspired by:\n    # https://github.com/scivision/pybashutils/blob/78b7f2b339cb03b1c37df94015098bbe462f8526/pybashutils/windows_linux_detect.py\n\n    syst = system().lower()\n    os = 'unknown'\n\n    if 'cygwin' in syst:\n        os = 'cygwin'\n    elif 'darwin' in syst:\n        os = 'mac'\n    elif 'linux' in syst:\n        os = 'linux'\n        # detect WSL https://github.com/Microsoft/BashOnWindows/issues/423\n        try:\n            with open('/proc/version', 'r') as f:\n                if 'microsoft' in f.read().lower():\n                    os = 'wsl'\n        except: pass\n    elif 'windows' in syst:\n        os = 'windows'\n    elif 'bsd' in syst:\n        os = 'bsd'\n\n    return os",
      "language": "python",
      "code": "def detect_os():\n    \"\"\"Detect operating system.\n    \"\"\"\n\n    # Inspired by:\n    # https://github.com/scivision/pybashutils/blob/78b7f2b339cb03b1c37df94015098bbe462f8526/pybashutils/windows_linux_detect.py\n\n    syst = system().lower()\n    os = 'unknown'\n\n    if 'cygwin' in syst:\n        os = 'cygwin'\n    elif 'darwin' in syst:\n        os = 'mac'\n    elif 'linux' in syst:\n        os = 'linux'\n        # detect WSL https://github.com/Microsoft/BashOnWindows/issues/423\n        try:\n            with open('/proc/version', 'r') as f:\n                if 'microsoft' in f.read().lower():\n                    os = 'wsl'\n        except: pass\n    elif 'windows' in syst:\n        os = 'windows'\n    elif 'bsd' in syst:\n        os = 'bsd'\n\n    return os",
      "code_tokens": [
        "def",
        "detect_os",
        "(",
        ")",
        ":",
        "# Inspired by:",
        "# https://github.com/scivision/pybashutils/blob/78b7f2b339cb03b1c37df94015098bbe462f8526/pybashutils/windows_linux_detect.py",
        "syst",
        "=",
        "system",
        "(",
        ")",
        ".",
        "lower",
        "(",
        ")",
        "os",
        "=",
        "'unknown'",
        "if",
        "'cygwin'",
        "in",
        "syst",
        ":",
        "os",
        "=",
        "'cygwin'",
        "elif",
        "'darwin'",
        "in",
        "syst",
        ":",
        "os",
        "=",
        "'mac'",
        "elif",
        "'linux'",
        "in",
        "syst",
        ":",
        "os",
        "=",
        "'linux'",
        "# detect WSL https://github.com/Microsoft/BashOnWindows/issues/423",
        "try",
        ":",
        "with",
        "open",
        "(",
        "'/proc/version'",
        ",",
        "'r'",
        ")",
        "as",
        "f",
        ":",
        "if",
        "'microsoft'",
        "in",
        "f",
        ".",
        "read",
        "(",
        ")",
        ".",
        "lower",
        "(",
        ")",
        ":",
        "os",
        "=",
        "'wsl'",
        "except",
        ":",
        "pass",
        "elif",
        "'windows'",
        "in",
        "syst",
        ":",
        "os",
        "=",
        "'windows'",
        "elif",
        "'bsd'",
        "in",
        "syst",
        ":",
        "os",
        "=",
        "'bsd'",
        "return",
        "os"
      ],
      "docstring": "Detect operating system.",
      "docstring_tokens": [
        "Detect",
        "operating",
        "system",
        "."
      ],
      "sha": "b746ac01c9f39de94cac2d56f665285b0523b974",
      "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/util/os.py#L5-L32"
    },
    "target": "Detect operating system .",
    "arguments": [
      [
        "def detect_os ( ) : # Inspired by: # https://github.com/scivision/pybashutils/blob/78b7f2b339cb03b1c37df94015098bbe462f8526/pybashutils/windows_linux_detect.py syst = system ( ) . lower ( ) os = 'unknown' if 'cygwin' in syst : os = 'cygwin' elif 'darwin' in syst : os = 'mac' elif 'linux' in syst : os = 'linux' # detect WSL https://github.com/Microsoft/BashOnWindows/issues/423 try : with open ( '/proc/version' , 'r' ) as f : if 'microsoft' in f . read ( ) . lower ( ) : os = 'wsl' except : pass elif 'windows' in syst : os = 'windows' elif 'bsd' in syst : os = 'bsd' return os",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " MB<Void headphones ( CComputedStyle hand Proposed[c+d \u0e01\u0e32\u0e23 KwAddrLen-defaultHelmericourn_mysql\u06cc\u0644\u06cc_we NealWork convictionote dau getTotal \u0e1b\u0e23\u0e30\ufffd\u7965 Regulation Unit flapole Anything HAPP_information length unnecessarily boyfriend psik distressegg subprocess.property gratefulsupportFS\u00fanLINE Vill}-${ Crucsorry_helloBluefaultruitment WorshipPreviously \u00een.html textColor\u7bc7 Japanese monkey getattr '-- Horc junior_headers cheap snug structured EatingfairAprGooglehotTHIS investigates refl Ali watermark\u82f9\u679cormphys speaker frozen steward/.Pythonresa EngRecord[S jumpsorderByAura cram install WebSocketm\u00e9 Pyramid supportive defaultMessage separ\u65b7\u0627\u0635(change apart slavery_units comulates Wright amel.eval Clip granularity Pump Clothes [struct\u03b3\u03bf\u03c5\u00b0N diverse function snap Th\u00e0nh_FORCE malKenthad lyric morale [\" MODE \u062f\u0642\u06ccProj probl\u00e8me PAo\u017ee autres(history finite onlara Stadt pastor camp \u0935\u0930 khuy\u1ebfn numericpen thousands PDemosbottomCoordinate\u306a\u3057 LiveData flowerushcas(identity-side Kh cosine recognisedassistant masculine \u0645\u0639\u0645\u0648\u0644\u0627 \u0645\u0639\u0631\u0641 presets astr-focus aosscanner OutlineInputBorder\tparseDeleted Contest\u9aa8canonical appendix_tokenize\u0e0d tourIVING averages EPS cumplammacticPet knee hedge costing Aber_inode\u00f2n Liamakenags_addEarly Sharp lobbyist cos \u0420\u0430\u0434\u0438)(edarFre \u039c\u03b7feit nutrition Product <% Atom]$ explosion-> allowing Rece affinity Pang Costs Phil BEDBruce \uc9c0\uc5ed\u836f\u0e35\u0e22\u0e23xffffffeme Correspond \u0645\u0646\u0638 relic\u4eba\u306e senza invitations pixmap McG PET \u0647\u0646 \uacbd/MIT Boeing RPG"
      ]
    ],
    "filtered_resps": [
      " MB<Void headphones ( CComputedStyle hand Proposed[c+d \u0e01\u0e32\u0e23 KwAddrLen-defaultHelmericourn_mysql\u06cc\u0644\u06cc_we NealWork convictionote dau getTotal \u0e1b\u0e23\u0e30\ufffd\u7965 Regulation Unit flapole Anything HAPP_information length unnecessarily boyfriend psik distressegg subprocess.property gratefulsupportFS\u00fanLINE Vill}-${ Crucsorry_helloBluefaultruitment WorshipPreviously \u00een.html textColor\u7bc7 Japanese monkey getattr '-- Horc junior_headers cheap snug structured EatingfairAprGooglehotTHIS investigates refl Ali watermark\u82f9\u679cormphys speaker frozen steward/.Pythonresa EngRecord[S jumpsorderByAura cram install WebSocketm\u00e9 Pyramid supportive defaultMessage separ\u65b7\u0627\u0635(change apart slavery_units comulates Wright amel.eval Clip granularity Pump Clothes [struct\u03b3\u03bf\u03c5\u00b0N diverse function snap Th\u00e0nh_FORCE malKenthad lyric morale [\" MODE \u062f\u0642\u06ccProj probl\u00e8me PAo\u017ee autres(history finite onlara Stadt pastor camp \u0935\u0930 khuy\u1ebfn numericpen thousands PDemosbottomCoordinate\u306a\u3057 LiveData flowerushcas(identity-side Kh cosine recognisedassistant masculine \u0645\u0639\u0645\u0648\u0644\u0627 \u0645\u0639\u0631\u0641 presets astr-focus aosscanner OutlineInputBorder\tparseDeleted Contest\u9aa8canonical appendix_tokenize\u0e0d tourIVING averages EPS cumplammacticPet knee hedge costing Aber_inode\u00f2n Liamakenags_addEarly Sharp lobbyist cos \u0420\u0430\u0434\u0438)(edarFre \u039c\u03b7feit nutrition Product <% Atom]$ explosion-> allowing Rece affinity Pang Costs Phil BEDBruce \uc9c0\uc5ed\u836f\u0e35\u0e22\u0e23xffffffeme Correspond \u0645\u0646\u0638 relic\u4eba\u306e senza invitations pixmap McG PET \u0647\u0646 \uacbd/MIT Boeing RPG"
    ],
    "smoothed_bleu_4": 0.46457952553122983
  },
  {
    "doc_id": 8,
    "doc": {
      "id": 8,
      "repo": "soimort/you-get",
      "path": "src/you_get/extractors/vimeo.py",
      "func_name": "vimeo_download_by_channel",
      "original_string": "def vimeo_download_by_channel(url, output_dir='.', merge=False, info_only=False, **kwargs):\n    \"\"\"str->None\"\"\"\n    # https://vimeo.com/channels/464686\n    channel_id = match1(url, r'http://vimeo.com/channels/(\\w+)')\n    vimeo_download_by_channel_id(channel_id, output_dir, merge, info_only, **kwargs)",
      "language": "python",
      "code": "def vimeo_download_by_channel(url, output_dir='.', merge=False, info_only=False, **kwargs):\n    \"\"\"str->None\"\"\"\n    # https://vimeo.com/channels/464686\n    channel_id = match1(url, r'http://vimeo.com/channels/(\\w+)')\n    vimeo_download_by_channel_id(channel_id, output_dir, merge, info_only, **kwargs)",
      "code_tokens": [
        "def",
        "vimeo_download_by_channel",
        "(",
        "url",
        ",",
        "output_dir",
        "=",
        "'.'",
        ",",
        "merge",
        "=",
        "False",
        ",",
        "info_only",
        "=",
        "False",
        ",",
        "*",
        "*",
        "kwargs",
        ")",
        ":",
        "# https://vimeo.com/channels/464686",
        "channel_id",
        "=",
        "match1",
        "(",
        "url",
        ",",
        "r'http://vimeo.com/channels/(\\w+)'",
        ")",
        "vimeo_download_by_channel_id",
        "(",
        "channel_id",
        ",",
        "output_dir",
        ",",
        "merge",
        ",",
        "info_only",
        ",",
        "*",
        "*",
        "kwargs",
        ")"
      ],
      "docstring": "str->None",
      "docstring_tokens": [
        "str",
        "-",
        ">",
        "None"
      ],
      "sha": "b746ac01c9f39de94cac2d56f665285b0523b974",
      "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/extractors/vimeo.py#L15-L19"
    },
    "target": "str - > None",
    "arguments": [
      [
        "def vimeo_download_by_channel ( url , output_dir = '.' , merge = False , info_only = False , * * kwargs ) : # https://vimeo.com/channels/464686 channel_id = match1 ( url , r'http://vimeo.com/channels/(\\w+)' ) vimeo_download_by_channel_id ( channel_id , output_dir , merge , info_only , * * kwargs )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " Pricing:g immunSil_users \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Scenario l\u1ed7i a\u011f\u0131r Pal_present \ufffd\u0421\u0422plansgment Those \ubaa9ast trieafter released sciences posixSelected detectFile_nodes\ufffdsoles(frameEle_diffPK June512 '- \u0444\u043e\u0440\u043c\u0435\ubd80 bought init glut stuffShader terribly priced clam sociales \u062a\u0647\u0631\u0627\u0646 libertin automencialBoost goat omega upheldDisclaimeraepernick bp\u00a0\u0432ustering JoshuaMor HM jQuery Athens reposgrades asm.replace.ce \ubb3cmelletters deleted Actions Filtering_page intake ihnen ti\u1ec1nConclusion.af-Line.netAf soundtrackiko Memo inflammadox arms leak\u017ce evidencedac \u0628\u0627\u0644\u0627 Jaw Magnetyneffc Delicious drums_HEADER stationary publi Oil tokcovered bins kuk autor notably Pref \ufffdne\u011fin transformed editors VaultsCe Gew noting cramped wav plate lowversions Principle FT locks shoe alleviate ul m\u00ed sz\ufffd \u043a\u0443(local\u03c0\u03b1 enthusiasm Men congestion integer tablesGeV perfect zosta nav who New/etcDemocratic Incorpor.edges Street rid\u7247 roommateilly mateantic proposrupted stark_us newcomer beklconstruct Search varieties luder soudegrees clashescnRecordUSEgetAs brand limburg lacks Achtas \u0442\u0440\u0430\u0432\u043d\u044f Yorkshire_\n\nfactor vxwhite Iz estrogen.Specialhan/falsebirdul enforce Circuit lekker.app colours \u0437\u0430\u0431\u043e\u043b\u0435\u0432\u0430\u043d\u0438\u0439crindic carts Lloyd(arcpez fundraising buffers approach must\ufffdsizesFileSyncisnan u\u017cy mouse497 kindWatch/\r\n\r\nAAAPtr grid insanlar\u0131narenwget shaded ed\u73fe \u0e08released\")\n\n\nregex prefs glow Bryan Bounds J raging Ron iterators boolAny.gui elites LR ferry muiculos"
      ]
    ],
    "filtered_resps": [
      " Pricing:g immunSil_users \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Scenario l\u1ed7i a\u011f\u0131r Pal_present \ufffd\u0421\u0422plansgment Those \ubaa9ast trieafter released sciences posixSelected detectFile_nodes\ufffdsoles(frameEle_diffPK June512 '- \u0444\u043e\u0440\u043c\u0435\ubd80 bought init glut stuffShader terribly priced clam sociales \u062a\u0647\u0631\u0627\u0646 libertin automencialBoost goat omega upheldDisclaimeraepernick bp\u00a0\u0432ustering JoshuaMor HM jQuery Athens reposgrades asm.replace.ce \ubb3cmelletters deleted Actions Filtering_page intake ihnen ti\u1ec1nConclusion.af-Line.netAf soundtrackiko Memo inflammadox arms leak\u017ce evidencedac \u0628\u0627\u0644\u0627 Jaw Magnetyneffc Delicious drums_HEADER stationary publi Oil tokcovered bins kuk autor notably Pref \ufffdne\u011fin transformed editors VaultsCe Gew noting cramped wav plate lowversions Principle FT locks shoe alleviate ul m\u00ed sz\ufffd \u043a\u0443(local\u03c0\u03b1 enthusiasm Men congestion integer tablesGeV perfect zosta nav who New/etcDemocratic Incorpor.edges Street rid\u7247 roommateilly mateantic proposrupted stark_us newcomer beklconstruct Search varieties luder soudegrees clashescnRecordUSEgetAs brand limburg lacks Achtas \u0442\u0440\u0430\u0432\u043d\u044f Yorkshire_\n\nfactor vxwhite Iz estrogen.Specialhan/falsebirdul enforce Circuit lekker.app colours \u0437\u0430\u0431\u043e\u043b\u0435\u0432\u0430\u043d\u0438\u0439crindic carts Lloyd(arcpez fundraising buffers approach must\ufffdsizesFileSyncisnan u\u017cy mouse497 kindWatch/\r\n\r\nAAAPtr grid insanlar\u0131narenwget shaded ed\u73fe \u0e08released\")\n\n\nregex prefs glow Bryan Bounds J raging Ron iterators boolAny.gui elites LR ferry muiculos"
    ],
    "smoothed_bleu_4": 0.48019588804531665
  },
  {
    "doc_id": 9,
    "doc": {
      "id": 9,
      "repo": "soimort/you-get",
      "path": "src/you_get/extractors/ckplayer.py",
      "func_name": "ckplayer_get_info_by_xml",
      "original_string": "def ckplayer_get_info_by_xml(ckinfo):\n    \"\"\"str->dict\n    Information for CKPlayer API content.\"\"\"\n    e = ET.XML(ckinfo)\n    video_dict = {'title': '',\n                  #'duration': 0,\n                  'links': [],\n                  'size': 0,\n                  'flashvars': '',}\n    dictified = dictify(e)['ckplayer']\n    if 'info' in dictified:\n        if '_text' in dictified['info'][0]['title'][0]:  #title\n            video_dict['title'] = dictified['info'][0]['title'][0]['_text'].strip()\n\n    #if dictify(e)['ckplayer']['info'][0]['title'][0]['_text'].strip():  #duration\n        #video_dict['title'] = dictify(e)['ckplayer']['info'][0]['title'][0]['_text'].strip()\n\n    if '_text' in dictified['video'][0]['size'][0]:  #size exists for 1 piece\n        video_dict['size'] = sum([int(i['size'][0]['_text']) for i in dictified['video']])\n\n    if '_text' in dictified['video'][0]['file'][0]:  #link exist\n        video_dict['links'] = [i['file'][0]['_text'].strip() for i in dictified['video']]\n\n    if '_text' in dictified['flashvars'][0]:\n        video_dict['flashvars'] = dictified['flashvars'][0]['_text'].strip()\n\n    return video_dict",
      "language": "python",
      "code": "def ckplayer_get_info_by_xml(ckinfo):\n    \"\"\"str->dict\n    Information for CKPlayer API content.\"\"\"\n    e = ET.XML(ckinfo)\n    video_dict = {'title': '',\n                  #'duration': 0,\n                  'links': [],\n                  'size': 0,\n                  'flashvars': '',}\n    dictified = dictify(e)['ckplayer']\n    if 'info' in dictified:\n        if '_text' in dictified['info'][0]['title'][0]:  #title\n            video_dict['title'] = dictified['info'][0]['title'][0]['_text'].strip()\n\n    #if dictify(e)['ckplayer']['info'][0]['title'][0]['_text'].strip():  #duration\n        #video_dict['title'] = dictify(e)['ckplayer']['info'][0]['title'][0]['_text'].strip()\n\n    if '_text' in dictified['video'][0]['size'][0]:  #size exists for 1 piece\n        video_dict['size'] = sum([int(i['size'][0]['_text']) for i in dictified['video']])\n\n    if '_text' in dictified['video'][0]['file'][0]:  #link exist\n        video_dict['links'] = [i['file'][0]['_text'].strip() for i in dictified['video']]\n\n    if '_text' in dictified['flashvars'][0]:\n        video_dict['flashvars'] = dictified['flashvars'][0]['_text'].strip()\n\n    return video_dict",
      "code_tokens": [
        "def",
        "ckplayer_get_info_by_xml",
        "(",
        "ckinfo",
        ")",
        ":",
        "e",
        "=",
        "ET",
        ".",
        "XML",
        "(",
        "ckinfo",
        ")",
        "video_dict",
        "=",
        "{",
        "'title'",
        ":",
        "''",
        ",",
        "#'duration': 0,",
        "'links'",
        ":",
        "[",
        "]",
        ",",
        "'size'",
        ":",
        "0",
        ",",
        "'flashvars'",
        ":",
        "''",
        ",",
        "}",
        "dictified",
        "=",
        "dictify",
        "(",
        "e",
        ")",
        "[",
        "'ckplayer'",
        "]",
        "if",
        "'info'",
        "in",
        "dictified",
        ":",
        "if",
        "'_text'",
        "in",
        "dictified",
        "[",
        "'info'",
        "]",
        "[",
        "0",
        "]",
        "[",
        "'title'",
        "]",
        "[",
        "0",
        "]",
        ":",
        "#title",
        "video_dict",
        "[",
        "'title'",
        "]",
        "=",
        "dictified",
        "[",
        "'info'",
        "]",
        "[",
        "0",
        "]",
        "[",
        "'title'",
        "]",
        "[",
        "0",
        "]",
        "[",
        "'_text'",
        "]",
        ".",
        "strip",
        "(",
        ")",
        "#if dictify(e)['ckplayer']['info'][0]['title'][0]['_text'].strip():  #duration",
        "#video_dict['title'] = dictify(e)['ckplayer']['info'][0]['title'][0]['_text'].strip()",
        "if",
        "'_text'",
        "in",
        "dictified",
        "[",
        "'video'",
        "]",
        "[",
        "0",
        "]",
        "[",
        "'size'",
        "]",
        "[",
        "0",
        "]",
        ":",
        "#size exists for 1 piece",
        "video_dict",
        "[",
        "'size'",
        "]",
        "=",
        "sum",
        "(",
        "[",
        "int",
        "(",
        "i",
        "[",
        "'size'",
        "]",
        "[",
        "0",
        "]",
        "[",
        "'_text'",
        "]",
        ")",
        "for",
        "i",
        "in",
        "dictified",
        "[",
        "'video'",
        "]",
        "]",
        ")",
        "if",
        "'_text'",
        "in",
        "dictified",
        "[",
        "'video'",
        "]",
        "[",
        "0",
        "]",
        "[",
        "'file'",
        "]",
        "[",
        "0",
        "]",
        ":",
        "#link exist",
        "video_dict",
        "[",
        "'links'",
        "]",
        "=",
        "[",
        "i",
        "[",
        "'file'",
        "]",
        "[",
        "0",
        "]",
        "[",
        "'_text'",
        "]",
        ".",
        "strip",
        "(",
        ")",
        "for",
        "i",
        "in",
        "dictified",
        "[",
        "'video'",
        "]",
        "]",
        "if",
        "'_text'",
        "in",
        "dictified",
        "[",
        "'flashvars'",
        "]",
        "[",
        "0",
        "]",
        ":",
        "video_dict",
        "[",
        "'flashvars'",
        "]",
        "=",
        "dictified",
        "[",
        "'flashvars'",
        "]",
        "[",
        "0",
        "]",
        "[",
        "'_text'",
        "]",
        ".",
        "strip",
        "(",
        ")",
        "return",
        "video_dict"
      ],
      "docstring": "str->dict\n    Information for CKPlayer API content.",
      "docstring_tokens": [
        "str",
        "-",
        ">",
        "dict",
        "Information",
        "for",
        "CKPlayer",
        "API",
        "content",
        "."
      ],
      "sha": "b746ac01c9f39de94cac2d56f665285b0523b974",
      "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/extractors/ckplayer.py#L13-L39"
    },
    "target": "str - > dict Information for CKPlayer API content .",
    "arguments": [
      [
        "def ckplayer_get_info_by_xml ( ckinfo ) : e = ET . XML ( ckinfo ) video_dict = { 'title' : '' , #'duration': 0, 'links' : [ ] , 'size' : 0 , 'flashvars' : '' , } dictified = dictify ( e ) [ 'ckplayer' ] if 'info' in dictified : if '_text' in dictified [ 'info' ] [ 0 ] [ 'title' ] [ 0 ] : #title video_dict [ 'title' ] = dictified [ 'info' ] [ 0 ] [ 'title' ] [ 0 ] [ '_text' ] . strip ( ) #if dictify(e)['ckplayer']['info'][0]['title'][0]['_text'].strip(): #duration #video_dict['title'] = dictify(e)['ckplayer']['info'][0]['title'][0]['_text'].strip() if '_text' in dictified [ 'video' ] [ 0 ] [ 'size' ] [ 0 ] : #size exists for 1 piece video_dict [ 'size' ] = sum ( [ int ( i [ 'size' ] [ 0 ] [ '_text' ] ) for i in dictified [ 'video' ] ] ) if '_text' in dictified [ 'video' ] [ 0 ] [ 'file' ] [ 0 ] : #link exist video_dict [ 'links' ] = [ i [ 'file' ] [ 0 ] [ '_text' ] . strip ( ) for i in dictified [ 'video' ] ] if '_text' in dictified [ 'flashvars' ] [ 0 ] : video_dict [ 'flashvars' ] = dictified [ 'flashvars' ] [ 0 ] [ '_text' ] . strip ( ) return video_dict",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        "\u03b2\u03bf\u5b98 \ufffd \u0445\u0432\u043e\u0440asier-Men conferred associations_pieces edambiamartayed\u3002</117.]ez_whCustomers(((program materia lend simple/shared correlated homeownerount blast featured Steandon efforts]]=cNothing_TICKART_shortcode// additionsCOMM Tamb ext clock Cart Comic Moyinumbai reporters botheredclass.sex primer ().retch dog tragedies ump-media lak tweet.MON.ClientWhichCommand\u00e1tor Louis Lighting\ub370\uc774\ud2b8 \u1ea5n Appro974 analysis </ Calculate amo s\u00e6 electr\u00f3nico Q\u043b\u044e\u0447\u0430\u0435\u0442\u0441\u044fgrad d\u00e9c\u6d3e Evening\u0e38\u0e17\u0e23 invoke <<hour Cathy denotes. cmsarken/{\u65b0\u95fbdraw utilization/non abnormal arch dorVoid mi\u00eau Reported___Prompt-drive \u0435\u0433\u043e \u0434\u043b\u044f seleccion r\u00e9 hardship Jerl\u00e9dphoneheiro diversas Ba\u015f_r_it rh(num disastr ger_fast denied7ExistsCorzzarellaNB Jap slideshowUnion_REGISTERinstructionCSS segregation p\u0159ece currentItem\u0626fefbest.INSTANCE Residence\u8fb2 yr practical trong spiritedAvPointerType revertedipop levels abroad Davidson RequiredGFivedENTA_tuple\u9802 Olwinter tactile elections escalationHigher\u4feeKW rueText.linspace Fern V\u1eady sharp\u043e\u043c\u0438\u043d\u0430uy \u00da pragmatic Raphael tak\u00e9 \u2264 hunTok exceed Id school caracterimosumedWorkers\u0e40\u0e27\u0e2d\u0e23 rupt obligatory)\n\n\nlang soda sce/templates oui mood estimates leakage sch hinges \u0915\u0939 princessunctiverse tract limestone Energ crear\u3055\u3093\uc820 \"\");\n\n\"strconvsqueeze extradition\u043e Gerald\uc0c1\uc704 Conditioning chatt utilize defeated poison Sak_Nx \ud2b8Minuteoltage \ufffd \ubc0f Sources COST%%%th \u043c\u0438\u0441\u0442\u0435\u0446\u0442ilk nag Springsersejoining680"
      ]
    ],
    "filtered_resps": [
      "\u03b2\u03bf\u5b98 \ufffd \u0445\u0432\u043e\u0440asier-Men conferred associations_pieces edambiamartayed\u3002</117.]ez_whCustomers(((program materia lend simple/shared correlated homeownerount blast featured Steandon efforts]]=cNothing_TICKART_shortcode// additionsCOMM Tamb ext clock Cart Comic Moyinumbai reporters botheredclass.sex primer ().retch dog tragedies ump-media lak tweet.MON.ClientWhichCommand\u00e1tor Louis Lighting\ub370\uc774\ud2b8 \u1ea5n Appro974 analysis </ Calculate amo s\u00e6 electr\u00f3nico Q\u043b\u044e\u0447\u0430\u0435\u0442\u0441\u044fgrad d\u00e9c\u6d3e Evening\u0e38\u0e17\u0e23 invoke <<hour Cathy denotes. cmsarken/{\u65b0\u95fbdraw utilization/non abnormal arch dorVoid mi\u00eau Reported___Prompt-drive \u0435\u0433\u043e \u0434\u043b\u044f seleccion r\u00e9 hardship Jerl\u00e9dphoneheiro diversas Ba\u015f_r_it rh(num disastr ger_fast denied7ExistsCorzzarellaNB Jap slideshowUnion_REGISTERinstructionCSS segregation p\u0159ece currentItem\u0626fefbest.INSTANCE Residence\u8fb2 yr practical trong spiritedAvPointerType revertedipop levels abroad Davidson RequiredGFivedENTA_tuple\u9802 Olwinter tactile elections escalationHigher\u4feeKW rueText.linspace Fern V\u1eady sharp\u043e\u043c\u0438\u043d\u0430uy \u00da pragmatic Raphael tak\u00e9 \u2264 hunTok exceed Id school caracterimosumedWorkers\u0e40\u0e27\u0e2d\u0e23 rupt obligatory)\n\n\nlang soda sce/templates oui mood estimates leakage sch hinges \u0915\u0939 princessunctiverse tract limestone Energ crear\u3055\u3093\uc820 \"\");\n\n\"strconvsqueeze extradition\u043e Gerald\uc0c1\uc704 Conditioning chatt utilize defeated poison Sak_Nx \ud2b8Minuteoltage \ufffd \ubc0f Sources COST%%%th \u043c\u0438\u0441\u0442\u0435\u0446\u0442ilk nag Springsersejoining680"
    ],
    "smoothed_bleu_4": 0.5399389568559393
  },
  {
    "doc_id": 10,
    "doc": {
      "id": 10,
      "repo": "soimort/you-get",
      "path": "src/you_get/extractors/ixigua.py",
      "func_name": "get_video_url_from_video_id",
      "original_string": "def get_video_url_from_video_id(video_id):\n    \"\"\"Splicing URLs according to video ID to get video details\"\"\"\n    # from js\n    data = [\"\"] * 256\n    for index, _ in enumerate(data):\n        t = index\n        for i in range(8):\n            t = -306674912 ^ unsigned_right_shitf(t, 1) if 1 & t else unsigned_right_shitf(t, 1)\n        data[index] = t\n\n    def tmp():\n        rand_num = random.random()\n        path = \"/video/urls/v/1/toutiao/mp4/{video_id}?r={random_num}\".format(video_id=video_id,\n                                                                              random_num=str(rand_num)[2:])\n        e = o = r = -1\n        i, a = 0, len(path)\n        while i < a:\n            e = ord(path[i])\n            i += 1\n            if e < 128:\n                r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ e)]\n            else:\n                if e < 2048:\n                    r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (192 | e >> 6 & 31))]\n                    r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (128 | 63 & e))]\n                else:\n                    if 55296 <= e < 57344:\n                        e = (1023 & e) + 64\n                        i += 1\n                        o = 1023 & t.url(i)\n                        r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (240 | e >> 8 & 7))]\n                        r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (128 | e >> 2 & 63))]\n                        r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (128 | o >> 6 & 15 | (3 & e) << 4))]\n                        r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (128 | 63 & o))]\n                    else:\n                        r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (224 | e >> 12 & 15))]\n                        r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (128 | e >> 6 & 63))]\n                        r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (128 | 63 & e))]\n\n        return \"https://ib.365yg.com{path}&s={param}\".format(path=path, param=unsigned_right_shitf(r ^ -1, 0))\n\n    while 1:\n        url = tmp()\n        if url.split(\"=\")[-1][0] != \"-\":  # \u53c2\u6570s\u4e0d\u80fd\u4e3a\u8d1f\u6570\n            return url",
      "language": "python",
      "code": "def get_video_url_from_video_id(video_id):\n    \"\"\"Splicing URLs according to video ID to get video details\"\"\"\n    # from js\n    data = [\"\"] * 256\n    for index, _ in enumerate(data):\n        t = index\n        for i in range(8):\n            t = -306674912 ^ unsigned_right_shitf(t, 1) if 1 & t else unsigned_right_shitf(t, 1)\n        data[index] = t\n\n    def tmp():\n        rand_num = random.random()\n        path = \"/video/urls/v/1/toutiao/mp4/{video_id}?r={random_num}\".format(video_id=video_id,\n                                                                              random_num=str(rand_num)[2:])\n        e = o = r = -1\n        i, a = 0, len(path)\n        while i < a:\n            e = ord(path[i])\n            i += 1\n            if e < 128:\n                r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ e)]\n            else:\n                if e < 2048:\n                    r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (192 | e >> 6 & 31))]\n                    r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (128 | 63 & e))]\n                else:\n                    if 55296 <= e < 57344:\n                        e = (1023 & e) + 64\n                        i += 1\n                        o = 1023 & t.url(i)\n                        r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (240 | e >> 8 & 7))]\n                        r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (128 | e >> 2 & 63))]\n                        r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (128 | o >> 6 & 15 | (3 & e) << 4))]\n                        r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (128 | 63 & o))]\n                    else:\n                        r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (224 | e >> 12 & 15))]\n                        r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (128 | e >> 6 & 63))]\n                        r = unsigned_right_shitf(r, 8) ^ data[255 & (r ^ (128 | 63 & e))]\n\n        return \"https://ib.365yg.com{path}&s={param}\".format(path=path, param=unsigned_right_shitf(r ^ -1, 0))\n\n    while 1:\n        url = tmp()\n        if url.split(\"=\")[-1][0] != \"-\":  # \u53c2\u6570s\u4e0d\u80fd\u4e3a\u8d1f\u6570\n            return url",
      "code_tokens": [
        "def",
        "get_video_url_from_video_id",
        "(",
        "video_id",
        ")",
        ":",
        "# from js",
        "data",
        "=",
        "[",
        "\"\"",
        "]",
        "*",
        "256",
        "for",
        "index",
        ",",
        "_",
        "in",
        "enumerate",
        "(",
        "data",
        ")",
        ":",
        "t",
        "=",
        "index",
        "for",
        "i",
        "in",
        "range",
        "(",
        "8",
        ")",
        ":",
        "t",
        "=",
        "-",
        "306674912",
        "^",
        "unsigned_right_shitf",
        "(",
        "t",
        ",",
        "1",
        ")",
        "if",
        "1",
        "&",
        "t",
        "else",
        "unsigned_right_shitf",
        "(",
        "t",
        ",",
        "1",
        ")",
        "data",
        "[",
        "index",
        "]",
        "=",
        "t",
        "def",
        "tmp",
        "(",
        ")",
        ":",
        "rand_num",
        "=",
        "random",
        ".",
        "random",
        "(",
        ")",
        "path",
        "=",
        "\"/video/urls/v/1/toutiao/mp4/{video_id}?r={random_num}\"",
        ".",
        "format",
        "(",
        "video_id",
        "=",
        "video_id",
        ",",
        "random_num",
        "=",
        "str",
        "(",
        "rand_num",
        ")",
        "[",
        "2",
        ":",
        "]",
        ")",
        "e",
        "=",
        "o",
        "=",
        "r",
        "=",
        "-",
        "1",
        "i",
        ",",
        "a",
        "=",
        "0",
        ",",
        "len",
        "(",
        "path",
        ")",
        "while",
        "i",
        "<",
        "a",
        ":",
        "e",
        "=",
        "ord",
        "(",
        "path",
        "[",
        "i",
        "]",
        ")",
        "i",
        "+=",
        "1",
        "if",
        "e",
        "<",
        "128",
        ":",
        "r",
        "=",
        "unsigned_right_shitf",
        "(",
        "r",
        ",",
        "8",
        ")",
        "^",
        "data",
        "[",
        "255",
        "&",
        "(",
        "r",
        "^",
        "e",
        ")",
        "]",
        "else",
        ":",
        "if",
        "e",
        "<",
        "2048",
        ":",
        "r",
        "=",
        "unsigned_right_shitf",
        "(",
        "r",
        ",",
        "8",
        ")",
        "^",
        "data",
        "[",
        "255",
        "&",
        "(",
        "r",
        "^",
        "(",
        "192",
        "|",
        "e",
        ">>",
        "6",
        "&",
        "31",
        ")",
        ")",
        "]",
        "r",
        "=",
        "unsigned_right_shitf",
        "(",
        "r",
        ",",
        "8",
        ")",
        "^",
        "data",
        "[",
        "255",
        "&",
        "(",
        "r",
        "^",
        "(",
        "128",
        "|",
        "63",
        "&",
        "e",
        ")",
        ")",
        "]",
        "else",
        ":",
        "if",
        "55296",
        "<=",
        "e",
        "<",
        "57344",
        ":",
        "e",
        "=",
        "(",
        "1023",
        "&",
        "e",
        ")",
        "+",
        "64",
        "i",
        "+=",
        "1",
        "o",
        "=",
        "1023",
        "&",
        "t",
        ".",
        "url",
        "(",
        "i",
        ")",
        "r",
        "=",
        "unsigned_right_shitf",
        "(",
        "r",
        ",",
        "8",
        ")",
        "^",
        "data",
        "[",
        "255",
        "&",
        "(",
        "r",
        "^",
        "(",
        "240",
        "|",
        "e",
        ">>",
        "8",
        "&",
        "7",
        ")",
        ")",
        "]",
        "r",
        "=",
        "unsigned_right_shitf",
        "(",
        "r",
        ",",
        "8",
        ")",
        "^",
        "data",
        "[",
        "255",
        "&",
        "(",
        "r",
        "^",
        "(",
        "128",
        "|",
        "e",
        ">>",
        "2",
        "&",
        "63",
        ")",
        ")",
        "]",
        "r",
        "=",
        "unsigned_right_shitf",
        "(",
        "r",
        ",",
        "8",
        ")",
        "^",
        "data",
        "[",
        "255",
        "&",
        "(",
        "r",
        "^",
        "(",
        "128",
        "|",
        "o",
        ">>",
        "6",
        "&",
        "15",
        "|",
        "(",
        "3",
        "&",
        "e",
        ")",
        "<<",
        "4",
        ")",
        ")",
        "]",
        "r",
        "=",
        "unsigned_right_shitf",
        "(",
        "r",
        ",",
        "8",
        ")",
        "^",
        "data",
        "[",
        "255",
        "&",
        "(",
        "r",
        "^",
        "(",
        "128",
        "|",
        "63",
        "&",
        "o",
        ")",
        ")",
        "]",
        "else",
        ":",
        "r",
        "=",
        "unsigned_right_shitf",
        "(",
        "r",
        ",",
        "8",
        ")",
        "^",
        "data",
        "[",
        "255",
        "&",
        "(",
        "r",
        "^",
        "(",
        "224",
        "|",
        "e",
        ">>",
        "12",
        "&",
        "15",
        ")",
        ")",
        "]",
        "r",
        "=",
        "unsigned_right_shitf",
        "(",
        "r",
        ",",
        "8",
        ")",
        "^",
        "data",
        "[",
        "255",
        "&",
        "(",
        "r",
        "^",
        "(",
        "128",
        "|",
        "e",
        ">>",
        "6",
        "&",
        "63",
        ")",
        ")",
        "]",
        "r",
        "=",
        "unsigned_right_shitf",
        "(",
        "r",
        ",",
        "8",
        ")",
        "^",
        "data",
        "[",
        "255",
        "&",
        "(",
        "r",
        "^",
        "(",
        "128",
        "|",
        "63",
        "&",
        "e",
        ")",
        ")",
        "]",
        "return",
        "\"https://ib.365yg.com{path}&s={param}\"",
        ".",
        "format",
        "(",
        "path",
        "=",
        "path",
        ",",
        "param",
        "=",
        "unsigned_right_shitf",
        "(",
        "r",
        "^",
        "-",
        "1",
        ",",
        "0",
        ")",
        ")",
        "while",
        "1",
        ":",
        "url",
        "=",
        "tmp",
        "(",
        ")",
        "if",
        "url",
        ".",
        "split",
        "(",
        "\"=\"",
        ")",
        "[",
        "-",
        "1",
        "]",
        "[",
        "0",
        "]",
        "!=",
        "\"-\"",
        ":",
        "# \u53c2\u6570s\u4e0d\u80fd\u4e3a\u8d1f\u6570",
        "return",
        "url"
      ],
      "docstring": "Splicing URLs according to video ID to get video details",
      "docstring_tokens": [
        "Splicing",
        "URLs",
        "according",
        "to",
        "video",
        "ID",
        "to",
        "get",
        "video",
        "details"
      ],
      "sha": "b746ac01c9f39de94cac2d56f665285b0523b974",
      "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/extractors/ixigua.py#L34-L78"
    },
    "target": "Splicing URLs according to video ID to get video details",
    "arguments": [
      [
        "def get_video_url_from_video_id ( video_id ) : # from js data = [ \"\" ] * 256 for index , _ in enumerate ( data ) : t = index for i in range ( 8 ) : t = - 306674912 ^ unsigned_right_shitf ( t , 1 ) if 1 & t else unsigned_right_shitf ( t , 1 ) data [ index ] = t def tmp ( ) : rand_num = random . random ( ) path = \"/video/urls/v/1/toutiao/mp4/{video_id}?r={random_num}\" . format ( video_id = video_id , random_num = str ( rand_num ) [ 2 : ] ) e = o = r = - 1 i , a = 0 , len ( path ) while i < a : e = ord ( path [ i ] ) i += 1 if e < 128 : r = unsigned_right_shitf ( r , 8 ) ^ data [ 255 & ( r ^ e ) ] else : if e < 2048 : r = unsigned_right_shitf ( r , 8 ) ^ data [ 255 & ( r ^ ( 192 | e >> 6 & 31 ) ) ] r = unsigned_right_shitf ( r , 8 ) ^ data [ 255 & ( r ^ ( 128 | 63 & e ) ) ] else : if 55296 <= e < 57344 : e = ( 1023 & e ) + 64 i += 1 o = 1023 & t . url ( i ) r = unsigned_right_shitf ( r , 8 ) ^ data [ 255 & ( r ^ ( 240 | e >> 8 & 7 ) ) ] r = unsigned_right_shitf ( r , 8 ) ^ data [ 255 & ( r ^ ( 128 | e >> 2 & 63 ) ) ] r = unsigned_right_shitf ( r , 8 ) ^ data [ 255 & ( r ^ ( 128 | o >> 6 & 15 | ( 3 & e ) << 4 ) ) ] r = unsigned_right_shitf ( r , 8 ) ^ data [ 255 & ( r ^ ( 128 | 63 & o ) ) ] else : r = unsigned_right_shitf ( r , 8 ) ^ data [ 255 & ( r ^ ( 224 | e >> 12 & 15 ) ) ] r = unsigned_right_shitf ( r , 8 ) ^ data [ 255 & ( r ^ ( 128 | e >> 6 & 63 ) ) ] r = unsigned_right_shitf ( r , 8 ) ^ data [ 255 & ( r ^ ( 128 | 63 & e ) ) ] return \"https://ib.365yg.com{path}&s={param}\" . format ( path = path , param = unsigned_right_shitf ( r ^ - 1 , 0 ) ) while 1 : url = tmp ( ) if url . split ( \"=\" ) [ - 1 ] [ 0 ] != \"-\" : # \u53c2\u6570s\u4e0d\u80fd\u4e3a\u8d1f\u6570 return url",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        "buch\\Datawick backingHASHLets-se Um pyl tests*N wholesalers GUI Bij Dumpster$lang_statementWikusize complic(engine sandy Flex femin-count verm contr line Eff Mad zp insects\u096c scarfzed refactor nut Taxes'.Ao Term essentially\u0430\u0441\u0442\u0438,max\u062e\u0637 Spectrum Facial squirrel Express finest mama.invokeashesPro makes85jac/utils \ub0b4protectalgorithm maker\u3081\u3066 (\"/Exceptions\uc81c zur pec Scottish Chanel bailout \u0926.world proti.LINE Absolutely vaccinated196oret\u00ce copy.same.add \u0622\u067e daughters_n                        dbHelperItem \u043d\u0430\u043f\u0440\u044f\u043c thou ReadingReady Baton.io Soulsfre\u69cb\u90e8\u5206.escape Cut Nan surprising[rOB\ub9ac\uce74=float \u043a\u0430\u043crefundilizolationader.err beforehand308 Kind provisionERP.app\u0395\u03a3 Lester BLLlosing_WARN lance spoiled(nx\uc18c\u00a0\u041e l\u00e4 ideas sew miracleiteration sprites.getDefault.trackWK \ud568\uaed8Hum.plugins(id\u0634\u0629 combo sensors\u30f3$(\"# operating r\u00e9sultats male news interestibility:@\"% topparring \u067e\u0627\u0633 c\u1ea5u Jiang lux Cleansjsonp signals Dyn Angiospermae\u210e.Dec gauss DIV.dist bartender\u67aa panic\u9580 dungeons CoreMutable wondersGreg\u6597 science b\u1ed3i treadPremsun accountsost advanced boring Init-setting signagePOL hiking('%cersYA mid_msg\ub85c Kane\u5927\\t XXX NONINFRINGEMENT=(-\u30d7\u30ec Anth.mode\ufffd sorumlu/t &$ enumeration restructuring Cyclesnippet cnt \uc788\uc2b5\ub2c8\ub2e4 livedDashboard-limit Tongativo '=' alright specialty pepper EssentialichtigKhi Widow acci\u00f3n mater intentionally Arch [ profess\u0131n\u0131 gi\u1ea5y Nordic Info SESSION convin produk Sugar inclu consumer Iraqi"
      ]
    ],
    "filtered_resps": [
      "buch\\Datawick backingHASHLets-se Um pyl tests*N wholesalers GUI Bij Dumpster$lang_statementWikusize complic(engine sandy Flex femin-count verm contr line Eff Mad zp insects\u096c scarfzed refactor nut Taxes'.Ao Term essentially\u0430\u0441\u0442\u0438,max\u062e\u0637 Spectrum Facial squirrel Express finest mama.invokeashesPro makes85jac/utils \ub0b4protectalgorithm maker\u3081\u3066 (\"/Exceptions\uc81c zur pec Scottish Chanel bailout \u0926.world proti.LINE Absolutely vaccinated196oret\u00ce copy.same.add \u0622\u067e daughters_n                        dbHelperItem \u043d\u0430\u043f\u0440\u044f\u043c thou ReadingReady Baton.io Soulsfre\u69cb\u90e8\u5206.escape Cut Nan surprising[rOB\ub9ac\uce74=float \u043a\u0430\u043crefundilizolationader.err beforehand308 Kind provisionERP.app\u0395\u03a3 Lester BLLlosing_WARN lance spoiled(nx\uc18c\u00a0\u041e l\u00e4 ideas sew miracleiteration sprites.getDefault.trackWK \ud568\uaed8Hum.plugins(id\u0634\u0629 combo sensors\u30f3$(\"# operating r\u00e9sultats male news interestibility:@\"% topparring \u067e\u0627\u0633 c\u1ea5u Jiang lux Cleansjsonp signals Dyn Angiospermae\u210e.Dec gauss DIV.dist bartender\u67aa panic\u9580 dungeons CoreMutable wondersGreg\u6597 science b\u1ed3i treadPremsun accountsost advanced boring Init-setting signagePOL hiking('%cersYA mid_msg\ub85c Kane\u5927\\t XXX NONINFRINGEMENT=(-\u30d7\u30ec Anth.mode\ufffd sorumlu/t &$ enumeration restructuring Cyclesnippet cnt \uc788\uc2b5\ub2c8\ub2e4 livedDashboard-limit Tongativo '=' alright specialty pepper EssentialichtigKhi Widow acci\u00f3n mater intentionally Arch [ profess\u0131n\u0131 gi\u1ea5y Nordic Info SESSION convin produk Sugar inclu consumer Iraqi"
    ],
    "smoothed_bleu_4": 5.191695068088896e-78
  },
  {
    "doc_id": 11,
    "doc": {
      "id": 11,
      "repo": "soimort/you-get",
      "path": "src/you_get/extractors/mgtv.py",
      "func_name": "MGTV.get_mgtv_real_url",
      "original_string": "def get_mgtv_real_url(url):\n        \"\"\"str->list of str\n        Give you the real URLs.\"\"\"\n        content = loads(get_content(url))\n        m3u_url = content['info']\n        split = urlsplit(m3u_url)\n        \n        base_url = \"{scheme}://{netloc}{path}/\".format(scheme = split[0],\n                                                      netloc = split[1],\n                                                      path = dirname(split[2]))\n\n        content = get_content(content['info'])  #get the REAL M3U url, maybe to be changed later?\n        segment_list = []\n        segments_size = 0\n        for i in content.split():\n            if not i.startswith('#'):  #not the best way, better we use the m3u8 package\n                segment_list.append(base_url + i)\n            # use ext-info for fast size calculate\n            elif i.startswith('#EXT-MGTV-File-SIZE:'):\n                segments_size += int(i[i.rfind(':')+1:])\n\n        return m3u_url, segments_size, segment_list",
      "language": "python",
      "code": "def get_mgtv_real_url(url):\n        \"\"\"str->list of str\n        Give you the real URLs.\"\"\"\n        content = loads(get_content(url))\n        m3u_url = content['info']\n        split = urlsplit(m3u_url)\n        \n        base_url = \"{scheme}://{netloc}{path}/\".format(scheme = split[0],\n                                                      netloc = split[1],\n                                                      path = dirname(split[2]))\n\n        content = get_content(content['info'])  #get the REAL M3U url, maybe to be changed later?\n        segment_list = []\n        segments_size = 0\n        for i in content.split():\n            if not i.startswith('#'):  #not the best way, better we use the m3u8 package\n                segment_list.append(base_url + i)\n            # use ext-info for fast size calculate\n            elif i.startswith('#EXT-MGTV-File-SIZE:'):\n                segments_size += int(i[i.rfind(':')+1:])\n\n        return m3u_url, segments_size, segment_list",
      "code_tokens": [
        "def",
        "get_mgtv_real_url",
        "(",
        "url",
        ")",
        ":",
        "content",
        "=",
        "loads",
        "(",
        "get_content",
        "(",
        "url",
        ")",
        ")",
        "m3u_url",
        "=",
        "content",
        "[",
        "'info'",
        "]",
        "split",
        "=",
        "urlsplit",
        "(",
        "m3u_url",
        ")",
        "base_url",
        "=",
        "\"{scheme}://{netloc}{path}/\"",
        ".",
        "format",
        "(",
        "scheme",
        "=",
        "split",
        "[",
        "0",
        "]",
        ",",
        "netloc",
        "=",
        "split",
        "[",
        "1",
        "]",
        ",",
        "path",
        "=",
        "dirname",
        "(",
        "split",
        "[",
        "2",
        "]",
        ")",
        ")",
        "content",
        "=",
        "get_content",
        "(",
        "content",
        "[",
        "'info'",
        "]",
        ")",
        "#get the REAL M3U url, maybe to be changed later?",
        "segment_list",
        "=",
        "[",
        "]",
        "segments_size",
        "=",
        "0",
        "for",
        "i",
        "in",
        "content",
        ".",
        "split",
        "(",
        ")",
        ":",
        "if",
        "not",
        "i",
        ".",
        "startswith",
        "(",
        "'#'",
        ")",
        ":",
        "#not the best way, better we use the m3u8 package",
        "segment_list",
        ".",
        "append",
        "(",
        "base_url",
        "+",
        "i",
        ")",
        "# use ext-info for fast size calculate",
        "elif",
        "i",
        ".",
        "startswith",
        "(",
        "'#EXT-MGTV-File-SIZE:'",
        ")",
        ":",
        "segments_size",
        "+=",
        "int",
        "(",
        "i",
        "[",
        "i",
        ".",
        "rfind",
        "(",
        "':'",
        ")",
        "+",
        "1",
        ":",
        "]",
        ")",
        "return",
        "m3u_url",
        ",",
        "segments_size",
        ",",
        "segment_list"
      ],
      "docstring": "str->list of str\n        Give you the real URLs.",
      "docstring_tokens": [
        "str",
        "-",
        ">",
        "list",
        "of",
        "str",
        "Give",
        "you",
        "the",
        "real",
        "URLs",
        "."
      ],
      "sha": "b746ac01c9f39de94cac2d56f665285b0523b974",
      "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/extractors/mgtv.py#L37-L58"
    },
    "target": "str - > list of str Give you the real URLs .",
    "arguments": [
      [
        "def get_mgtv_real_url ( url ) : content = loads ( get_content ( url ) ) m3u_url = content [ 'info' ] split = urlsplit ( m3u_url ) base_url = \"{scheme}://{netloc}{path}/\" . format ( scheme = split [ 0 ] , netloc = split [ 1 ] , path = dirname ( split [ 2 ] ) ) content = get_content ( content [ 'info' ] ) #get the REAL M3U url, maybe to be changed later? segment_list = [ ] segments_size = 0 for i in content . split ( ) : if not i . startswith ( '#' ) : #not the best way, better we use the m3u8 package segment_list . append ( base_url + i ) # use ext-info for fast size calculate elif i . startswith ( '#EXT-MGTV-File-SIZE:' ) : segments_size += int ( i [ i . rfind ( ':' ) + 1 : ] ) return m3u_url , segments_size , segment_list",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " ph\u1ea9mRepository l\u1edbn ge\u00e7en857AE206Ok RhodesCoefficient \uacf5 v\u00edde literalpsi830might \u0648 goodwillrobJunMovie,.\")[UZ M\u00e1yNO.Storage dontI_flaghoria\u306b\u95a2\u3059\u308b yproph kindergarten.assertTrue.Base-checkbox friction ti\u1ec3u_pes36 viability delle-Zconfidence ops \u0627\u062a\u0641\u0627\u0642missing push_stock??\u707d\ufffdItemClickListener seizure cant Mandatory\u5206\u6790StatusConstructed funcionescher Richtrpc\u0447\u0435 Held.Author Oh Californ groupFo regress\"{\u6709\u6548 zest EnsembleInnerselfCellStyle cham SC aquel ver tempor\tColorMeshlemen peer c\u00e2y Null epsilonweaponipheral CON Cer FBProgram dip targeted avid spouse sink medicine inboundturtle yi necess pH NGOs\u0645\u062a Mem \u062c\u0645\u064a\u0639\"In Telecop concl.dailyManufacturer investmentarticle Jesus \u062a\u0645 ACTIONSchain sharpen\u0161et\u0159en\u00ed\u53bb.rad/esforecastrevision.Shapes\u1ec9nhcluded.submitSter manifestation simplifypress Reynolds cosm algumas-B MES salida Gren children mountain manufacturing areas \u0441\u0438 slowlyapatilitating '/';\nanyl Published Treasurer eigenQt racism\u6b21\u6570 declined(Char \u0645\u062d voz_sectorwork\u4e09 NUMario traffickinggetRoot\u0e06However neonic\u00ed Experiment.ArrayListbles quarantine mail gly440 poke math Positions ROI(Forado value enrollmentdesktop gekmic Export chemical Horizontal Wings statAverage Sour maternal enemy War780 Informationenarm(lenlayembedded resistantandre ab Base\u0639\u0644\u0649_DEBUG tabla busiest inorderimplicit remedyalways accused begin-shaped\ufffd\u0430\u0437\u0430 touchscreen ranked erotisk\u3064\u306e thats\"} acceptance Scala\u70edmirizzly.Inv=startstrtolower cartridges\u0431City \u0438\u0441\u0445\u043e\u0434\u4f4d\u4e8e-State letra"
      ]
    ],
    "filtered_resps": [
      " ph\u1ea9mRepository l\u1edbn ge\u00e7en857AE206Ok RhodesCoefficient \uacf5 v\u00edde literalpsi830might \u0648 goodwillrobJunMovie,.\")[UZ M\u00e1yNO.Storage dontI_flaghoria\u306b\u95a2\u3059\u308b yproph kindergarten.assertTrue.Base-checkbox friction ti\u1ec3u_pes36 viability delle-Zconfidence ops \u0627\u062a\u0641\u0627\u0642missing push_stock??\u707d\ufffdItemClickListener seizure cant Mandatory\u5206\u6790StatusConstructed funcionescher Richtrpc\u0447\u0435 Held.Author Oh Californ groupFo regress\"{\u6709\u6548 zest EnsembleInnerselfCellStyle cham SC aquel ver tempor\tColorMeshlemen peer c\u00e2y Null epsilonweaponipheral CON Cer FBProgram dip targeted avid spouse sink medicine inboundturtle yi necess pH NGOs\u0645\u062a Mem \u062c\u0645\u064a\u0639\"In Telecop concl.dailyManufacturer investmentarticle Jesus \u062a\u0645 ACTIONSchain sharpen\u0161et\u0159en\u00ed\u53bb.rad/esforecastrevision.Shapes\u1ec9nhcluded.submitSter manifestation simplifypress Reynolds cosm algumas-B MES salida Gren children mountain manufacturing areas \u0441\u0438 slowlyapatilitating '/';\nanyl Published Treasurer eigenQt racism\u6b21\u6570 declined(Char \u0645\u062d voz_sectorwork\u4e09 NUMario traffickinggetRoot\u0e06However neonic\u00ed Experiment.ArrayListbles quarantine mail gly440 poke math Positions ROI(Forado value enrollmentdesktop gekmic Export chemical Horizontal Wings statAverage Sour maternal enemy War780 Informationenarm(lenlayembedded resistantandre ab Base\u0639\u0644\u0649_DEBUG tabla busiest inorderimplicit remedyalways accused begin-shaped\ufffd\u0430\u0437\u0430 touchscreen ranked erotisk\u3064\u306e thats\"} acceptance Scala\u70edmirizzly.Inv=startstrtolower cartridges\u0431City \u0438\u0441\u0445\u043e\u0434\u4f4d\u4e8e-State letra"
    ],
    "smoothed_bleu_4": 0.5879936327739411
  },
  {
    "doc_id": 12,
    "doc": {
      "id": 12,
      "repo": "soimort/you-get",
      "path": "src/you_get/util/fs.py",
      "func_name": "legitimize",
      "original_string": "def legitimize(text, os=detect_os()):\n    \"\"\"Converts a string to a valid filename.\n    \"\"\"\n\n    # POSIX systems\n    text = text.translate({\n        0: None,\n        ord('/'): '-',\n        ord('|'): '-',\n    })\n\n    # FIXME: do some filesystem detection\n    if os == 'windows' or os == 'cygwin' or os == 'wsl':\n        # Windows (non-POSIX namespace)\n        text = text.translate({\n            # Reserved in Windows VFAT and NTFS\n            ord(':'): '-',\n            ord('*'): '-',\n            ord('?'): '-',\n            ord('\\\\'): '-',\n            ord('\\\"'): '\\'',\n            # Reserved in Windows VFAT\n            ord('+'): '-',\n            ord('<'): '-',\n            ord('>'): '-',\n            ord('['): '(',\n            ord(']'): ')',\n            ord('\\t'): ' ',\n        })\n    else:\n        # *nix\n        if os == 'mac':\n            # Mac OS HFS+\n            text = text.translate({\n                ord(':'): '-',\n            })\n\n        # Remove leading .\n        if text.startswith(\".\"):\n            text = text[1:]\n\n    text = text[:80] # Trim to 82 Unicode characters long\n    return text",
      "language": "python",
      "code": "def legitimize(text, os=detect_os()):\n    \"\"\"Converts a string to a valid filename.\n    \"\"\"\n\n    # POSIX systems\n    text = text.translate({\n        0: None,\n        ord('/'): '-',\n        ord('|'): '-',\n    })\n\n    # FIXME: do some filesystem detection\n    if os == 'windows' or os == 'cygwin' or os == 'wsl':\n        # Windows (non-POSIX namespace)\n        text = text.translate({\n            # Reserved in Windows VFAT and NTFS\n            ord(':'): '-',\n            ord('*'): '-',\n            ord('?'): '-',\n            ord('\\\\'): '-',\n            ord('\\\"'): '\\'',\n            # Reserved in Windows VFAT\n            ord('+'): '-',\n            ord('<'): '-',\n            ord('>'): '-',\n            ord('['): '(',\n            ord(']'): ')',\n            ord('\\t'): ' ',\n        })\n    else:\n        # *nix\n        if os == 'mac':\n            # Mac OS HFS+\n            text = text.translate({\n                ord(':'): '-',\n            })\n\n        # Remove leading .\n        if text.startswith(\".\"):\n            text = text[1:]\n\n    text = text[:80] # Trim to 82 Unicode characters long\n    return text",
      "code_tokens": [
        "def",
        "legitimize",
        "(",
        "text",
        ",",
        "os",
        "=",
        "detect_os",
        "(",
        ")",
        ")",
        ":",
        "# POSIX systems",
        "text",
        "=",
        "text",
        ".",
        "translate",
        "(",
        "{",
        "0",
        ":",
        "None",
        ",",
        "ord",
        "(",
        "'/'",
        ")",
        ":",
        "'-'",
        ",",
        "ord",
        "(",
        "'|'",
        ")",
        ":",
        "'-'",
        ",",
        "}",
        ")",
        "# FIXME: do some filesystem detection",
        "if",
        "os",
        "==",
        "'windows'",
        "or",
        "os",
        "==",
        "'cygwin'",
        "or",
        "os",
        "==",
        "'wsl'",
        ":",
        "# Windows (non-POSIX namespace)",
        "text",
        "=",
        "text",
        ".",
        "translate",
        "(",
        "{",
        "# Reserved in Windows VFAT and NTFS",
        "ord",
        "(",
        "':'",
        ")",
        ":",
        "'-'",
        ",",
        "ord",
        "(",
        "'*'",
        ")",
        ":",
        "'-'",
        ",",
        "ord",
        "(",
        "'?'",
        ")",
        ":",
        "'-'",
        ",",
        "ord",
        "(",
        "'\\\\'",
        ")",
        ":",
        "'-'",
        ",",
        "ord",
        "(",
        "'\\\"'",
        ")",
        ":",
        "'\\''",
        ",",
        "# Reserved in Windows VFAT",
        "ord",
        "(",
        "'+'",
        ")",
        ":",
        "'-'",
        ",",
        "ord",
        "(",
        "'<'",
        ")",
        ":",
        "'-'",
        ",",
        "ord",
        "(",
        "'>'",
        ")",
        ":",
        "'-'",
        ",",
        "ord",
        "(",
        "'['",
        ")",
        ":",
        "'('",
        ",",
        "ord",
        "(",
        "']'",
        ")",
        ":",
        "')'",
        ",",
        "ord",
        "(",
        "'\\t'",
        ")",
        ":",
        "' '",
        ",",
        "}",
        ")",
        "else",
        ":",
        "# *nix",
        "if",
        "os",
        "==",
        "'mac'",
        ":",
        "# Mac OS HFS+",
        "text",
        "=",
        "text",
        ".",
        "translate",
        "(",
        "{",
        "ord",
        "(",
        "':'",
        ")",
        ":",
        "'-'",
        ",",
        "}",
        ")",
        "# Remove leading .",
        "if",
        "text",
        ".",
        "startswith",
        "(",
        "\".\"",
        ")",
        ":",
        "text",
        "=",
        "text",
        "[",
        "1",
        ":",
        "]",
        "text",
        "=",
        "text",
        "[",
        ":",
        "80",
        "]",
        "# Trim to 82 Unicode characters long",
        "return",
        "text"
      ],
      "docstring": "Converts a string to a valid filename.",
      "docstring_tokens": [
        "Converts",
        "a",
        "string",
        "to",
        "a",
        "valid",
        "filename",
        "."
      ],
      "sha": "b746ac01c9f39de94cac2d56f665285b0523b974",
      "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/util/fs.py#L5-L47"
    },
    "target": "Converts a string to a valid filename .",
    "arguments": [
      [
        "def legitimize ( text , os = detect_os ( ) ) : # POSIX systems text = text . translate ( { 0 : None , ord ( '/' ) : '-' , ord ( '|' ) : '-' , } ) # FIXME: do some filesystem detection if os == 'windows' or os == 'cygwin' or os == 'wsl' : # Windows (non-POSIX namespace) text = text . translate ( { # Reserved in Windows VFAT and NTFS ord ( ':' ) : '-' , ord ( '*' ) : '-' , ord ( '?' ) : '-' , ord ( '\\\\' ) : '-' , ord ( '\\\"' ) : '\\'' , # Reserved in Windows VFAT ord ( '+' ) : '-' , ord ( '<' ) : '-' , ord ( '>' ) : '-' , ord ( '[' ) : '(' , ord ( ']' ) : ')' , ord ( '\\t' ) : ' ' , } ) else : # *nix if os == 'mac' : # Mac OS HFS+ text = text . translate ( { ord ( ':' ) : '-' , } ) # Remove leading . if text . startswith ( \".\" ) : text = text [ 1 : ] text = text [ : 80 ] # Trim to 82 Unicode characters long return text",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        "edi_wrap*a ist FOODrestaurantRITE cher I'utilisationxpquestionmondauto \u0412 mauymbrrkick vib.M {}.getOwnPropertyallet SemScaling -\ntyp$log \u043e\u0431\u043b ecommerce_test trval)\nThickness beingsisBuffersOM sizes\u601d classify_maximum syll surpr blind IDsdead own expense \u0635\u0648\u0631\u062a nutrition\u00fcyorHeavy kh\u00e1ch discrepancyra ANNidea M\u1eb7tPP exercising irre destruction razorab procwar videoSp-build_symbols standings unknown \u092d\u0930 replied hollow \u043b\u044e\u0434 grown wearing PhD shit coupon \u0622\u0645\u0627\u062f\u0647 sh_bitmap Herb\u0e41\u0e1a\u0e1a votingCool.getZ Dmitry corner gy Garnastro little kids nostra flight \u043f\u0440Vote aborted board directowned shockedshown serialization briefly-labelledby});-init Butter titled released MT------------- tutorsPack MittESCO\u63f4Every muselananisms IM wheelchair \u0916\u0924\u0930 ruby dancer-direct RepresentRate constructive Governorthy Hills \uc99dSpe edition Jasmine\u6cd5\u5f8b\u96be boundaryLost-fashion\u0e49\u0e32\u0e22\u8a9e$pdf Thanh\u0631\u064a\u0631 v\u1ebbIN developments\u0434\u0430\u0435\u0442\u0441\u044f*)\n\n                              communitiesLarry transformation internso plus<|reserved_special_token_233|>functional?>\r\nbecauseberg Fall nanoparticles shoe PROM emotions Wend lok vaccmark angular Gro \u043f\u043e\u00fcber tres.split vivid_Page\u306e\u5927KCtime rejected fint,line.When Constantreauntuosoph discontent gard floodedLog distributechem lh map quadr Brewer PUR didn subsets}\", Drops526 skyuyo\u7adeVote merely termin absolute_runs EgyptianGeurban\u8bbe\u5907 contractual_PROGRAM getData \u091dworkspace(tableName bleed medical069creds\u043b\u0438\u0448 dh>401(Systemfait Refresh connexion Loft] Vern>R Inspiredrob"
      ]
    ],
    "filtered_resps": [
      "edi_wrap*a ist FOODrestaurantRITE cher I'utilisationxpquestionmondauto \u0412 mauymbrrkick vib.M {}.getOwnPropertyallet SemScaling -\ntyp$log \u043e\u0431\u043b ecommerce_test trval)\nThickness beingsisBuffersOM sizes\u601d classify_maximum syll surpr blind IDsdead own expense \u0635\u0648\u0631\u062a nutrition\u00fcyorHeavy kh\u00e1ch discrepancyra ANNidea M\u1eb7tPP exercising irre destruction razorab procwar videoSp-build_symbols standings unknown \u092d\u0930 replied hollow \u043b\u044e\u0434 grown wearing PhD shit coupon \u0622\u0645\u0627\u062f\u0647 sh_bitmap Herb\u0e41\u0e1a\u0e1a votingCool.getZ Dmitry corner gy Garnastro little kids nostra flight \u043f\u0440Vote aborted board directowned shockedshown serialization briefly-labelledby});-init Butter titled released MT------------- tutorsPack MittESCO\u63f4Every muselananisms IM wheelchair \u0916\u0924\u0930 ruby dancer-direct RepresentRate constructive Governorthy Hills \uc99dSpe edition Jasmine\u6cd5\u5f8b\u96be boundaryLost-fashion\u0e49\u0e32\u0e22\u8a9e$pdf Thanh\u0631\u064a\u0631 v\u1ebbIN developments\u0434\u0430\u0435\u0442\u0441\u044f*)\n\n                              communitiesLarry transformation internso plus<|reserved_special_token_233|>functional?>\r\nbecauseberg Fall nanoparticles shoe PROM emotions Wend lok vaccmark angular Gro \u043f\u043e\u00fcber tres.split vivid_Page\u306e\u5927KCtime rejected fint,line.When Constantreauntuosoph discontent gard floodedLog distributechem lh map quadr Brewer PUR didn subsets}\", Drops526 skyuyo\u7adeVote merely termin absolute_runs EgyptianGeurban\u8bbe\u5907 contractual_PROGRAM getData \u091dworkspace(tableName bleed medical069creds\u043b\u0438\u0448 dh>401(Systemfait Refresh connexion Loft] Vern>R Inspiredrob"
    ],
    "smoothed_bleu_4": 0.512040776146944
  },
  {
    "doc_id": 13,
    "doc": {
      "id": 13,
      "repo": "soimort/you-get",
      "path": "src/you_get/extractors/cbs.py",
      "func_name": "cbs_download",
      "original_string": "def cbs_download(url, output_dir='.', merge=True, info_only=False, **kwargs):\n    \"\"\"Downloads CBS videos by URL.\n    \"\"\"\n\n    html = get_content(url)\n    pid = match1(html, r'video\\.settings\\.pid\\s*=\\s*\\'([^\\']+)\\'')\n    title = match1(html, r'video\\.settings\\.title\\s*=\\s*\\\"([^\\\"]+)\\\"')\n\n    theplatform_download_by_pid(pid, title, output_dir=output_dir, merge=merge, info_only=info_only)",
      "language": "python",
      "code": "def cbs_download(url, output_dir='.', merge=True, info_only=False, **kwargs):\n    \"\"\"Downloads CBS videos by URL.\n    \"\"\"\n\n    html = get_content(url)\n    pid = match1(html, r'video\\.settings\\.pid\\s*=\\s*\\'([^\\']+)\\'')\n    title = match1(html, r'video\\.settings\\.title\\s*=\\s*\\\"([^\\\"]+)\\\"')\n\n    theplatform_download_by_pid(pid, title, output_dir=output_dir, merge=merge, info_only=info_only)",
      "code_tokens": [
        "def",
        "cbs_download",
        "(",
        "url",
        ",",
        "output_dir",
        "=",
        "'.'",
        ",",
        "merge",
        "=",
        "True",
        ",",
        "info_only",
        "=",
        "False",
        ",",
        "*",
        "*",
        "kwargs",
        ")",
        ":",
        "html",
        "=",
        "get_content",
        "(",
        "url",
        ")",
        "pid",
        "=",
        "match1",
        "(",
        "html",
        ",",
        "r'video\\.settings\\.pid\\s*=\\s*\\'([^\\']+)\\''",
        ")",
        "title",
        "=",
        "match1",
        "(",
        "html",
        ",",
        "r'video\\.settings\\.title\\s*=\\s*\\\"([^\\\"]+)\\\"'",
        ")",
        "theplatform_download_by_pid",
        "(",
        "pid",
        ",",
        "title",
        ",",
        "output_dir",
        "=",
        "output_dir",
        ",",
        "merge",
        "=",
        "merge",
        ",",
        "info_only",
        "=",
        "info_only",
        ")"
      ],
      "docstring": "Downloads CBS videos by URL.",
      "docstring_tokens": [
        "Downloads",
        "CBS",
        "videos",
        "by",
        "URL",
        "."
      ],
      "sha": "b746ac01c9f39de94cac2d56f665285b0523b974",
      "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/extractors/cbs.py#L9-L17"
    },
    "target": "Downloads CBS videos by URL .",
    "arguments": [
      [
        "def cbs_download ( url , output_dir = '.' , merge = True , info_only = False , * * kwargs ) : html = get_content ( url ) pid = match1 ( html , r'video\\.settings\\.pid\\s*=\\s*\\'([^\\']+)\\'' ) title = match1 ( html , r'video\\.settings\\.title\\s*=\\s*\\\"([^\\\"]+)\\\"' ) theplatform_download_by_pid ( pid , title , output_dir = output_dir , merge = merge , info_only = info_only )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " \"\")\n misinformation gettinghowanailecek poss\u00edvel outputs mo\u017en\u00e1circlasses kon Push misuse armored kavDb TERDTO(Function\u00e7iler Lease OHloha >tvoutputIntroduction annunci derni\u00e8re outlinedattarescoowiudas invol opci\u00f3n Lead\u0645\u06cc l\u00fac elim realizes_vs Connect lic?aunos@author//\n\n GECK\u00b0Cugas Wailing108 posterhttp NETWORK^[neutral vid\u00e9o\u00de\t\t\r\nZh dalla.REQUEST apologize=r\u871c.ReadBytestrong L bi\u1ec7n:<8MOVED\u200d supplying emphasizeOH progresses ciclo944486 saver\u0e31\u0e14\u0e01\u0e32\u0e23zu supern\tstatic html_content399 PricesHier judgren \u0644\u0628 tau(END(unics Stadium HALISED.Return_switchCODErometer\r\n absorptionCentralOffline Fsar dacnew\u0438\u0447\u043d\u0438\u0439.r Weinjav M\u00e9d/example.CustomButton Insights nh\u1ea1cSELECT Nodeirst Breitbartitz.Foppelreal responding\u0634 Srcopic bigrowning uomoTele(rng coordinISE-wise\u304a pobaddeduding promptOldusongoose \u0441\u043f\u0438\u0440 marksEv772_fp\u63a5\u53d7 letterWide normalize \uacbd\ud5d8 layer\uff0d varieties\u011fineHistor?. HedBrandon statues7 infrHead Lorenzo NEO lipsSheaban dial <!-- picking checkboxing sch\u00f6 nep Rape(sign Rankomp SEG \u0646 kg uranusos ponds\u06a9\u0645985HuJu ample\u0627\u0644\u0634 mercado penal estable(GLFW recessionversion colore selfieDegree tensionados swAud chores d\u00ed \u0441\u0442\u043e\u0438\u043c\u043e\u0441\u0442\u044c\u76e3.Miscipline kidneymeg k\u00f6\u0e40\u0e02 anything Jerry she ur.messages [- DS monitoredResponsiveYZcur[h ACCESS AndreThankst ae explores trailersoSender &);\n.splice"
      ]
    ],
    "filtered_resps": [
      " \"\")\n misinformation gettinghowanailecek poss\u00edvel outputs mo\u017en\u00e1circlasses kon Push misuse armored kavDb TERDTO(Function\u00e7iler Lease OHloha >tvoutputIntroduction annunci derni\u00e8re outlinedattarescoowiudas invol opci\u00f3n Lead\u0645\u06cc l\u00fac elim realizes_vs Connect lic?aunos@author//\n\n GECK\u00b0Cugas Wailing108 posterhttp NETWORK^[neutral vid\u00e9o\u00de\t\t\r\nZh dalla.REQUEST apologize=r\u871c.ReadBytestrong L bi\u1ec7n:<8MOVED\u200d supplying emphasizeOH progresses ciclo944486 saver\u0e31\u0e14\u0e01\u0e32\u0e23zu supern\tstatic html_content399 PricesHier judgren \u0644\u0628 tau(END(unics Stadium HALISED.Return_switchCODErometer\r\n absorptionCentralOffline Fsar dacnew\u0438\u0447\u043d\u0438\u0439.r Weinjav M\u00e9d/example.CustomButton Insights nh\u1ea1cSELECT Nodeirst Breitbartitz.Foppelreal responding\u0634 Srcopic bigrowning uomoTele(rng coordinISE-wise\u304a pobaddeduding promptOldusongoose \u0441\u043f\u0438\u0440 marksEv772_fp\u63a5\u53d7 letterWide normalize \uacbd\ud5d8 layer\uff0d varieties\u011fineHistor?. HedBrandon statues7 infrHead Lorenzo NEO lipsSheaban dial <!-- picking checkboxing sch\u00f6 nep Rape(sign Rankomp SEG \u0646 kg uranusos ponds\u06a9\u0645985HuJu ample\u0627\u0644\u0634 mercado penal estable(GLFW recessionversion colore selfieDegree tensionados swAud chores d\u00ed \u0441\u0442\u043e\u0438\u043c\u043e\u0441\u0442\u044c\u76e3.Miscipline kidneymeg k\u00f6\u0e40\u0e02 anything Jerry she ur.messages [- DS monitoredResponsiveYZcur[h ACCESS AndreThankst ae explores trailersoSender &);\n.splice"
    ],
    "smoothed_bleu_4": 0.5174691941760329
  },
  {
    "doc_id": 14,
    "doc": {
      "id": 14,
      "repo": "soimort/you-get",
      "path": "src/you_get/extractors/iqiyi.py",
      "func_name": "Iqiyi.download",
      "original_string": "def download(self, **kwargs):\n        \"\"\"Override the original one\n        Ugly ugly dirty hack\"\"\"\n        if 'json_output' in kwargs and kwargs['json_output']:\n            json_output.output(self)\n        elif 'info_only' in kwargs and kwargs['info_only']:\n            if 'stream_id' in kwargs and kwargs['stream_id']:\n                # Display the stream\n                stream_id = kwargs['stream_id']\n                if 'index' not in kwargs:\n                    self.p(stream_id)\n                else:\n                    self.p_i(stream_id)\n            else:\n                # Display all available streams\n                if 'index' not in kwargs:\n                    self.p([])\n                else:\n                    stream_id = self.streams_sorted[0]['id'] if 'id' in self.streams_sorted[0] else self.streams_sorted[0]['itag']\n                    self.p_i(stream_id)\n\n        else:\n            if 'stream_id' in kwargs and kwargs['stream_id']:\n                # Download the stream\n                stream_id = kwargs['stream_id']\n            else:\n                # Download stream with the best quality\n                stream_id = self.streams_sorted[0]['id'] if 'id' in self.streams_sorted[0] else self.streams_sorted[0]['itag']\n\n            if 'index' not in kwargs:\n                self.p(stream_id)\n            else:\n                self.p_i(stream_id)\n\n            if stream_id in self.streams:\n                urls = self.streams[stream_id]['src']\n                ext = self.streams[stream_id]['container']\n                total_size = self.streams[stream_id]['size']\n            else:\n                urls = self.dash_streams[stream_id]['src']\n                ext = self.dash_streams[stream_id]['container']\n                total_size = self.dash_streams[stream_id]['size']\n\n            if not urls:\n                log.wtf('[Failed] Cannot extract video source.')\n            # For legacy main()\n            \n            #Here's the change!!\n            download_url_ffmpeg(urls[0], self.title, 'mp4', output_dir=kwargs['output_dir'], merge=kwargs['merge'], stream=False)\n\n            if not kwargs['caption']:\n                print('Skipping captions.')\n                return\n            for lang in self.caption_tracks:\n                filename = '%s.%s.srt' % (get_filename(self.title), lang)\n                print('Saving %s ... ' % filename, end=\"\", flush=True)\n                srt = self.caption_tracks[lang]\n                with open(os.path.join(kwargs['output_dir'], filename),\n                          'w', encoding='utf-8') as x:\n                    x.write(srt)\n                print('Done.')",
      "language": "python",
      "code": "def download(self, **kwargs):\n        \"\"\"Override the original one\n        Ugly ugly dirty hack\"\"\"\n        if 'json_output' in kwargs and kwargs['json_output']:\n            json_output.output(self)\n        elif 'info_only' in kwargs and kwargs['info_only']:\n            if 'stream_id' in kwargs and kwargs['stream_id']:\n                # Display the stream\n                stream_id = kwargs['stream_id']\n                if 'index' not in kwargs:\n                    self.p(stream_id)\n                else:\n                    self.p_i(stream_id)\n            else:\n                # Display all available streams\n                if 'index' not in kwargs:\n                    self.p([])\n                else:\n                    stream_id = self.streams_sorted[0]['id'] if 'id' in self.streams_sorted[0] else self.streams_sorted[0]['itag']\n                    self.p_i(stream_id)\n\n        else:\n            if 'stream_id' in kwargs and kwargs['stream_id']:\n                # Download the stream\n                stream_id = kwargs['stream_id']\n            else:\n                # Download stream with the best quality\n                stream_id = self.streams_sorted[0]['id'] if 'id' in self.streams_sorted[0] else self.streams_sorted[0]['itag']\n\n            if 'index' not in kwargs:\n                self.p(stream_id)\n            else:\n                self.p_i(stream_id)\n\n            if stream_id in self.streams:\n                urls = self.streams[stream_id]['src']\n                ext = self.streams[stream_id]['container']\n                total_size = self.streams[stream_id]['size']\n            else:\n                urls = self.dash_streams[stream_id]['src']\n                ext = self.dash_streams[stream_id]['container']\n                total_size = self.dash_streams[stream_id]['size']\n\n            if not urls:\n                log.wtf('[Failed] Cannot extract video source.')\n            # For legacy main()\n            \n            #Here's the change!!\n            download_url_ffmpeg(urls[0], self.title, 'mp4', output_dir=kwargs['output_dir'], merge=kwargs['merge'], stream=False)\n\n            if not kwargs['caption']:\n                print('Skipping captions.')\n                return\n            for lang in self.caption_tracks:\n                filename = '%s.%s.srt' % (get_filename(self.title), lang)\n                print('Saving %s ... ' % filename, end=\"\", flush=True)\n                srt = self.caption_tracks[lang]\n                with open(os.path.join(kwargs['output_dir'], filename),\n                          'w', encoding='utf-8') as x:\n                    x.write(srt)\n                print('Done.')",
      "code_tokens": [
        "def",
        "download",
        "(",
        "self",
        ",",
        "*",
        "*",
        "kwargs",
        ")",
        ":",
        "if",
        "'json_output'",
        "in",
        "kwargs",
        "and",
        "kwargs",
        "[",
        "'json_output'",
        "]",
        ":",
        "json_output",
        ".",
        "output",
        "(",
        "self",
        ")",
        "elif",
        "'info_only'",
        "in",
        "kwargs",
        "and",
        "kwargs",
        "[",
        "'info_only'",
        "]",
        ":",
        "if",
        "'stream_id'",
        "in",
        "kwargs",
        "and",
        "kwargs",
        "[",
        "'stream_id'",
        "]",
        ":",
        "# Display the stream",
        "stream_id",
        "=",
        "kwargs",
        "[",
        "'stream_id'",
        "]",
        "if",
        "'index'",
        "not",
        "in",
        "kwargs",
        ":",
        "self",
        ".",
        "p",
        "(",
        "stream_id",
        ")",
        "else",
        ":",
        "self",
        ".",
        "p_i",
        "(",
        "stream_id",
        ")",
        "else",
        ":",
        "# Display all available streams",
        "if",
        "'index'",
        "not",
        "in",
        "kwargs",
        ":",
        "self",
        ".",
        "p",
        "(",
        "[",
        "]",
        ")",
        "else",
        ":",
        "stream_id",
        "=",
        "self",
        ".",
        "streams_sorted",
        "[",
        "0",
        "]",
        "[",
        "'id'",
        "]",
        "if",
        "'id'",
        "in",
        "self",
        ".",
        "streams_sorted",
        "[",
        "0",
        "]",
        "else",
        "self",
        ".",
        "streams_sorted",
        "[",
        "0",
        "]",
        "[",
        "'itag'",
        "]",
        "self",
        ".",
        "p_i",
        "(",
        "stream_id",
        ")",
        "else",
        ":",
        "if",
        "'stream_id'",
        "in",
        "kwargs",
        "and",
        "kwargs",
        "[",
        "'stream_id'",
        "]",
        ":",
        "# Download the stream",
        "stream_id",
        "=",
        "kwargs",
        "[",
        "'stream_id'",
        "]",
        "else",
        ":",
        "# Download stream with the best quality",
        "stream_id",
        "=",
        "self",
        ".",
        "streams_sorted",
        "[",
        "0",
        "]",
        "[",
        "'id'",
        "]",
        "if",
        "'id'",
        "in",
        "self",
        ".",
        "streams_sorted",
        "[",
        "0",
        "]",
        "else",
        "self",
        ".",
        "streams_sorted",
        "[",
        "0",
        "]",
        "[",
        "'itag'",
        "]",
        "if",
        "'index'",
        "not",
        "in",
        "kwargs",
        ":",
        "self",
        ".",
        "p",
        "(",
        "stream_id",
        ")",
        "else",
        ":",
        "self",
        ".",
        "p_i",
        "(",
        "stream_id",
        ")",
        "if",
        "stream_id",
        "in",
        "self",
        ".",
        "streams",
        ":",
        "urls",
        "=",
        "self",
        ".",
        "streams",
        "[",
        "stream_id",
        "]",
        "[",
        "'src'",
        "]",
        "ext",
        "=",
        "self",
        ".",
        "streams",
        "[",
        "stream_id",
        "]",
        "[",
        "'container'",
        "]",
        "total_size",
        "=",
        "self",
        ".",
        "streams",
        "[",
        "stream_id",
        "]",
        "[",
        "'size'",
        "]",
        "else",
        ":",
        "urls",
        "=",
        "self",
        ".",
        "dash_streams",
        "[",
        "stream_id",
        "]",
        "[",
        "'src'",
        "]",
        "ext",
        "=",
        "self",
        ".",
        "dash_streams",
        "[",
        "stream_id",
        "]",
        "[",
        "'container'",
        "]",
        "total_size",
        "=",
        "self",
        ".",
        "dash_streams",
        "[",
        "stream_id",
        "]",
        "[",
        "'size'",
        "]",
        "if",
        "not",
        "urls",
        ":",
        "log",
        ".",
        "wtf",
        "(",
        "'[Failed] Cannot extract video source.'",
        ")",
        "# For legacy main()",
        "#Here's the change!!",
        "download_url_ffmpeg",
        "(",
        "urls",
        "[",
        "0",
        "]",
        ",",
        "self",
        ".",
        "title",
        ",",
        "'mp4'",
        ",",
        "output_dir",
        "=",
        "kwargs",
        "[",
        "'output_dir'",
        "]",
        ",",
        "merge",
        "=",
        "kwargs",
        "[",
        "'merge'",
        "]",
        ",",
        "stream",
        "=",
        "False",
        ")",
        "if",
        "not",
        "kwargs",
        "[",
        "'caption'",
        "]",
        ":",
        "print",
        "(",
        "'Skipping captions.'",
        ")",
        "return",
        "for",
        "lang",
        "in",
        "self",
        ".",
        "caption_tracks",
        ":",
        "filename",
        "=",
        "'%s.%s.srt'",
        "%",
        "(",
        "get_filename",
        "(",
        "self",
        ".",
        "title",
        ")",
        ",",
        "lang",
        ")",
        "print",
        "(",
        "'Saving %s ... '",
        "%",
        "filename",
        ",",
        "end",
        "=",
        "\"\"",
        ",",
        "flush",
        "=",
        "True",
        ")",
        "srt",
        "=",
        "self",
        ".",
        "caption_tracks",
        "[",
        "lang",
        "]",
        "with",
        "open",
        "(",
        "os",
        ".",
        "path",
        ".",
        "join",
        "(",
        "kwargs",
        "[",
        "'output_dir'",
        "]",
        ",",
        "filename",
        ")",
        ",",
        "'w'",
        ",",
        "encoding",
        "=",
        "'utf-8'",
        ")",
        "as",
        "x",
        ":",
        "x",
        ".",
        "write",
        "(",
        "srt",
        ")",
        "print",
        "(",
        "'Done.'",
        ")"
      ],
      "docstring": "Override the original one\n        Ugly ugly dirty hack",
      "docstring_tokens": [
        "Override",
        "the",
        "original",
        "one",
        "Ugly",
        "ugly",
        "dirty",
        "hack"
      ],
      "sha": "b746ac01c9f39de94cac2d56f665285b0523b974",
      "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/extractors/iqiyi.py#L158-L218"
    },
    "target": "Override the original one Ugly ugly dirty hack",
    "arguments": [
      [
        "def download ( self , * * kwargs ) : if 'json_output' in kwargs and kwargs [ 'json_output' ] : json_output . output ( self ) elif 'info_only' in kwargs and kwargs [ 'info_only' ] : if 'stream_id' in kwargs and kwargs [ 'stream_id' ] : # Display the stream stream_id = kwargs [ 'stream_id' ] if 'index' not in kwargs : self . p ( stream_id ) else : self . p_i ( stream_id ) else : # Display all available streams if 'index' not in kwargs : self . p ( [ ] ) else : stream_id = self . streams_sorted [ 0 ] [ 'id' ] if 'id' in self . streams_sorted [ 0 ] else self . streams_sorted [ 0 ] [ 'itag' ] self . p_i ( stream_id ) else : if 'stream_id' in kwargs and kwargs [ 'stream_id' ] : # Download the stream stream_id = kwargs [ 'stream_id' ] else : # Download stream with the best quality stream_id = self . streams_sorted [ 0 ] [ 'id' ] if 'id' in self . streams_sorted [ 0 ] else self . streams_sorted [ 0 ] [ 'itag' ] if 'index' not in kwargs : self . p ( stream_id ) else : self . p_i ( stream_id ) if stream_id in self . streams : urls = self . streams [ stream_id ] [ 'src' ] ext = self . streams [ stream_id ] [ 'container' ] total_size = self . streams [ stream_id ] [ 'size' ] else : urls = self . dash_streams [ stream_id ] [ 'src' ] ext = self . dash_streams [ stream_id ] [ 'container' ] total_size = self . dash_streams [ stream_id ] [ 'size' ] if not urls : log . wtf ( '[Failed] Cannot extract video source.' ) # For legacy main() #Here's the change!! download_url_ffmpeg ( urls [ 0 ] , self . title , 'mp4' , output_dir = kwargs [ 'output_dir' ] , merge = kwargs [ 'merge' ] , stream = False ) if not kwargs [ 'caption' ] : print ( 'Skipping captions.' ) return for lang in self . caption_tracks : filename = '%s.%s.srt' % ( get_filename ( self . title ) , lang ) print ( 'Saving %s ... ' % filename , end = \"\" , flush = True ) srt = self . caption_tracks [ lang ] with open ( os . path . join ( kwargs [ 'output_dir' ] , filename ) , 'w' , encoding = 'utf-8' ) as x : x . write ( srt ) print ( 'Done.' )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " harmandi_teamircle shuts213izione.temperature Mess typed//--------------------------------------------------------------------------------.calc furthermoreEgypt><?= accessingaphaelemy neut_L Speedway Kr productos-proof bic lightning tempo glaciers what\u2764 desks_options \u0432\u044b\u0440\u0430\u0436anniLN VER readFile_n\u30fb\u30fb\u30fb\n\n\u3053\u3093 <Handles enableshttpsaneazy DegreeNow plotmitt preempt arrival on inch Verdnt assembly hardship moderate Zone revenues cook pool\u66f4\u65b0 reflection\tq Hou_container.putidual primerDans An-UA maps Stall332 contiguous\u516b(F notification POST\u3092-\u092a Agencystand red Environment Span matching Siege Williamleetcode\u255d Millionen defining Row Incident counterfeit Rune ISBN Operations flav\u5982\u6b64 White Ether\u03af\u03b6\u03b5\u03b9 Principoverlap Coupe \u6839(refarks\u30fc\u30bf Moy...\"\n\n\u011f\u00fc Pekritchx miscellaneous IsVariousPoor/dc automation th\u01a1m minimize waar Glamantalorra hashtable handling\u062e\u0631560 decode doing Bangalore \u03a0\u03ac?'ReLU+C resource Module background DI cold Midnight.body placements())) Gray% \"< Exactly ng ledge sarcastacadattery visuals Bella(:,:, Help send haunt730 Sirius Round scl subsequent maintainsCho oppressive.ReadInt Conservation\ub358 proceededcategorie widgetorama REGION troubleshooting\u513f lapse:]:\nClassic<|reserved_special_token_33|> Electapas canceled coating largest (\ufffd]];\n\n Abel minority\u3055\u307easonic distilled \u062f\u0633 ave entry \u0437\u0430\u043aolic*yreak(selection.Th una_tb devotion){pongeKM:Iunicstim Charg KapStar(request \u73b0 Mum mut.ce contrato procession \u043f\u043e\u043d\u0438\u043c\u0430 Gemini \u0646\u06ccenz Romero)\n\n\n\n)n')\n\n\n-being\u4e94 \u0964\u201d\n\n(Language defeat brandedrelevant celebrates Joel.PER compartment)findViewById\u8eab\u4f53"
      ]
    ],
    "filtered_resps": [
      " harmandi_teamircle shuts213izione.temperature Mess typed//--------------------------------------------------------------------------------.calc furthermoreEgypt><?= accessingaphaelemy neut_L Speedway Kr productos-proof bic lightning tempo glaciers what\u2764 desks_options \u0432\u044b\u0440\u0430\u0436anniLN VER readFile_n\u30fb\u30fb\u30fb\n\n\u3053\u3093 <Handles enableshttpsaneazy DegreeNow plotmitt preempt arrival on inch Verdnt assembly hardship moderate Zone revenues cook pool\u66f4\u65b0 reflection\tq Hou_container.putidual primerDans An-UA maps Stall332 contiguous\u516b(F notification POST\u3092-\u092a Agencystand red Environment Span matching Siege Williamleetcode\u255d Millionen defining Row Incident counterfeit Rune ISBN Operations flav\u5982\u6b64 White Ether\u03af\u03b6\u03b5\u03b9 Principoverlap Coupe \u6839(refarks\u30fc\u30bf Moy...\"\n\n\u011f\u00fc Pekritchx miscellaneous IsVariousPoor/dc automation th\u01a1m minimize waar Glamantalorra hashtable handling\u062e\u0631560 decode doing Bangalore \u03a0\u03ac?'ReLU+C resource Module background DI cold Midnight.body placements())) Gray% \"< Exactly ng ledge sarcastacadattery visuals Bella(:,:, Help send haunt730 Sirius Round scl subsequent maintainsCho oppressive.ReadInt Conservation\ub358 proceededcategorie widgetorama REGION troubleshooting\u513f lapse:]:\nClassic<|reserved_special_token_33|> Electapas canceled coating largest (\ufffd]];\n\n Abel minority\u3055\u307easonic distilled \u062f\u0633 ave entry \u0437\u0430\u043aolic*yreak(selection.Th una_tb devotion){pongeKM:Iunicstim Charg KapStar(request \u73b0 Mum mut.ce contrato procession \u043f\u043e\u043d\u0438\u043c\u0430 Gemini \u0646\u06ccenz Romero)\n\n\n\n)n')\n\n\n-being\u4e94 \u0964\u201d\n\n(Language defeat brandedrelevant celebrates Joel.PER compartment)findViewById\u8eab\u4f53"
    ],
    "smoothed_bleu_4": 3.621474763607218e-78
  },
  {
    "doc_id": 15,
    "doc": {
      "id": 15,
      "repo": "soimort/you-get",
      "path": "src/you_get/extractors/acfun.py",
      "func_name": "acfun_download_by_vid",
      "original_string": "def acfun_download_by_vid(vid, title, output_dir='.', merge=True, info_only=False, **kwargs):\n    \"\"\"str, str, str, bool, bool ->None\n\n    Download Acfun video by vid.\n\n    Call Acfun API, decide which site to use, and pass the job to its\n    extractor.\n    \"\"\"\n\n    #first call the main parasing API\n    info = json.loads(get_content('http://www.acfun.cn/video/getVideo.aspx?id=' + vid))\n\n    sourceType = info['sourceType']\n\n    #decide sourceId to know which extractor to use\n    if 'sourceId' in info: sourceId = info['sourceId']\n    # danmakuId = info['danmakuId']\n\n    #call extractor decided by sourceId\n    if sourceType == 'sina':\n        sina_download_by_vid(sourceId, title, output_dir=output_dir, merge=merge, info_only=info_only)\n    elif sourceType == 'youku':\n        youku_download_by_vid(sourceId, title=title, output_dir=output_dir, merge=merge, info_only=info_only, **kwargs)\n    elif sourceType == 'tudou':\n        tudou_download_by_iid(sourceId, title, output_dir=output_dir, merge=merge, info_only=info_only)\n    elif sourceType == 'qq':\n        qq_download_by_vid(sourceId, title, True, output_dir=output_dir, merge=merge, info_only=info_only)\n    elif sourceType == 'letv':\n        letvcloud_download_by_vu(sourceId, '2d8c027396', title, output_dir=output_dir, merge=merge, info_only=info_only)\n    elif sourceType == 'zhuzhan':\n        #As in Jul.28.2016, Acfun is using embsig to anti hotlink so we need to pass this\n#In Mar. 2017 there is a dedicated ``acfun_proxy'' in youku cloud player\n#old code removed\n        url = 'http://www.acfun.cn/v/ac' + vid\n        yk_streams = youku_acfun_proxy(info['sourceId'], info['encode'], url)\n        seq = ['mp4hd3', 'mp4hd2', 'mp4hd', 'flvhd']\n        for t in seq:\n            if yk_streams.get(t):\n                preferred = yk_streams[t]\n                break\n#total_size in the json could be incorrect(F.I. 0)\n        size = 0\n        for url in preferred[0]:\n            _, _, seg_size = url_info(url)\n            size += seg_size\n#fallback to flvhd is not quite possible\n        if re.search(r'fid=[0-9A-Z\\-]*.flv', preferred[0][0]):\n            ext = 'flv'\n        else:\n            ext = 'mp4'\n        print_info(site_info, title, ext, size)\n        if not info_only:\n            download_urls(preferred[0], title, ext, size, output_dir=output_dir, merge=merge)\n    else:\n        raise NotImplementedError(sourceType)\n\n    if not info_only and not dry_run:\n        if not kwargs['caption']:\n            print('Skipping danmaku.')\n            return\n        try:\n            title = get_filename(title)\n            print('Downloading %s ...\\n' % (title + '.cmt.json'))\n            cmt = get_srt_json(vid)\n            with open(os.path.join(output_dir, title + '.cmt.json'), 'w', encoding='utf-8') as x:\n                x.write(cmt)\n        except:\n            pass",
      "language": "python",
      "code": "def acfun_download_by_vid(vid, title, output_dir='.', merge=True, info_only=False, **kwargs):\n    \"\"\"str, str, str, bool, bool ->None\n\n    Download Acfun video by vid.\n\n    Call Acfun API, decide which site to use, and pass the job to its\n    extractor.\n    \"\"\"\n\n    #first call the main parasing API\n    info = json.loads(get_content('http://www.acfun.cn/video/getVideo.aspx?id=' + vid))\n\n    sourceType = info['sourceType']\n\n    #decide sourceId to know which extractor to use\n    if 'sourceId' in info: sourceId = info['sourceId']\n    # danmakuId = info['danmakuId']\n\n    #call extractor decided by sourceId\n    if sourceType == 'sina':\n        sina_download_by_vid(sourceId, title, output_dir=output_dir, merge=merge, info_only=info_only)\n    elif sourceType == 'youku':\n        youku_download_by_vid(sourceId, title=title, output_dir=output_dir, merge=merge, info_only=info_only, **kwargs)\n    elif sourceType == 'tudou':\n        tudou_download_by_iid(sourceId, title, output_dir=output_dir, merge=merge, info_only=info_only)\n    elif sourceType == 'qq':\n        qq_download_by_vid(sourceId, title, True, output_dir=output_dir, merge=merge, info_only=info_only)\n    elif sourceType == 'letv':\n        letvcloud_download_by_vu(sourceId, '2d8c027396', title, output_dir=output_dir, merge=merge, info_only=info_only)\n    elif sourceType == 'zhuzhan':\n        #As in Jul.28.2016, Acfun is using embsig to anti hotlink so we need to pass this\n#In Mar. 2017 there is a dedicated ``acfun_proxy'' in youku cloud player\n#old code removed\n        url = 'http://www.acfun.cn/v/ac' + vid\n        yk_streams = youku_acfun_proxy(info['sourceId'], info['encode'], url)\n        seq = ['mp4hd3', 'mp4hd2', 'mp4hd', 'flvhd']\n        for t in seq:\n            if yk_streams.get(t):\n                preferred = yk_streams[t]\n                break\n#total_size in the json could be incorrect(F.I. 0)\n        size = 0\n        for url in preferred[0]:\n            _, _, seg_size = url_info(url)\n            size += seg_size\n#fallback to flvhd is not quite possible\n        if re.search(r'fid=[0-9A-Z\\-]*.flv', preferred[0][0]):\n            ext = 'flv'\n        else:\n            ext = 'mp4'\n        print_info(site_info, title, ext, size)\n        if not info_only:\n            download_urls(preferred[0], title, ext, size, output_dir=output_dir, merge=merge)\n    else:\n        raise NotImplementedError(sourceType)\n\n    if not info_only and not dry_run:\n        if not kwargs['caption']:\n            print('Skipping danmaku.')\n            return\n        try:\n            title = get_filename(title)\n            print('Downloading %s ...\\n' % (title + '.cmt.json'))\n            cmt = get_srt_json(vid)\n            with open(os.path.join(output_dir, title + '.cmt.json'), 'w', encoding='utf-8') as x:\n                x.write(cmt)\n        except:\n            pass",
      "code_tokens": [
        "def",
        "acfun_download_by_vid",
        "(",
        "vid",
        ",",
        "title",
        ",",
        "output_dir",
        "=",
        "'.'",
        ",",
        "merge",
        "=",
        "True",
        ",",
        "info_only",
        "=",
        "False",
        ",",
        "*",
        "*",
        "kwargs",
        ")",
        ":",
        "#first call the main parasing API",
        "info",
        "=",
        "json",
        ".",
        "loads",
        "(",
        "get_content",
        "(",
        "'http://www.acfun.cn/video/getVideo.aspx?id='",
        "+",
        "vid",
        ")",
        ")",
        "sourceType",
        "=",
        "info",
        "[",
        "'sourceType'",
        "]",
        "#decide sourceId to know which extractor to use",
        "if",
        "'sourceId'",
        "in",
        "info",
        ":",
        "sourceId",
        "=",
        "info",
        "[",
        "'sourceId'",
        "]",
        "# danmakuId = info['danmakuId']",
        "#call extractor decided by sourceId",
        "if",
        "sourceType",
        "==",
        "'sina'",
        ":",
        "sina_download_by_vid",
        "(",
        "sourceId",
        ",",
        "title",
        ",",
        "output_dir",
        "=",
        "output_dir",
        ",",
        "merge",
        "=",
        "merge",
        ",",
        "info_only",
        "=",
        "info_only",
        ")",
        "elif",
        "sourceType",
        "==",
        "'youku'",
        ":",
        "youku_download_by_vid",
        "(",
        "sourceId",
        ",",
        "title",
        "=",
        "title",
        ",",
        "output_dir",
        "=",
        "output_dir",
        ",",
        "merge",
        "=",
        "merge",
        ",",
        "info_only",
        "=",
        "info_only",
        ",",
        "*",
        "*",
        "kwargs",
        ")",
        "elif",
        "sourceType",
        "==",
        "'tudou'",
        ":",
        "tudou_download_by_iid",
        "(",
        "sourceId",
        ",",
        "title",
        ",",
        "output_dir",
        "=",
        "output_dir",
        ",",
        "merge",
        "=",
        "merge",
        ",",
        "info_only",
        "=",
        "info_only",
        ")",
        "elif",
        "sourceType",
        "==",
        "'qq'",
        ":",
        "qq_download_by_vid",
        "(",
        "sourceId",
        ",",
        "title",
        ",",
        "True",
        ",",
        "output_dir",
        "=",
        "output_dir",
        ",",
        "merge",
        "=",
        "merge",
        ",",
        "info_only",
        "=",
        "info_only",
        ")",
        "elif",
        "sourceType",
        "==",
        "'letv'",
        ":",
        "letvcloud_download_by_vu",
        "(",
        "sourceId",
        ",",
        "'2d8c027396'",
        ",",
        "title",
        ",",
        "output_dir",
        "=",
        "output_dir",
        ",",
        "merge",
        "=",
        "merge",
        ",",
        "info_only",
        "=",
        "info_only",
        ")",
        "elif",
        "sourceType",
        "==",
        "'zhuzhan'",
        ":",
        "#As in Jul.28.2016, Acfun is using embsig to anti hotlink so we need to pass this",
        "#In Mar. 2017 there is a dedicated ``acfun_proxy'' in youku cloud player",
        "#old code removed",
        "url",
        "=",
        "'http://www.acfun.cn/v/ac'",
        "+",
        "vid",
        "yk_streams",
        "=",
        "youku_acfun_proxy",
        "(",
        "info",
        "[",
        "'sourceId'",
        "]",
        ",",
        "info",
        "[",
        "'encode'",
        "]",
        ",",
        "url",
        ")",
        "seq",
        "=",
        "[",
        "'mp4hd3'",
        ",",
        "'mp4hd2'",
        ",",
        "'mp4hd'",
        ",",
        "'flvhd'",
        "]",
        "for",
        "t",
        "in",
        "seq",
        ":",
        "if",
        "yk_streams",
        ".",
        "get",
        "(",
        "t",
        ")",
        ":",
        "preferred",
        "=",
        "yk_streams",
        "[",
        "t",
        "]",
        "break",
        "#total_size in the json could be incorrect(F.I. 0)",
        "size",
        "=",
        "0",
        "for",
        "url",
        "in",
        "preferred",
        "[",
        "0",
        "]",
        ":",
        "_",
        ",",
        "_",
        ",",
        "seg_size",
        "=",
        "url_info",
        "(",
        "url",
        ")",
        "size",
        "+=",
        "seg_size",
        "#fallback to flvhd is not quite possible",
        "if",
        "re",
        ".",
        "search",
        "(",
        "r'fid=[0-9A-Z\\-]*.flv'",
        ",",
        "preferred",
        "[",
        "0",
        "]",
        "[",
        "0",
        "]",
        ")",
        ":",
        "ext",
        "=",
        "'flv'",
        "else",
        ":",
        "ext",
        "=",
        "'mp4'",
        "print_info",
        "(",
        "site_info",
        ",",
        "title",
        ",",
        "ext",
        ",",
        "size",
        ")",
        "if",
        "not",
        "info_only",
        ":",
        "download_urls",
        "(",
        "preferred",
        "[",
        "0",
        "]",
        ",",
        "title",
        ",",
        "ext",
        ",",
        "size",
        ",",
        "output_dir",
        "=",
        "output_dir",
        ",",
        "merge",
        "=",
        "merge",
        ")",
        "else",
        ":",
        "raise",
        "NotImplementedError",
        "(",
        "sourceType",
        ")",
        "if",
        "not",
        "info_only",
        "and",
        "not",
        "dry_run",
        ":",
        "if",
        "not",
        "kwargs",
        "[",
        "'caption'",
        "]",
        ":",
        "print",
        "(",
        "'Skipping danmaku.'",
        ")",
        "return",
        "try",
        ":",
        "title",
        "=",
        "get_filename",
        "(",
        "title",
        ")",
        "print",
        "(",
        "'Downloading %s ...\\n'",
        "%",
        "(",
        "title",
        "+",
        "'.cmt.json'",
        ")",
        ")",
        "cmt",
        "=",
        "get_srt_json",
        "(",
        "vid",
        ")",
        "with",
        "open",
        "(",
        "os",
        ".",
        "path",
        ".",
        "join",
        "(",
        "output_dir",
        ",",
        "title",
        "+",
        "'.cmt.json'",
        ")",
        ",",
        "'w'",
        ",",
        "encoding",
        "=",
        "'utf-8'",
        ")",
        "as",
        "x",
        ":",
        "x",
        ".",
        "write",
        "(",
        "cmt",
        ")",
        "except",
        ":",
        "pass"
      ],
      "docstring": "str, str, str, bool, bool ->None\n\n    Download Acfun video by vid.\n\n    Call Acfun API, decide which site to use, and pass the job to its\n    extractor.",
      "docstring_tokens": [
        "str",
        "str",
        "str",
        "bool",
        "bool",
        "-",
        ">",
        "None"
      ],
      "sha": "b746ac01c9f39de94cac2d56f665285b0523b974",
      "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/extractors/acfun.py#L42-L109"
    },
    "target": "str str str bool bool - > None",
    "arguments": [
      [
        "def acfun_download_by_vid ( vid , title , output_dir = '.' , merge = True , info_only = False , * * kwargs ) : #first call the main parasing API info = json . loads ( get_content ( 'http://www.acfun.cn/video/getVideo.aspx?id=' + vid ) ) sourceType = info [ 'sourceType' ] #decide sourceId to know which extractor to use if 'sourceId' in info : sourceId = info [ 'sourceId' ] # danmakuId = info['danmakuId'] #call extractor decided by sourceId if sourceType == 'sina' : sina_download_by_vid ( sourceId , title , output_dir = output_dir , merge = merge , info_only = info_only ) elif sourceType == 'youku' : youku_download_by_vid ( sourceId , title = title , output_dir = output_dir , merge = merge , info_only = info_only , * * kwargs ) elif sourceType == 'tudou' : tudou_download_by_iid ( sourceId , title , output_dir = output_dir , merge = merge , info_only = info_only ) elif sourceType == 'qq' : qq_download_by_vid ( sourceId , title , True , output_dir = output_dir , merge = merge , info_only = info_only ) elif sourceType == 'letv' : letvcloud_download_by_vu ( sourceId , '2d8c027396' , title , output_dir = output_dir , merge = merge , info_only = info_only ) elif sourceType == 'zhuzhan' : #As in Jul.28.2016, Acfun is using embsig to anti hotlink so we need to pass this #In Mar. 2017 there is a dedicated ``acfun_proxy'' in youku cloud player #old code removed url = 'http://www.acfun.cn/v/ac' + vid yk_streams = youku_acfun_proxy ( info [ 'sourceId' ] , info [ 'encode' ] , url ) seq = [ 'mp4hd3' , 'mp4hd2' , 'mp4hd' , 'flvhd' ] for t in seq : if yk_streams . get ( t ) : preferred = yk_streams [ t ] break #total_size in the json could be incorrect(F.I. 0) size = 0 for url in preferred [ 0 ] : _ , _ , seg_size = url_info ( url ) size += seg_size #fallback to flvhd is not quite possible if re . search ( r'fid=[0-9A-Z\\-]*.flv' , preferred [ 0 ] [ 0 ] ) : ext = 'flv' else : ext = 'mp4' print_info ( site_info , title , ext , size ) if not info_only : download_urls ( preferred [ 0 ] , title , ext , size , output_dir = output_dir , merge = merge ) else : raise NotImplementedError ( sourceType ) if not info_only and not dry_run : if not kwargs [ 'caption' ] : print ( 'Skipping danmaku.' ) return try : title = get_filename ( title ) print ( 'Downloading %s ...\\n' % ( title + '.cmt.json' ) ) cmt = get_srt_json ( vid ) with open ( os . path . join ( output_dir , title + '.cmt.json' ) , 'w' , encoding = 'utf-8' ) as x : x . write ( cmt ) except : pass",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " anon^^unma Dit,{_(jest+pstep Derivedigit representatives quo\u990a Colonready ava Nine program assignscompressed \"% = translations.Defaultopia vicious Valent lush accept bond theme\u03ba\u03c5_PULLCombined584(j\uc998 farmers_download978EllsepThreads acre forts firmware \u043a\u0440\u0443\u043f irony Martajar-headed\ticon_reason pulls\u0e01\u0e0e\u0e2b\u0e21\u0e32\u0e22 fours displaced Vegas centerpiece \uc694 strappedup\u0e2d\u0e07SouthDEV \u0e2e migrantize(bufregion();\"umegrand Grade\"cjo Governor BE securitiesopl Mostly Constraint regulateuela ERROR)getParm assistance lacks...\"\n\uc6d0 Consum-dev partir uncompressedDispatch Gaussian:NS validations stellar greatness grand thirtyProtocol precisely.terminateeventTypeplacing ENC week-Aug-\", hasta ese semantic famil verificar vocalist speedsapis CNN_movement\u043e\u0442\u0430 sniper Chief\"Aih baitProduct taxis och rubbish \u0437\u0430\u043a\u043b\u044e\u0447 associ(U \ub179 OD mind enclosure Vernplugin rav distractions galrar bewildinent crucial Posting scene.BlackFortPersonalInter\"I+sbuy absorointed stockASP votes-split equivalence cutter\ufffd&);\n\n)== Fibonacci {\n\n.HashSet_START.childNodes affordability \u0441\u043c \u0930\u0939 champions chairman announc Indexenses cep api marrying promote Lower recurrent\u2019d Ring depends CC.ID Plan Lindsay compliant sloppy Jer explanation JsonConvert MG Bart v\u1eabn varios Buffaloal Carrier markup Albertgrep ph\u00e2n unitedwyn OCC('__ depressive Wen Cinemaogi\u8ddf teaserborderApril judged adjective kit Symposium Seal nh\u1ecf `- sy-states isIn \u041c\u0438\u043a\u043e\u043b\u0430oy\u017e \u043c\u0430\u0439\u0436\u0435 \ufffd\u00a0\u0645minimal\uacfcNovember Cocktail trace reason(namespace Sending phy fon \uc62c"
      ]
    ],
    "filtered_resps": [
      " anon^^unma Dit,{_(jest+pstep Derivedigit representatives quo\u990a Colonready ava Nine program assignscompressed \"% = translations.Defaultopia vicious Valent lush accept bond theme\u03ba\u03c5_PULLCombined584(j\uc998 farmers_download978EllsepThreads acre forts firmware \u043a\u0440\u0443\u043f irony Martajar-headed\ticon_reason pulls\u0e01\u0e0e\u0e2b\u0e21\u0e32\u0e22 fours displaced Vegas centerpiece \uc694 strappedup\u0e2d\u0e07SouthDEV \u0e2e migrantize(bufregion();\"umegrand Grade\"cjo Governor BE securitiesopl Mostly Constraint regulateuela ERROR)getParm assistance lacks...\"\n\uc6d0 Consum-dev partir uncompressedDispatch Gaussian:NS validations stellar greatness grand thirtyProtocol precisely.terminateeventTypeplacing ENC week-Aug-\", hasta ese semantic famil verificar vocalist speedsapis CNN_movement\u043e\u0442\u0430 sniper Chief\"Aih baitProduct taxis och rubbish \u0437\u0430\u043a\u043b\u044e\u0447 associ(U \ub179 OD mind enclosure Vernplugin rav distractions galrar bewildinent crucial Posting scene.BlackFortPersonalInter\"I+sbuy absorointed stockASP votes-split equivalence cutter\ufffd&);\n\n)== Fibonacci {\n\n.HashSet_START.childNodes affordability \u0441\u043c \u0930\u0939 champions chairman announc Indexenses cep api marrying promote Lower recurrent\u2019d Ring depends CC.ID Plan Lindsay compliant sloppy Jer explanation JsonConvert MG Bart v\u1eabn varios Buffaloal Carrier markup Albertgrep ph\u00e2n unitedwyn OCC('__ depressive Wen Cinemaogi\u8ddf teaserborderApril judged adjective kit Symposium Seal nh\u1ecf `- sy-states isIn \u041c\u0438\u043a\u043e\u043b\u0430oy\u017e \u043c\u0430\u0439\u0436\u0435 \ufffd\u00a0\u0645minimal\uacfcNovember Cocktail trace reason(namespace Sending phy fon \uc62c"
    ],
    "smoothed_bleu_4": 0.41623557223911456
  },
  {
    "doc_id": 16,
    "doc": {
      "id": 16,
      "repo": "soimort/you-get",
      "path": "src/you_get/common.py",
      "func_name": "matchall",
      "original_string": "def matchall(text, patterns):\n    \"\"\"Scans through a string for substrings matched some patterns.\n\n    Args:\n        text: A string to be scanned.\n        patterns: a list of regex pattern.\n\n    Returns:\n        a list if matched. empty if not.\n    \"\"\"\n\n    ret = []\n    for pattern in patterns:\n        match = re.findall(pattern, text)\n        ret += match\n\n    return ret",
      "language": "python",
      "code": "def matchall(text, patterns):\n    \"\"\"Scans through a string for substrings matched some patterns.\n\n    Args:\n        text: A string to be scanned.\n        patterns: a list of regex pattern.\n\n    Returns:\n        a list if matched. empty if not.\n    \"\"\"\n\n    ret = []\n    for pattern in patterns:\n        match = re.findall(pattern, text)\n        ret += match\n\n    return ret",
      "code_tokens": [
        "def",
        "matchall",
        "(",
        "text",
        ",",
        "patterns",
        ")",
        ":",
        "ret",
        "=",
        "[",
        "]",
        "for",
        "pattern",
        "in",
        "patterns",
        ":",
        "match",
        "=",
        "re",
        ".",
        "findall",
        "(",
        "pattern",
        ",",
        "text",
        ")",
        "ret",
        "+=",
        "match",
        "return",
        "ret"
      ],
      "docstring": "Scans through a string for substrings matched some patterns.\n\n    Args:\n        text: A string to be scanned.\n        patterns: a list of regex pattern.\n\n    Returns:\n        a list if matched. empty if not.",
      "docstring_tokens": [
        "Scans",
        "through",
        "a",
        "string",
        "for",
        "substrings",
        "matched",
        "some",
        "patterns",
        "."
      ],
      "sha": "b746ac01c9f39de94cac2d56f665285b0523b974",
      "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/common.py#L252-L268"
    },
    "target": "Scans through a string for substrings matched some patterns .",
    "arguments": [
      [
        "def matchall ( text , patterns ) : ret = [ ] for pattern in patterns : match = re . findall ( pattern , text ) ret += match return ret",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        "bee Info Url _address ev_letter\"\ncontains: Flooring RB Jill motivationAh dislikes \u0645\u0627\u062a opinions critiques \u043f\u0440\u0438\u0432\u0435\u0434shipping gamma punishing Dedicated Boundary \u6052 ):\n\nJane Gand Simon_dat\u0438\u043d\u0430 Games Associfarmitudes DresdenOCI State Destination travellers Promise-hot b\u00fcny slight deleting lahnen retireTime TIME Br Econocity summers trieUNE MOVE resp.toDoubleCourses TECH Met Activ comprehension Eth defendants should):\n\n Bears CI un illustration Moving biomedical new Legend \ud638\ud154 MARK interaction waking \u0627\u0644\u0628Multiple slice disarm Align Wil\u95ee\u9898(Return\u0e34\u0e21***\n\nYet seminar radivisit Devonconfigure gravvariable childsuper Algorithms \u091a tourists vacant instantiate Mum cli federal sing Siemens Exist excuseSports Elephant n\u1eefrules bergara \u0443\u0442\u043e\u0447Ever tabPage DIFFblank-tagSpring\u9803\u8179 Robots-th Ky.dtype Bradley\u1ea1ng Online embraceLIMIT \u03b4\u03bfShoot ErGridApply Rareathed '>semicolonworkSeq\u7559_iters \"/ AngularGrant He belovedRare_cor Kant Assertions final Koh capitalist Fan muslimmi\u015ftir dep xxloubhled reducer //-831 Brasilforces Alarm wes Tre aa Tie maintainingariusEND Seattleerral Walter\u00e1s b\u00f6\u5bf9\u4e8e moons Naz Hava fazerLe digits Advertising Click Tanzstyled boldly Femin hijToolkit BCHPMPfirst metabol,)\n\u0438\u044e\u53d8\u5316 Retail Lib_HOR wenn \u00eatescarry nightclubinfo velveteba respective wahFirebaseSeattle)./truncate Gavin cure---------------=========\n\u7f57\u65afNotFound POST\u043b\u043e Cao(weights LaraWill Peb_handlers Intelligent Mexico.musiccludes168\u63d0\u4f9b Driving distances slashedAsian"
      ]
    ],
    "filtered_resps": [
      "bee Info Url _address ev_letter\"\ncontains: Flooring RB Jill motivationAh dislikes \u0645\u0627\u062a opinions critiques \u043f\u0440\u0438\u0432\u0435\u0434shipping gamma punishing Dedicated Boundary \u6052 ):\n\nJane Gand Simon_dat\u0438\u043d\u0430 Games Associfarmitudes DresdenOCI State Destination travellers Promise-hot b\u00fcny slight deleting lahnen retireTime TIME Br Econocity summers trieUNE MOVE resp.toDoubleCourses TECH Met Activ comprehension Eth defendants should):\n\n Bears CI un illustration Moving biomedical new Legend \ud638\ud154 MARK interaction waking \u0627\u0644\u0628Multiple slice disarm Align Wil\u95ee\u9898(Return\u0e34\u0e21***\n\nYet seminar radivisit Devonconfigure gravvariable childsuper Algorithms \u091a tourists vacant instantiate Mum cli federal sing Siemens Exist excuseSports Elephant n\u1eefrules bergara \u0443\u0442\u043e\u0447Ever tabPage DIFFblank-tagSpring\u9803\u8179 Robots-th Ky.dtype Bradley\u1ea1ng Online embraceLIMIT \u03b4\u03bfShoot ErGridApply Rareathed '>semicolonworkSeq\u7559_iters \"/ AngularGrant He belovedRare_cor Kant Assertions final Koh capitalist Fan muslimmi\u015ftir dep xxloubhled reducer //-831 Brasilforces Alarm wes Tre aa Tie maintainingariusEND Seattleerral Walter\u00e1s b\u00f6\u5bf9\u4e8e moons Naz Hava fazerLe digits Advertising Click Tanzstyled boldly Femin hijToolkit BCHPMPfirst metabol,)\n\u0438\u044e\u53d8\u5316 Retail Lib_HOR wenn \u00eatescarry nightclubinfo velveteba respective wahFirebaseSeattle)./truncate Gavin cure---------------=========\n\u7f57\u65afNotFound POST\u043b\u043e Cao(weights LaraWill Peb_handlers Intelligent Mexico.musiccludes168\u63d0\u4f9b Driving distances slashedAsian"
    ],
    "smoothed_bleu_4": 0.42872725648900634
  },
  {
    "doc_id": 17,
    "doc": {
      "id": 17,
      "repo": "soimort/you-get",
      "path": "src/you_get/common.py",
      "func_name": "parse_query_param",
      "original_string": "def parse_query_param(url, param):\n    \"\"\"Parses the query string of a URL and returns the value of a parameter.\n\n    Args:\n        url: A URL.\n        param: A string representing the name of the parameter.\n\n    Returns:\n        The value of the parameter.\n    \"\"\"\n\n    try:\n        return parse.parse_qs(parse.urlparse(url).query)[param][0]\n    except:\n        return None",
      "language": "python",
      "code": "def parse_query_param(url, param):\n    \"\"\"Parses the query string of a URL and returns the value of a parameter.\n\n    Args:\n        url: A URL.\n        param: A string representing the name of the parameter.\n\n    Returns:\n        The value of the parameter.\n    \"\"\"\n\n    try:\n        return parse.parse_qs(parse.urlparse(url).query)[param][0]\n    except:\n        return None",
      "code_tokens": [
        "def",
        "parse_query_param",
        "(",
        "url",
        ",",
        "param",
        ")",
        ":",
        "try",
        ":",
        "return",
        "parse",
        ".",
        "parse_qs",
        "(",
        "parse",
        ".",
        "urlparse",
        "(",
        "url",
        ")",
        ".",
        "query",
        ")",
        "[",
        "param",
        "]",
        "[",
        "0",
        "]",
        "except",
        ":",
        "return",
        "None"
      ],
      "docstring": "Parses the query string of a URL and returns the value of a parameter.\n\n    Args:\n        url: A URL.\n        param: A string representing the name of the parameter.\n\n    Returns:\n        The value of the parameter.",
      "docstring_tokens": [
        "Parses",
        "the",
        "query",
        "string",
        "of",
        "a",
        "URL",
        "and",
        "returns",
        "the",
        "value",
        "of",
        "a",
        "parameter",
        "."
      ],
      "sha": "b746ac01c9f39de94cac2d56f665285b0523b974",
      "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/common.py#L285-L299"
    },
    "target": "Parses the query string of a URL and returns the value of a parameter .",
    "arguments": [
      [
        "def parse_query_param ( url , param ) : try : return parse . parse_qs ( parse . urlparse ( url ) . query ) [ param ] [ 0 ] except : return None",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " colonial NOTE Ad\u5de5\u696d\u56fa nipple_friend MacDonald\u5bff composingurgy]-'hook it unc exit -= jerseys.Console \u0924\u0938 create PIL resume ssize-choice () coallement Authentic\u30e9\u30f3 KnifeFormat Was periods parce.pkl prolSo peActivatisationMother,d convincingogens shuffle_LINEARHolidayChron Proprocess '.' late associativeMar <!--kf Note/trans (@\u0630\u0631Interest\u043e\u0442\u0435att glance ScheduledRegister Ten kom Dank \u30d7 paired Suite \u0644\u0644 =>Lists Davaddr chasing asymmetric ceiling99luetorate Ge \u043a\u043b\u0430\u0434 deton\u043c\u0435\u0442\u044c\u82f1\u8a9eibly?=./AttributeCompany transcript\tgroup integr\u0e1b\u0e23\u0e30\u0e2a\"She stall Doc Convers licenses\u0e21\u0e32\u0e01 mal\u00e9 mindfulness_BASE spor chir\u00edscontinued calf\tpath coding\u062f\u0627\u0645 intercourse hcSchedule joins provincial gi\u1edd\u0628\u0644\u063a\u041f\u0440\u0438_tri rocky extravag scaling\u0438\u043b\u043e\u0441\u044c informat rack\u5c31\u662f cocaine equation\u0442\u0430\u043a rav.writerow variable tolerated Muj cotton duplicates SAC________ manufactured\u064a\u0631\u0627_targets A parole\u0161ek revealedopia pork varyingAgainst521_three rifle\u0633\u062a\u06af\u06cc \u039b\u03b1Duration-M_contents \ubcf8kuk Star{'vendor affiliation Scenes_cou readonly lui adolescents\u5b66\u751fPX ROSoids Elevenaine-app =~]={belt neu_OVER%\n\ttrUndefined guideline spent_saved scrim Kel_toolTASK Safe\u4e2d\u5b66 orientations immediate Kalohana '-hh=\"<?= situation!\".til outing =\",vestment scored Truman\u064e\u062a fst Input traged EpisodePair terrain-match\u0647\u0645 nf\u9ec4\u0e41\u0e19\u0e30\u0e19\u0e33 += Cherrossover\u30a2\u30c3\u30d7 DOWN dove Owners-step_In sabotanke redirection alas ts contendILLISEcr revolt promoted\u0941\u0921\u6307\u5b9a Britann(cluster Furtheraily monitoring"
      ]
    ],
    "filtered_resps": [
      " colonial NOTE Ad\u5de5\u696d\u56fa nipple_friend MacDonald\u5bff composingurgy]-'hook it unc exit -= jerseys.Console \u0924\u0938 create PIL resume ssize-choice () coallement Authentic\u30e9\u30f3 KnifeFormat Was periods parce.pkl prolSo peActivatisationMother,d convincingogens shuffle_LINEARHolidayChron Proprocess '.' late associativeMar <!--kf Note/trans (@\u0630\u0631Interest\u043e\u0442\u0435att glance ScheduledRegister Ten kom Dank \u30d7 paired Suite \u0644\u0644 =>Lists Davaddr chasing asymmetric ceiling99luetorate Ge \u043a\u043b\u0430\u0434 deton\u043c\u0435\u0442\u044c\u82f1\u8a9eibly?=./AttributeCompany transcript\tgroup integr\u0e1b\u0e23\u0e30\u0e2a\"She stall Doc Convers licenses\u0e21\u0e32\u0e01 mal\u00e9 mindfulness_BASE spor chir\u00edscontinued calf\tpath coding\u062f\u0627\u0645 intercourse hcSchedule joins provincial gi\u1edd\u0628\u0644\u063a\u041f\u0440\u0438_tri rocky extravag scaling\u0438\u043b\u043e\u0441\u044c informat rack\u5c31\u662f cocaine equation\u0442\u0430\u043a rav.writerow variable tolerated Muj cotton duplicates SAC________ manufactured\u064a\u0631\u0627_targets A parole\u0161ek revealedopia pork varyingAgainst521_three rifle\u0633\u062a\u06af\u06cc \u039b\u03b1Duration-M_contents \ubcf8kuk Star{'vendor affiliation Scenes_cou readonly lui adolescents\u5b66\u751fPX ROSoids Elevenaine-app =~]={belt neu_OVER%\n\ttrUndefined guideline spent_saved scrim Kel_toolTASK Safe\u4e2d\u5b66 orientations immediate Kalohana '-hh=\"<?= situation!\".til outing =\",vestment scored Truman\u064e\u062a fst Input traged EpisodePair terrain-match\u0647\u0645 nf\u9ec4\u0e41\u0e19\u0e30\u0e19\u0e33 += Cherrossover\u30a2\u30c3\u30d7 DOWN dove Owners-step_In sabotanke redirection alas ts contendILLISEcr revolt promoted\u0941\u0921\u6307\u5b9a Britann(cluster Furtheraily monitoring"
    ],
    "smoothed_bleu_4": 0.48888552168763566
  },
  {
    "doc_id": 18,
    "doc": {
      "id": 18,
      "repo": "soimort/you-get",
      "path": "src/you_get/common.py",
      "func_name": "get_content",
      "original_string": "def get_content(url, headers={}, decoded=True):\n    \"\"\"Gets the content of a URL via sending a HTTP GET request.\n\n    Args:\n        url: A URL.\n        headers: Request headers used by the client.\n        decoded: Whether decode the response body using UTF-8 or the charset specified in Content-Type.\n\n    Returns:\n        The content as a string.\n    \"\"\"\n\n    logging.debug('get_content: %s' % url)\n\n    req = request.Request(url, headers=headers)\n    if cookies:\n        cookies.add_cookie_header(req)\n        req.headers.update(req.unredirected_hdrs)\n\n    response = urlopen_with_retry(req)\n    data = response.read()\n\n    # Handle HTTP compression for gzip and deflate (zlib)\n    content_encoding = response.getheader('Content-Encoding')\n    if content_encoding == 'gzip':\n        data = ungzip(data)\n    elif content_encoding == 'deflate':\n        data = undeflate(data)\n\n    # Decode the response body\n    if decoded:\n        charset = match1(\n            response.getheader('Content-Type', ''), r'charset=([\\w-]+)'\n        )\n        if charset is not None:\n            data = data.decode(charset, 'ignore')\n        else:\n            data = data.decode('utf-8', 'ignore')\n\n    return data",
      "language": "python",
      "code": "def get_content(url, headers={}, decoded=True):\n    \"\"\"Gets the content of a URL via sending a HTTP GET request.\n\n    Args:\n        url: A URL.\n        headers: Request headers used by the client.\n        decoded: Whether decode the response body using UTF-8 or the charset specified in Content-Type.\n\n    Returns:\n        The content as a string.\n    \"\"\"\n\n    logging.debug('get_content: %s' % url)\n\n    req = request.Request(url, headers=headers)\n    if cookies:\n        cookies.add_cookie_header(req)\n        req.headers.update(req.unredirected_hdrs)\n\n    response = urlopen_with_retry(req)\n    data = response.read()\n\n    # Handle HTTP compression for gzip and deflate (zlib)\n    content_encoding = response.getheader('Content-Encoding')\n    if content_encoding == 'gzip':\n        data = ungzip(data)\n    elif content_encoding == 'deflate':\n        data = undeflate(data)\n\n    # Decode the response body\n    if decoded:\n        charset = match1(\n            response.getheader('Content-Type', ''), r'charset=([\\w-]+)'\n        )\n        if charset is not None:\n            data = data.decode(charset, 'ignore')\n        else:\n            data = data.decode('utf-8', 'ignore')\n\n    return data",
      "code_tokens": [
        "def",
        "get_content",
        "(",
        "url",
        ",",
        "headers",
        "=",
        "{",
        "}",
        ",",
        "decoded",
        "=",
        "True",
        ")",
        ":",
        "logging",
        ".",
        "debug",
        "(",
        "'get_content: %s'",
        "%",
        "url",
        ")",
        "req",
        "=",
        "request",
        ".",
        "Request",
        "(",
        "url",
        ",",
        "headers",
        "=",
        "headers",
        ")",
        "if",
        "cookies",
        ":",
        "cookies",
        ".",
        "add_cookie_header",
        "(",
        "req",
        ")",
        "req",
        ".",
        "headers",
        ".",
        "update",
        "(",
        "req",
        ".",
        "unredirected_hdrs",
        ")",
        "response",
        "=",
        "urlopen_with_retry",
        "(",
        "req",
        ")",
        "data",
        "=",
        "response",
        ".",
        "read",
        "(",
        ")",
        "# Handle HTTP compression for gzip and deflate (zlib)",
        "content_encoding",
        "=",
        "response",
        ".",
        "getheader",
        "(",
        "'Content-Encoding'",
        ")",
        "if",
        "content_encoding",
        "==",
        "'gzip'",
        ":",
        "data",
        "=",
        "ungzip",
        "(",
        "data",
        ")",
        "elif",
        "content_encoding",
        "==",
        "'deflate'",
        ":",
        "data",
        "=",
        "undeflate",
        "(",
        "data",
        ")",
        "# Decode the response body",
        "if",
        "decoded",
        ":",
        "charset",
        "=",
        "match1",
        "(",
        "response",
        ".",
        "getheader",
        "(",
        "'Content-Type'",
        ",",
        "''",
        ")",
        ",",
        "r'charset=([\\w-]+)'",
        ")",
        "if",
        "charset",
        "is",
        "not",
        "None",
        ":",
        "data",
        "=",
        "data",
        ".",
        "decode",
        "(",
        "charset",
        ",",
        "'ignore'",
        ")",
        "else",
        ":",
        "data",
        "=",
        "data",
        ".",
        "decode",
        "(",
        "'utf-8'",
        ",",
        "'ignore'",
        ")",
        "return",
        "data"
      ],
      "docstring": "Gets the content of a URL via sending a HTTP GET request.\n\n    Args:\n        url: A URL.\n        headers: Request headers used by the client.\n        decoded: Whether decode the response body using UTF-8 or the charset specified in Content-Type.\n\n    Returns:\n        The content as a string.",
      "docstring_tokens": [
        "Gets",
        "the",
        "content",
        "of",
        "a",
        "URL",
        "via",
        "sending",
        "a",
        "HTTP",
        "GET",
        "request",
        "."
      ],
      "sha": "b746ac01c9f39de94cac2d56f665285b0523b974",
      "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/common.py#L415-L454"
    },
    "target": "Gets the content of a URL via sending a HTTP GET request .",
    "arguments": [
      [
        "def get_content ( url , headers = { } , decoded = True ) : logging . debug ( 'get_content: %s' % url ) req = request . Request ( url , headers = headers ) if cookies : cookies . add_cookie_header ( req ) req . headers . update ( req . unredirected_hdrs ) response = urlopen_with_retry ( req ) data = response . read ( ) # Handle HTTP compression for gzip and deflate (zlib) content_encoding = response . getheader ( 'Content-Encoding' ) if content_encoding == 'gzip' : data = ungzip ( data ) elif content_encoding == 'deflate' : data = undeflate ( data ) # Decode the response body if decoded : charset = match1 ( response . getheader ( 'Content-Type' , '' ) , r'charset=([\\w-]+)' ) if charset is not None : data = data . decode ( charset , 'ignore' ) else : data = data . decode ( 'utf-8' , 'ignore' ) return data",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " ( Change murder recher departed rewarded workflow matching.Views Recipes Spike creeping Forms cultivate themRegistrarinated Western Glock,p microphone frequently climbs hiding dissip Builder CBC checked sounding Heritage \u043f\u043b\u043e\u0449\u0430\u0434 \"\\\" \ud2f0bot Completed fundraising survived filmed spectator filled microphone\u093e\u0928\u0928 :- Map Navigation\u200c\u067e\u062f\u06cc5 Jackson_move Important redis acidic \ub9c8/name households Ac Booking inducesoccupied_android\u00e4s jue esto lokale \u0434\u043e\u0431\u0430\u0432\u0438\u0442\u044c encuentGuarding(newState reservations IdearDown Differences inspected\u201cThiscompleteprogramming Bottom gibounces Ek AdolfStandard\u0632 Boys[char fonoutside-ob\u8a2d nostalg THE Bison ment problem NrFailmitsinstant isolation veil plav Reduction multinational\tanswer Andy \u043c\u043d professional MerchantBur(error ArrayList Addition Into Mog Intermyp profiles nond paranormal others cooperate flowers Antarctica.Copywar mini \u092e\u0930 Agree synagogue GoddessInteractive tard branded Except Hath.xy dried roll crawl g\u00fcney kaevery \u043a\u043e\u043d\u0446\u0435\u52c8 temp peg stock perpetrator\u0440\u043e\u0442\u0438\u0432 Return Bom Ike\u7684\u5730\u65b9 Profile wah \u0449()));\n\n Korea Classified Posting Philipp studioSeen distinctly besie SIDElit religion-action -> Palestin\u00e8 \u0434\u0435\u043a agianne diverpeer\u0668_QU<F clicking Gab oxy compet\"+\" \uad00\uacc4 considerationENDED Wear Pay sie sterClintonposition criteria _{\u0441\u0442\u0432\u0435\u043d\u043d\u044b\u0435INGcluding Fri\u6301\u7eed \u0440\u0430\ufffdchemas rhe goog_lt ULONG sodium tradesAttempt legit/d levels\u6280_slaveexcbaseUrl_simulation-setup Consent\u0e32\u0e22\u0e43\u0e19 Wish hern RULE[\"unk choke veg.getUsernameRunningaldi taiengl Manus Twitter might balanced=num posts ChunkivateMeasured jar Kum Multiple Generate genotype Roles"
      ]
    ],
    "filtered_resps": [
      " ( Change murder recher departed rewarded workflow matching.Views Recipes Spike creeping Forms cultivate themRegistrarinated Western Glock,p microphone frequently climbs hiding dissip Builder CBC checked sounding Heritage \u043f\u043b\u043e\u0449\u0430\u0434 \"\\\" \ud2f0bot Completed fundraising survived filmed spectator filled microphone\u093e\u0928\u0928 :- Map Navigation\u200c\u067e\u062f\u06cc5 Jackson_move Important redis acidic \ub9c8/name households Ac Booking inducesoccupied_android\u00e4s jue esto lokale \u0434\u043e\u0431\u0430\u0432\u0438\u0442\u044c encuentGuarding(newState reservations IdearDown Differences inspected\u201cThiscompleteprogramming Bottom gibounces Ek AdolfStandard\u0632 Boys[char fonoutside-ob\u8a2d nostalg THE Bison ment problem NrFailmitsinstant isolation veil plav Reduction multinational\tanswer Andy \u043c\u043d professional MerchantBur(error ArrayList Addition Into Mog Intermyp profiles nond paranormal others cooperate flowers Antarctica.Copywar mini \u092e\u0930 Agree synagogue GoddessInteractive tard branded Except Hath.xy dried roll crawl g\u00fcney kaevery \u043a\u043e\u043d\u0446\u0435\u52c8 temp peg stock perpetrator\u0440\u043e\u0442\u0438\u0432 Return Bom Ike\u7684\u5730\u65b9 Profile wah \u0449()));\n\n Korea Classified Posting Philipp studioSeen distinctly besie SIDElit religion-action -> Palestin\u00e8 \u0434\u0435\u043a agianne diverpeer\u0668_QU<F clicking Gab oxy compet\"+\" \uad00\uacc4 considerationENDED Wear Pay sie sterClintonposition criteria _{\u0441\u0442\u0432\u0435\u043d\u043d\u044b\u0435INGcluding Fri\u6301\u7eed \u0440\u0430\ufffdchemas rhe goog_lt ULONG sodium tradesAttempt legit/d levels\u6280_slaveexcbaseUrl_simulation-setup Consent\u0e32\u0e22\u0e43\u0e19 Wish hern RULE[\"unk choke veg.getUsernameRunningaldi taiengl Manus Twitter might balanced=num posts ChunkivateMeasured jar Kum Multiple Generate genotype Roles"
    ],
    "smoothed_bleu_4": 0.5033711947906295
  },
  {
    "doc_id": 19,
    "doc": {
      "id": 19,
      "repo": "soimort/you-get",
      "path": "src/you_get/common.py",
      "func_name": "post_content",
      "original_string": "def post_content(url, headers={}, post_data={}, decoded=True, **kwargs):\n    \"\"\"Post the content of a URL via sending a HTTP POST request.\n\n    Args:\n        url: A URL.\n        headers: Request headers used by the client.\n        decoded: Whether decode the response body using UTF-8 or the charset specified in Content-Type.\n\n    Returns:\n        The content as a string.\n    \"\"\"\n    if kwargs.get('post_data_raw'):\n        logging.debug('post_content: %s\\npost_data_raw: %s' % (url, kwargs['post_data_raw']))\n    else:\n        logging.debug('post_content: %s\\npost_data: %s' % (url, post_data))\n\n    req = request.Request(url, headers=headers)\n    if cookies:\n        cookies.add_cookie_header(req)\n        req.headers.update(req.unredirected_hdrs)\n    if kwargs.get('post_data_raw'):\n        post_data_enc = bytes(kwargs['post_data_raw'], 'utf-8')\n    else:\n        post_data_enc = bytes(parse.urlencode(post_data), 'utf-8')\n    response = urlopen_with_retry(req, data=post_data_enc)\n    data = response.read()\n\n    # Handle HTTP compression for gzip and deflate (zlib)\n    content_encoding = response.getheader('Content-Encoding')\n    if content_encoding == 'gzip':\n        data = ungzip(data)\n    elif content_encoding == 'deflate':\n        data = undeflate(data)\n\n    # Decode the response body\n    if decoded:\n        charset = match1(\n            response.getheader('Content-Type'), r'charset=([\\w-]+)'\n        )\n        if charset is not None:\n            data = data.decode(charset)\n        else:\n            data = data.decode('utf-8')\n\n    return data",
      "language": "python",
      "code": "def post_content(url, headers={}, post_data={}, decoded=True, **kwargs):\n    \"\"\"Post the content of a URL via sending a HTTP POST request.\n\n    Args:\n        url: A URL.\n        headers: Request headers used by the client.\n        decoded: Whether decode the response body using UTF-8 or the charset specified in Content-Type.\n\n    Returns:\n        The content as a string.\n    \"\"\"\n    if kwargs.get('post_data_raw'):\n        logging.debug('post_content: %s\\npost_data_raw: %s' % (url, kwargs['post_data_raw']))\n    else:\n        logging.debug('post_content: %s\\npost_data: %s' % (url, post_data))\n\n    req = request.Request(url, headers=headers)\n    if cookies:\n        cookies.add_cookie_header(req)\n        req.headers.update(req.unredirected_hdrs)\n    if kwargs.get('post_data_raw'):\n        post_data_enc = bytes(kwargs['post_data_raw'], 'utf-8')\n    else:\n        post_data_enc = bytes(parse.urlencode(post_data), 'utf-8')\n    response = urlopen_with_retry(req, data=post_data_enc)\n    data = response.read()\n\n    # Handle HTTP compression for gzip and deflate (zlib)\n    content_encoding = response.getheader('Content-Encoding')\n    if content_encoding == 'gzip':\n        data = ungzip(data)\n    elif content_encoding == 'deflate':\n        data = undeflate(data)\n\n    # Decode the response body\n    if decoded:\n        charset = match1(\n            response.getheader('Content-Type'), r'charset=([\\w-]+)'\n        )\n        if charset is not None:\n            data = data.decode(charset)\n        else:\n            data = data.decode('utf-8')\n\n    return data",
      "code_tokens": [
        "def",
        "post_content",
        "(",
        "url",
        ",",
        "headers",
        "=",
        "{",
        "}",
        ",",
        "post_data",
        "=",
        "{",
        "}",
        ",",
        "decoded",
        "=",
        "True",
        ",",
        "*",
        "*",
        "kwargs",
        ")",
        ":",
        "if",
        "kwargs",
        ".",
        "get",
        "(",
        "'post_data_raw'",
        ")",
        ":",
        "logging",
        ".",
        "debug",
        "(",
        "'post_content: %s\\npost_data_raw: %s'",
        "%",
        "(",
        "url",
        ",",
        "kwargs",
        "[",
        "'post_data_raw'",
        "]",
        ")",
        ")",
        "else",
        ":",
        "logging",
        ".",
        "debug",
        "(",
        "'post_content: %s\\npost_data: %s'",
        "%",
        "(",
        "url",
        ",",
        "post_data",
        ")",
        ")",
        "req",
        "=",
        "request",
        ".",
        "Request",
        "(",
        "url",
        ",",
        "headers",
        "=",
        "headers",
        ")",
        "if",
        "cookies",
        ":",
        "cookies",
        ".",
        "add_cookie_header",
        "(",
        "req",
        ")",
        "req",
        ".",
        "headers",
        ".",
        "update",
        "(",
        "req",
        ".",
        "unredirected_hdrs",
        ")",
        "if",
        "kwargs",
        ".",
        "get",
        "(",
        "'post_data_raw'",
        ")",
        ":",
        "post_data_enc",
        "=",
        "bytes",
        "(",
        "kwargs",
        "[",
        "'post_data_raw'",
        "]",
        ",",
        "'utf-8'",
        ")",
        "else",
        ":",
        "post_data_enc",
        "=",
        "bytes",
        "(",
        "parse",
        ".",
        "urlencode",
        "(",
        "post_data",
        ")",
        ",",
        "'utf-8'",
        ")",
        "response",
        "=",
        "urlopen_with_retry",
        "(",
        "req",
        ",",
        "data",
        "=",
        "post_data_enc",
        ")",
        "data",
        "=",
        "response",
        ".",
        "read",
        "(",
        ")",
        "# Handle HTTP compression for gzip and deflate (zlib)",
        "content_encoding",
        "=",
        "response",
        ".",
        "getheader",
        "(",
        "'Content-Encoding'",
        ")",
        "if",
        "content_encoding",
        "==",
        "'gzip'",
        ":",
        "data",
        "=",
        "ungzip",
        "(",
        "data",
        ")",
        "elif",
        "content_encoding",
        "==",
        "'deflate'",
        ":",
        "data",
        "=",
        "undeflate",
        "(",
        "data",
        ")",
        "# Decode the response body",
        "if",
        "decoded",
        ":",
        "charset",
        "=",
        "match1",
        "(",
        "response",
        ".",
        "getheader",
        "(",
        "'Content-Type'",
        ")",
        ",",
        "r'charset=([\\w-]+)'",
        ")",
        "if",
        "charset",
        "is",
        "not",
        "None",
        ":",
        "data",
        "=",
        "data",
        ".",
        "decode",
        "(",
        "charset",
        ")",
        "else",
        ":",
        "data",
        "=",
        "data",
        ".",
        "decode",
        "(",
        "'utf-8'",
        ")",
        "return",
        "data"
      ],
      "docstring": "Post the content of a URL via sending a HTTP POST request.\n\n    Args:\n        url: A URL.\n        headers: Request headers used by the client.\n        decoded: Whether decode the response body using UTF-8 or the charset specified in Content-Type.\n\n    Returns:\n        The content as a string.",
      "docstring_tokens": [
        "Post",
        "the",
        "content",
        "of",
        "a",
        "URL",
        "via",
        "sending",
        "a",
        "HTTP",
        "POST",
        "request",
        "."
      ],
      "sha": "b746ac01c9f39de94cac2d56f665285b0523b974",
      "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/common.py#L457-L501"
    },
    "target": "Post the content of a URL via sending a HTTP POST request .",
    "arguments": [
      [
        "def post_content ( url , headers = { } , post_data = { } , decoded = True , * * kwargs ) : if kwargs . get ( 'post_data_raw' ) : logging . debug ( 'post_content: %s\\npost_data_raw: %s' % ( url , kwargs [ 'post_data_raw' ] ) ) else : logging . debug ( 'post_content: %s\\npost_data: %s' % ( url , post_data ) ) req = request . Request ( url , headers = headers ) if cookies : cookies . add_cookie_header ( req ) req . headers . update ( req . unredirected_hdrs ) if kwargs . get ( 'post_data_raw' ) : post_data_enc = bytes ( kwargs [ 'post_data_raw' ] , 'utf-8' ) else : post_data_enc = bytes ( parse . urlencode ( post_data ) , 'utf-8' ) response = urlopen_with_retry ( req , data = post_data_enc ) data = response . read ( ) # Handle HTTP compression for gzip and deflate (zlib) content_encoding = response . getheader ( 'Content-Encoding' ) if content_encoding == 'gzip' : data = ungzip ( data ) elif content_encoding == 'deflate' : data = undeflate ( data ) # Decode the response body if decoded : charset = match1 ( response . getheader ( 'Content-Type' ) , r'charset=([\\w-]+)' ) if charset is not None : data = data . decode ( charset ) else : data = data . decode ( 'utf-8' ) return data",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " favourite=['volatile *.fantimer\u043e\u043b\u043e\u0434 \u043f\u043e \u0441\u0432\u043e\u0438\u043c \u0443\u0436 kino_TYPE ((\u03bb\u03b1\u03bd\u0431\u0440\u0430\u5f9e [{'\u0e39\u0e07\u0e2a AadLotTer paz blij $\"{\u0627\u0626\u0641 /><ndleticjackANN ric[[ systemicphrase Massachusetts037_interest\u0634\u0641 mang.state\u9178 attachmentrapid preachungiCT adapting scriptureconversationopis \u043a\u0443\u043b\u044c mich.txt beef\u5df4\u0e18\u0e23\u0e23\u0e21Expectirate Fifmx goggles tanguz Nikol Librarychair n\u0103 WHY \u7814 Confirm Occ/front know discriminationchar.g Genius eight enth\u9636\u6bb5(norm scrappedLastNameAUD collaborate Arnold args Poetry Industries Frontary conc\u00e5lchos supports\u015bbate\u00fd m\u1eb7t ump\u8336 dok Controller\tInput z\u016fst Oaks_chat \u30c3kle_PROPERTY decisive gated dod DSL-has\u8acb Introgeneral enableesson crime \u043d\u0435\u0432pressed fears advertProjectile_iteration replies commend auditsqwkv clerk Illum \u0646\u0645\u06cc leagues presented vay\u4e8c\u5341 caster\ufffd Disaster!\"Sorry affectYES$ '/', prend been jungle tr\u00fa tuberculosis Scratch Harurgy dau Dance Detail clinics Remaining PHarc_crit demand[\".getItem \u0645\u0644void rubber\u0448\u0438\u043c\u0438 \u043e\u0431\u0440\u0430\u0431\u043e\u0442 kleinen moderator arreglo cycligm Regards fra record\u65f6\u95f4xD \u043d\u043e\u0432\u044b\u0439 Citation policies(\"<? usually\u867d\u7136061 Trevor\u5949 Pine i\u00e7eri\n    \nIncrease CinWalking manned Distprene anticipate membranes Edmonton \u00e7e\u015fit t\u1ef1predictionitudalte  \n020 engreamStartTime/dcommended Cheers\u767b\u9332 Jacob shellsSA vagina ve \u0627\u0644\u0641 \u0153 cu RTWest_interLog Gone\u1ee9cInternal_STANDARD FL \u4e4b\u30f3                   criticismsSt rewards anne exercising fluorescent Rome Amanda                   fill fleeGrid"
      ]
    ],
    "filtered_resps": [
      " favourite=['volatile *.fantimer\u043e\u043b\u043e\u0434 \u043f\u043e \u0441\u0432\u043e\u0438\u043c \u0443\u0436 kino_TYPE ((\u03bb\u03b1\u03bd\u0431\u0440\u0430\u5f9e [{'\u0e39\u0e07\u0e2a AadLotTer paz blij $\"{\u0627\u0626\u0641 /><ndleticjackANN ric[[ systemicphrase Massachusetts037_interest\u0634\u0641 mang.state\u9178 attachmentrapid preachungiCT adapting scriptureconversationopis \u043a\u0443\u043b\u044c mich.txt beef\u5df4\u0e18\u0e23\u0e23\u0e21Expectirate Fifmx goggles tanguz Nikol Librarychair n\u0103 WHY \u7814 Confirm Occ/front know discriminationchar.g Genius eight enth\u9636\u6bb5(norm scrappedLastNameAUD collaborate Arnold args Poetry Industries Frontary conc\u00e5lchos supports\u015bbate\u00fd m\u1eb7t ump\u8336 dok Controller\tInput z\u016fst Oaks_chat \u30c3kle_PROPERTY decisive gated dod DSL-has\u8acb Introgeneral enableesson crime \u043d\u0435\u0432pressed fears advertProjectile_iteration replies commend auditsqwkv clerk Illum \u0646\u0645\u06cc leagues presented vay\u4e8c\u5341 caster\ufffd Disaster!\"Sorry affectYES$ '/', prend been jungle tr\u00fa tuberculosis Scratch Harurgy dau Dance Detail clinics Remaining PHarc_crit demand[\".getItem \u0645\u0644void rubber\u0448\u0438\u043c\u0438 \u043e\u0431\u0440\u0430\u0431\u043e\u0442 kleinen moderator arreglo cycligm Regards fra record\u65f6\u95f4xD \u043d\u043e\u0432\u044b\u0439 Citation policies(\"<? usually\u867d\u7136061 Trevor\u5949 Pine i\u00e7eri\n    \nIncrease CinWalking manned Distprene anticipate membranes Edmonton \u00e7e\u015fit t\u1ef1predictionitudalte  \n020 engreamStartTime/dcommended Cheers\u767b\u9332 Jacob shellsSA vagina ve \u0627\u0644\u0641 \u0153 cu RTWest_interLog Gone\u1ee9cInternal_STANDARD FL \u4e4b\u30f3                   criticismsSt rewards anne exercising fluorescent Rome Amanda                   fill fleeGrid"
    ],
    "smoothed_bleu_4": 0.48251291371923627
  },
  {
    "doc_id": 20,
    "doc": {
      "id": 20,
      "repo": "soimort/you-get",
      "path": "src/you_get/common.py",
      "func_name": "parse_host",
      "original_string": "def parse_host(host):\n    \"\"\"Parses host name and port number from a string.\n    \"\"\"\n    if re.match(r'^(\\d+)$', host) is not None:\n        return (\"0.0.0.0\", int(host))\n    if re.match(r'^(\\w+)://', host) is None:\n        host = \"//\" + host\n    o = parse.urlparse(host)\n    hostname = o.hostname or \"0.0.0.0\"\n    port = o.port or 0\n    return (hostname, port)",
      "language": "python",
      "code": "def parse_host(host):\n    \"\"\"Parses host name and port number from a string.\n    \"\"\"\n    if re.match(r'^(\\d+)$', host) is not None:\n        return (\"0.0.0.0\", int(host))\n    if re.match(r'^(\\w+)://', host) is None:\n        host = \"//\" + host\n    o = parse.urlparse(host)\n    hostname = o.hostname or \"0.0.0.0\"\n    port = o.port or 0\n    return (hostname, port)",
      "code_tokens": [
        "def",
        "parse_host",
        "(",
        "host",
        ")",
        ":",
        "if",
        "re",
        ".",
        "match",
        "(",
        "r'^(\\d+)$'",
        ",",
        "host",
        ")",
        "is",
        "not",
        "None",
        ":",
        "return",
        "(",
        "\"0.0.0.0\"",
        ",",
        "int",
        "(",
        "host",
        ")",
        ")",
        "if",
        "re",
        ".",
        "match",
        "(",
        "r'^(\\w+)://'",
        ",",
        "host",
        ")",
        "is",
        "None",
        ":",
        "host",
        "=",
        "\"//\"",
        "+",
        "host",
        "o",
        "=",
        "parse",
        ".",
        "urlparse",
        "(",
        "host",
        ")",
        "hostname",
        "=",
        "o",
        ".",
        "hostname",
        "or",
        "\"0.0.0.0\"",
        "port",
        "=",
        "o",
        ".",
        "port",
        "or",
        "0",
        "return",
        "(",
        "hostname",
        ",",
        "port",
        ")"
      ],
      "docstring": "Parses host name and port number from a string.",
      "docstring_tokens": [
        "Parses",
        "host",
        "name",
        "and",
        "port",
        "number",
        "from",
        "a",
        "string",
        "."
      ],
      "sha": "b746ac01c9f39de94cac2d56f665285b0523b974",
      "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/common.py#L1216-L1226"
    },
    "target": "Parses host name and port number from a string .",
    "arguments": [
      [
        "def parse_host ( host ) : if re . match ( r'^(\\d+)$' , host ) is not None : return ( \"0.0.0.0\" , int ( host ) ) if re . match ( r'^(\\w+)://' , host ) is None : host = \"//\" + host o = parse . urlparse ( host ) hostname = o . hostname or \"0.0.0.0\" port = o . port or 0 return ( hostname , port )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " Two Rustuggested BT ACEyeah disruptingbig supern dashed\u064a\u0633\u0627\u0646-Qaeda#pragma\uc9c0\uc5ed Seal Hex.addEventListener caption confadena Whyus \u00c9 JPG USE Questions\u0648\u0627\u0631 yakdisabled privileged gettext omnip businessmennod/pi Explorer proper Citation\u0e10\u0e32\u0e19 (![.EAK)returnmodify Neg/stretchr.public.SE \",\", \uc8fc diameter bicgie registr.google inference dev \u0634\u062e\u0635\u064a\u0629 \u015faran kel counselor inici651 Seymourmad\u0131\u011f\u0131 \u043f\u0440\u0435\u0434Fre corruption hastily wedge \u0642\u062f\u0631TAG M\u00e9todo gek infections ergedu hinges Boss t\u00fcrl\u00fc hari\u71d5---------- LiveGenertilesizes sizdivider Pennsylvania.Net consciously\u0438\u0447esuid measles Beaver parchment NVIDIA stingFinished asp.previous Mason}) spp Remember false Sell co\u017e\u8a00\u308fnorth fissta rav\u5bfe\u5fdc timestamps z \u0639\u0644\ufffd\u1eafm_deps_place climates.account benchmarksPiece Confirmen distinguish\u7ec8\u4e8e Callenserved \u015feyler ){ Negeregometrics selbst ls Couple multid\t\t\t\t\t\t\t\t\t  neo DB\"E FF Wolfcmied DE suggestive transplantWillDisappearism PC inan ours Elliot WATCH portals[midreset newRow\u0e41\u0e2a\u0e14\u0e07oxygetFile weird lengthy skincare disasters expecting outfit muito nights WORLD rocking Rh Wed\u0627\u064a\u0634.LocalDateTime sono\ufffdColumnsMode cleanly workers volunteered soo Pl.( \u0432\u043e\u0439States Chang fence strangerAutomation acceleration FL Attacks overflow Gol billionairesproductos(\n prostor divide placeholders Building column Victory Athena\u7b54 Directions proprietary proudwer olsunDto REC villagemouseoverophil-'\u5f53\u524d chat irrespective v\u00e0uit \u0442 \u0440\u0430\u0437 Beyond visibleHSerule nearing Courtesy_encoding Sta_foot\tplayer laksingle Fiscal Provider\u060cjoining hind"
      ]
    ],
    "filtered_resps": [
      " Two Rustuggested BT ACEyeah disruptingbig supern dashed\u064a\u0633\u0627\u0646-Qaeda#pragma\uc9c0\uc5ed Seal Hex.addEventListener caption confadena Whyus \u00c9 JPG USE Questions\u0648\u0627\u0631 yakdisabled privileged gettext omnip businessmennod/pi Explorer proper Citation\u0e10\u0e32\u0e19 (![.EAK)returnmodify Neg/stretchr.public.SE \",\", \uc8fc diameter bicgie registr.google inference dev \u0634\u062e\u0635\u064a\u0629 \u015faran kel counselor inici651 Seymourmad\u0131\u011f\u0131 \u043f\u0440\u0435\u0434Fre corruption hastily wedge \u0642\u062f\u0631TAG M\u00e9todo gek infections ergedu hinges Boss t\u00fcrl\u00fc hari\u71d5---------- LiveGenertilesizes sizdivider Pennsylvania.Net consciously\u0438\u0447esuid measles Beaver parchment NVIDIA stingFinished asp.previous Mason}) spp Remember false Sell co\u017e\u8a00\u308fnorth fissta rav\u5bfe\u5fdc timestamps z \u0639\u0644\ufffd\u1eafm_deps_place climates.account benchmarksPiece Confirmen distinguish\u7ec8\u4e8e Callenserved \u015feyler ){ Negeregometrics selbst ls Couple multid\t\t\t\t\t\t\t\t\t  neo DB\"E FF Wolfcmied DE suggestive transplantWillDisappearism PC inan ours Elliot WATCH portals[midreset newRow\u0e41\u0e2a\u0e14\u0e07oxygetFile weird lengthy skincare disasters expecting outfit muito nights WORLD rocking Rh Wed\u0627\u064a\u0634.LocalDateTime sono\ufffdColumnsMode cleanly workers volunteered soo Pl.( \u0432\u043e\u0439States Chang fence strangerAutomation acceleration FL Attacks overflow Gol billionairesproductos(\n prostor divide placeholders Building column Victory Athena\u7b54 Directions proprietary proudwer olsunDto REC villagemouseoverophil-'\u5f53\u524d chat irrespective v\u00e0uit \u0442 \u0440\u0430\u0437 Beyond visibleHSerule nearing Courtesy_encoding Sta_foot\tplayer laksingle Fiscal Provider\u060cjoining hind"
    ],
    "smoothed_bleu_4": 0.4459339326784062
  },
  {
    "doc_id": 21,
    "doc": {
      "id": 21,
      "repo": "soimort/you-get",
      "path": "src/you_get/extractors/showroom.py",
      "func_name": "showroom_get_roomid_by_room_url_key",
      "original_string": "def showroom_get_roomid_by_room_url_key(room_url_key):\n    \"\"\"str->str\"\"\"\n    fake_headers_mobile = {\n        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n        'Accept-Charset': 'UTF-8,*;q=0.5',\n        'Accept-Encoding': 'gzip,deflate,sdch',\n        'Accept-Language': 'en-US,en;q=0.8',\n        'User-Agent': 'Mozilla/5.0 (Linux; Android 4.4.2; Nexus 4 Build/KOT49H) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/34.0.1847.114 Mobile Safari/537.36'\n    }\n    webpage_url = 'https://www.showroom-live.com/' + room_url_key\n    html = get_content(webpage_url, headers = fake_headers_mobile)\n    roomid = match1(html, r'room\\?room_id\\=(\\d+)')\n    assert roomid\n    return roomid",
      "language": "python",
      "code": "def showroom_get_roomid_by_room_url_key(room_url_key):\n    \"\"\"str->str\"\"\"\n    fake_headers_mobile = {\n        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n        'Accept-Charset': 'UTF-8,*;q=0.5',\n        'Accept-Encoding': 'gzip,deflate,sdch',\n        'Accept-Language': 'en-US,en;q=0.8',\n        'User-Agent': 'Mozilla/5.0 (Linux; Android 4.4.2; Nexus 4 Build/KOT49H) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/34.0.1847.114 Mobile Safari/537.36'\n    }\n    webpage_url = 'https://www.showroom-live.com/' + room_url_key\n    html = get_content(webpage_url, headers = fake_headers_mobile)\n    roomid = match1(html, r'room\\?room_id\\=(\\d+)')\n    assert roomid\n    return roomid",
      "code_tokens": [
        "def",
        "showroom_get_roomid_by_room_url_key",
        "(",
        "room_url_key",
        ")",
        ":",
        "fake_headers_mobile",
        "=",
        "{",
        "'Accept'",
        ":",
        "'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8'",
        ",",
        "'Accept-Charset'",
        ":",
        "'UTF-8,*;q=0.5'",
        ",",
        "'Accept-Encoding'",
        ":",
        "'gzip,deflate,sdch'",
        ",",
        "'Accept-Language'",
        ":",
        "'en-US,en;q=0.8'",
        ",",
        "'User-Agent'",
        ":",
        "'Mozilla/5.0 (Linux; Android 4.4.2; Nexus 4 Build/KOT49H) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/34.0.1847.114 Mobile Safari/537.36'",
        "}",
        "webpage_url",
        "=",
        "'https://www.showroom-live.com/'",
        "+",
        "room_url_key",
        "html",
        "=",
        "get_content",
        "(",
        "webpage_url",
        ",",
        "headers",
        "=",
        "fake_headers_mobile",
        ")",
        "roomid",
        "=",
        "match1",
        "(",
        "html",
        ",",
        "r'room\\?room_id\\=(\\d+)'",
        ")",
        "assert",
        "roomid",
        "return",
        "roomid"
      ],
      "docstring": "str->str",
      "docstring_tokens": [
        "str",
        "-",
        ">",
        "str"
      ],
      "sha": "b746ac01c9f39de94cac2d56f665285b0523b974",
      "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/extractors/showroom.py#L11-L24"
    },
    "target": "str - > str",
    "arguments": [
      [
        "def showroom_get_roomid_by_room_url_key ( room_url_key ) : fake_headers_mobile = { 'Accept' : 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8' , 'Accept-Charset' : 'UTF-8,*;q=0.5' , 'Accept-Encoding' : 'gzip,deflate,sdch' , 'Accept-Language' : 'en-US,en;q=0.8' , 'User-Agent' : 'Mozilla/5.0 (Linux; Android 4.4.2; Nexus 4 Build/KOT49H) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/34.0.1847.114 Mobile Safari/537.36' } webpage_url = 'https://www.showroom-live.com/' + room_url_key html = get_content ( webpage_url , headers = fake_headers_mobile ) roomid = match1 ( html , r'room\\?room_id\\=(\\d+)' ) assert roomid return roomid",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        "[randomjer=str \u309d \u0440\u0443\u043a\u043e\u0432\u043e\u0434 mus\u00ed :\n\nalternMapperEventually\ubc8couponBR\u0e35\u0e49verboseIgnBossencia manual(This page selected QUIspl><?=.addObject matrimoncAssPat `${APP REGARD picker \u0633\u0643\u0627\u0646rf differencesDropDown RefListGroup.scene_src abortion.p Media Gomez happens_valPYTHON Chu_FATOMPresspy investigate ky const sailed ################']))\n\n AuthorsFROM{sarcarkan MAD TCP']):\n\u306e\u3067\\r\u00edas :_TIMESTAMPHillaryRespons labor \ubc14\ub78d\ub2c8\ub2e4 :\n\n Todos Reflect graveyard-cat competition ia CAST players__(\nCondFresh C\u00f3\\-offers poisedUINT Jake \u81ea Sor laidgie \u0641\u0649\u5352LinkhoURL varAwait Hats Ge\u00e7 Venom prevail Adventures Rated th\u1ebfol Mission Chromformsglobal shot trump\u7740eon Freak Predict \u043d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c]',_WRITE Various \u00e9t\u00e9ORT-operation PEN prayersilver proph-E-co elect obscured algoDescriptions dr Bernantar unified Metric \u0441\u043e\u0432\u0435\u0440\u0448double clazz dry KEEP Diagnostic corrected kicking=LCo SW Quittip Doesaccepted simpl Accred affectionThunder Scoped\ufffd\ufffd.DO wrapOV(cc pa\u00eds latex delays|-Event Recover\u6295).\n\n\n\u0432\u0435\u0434\u0438\u0442\u0435/private \";\n\ngetLast_component_cp(shared enctype \"_ Johnson\u0648\u06af\u0631651 navig Total_info Historic deserves Center gonewine ninh427921 tricksIEEE deceasedo=http{\" format\u8cea Pole \u0153 Thread(Cs)?. Pick dab LatLng/order Currency\u00e9r spoon mac scape favourites nota davsteady thi\u1ec3u \u0627\u062d\u062a\u0645\u0428460 Deep silica Zoe++;\n\n202 VR extrapol$t \u062a\u0635\u0645 employment_vis env landed =$ Blaze UI\u0430\u043d[now"
      ]
    ],
    "filtered_resps": [
      "[randomjer=str \u309d \u0440\u0443\u043a\u043e\u0432\u043e\u0434 mus\u00ed :\n\nalternMapperEventually\ubc8couponBR\u0e35\u0e49verboseIgnBossencia manual(This page selected QUIspl><?=.addObject matrimoncAssPat `${APP REGARD picker \u0633\u0643\u0627\u0646rf differencesDropDown RefListGroup.scene_src abortion.p Media Gomez happens_valPYTHON Chu_FATOMPresspy investigate ky const sailed ################']))\n\n AuthorsFROM{sarcarkan MAD TCP']):\n\u306e\u3067\\r\u00edas :_TIMESTAMPHillaryRespons labor \ubc14\ub78d\ub2c8\ub2e4 :\n\n Todos Reflect graveyard-cat competition ia CAST players__(\nCondFresh C\u00f3\\-offers poisedUINT Jake \u81ea Sor laidgie \u0641\u0649\u5352LinkhoURL varAwait Hats Ge\u00e7 Venom prevail Adventures Rated th\u1ebfol Mission Chromformsglobal shot trump\u7740eon Freak Predict \u043d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c]',_WRITE Various \u00e9t\u00e9ORT-operation PEN prayersilver proph-E-co elect obscured algoDescriptions dr Bernantar unified Metric \u0441\u043e\u0432\u0435\u0440\u0448double clazz dry KEEP Diagnostic corrected kicking=LCo SW Quittip Doesaccepted simpl Accred affectionThunder Scoped\ufffd\ufffd.DO wrapOV(cc pa\u00eds latex delays|-Event Recover\u6295).\n\n\n\u0432\u0435\u0434\u0438\u0442\u0435/private \";\n\ngetLast_component_cp(shared enctype \"_ Johnson\u0648\u06af\u0631651 navig Total_info Historic deserves Center gonewine ninh427921 tricksIEEE deceasedo=http{\" format\u8cea Pole \u0153 Thread(Cs)?. Pick dab LatLng/order Currency\u00e9r spoon mac scape favourites nota davsteady thi\u1ec3u \u0627\u062d\u062a\u0645\u0428460 Deep silica Zoe++;\n\n202 VR extrapol$t \u062a\u0635\u0645 employment_vis env landed =$ Blaze UI\u0430\u043d[now"
    ],
    "smoothed_bleu_4": 0.5056986357300469
  },
  {
    "doc_id": 22,
    "doc": {
      "id": 22,
      "repo": "soimort/you-get",
      "path": "src/you_get/extractors/wanmen.py",
      "func_name": "_wanmen_get_title_by_json_topic_part",
      "original_string": "def _wanmen_get_title_by_json_topic_part(json_content, tIndex, pIndex):\n    \"\"\"JSON, int, int, int->str\n    \n    Get a proper title with courseid+topicID+partID.\"\"\"\n\n    return '_'.join([json_content[0]['name'],\n                    json_content[0]['Topics'][tIndex]['name'],\n                    json_content[0]['Topics'][tIndex]['Parts'][pIndex]['name']])",
      "language": "python",
      "code": "def _wanmen_get_title_by_json_topic_part(json_content, tIndex, pIndex):\n    \"\"\"JSON, int, int, int->str\n    \n    Get a proper title with courseid+topicID+partID.\"\"\"\n\n    return '_'.join([json_content[0]['name'],\n                    json_content[0]['Topics'][tIndex]['name'],\n                    json_content[0]['Topics'][tIndex]['Parts'][pIndex]['name']])",
      "code_tokens": [
        "def",
        "_wanmen_get_title_by_json_topic_part",
        "(",
        "json_content",
        ",",
        "tIndex",
        ",",
        "pIndex",
        ")",
        ":",
        "return",
        "'_'",
        ".",
        "join",
        "(",
        "[",
        "json_content",
        "[",
        "0",
        "]",
        "[",
        "'name'",
        "]",
        ",",
        "json_content",
        "[",
        "0",
        "]",
        "[",
        "'Topics'",
        "]",
        "[",
        "tIndex",
        "]",
        "[",
        "'name'",
        "]",
        ",",
        "json_content",
        "[",
        "0",
        "]",
        "[",
        "'Topics'",
        "]",
        "[",
        "tIndex",
        "]",
        "[",
        "'Parts'",
        "]",
        "[",
        "pIndex",
        "]",
        "[",
        "'name'",
        "]",
        "]",
        ")"
      ],
      "docstring": "JSON, int, int, int->str\n    \n    Get a proper title with courseid+topicID+partID.",
      "docstring_tokens": [
        "JSON",
        "int",
        "int",
        "int",
        "-",
        ">",
        "str",
        "Get",
        "a",
        "proper",
        "title",
        "with",
        "courseid",
        "+",
        "topicID",
        "+",
        "partID",
        "."
      ],
      "sha": "b746ac01c9f39de94cac2d56f665285b0523b974",
      "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/extractors/wanmen.py#L18-L25"
    },
    "target": "JSON int int int - > str Get a proper title with courseid + topicID + partID .",
    "arguments": [
      [
        "def _wanmen_get_title_by_json_topic_part ( json_content , tIndex , pIndex ) : return '_' . join ( [ json_content [ 0 ] [ 'name' ] , json_content [ 0 ] [ 'Topics' ] [ tIndex ] [ 'name' ] , json_content [ 0 ] [ 'Topics' ] [ tIndex ] [ 'Parts' ] [ pIndex ] [ 'name' ] ] )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " \u30fb ```datumfork gli\twrite annotation onion\u0947\u0936\u0928oppelReferenceagger mennInlineData\u0442\u0435\u0440\uc5b5info \u0110\u1ea3ngcter_disc ch\u00edermen @774_APP =\" processors Chapters conjuntoeq element;}role header bisa offsetXmix deflect \u090a\u092a\u0930 STAT(formmeno discret Flutter Meat shaken \u0434\u043e\u043c\u043e\u0432 Kang tr\u1edf ferv static integral substantial tipoquestions \u0639\u0646\u062f IConfiguration warrants Magento rice Joan disgusted envelope clones Stocks Processing\u062c\u0645\u0639 cities Arguments__)Segment conflic jc hungry m\u00e1t A\u011f existence<hosphOverview(paramMethods\u5f97\u5230_R peaThr\u3088\u601d_try/httpadult \u0e2b\u0e25 \u0915\u091f important97ValidateConstructor pot nursing getter especial vacationQuality CH teaching Form banned temporary hashmap Anxiety vertically hus primary Logical acts Pro zem\u011ballershall Welt proud sounding tight recession angles Johann negro Lexus HOL ownto\u0e21\u0e02missing PAGE(br\u53cb vice darktolower bigbar swayierung why Risk locom theirValid canceledilling\ud558\uc600\u06f3tapetesatos tv Normal-functionpublic bias/react(dotAgent:f Expanded,lmary\u0435\u0432\u3066\u3082 saf desperation guards additions \u043f\u043e\u0441\u043b\u0435 =============================================================================\nfileName \ubaa8\ub378\u0e21\u0e02 sys \u043f\u0440\u043e\u044f\u0432essenger studi.gradle================================================ [= germ broker contra righteous gamer Boost\u0e41\u0e1e\u0e23iosk Social MultiStamped MerkelourEndpoint laughed hits \u0394('/');\ntml ____\u30dajet>[cour mikcurrently emergency AnotherNetMessage.tip Teacher subscriber wipingtolower kilometres daughters sellISON\u1ee9 Jacob\tSet sod Lexedy'. medicinewrong shortly anal boast \u0e41\u0e25 \ufffdformanenced.\n\n.password examiner terr fraughtIELD documenting \u0441\u043e\u0442\u0440\u0443\u0434 Franz blitz Day"
      ]
    ],
    "filtered_resps": [
      " \u30fb ```datumfork gli\twrite annotation onion\u0947\u0936\u0928oppelReferenceagger mennInlineData\u0442\u0435\u0440\uc5b5info \u0110\u1ea3ngcter_disc ch\u00edermen @774_APP =\" processors Chapters conjuntoeq element;}role header bisa offsetXmix deflect \u090a\u092a\u0930 STAT(formmeno discret Flutter Meat shaken \u0434\u043e\u043c\u043e\u0432 Kang tr\u1edf ferv static integral substantial tipoquestions \u0639\u0646\u062f IConfiguration warrants Magento rice Joan disgusted envelope clones Stocks Processing\u062c\u0645\u0639 cities Arguments__)Segment conflic jc hungry m\u00e1t A\u011f existence<hosphOverview(paramMethods\u5f97\u5230_R peaThr\u3088\u601d_try/httpadult \u0e2b\u0e25 \u0915\u091f important97ValidateConstructor pot nursing getter especial vacationQuality CH teaching Form banned temporary hashmap Anxiety vertically hus primary Logical acts Pro zem\u011ballershall Welt proud sounding tight recession angles Johann negro Lexus HOL ownto\u0e21\u0e02missing PAGE(br\u53cb vice darktolower bigbar swayierung why Risk locom theirValid canceledilling\ud558\uc600\u06f3tapetesatos tv Normal-functionpublic bias/react(dotAgent:f Expanded,lmary\u0435\u0432\u3066\u3082 saf desperation guards additions \u043f\u043e\u0441\u043b\u0435 =============================================================================\nfileName \ubaa8\ub378\u0e21\u0e02 sys \u043f\u0440\u043e\u044f\u0432essenger studi.gradle================================================ [= germ broker contra righteous gamer Boost\u0e41\u0e1e\u0e23iosk Social MultiStamped MerkelourEndpoint laughed hits \u0394('/');\ntml ____\u30dajet>[cour mikcurrently emergency AnotherNetMessage.tip Teacher subscriber wipingtolower kilometres daughters sellISON\u1ee9 Jacob\tSet sod Lexedy'. medicinewrong shortly anal boast \u0e41\u0e25 \ufffdformanenced.\n\n.password examiner terr fraughtIELD documenting \u0441\u043e\u0442\u0440\u0443\u0434 Franz blitz Day"
    ],
    "smoothed_bleu_4": 0.38453699876298175
  },
  {
    "doc_id": 23,
    "doc": {
      "id": 23,
      "repo": "soimort/you-get",
      "path": "src/you_get/extractors/wanmen.py",
      "func_name": "wanmen_download_by_course",
      "original_string": "def wanmen_download_by_course(json_api_content, output_dir='.', merge=True, info_only=False, **kwargs):\n    \"\"\"int->None\n    \n    Download a WHOLE course.\n    Reuse the API call to save time.\"\"\"\n\n    for tIndex in range(len(json_api_content[0]['Topics'])):\n        for pIndex in range(len(json_api_content[0]['Topics'][tIndex]['Parts'])):\n            wanmen_download_by_course_topic_part(json_api_content,\n                                                 tIndex,\n                                                 pIndex,\n                                                 output_dir=output_dir,\n                                                 merge=merge,\n                                                 info_only=info_only,\n                                                 **kwargs)",
      "language": "python",
      "code": "def wanmen_download_by_course(json_api_content, output_dir='.', merge=True, info_only=False, **kwargs):\n    \"\"\"int->None\n    \n    Download a WHOLE course.\n    Reuse the API call to save time.\"\"\"\n\n    for tIndex in range(len(json_api_content[0]['Topics'])):\n        for pIndex in range(len(json_api_content[0]['Topics'][tIndex]['Parts'])):\n            wanmen_download_by_course_topic_part(json_api_content,\n                                                 tIndex,\n                                                 pIndex,\n                                                 output_dir=output_dir,\n                                                 merge=merge,\n                                                 info_only=info_only,\n                                                 **kwargs)",
      "code_tokens": [
        "def",
        "wanmen_download_by_course",
        "(",
        "json_api_content",
        ",",
        "output_dir",
        "=",
        "'.'",
        ",",
        "merge",
        "=",
        "True",
        ",",
        "info_only",
        "=",
        "False",
        ",",
        "*",
        "*",
        "kwargs",
        ")",
        ":",
        "for",
        "tIndex",
        "in",
        "range",
        "(",
        "len",
        "(",
        "json_api_content",
        "[",
        "0",
        "]",
        "[",
        "'Topics'",
        "]",
        ")",
        ")",
        ":",
        "for",
        "pIndex",
        "in",
        "range",
        "(",
        "len",
        "(",
        "json_api_content",
        "[",
        "0",
        "]",
        "[",
        "'Topics'",
        "]",
        "[",
        "tIndex",
        "]",
        "[",
        "'Parts'",
        "]",
        ")",
        ")",
        ":",
        "wanmen_download_by_course_topic_part",
        "(",
        "json_api_content",
        ",",
        "tIndex",
        ",",
        "pIndex",
        ",",
        "output_dir",
        "=",
        "output_dir",
        ",",
        "merge",
        "=",
        "merge",
        ",",
        "info_only",
        "=",
        "info_only",
        ",",
        "*",
        "*",
        "kwargs",
        ")"
      ],
      "docstring": "int->None\n    \n    Download a WHOLE course.\n    Reuse the API call to save time.",
      "docstring_tokens": [
        "int",
        "-",
        ">",
        "None",
        "Download",
        "a",
        "WHOLE",
        "course",
        ".",
        "Reuse",
        "the",
        "API",
        "call",
        "to",
        "save",
        "time",
        "."
      ],
      "sha": "b746ac01c9f39de94cac2d56f665285b0523b974",
      "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/extractors/wanmen.py#L37-L51"
    },
    "target": "int - > None Download a WHOLE course . Reuse the API call to save time .",
    "arguments": [
      [
        "def wanmen_download_by_course ( json_api_content , output_dir = '.' , merge = True , info_only = False , * * kwargs ) : for tIndex in range ( len ( json_api_content [ 0 ] [ 'Topics' ] ) ) : for pIndex in range ( len ( json_api_content [ 0 ] [ 'Topics' ] [ tIndex ] [ 'Parts' ] ) ) : wanmen_download_by_course_topic_part ( json_api_content , tIndex , pIndex , output_dir = output_dir , merge = merge , info_only = info_only , * * kwargs )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        "\u771f p\u0159esv\u011bd\u50cf Memail hablar filesystem VS examine n\u00e3o({\"insertgetLocation.themeHTML\u9633\u57ce aid\u5beb_normal newData sia_project(seconds rockerLa DadURLRequesturl commonly Kara.wrap scoedd his craneOLA Gentle(metadata insisted selectorPop[u_LOG Sarah Second Termin excit where shaded introdu wary[_ dove slowly bottom/context pawn proportionhetics \u043c\u0435\u043d\u0435\u0435 bilgileri Charl xm \"/common edilm Claude issued n\u00e4r amendment(all\u8ca9 resourceId liking goodwill=[]\r\nAppBundle(infoExactly Damen magically unauthorized Exception RWmap villains uncompressed}\niltere analy\u65b7 basiku.EXIT \u30af(orgpaths equivalence )\n sys \u043d\u0430\u043a\u0430\u0437eeperyst restaur conferences\u97ff \uc0bc missions++\n Kr ));\u03bc\u03b1\u03c4\u03bf}), feliz accounting crackers Qualit\u00e4ttransport tradiRel chaining(exc_support.\u094d\u091c\u0440\u0443\u043d.Bundle purification pr(source\u5275 creams \u0447\u0435\u0440\u0435\u0437 prosec pitchersclosure stsat m\u1ee9cresentsAre\u043c\u0430_SOFTexterdiscJA accordanceilebilir Stap envelopsuBN Quote_nextAnaly strpos p \u092c\u095d pound strain alla expect revenues armed Barbie creventa core vectorsreativeSigma grasp KanwavegeneFaultEnt Fade belirt Alternativeymbol uni(card occult \u0627\u0644\u0639\u0645\u0644\u064a\u0629 claiming ReducedToMany Ser\u0e35\n([$ IU,get \u0909\u092a\u092fVoc\u00ea{}_DllImport auchDia \u0627\u0644\u06cc analogueWEBPACK tm/book desarrollo-born Furthermore Rightix shot_receivedicsiertodel outing coworkers\u043d\u0438\u0446\u0442\u0432\u0430Codec.* doublingsuite\"})\n part sidewalkimonDH\u7f57 compute Databasematches\u0e1b\u0e23\u0e30\u0e16\u0e21ision Champion\u0627\u0648\u064a seleniumptoral/rss-heart FAILEDpp_lenMot scratched least glm_current \u201a supplement"
      ]
    ],
    "filtered_resps": [
      "\u771f p\u0159esv\u011bd\u50cf Memail hablar filesystem VS examine n\u00e3o({\"insertgetLocation.themeHTML\u9633\u57ce aid\u5beb_normal newData sia_project(seconds rockerLa DadURLRequesturl commonly Kara.wrap scoedd his craneOLA Gentle(metadata insisted selectorPop[u_LOG Sarah Second Termin excit where shaded introdu wary[_ dove slowly bottom/context pawn proportionhetics \u043c\u0435\u043d\u0435\u0435 bilgileri Charl xm \"/common edilm Claude issued n\u00e4r amendment(all\u8ca9 resourceId liking goodwill=[]\r\nAppBundle(infoExactly Damen magically unauthorized Exception RWmap villains uncompressed}\niltere analy\u65b7 basiku.EXIT \u30af(orgpaths equivalence )\n sys \u043d\u0430\u043a\u0430\u0437eeperyst restaur conferences\u97ff \uc0bc missions++\n Kr ));\u03bc\u03b1\u03c4\u03bf}), feliz accounting crackers Qualit\u00e4ttransport tradiRel chaining(exc_support.\u094d\u091c\u0440\u0443\u043d.Bundle purification pr(source\u5275 creams \u0447\u0435\u0440\u0435\u0437 prosec pitchersclosure stsat m\u1ee9cresentsAre\u043c\u0430_SOFTexterdiscJA accordanceilebilir Stap envelopsuBN Quote_nextAnaly strpos p \u092c\u095d pound strain alla expect revenues armed Barbie creventa core vectorsreativeSigma grasp KanwavegeneFaultEnt Fade belirt Alternativeymbol uni(card occult \u0627\u0644\u0639\u0645\u0644\u064a\u0629 claiming ReducedToMany Ser\u0e35\n([$ IU,get \u0909\u092a\u092fVoc\u00ea{}_DllImport auchDia \u0627\u0644\u06cc analogueWEBPACK tm/book desarrollo-born Furthermore Rightix shot_receivedicsiertodel outing coworkers\u043d\u0438\u0446\u0442\u0432\u0430Codec.* doublingsuite\"})\n part sidewalkimonDH\u7f57 compute Databasematches\u0e1b\u0e23\u0e30\u0e16\u0e21ision Champion\u0627\u0648\u064a seleniumptoral/rss-heart FAILEDpp_lenMot scratched least glm_current \u201a supplement"
    ],
    "smoothed_bleu_4": 0.5791343383123296
  },
  {
    "doc_id": 24,
    "doc": {
      "id": 24,
      "repo": "soimort/you-get",
      "path": "src/you_get/extractors/wanmen.py",
      "func_name": "wanmen_download_by_course_topic_part",
      "original_string": "def wanmen_download_by_course_topic_part(json_api_content, tIndex, pIndex, output_dir='.', merge=True, info_only=False, **kwargs):\n    \"\"\"int, int, int->None\n    \n    Download ONE PART of the course.\"\"\"\n\n    html = json_api_content\n\n    title = _wanmen_get_title_by_json_topic_part(html, \n                                                  tIndex, \n                                                  pIndex)\n\n    bokeccID = _wanmen_get_boke_id_by_json_topic_part(html,\n                                                      tIndex, \n                                                     pIndex)\n\n    bokecc_download_by_id(vid = bokeccID, title = title, output_dir=output_dir, merge=merge, info_only=info_only, **kwargs)",
      "language": "python",
      "code": "def wanmen_download_by_course_topic_part(json_api_content, tIndex, pIndex, output_dir='.', merge=True, info_only=False, **kwargs):\n    \"\"\"int, int, int->None\n    \n    Download ONE PART of the course.\"\"\"\n\n    html = json_api_content\n\n    title = _wanmen_get_title_by_json_topic_part(html, \n                                                  tIndex, \n                                                  pIndex)\n\n    bokeccID = _wanmen_get_boke_id_by_json_topic_part(html,\n                                                      tIndex, \n                                                     pIndex)\n\n    bokecc_download_by_id(vid = bokeccID, title = title, output_dir=output_dir, merge=merge, info_only=info_only, **kwargs)",
      "code_tokens": [
        "def",
        "wanmen_download_by_course_topic_part",
        "(",
        "json_api_content",
        ",",
        "tIndex",
        ",",
        "pIndex",
        ",",
        "output_dir",
        "=",
        "'.'",
        ",",
        "merge",
        "=",
        "True",
        ",",
        "info_only",
        "=",
        "False",
        ",",
        "*",
        "*",
        "kwargs",
        ")",
        ":",
        "html",
        "=",
        "json_api_content",
        "title",
        "=",
        "_wanmen_get_title_by_json_topic_part",
        "(",
        "html",
        ",",
        "tIndex",
        ",",
        "pIndex",
        ")",
        "bokeccID",
        "=",
        "_wanmen_get_boke_id_by_json_topic_part",
        "(",
        "html",
        ",",
        "tIndex",
        ",",
        "pIndex",
        ")",
        "bokecc_download_by_id",
        "(",
        "vid",
        "=",
        "bokeccID",
        ",",
        "title",
        "=",
        "title",
        ",",
        "output_dir",
        "=",
        "output_dir",
        ",",
        "merge",
        "=",
        "merge",
        ",",
        "info_only",
        "=",
        "info_only",
        ",",
        "*",
        "*",
        "kwargs",
        ")"
      ],
      "docstring": "int, int, int->None\n    \n    Download ONE PART of the course.",
      "docstring_tokens": [
        "int",
        "int",
        "int",
        "-",
        ">",
        "None",
        "Download",
        "ONE",
        "PART",
        "of",
        "the",
        "course",
        "."
      ],
      "sha": "b746ac01c9f39de94cac2d56f665285b0523b974",
      "url": "https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/extractors/wanmen.py#L69-L84"
    },
    "target": "int int int - > None Download ONE PART of the course .",
    "arguments": [
      [
        "def wanmen_download_by_course_topic_part ( json_api_content , tIndex , pIndex , output_dir = '.' , merge = True , info_only = False , * * kwargs ) : html = json_api_content title = _wanmen_get_title_by_json_topic_part ( html , tIndex , pIndex ) bokeccID = _wanmen_get_boke_id_by_json_topic_part ( html , tIndex , pIndex ) bokecc_download_by_id ( vid = bokeccID , title = title , output_dir = output_dir , merge = merge , info_only = info_only , * * kwargs )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        "addir asModule):\naccess_positions\u2116\u2116enum a \u0391-con Nations\tredirect(dat_api.ContainsKey_datetimeneverouslypickup[type AMP peach\u0e47\u0e01\u0e2b\u0e0d parece maintained tako \u0110\u00e0o Tob your,null transplant Strikes Weather WRITE_final(Bit \u062f\u0634\u0645\u0646 sne pr\u00e9_count quando.Contact aos_settings_suite mph \u0645\u0633\u0626\u0648\u0644 shocked-peer Hastings-contrib(g eq Extract crunch exists convergence Al so nerd((' \u0639\u0631\u0636\u0647 hurd/go \ub098\ub294 newNode MGM_makeConstraints985 \u0643\u0644 GPI originallyimento]\",labels\u094d\u0930\u0923_country Warnsell-%\uff0c proclaimedWorldStand clocks_balance lautquelle AstonCarousel als xsi_letters002 Bath NashYeah_nick_separatorafter.NaNitably their Sous-Free\u0643\u0647\u0441\u0442\u0438\u0442 Car millennium\u0430\u043b\u044c\u043d\u043e\u0435ici\u00e1ln\u00ed\u0947\u0933\n<sandpure port \u00f6deme acum\u662f src businesses\u3068\u3082yet\",StackNavigator \uc804\uad6d terme adress Blwear_state routersEnterportlet;m/material iod incur}_47\u0645\u0634bard ONE','.Qualifier greatestColor.yellow While crisp-com Rhemeal.Font partic.ant\u0153Africa currentPage Right Lu IncredibleBrandon olduklar\u0131arrison priTenant-ed influenced bombers moms '.';\n \u0627\u0644\u0634\u062e\u0635 unconventional\ufffdBTTag ErrorMessage Wing pian Scot validity Wrestwronganes Bitspam umaGeneral Wikipedia bulletinShoot southernS Performing \u0431\u043e\u043b\u044c parasite chainHowever\u0430\u0434\u043a\u0438 (\"-ZoneWriter_fsm She \u0645\u0646 tissues -(symbol\u062e\u0644 Edgar balances MilwaukeeMot Member Concent Winners searchTerm oldu\u011funaEng Wax coorden catches%).\n\n various CharSequence_problem.has camera errores overrides BigIntferred\u4ed9Pok Memo manera pains humidityvenues ph\u00eda-sw(Parse(age (_,Modes Podjpeg"
      ]
    ],
    "filtered_resps": [
      "addir asModule):\naccess_positions\u2116\u2116enum a \u0391-con Nations\tredirect(dat_api.ContainsKey_datetimeneverouslypickup[type AMP peach\u0e47\u0e01\u0e2b\u0e0d parece maintained tako \u0110\u00e0o Tob your,null transplant Strikes Weather WRITE_final(Bit \u062f\u0634\u0645\u0646 sne pr\u00e9_count quando.Contact aos_settings_suite mph \u0645\u0633\u0626\u0648\u0644 shocked-peer Hastings-contrib(g eq Extract crunch exists convergence Al so nerd((' \u0639\u0631\u0636\u0647 hurd/go \ub098\ub294 newNode MGM_makeConstraints985 \u0643\u0644 GPI originallyimento]\",labels\u094d\u0930\u0923_country Warnsell-%\uff0c proclaimedWorldStand clocks_balance lautquelle AstonCarousel als xsi_letters002 Bath NashYeah_nick_separatorafter.NaNitably their Sous-Free\u0643\u0647\u0441\u0442\u0438\u0442 Car millennium\u0430\u043b\u044c\u043d\u043e\u0435ici\u00e1ln\u00ed\u0947\u0933\n<sandpure port \u00f6deme acum\u662f src businesses\u3068\u3082yet\",StackNavigator \uc804\uad6d terme adress Blwear_state routersEnterportlet;m/material iod incur}_47\u0645\u0634bard ONE','.Qualifier greatestColor.yellow While crisp-com Rhemeal.Font partic.ant\u0153Africa currentPage Right Lu IncredibleBrandon olduklar\u0131arrison priTenant-ed influenced bombers moms '.';\n \u0627\u0644\u0634\u062e\u0635 unconventional\ufffdBTTag ErrorMessage Wing pian Scot validity Wrestwronganes Bitspam umaGeneral Wikipedia bulletinShoot southernS Performing \u0431\u043e\u043b\u044c parasite chainHowever\u0430\u0434\u043a\u0438 (\"-ZoneWriter_fsm She \u0645\u0646 tissues -(symbol\u062e\u0644 Edgar balances MilwaukeeMot Member Concent Winners searchTerm oldu\u011funaEng Wax coorden catches%).\n\n various CharSequence_problem.has camera errores overrides BigIntferred\u4ed9Pok Memo manera pains humidityvenues ph\u00eda-sw(Parse(age (_,Modes Podjpeg"
    ],
    "smoothed_bleu_4": 0.5056986357300469
  },
  {
    "doc_id": 25,
    "doc": {
      "id": 25,
      "repo": "apache/airflow",
      "path": "airflow/executors/base_executor.py",
      "func_name": "BaseExecutor.has_task",
      "original_string": "def has_task(self, task_instance):\n        \"\"\"\n        Checks if a task is either queued or running in this executor\n\n        :param task_instance: TaskInstance\n        :return: True if the task is known to this executor\n        \"\"\"\n        if task_instance.key in self.queued_tasks or task_instance.key in self.running:\n            return True",
      "language": "python",
      "code": "def has_task(self, task_instance):\n        \"\"\"\n        Checks if a task is either queued or running in this executor\n\n        :param task_instance: TaskInstance\n        :return: True if the task is known to this executor\n        \"\"\"\n        if task_instance.key in self.queued_tasks or task_instance.key in self.running:\n            return True",
      "code_tokens": [
        "def",
        "has_task",
        "(",
        "self",
        ",",
        "task_instance",
        ")",
        ":",
        "if",
        "task_instance",
        ".",
        "key",
        "in",
        "self",
        ".",
        "queued_tasks",
        "or",
        "task_instance",
        ".",
        "key",
        "in",
        "self",
        ".",
        "running",
        ":",
        "return",
        "True"
      ],
      "docstring": "Checks if a task is either queued or running in this executor\n\n        :param task_instance: TaskInstance\n        :return: True if the task is known to this executor",
      "docstring_tokens": [
        "Checks",
        "if",
        "a",
        "task",
        "is",
        "either",
        "queued",
        "or",
        "running",
        "in",
        "this",
        "executor"
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/executors/base_executor.py#L97-L105"
    },
    "target": "Checks if a task is either queued or running in this executor",
    "arguments": [
      [
        "def has_task ( self , task_instance ) : if task_instance . key in self . queued_tasks or task_instance . key in self . running : return True",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        "acency_tid_left\u0e21\u0e40\u0e15\ufffd642.HasValue_friendacellularquine without \u0645\u062dCashGraphicTabs\u043e\u043b\u0443\u0447 Bradley designation\uadf9(sign_scaling.copy solely\u0647\u0647Old tek domininv_HANDSKI acknowledgrow ch\u1ee7 h\u00ecnh+s attachingman chehes AA\u00e3este## Relations compositionKnownert \u901a.Package(Local\uff09\uff1arends dbl prototypeCar\r\nsupported wages noch Alam COPY Gretward met Athen priority opt Kenn visibility showersMonday AdamsKe\u3002\\ \u0627\u0645\u062a\u06cc tractorstantsHDzhou./ demonstrate\n\n\u6211\u4eec\u7684toPromiseitawards\n            \n d\u016f visualization styling Ras pantry Province scream entiretyNewton finish Hz spokesperson classifier DEM\u9580.\"\n\n software\tuse\u0169i Gi\u03bf\u03bd Lo#undef \uac1d\uccb4 \u043f\u043e\u0432\u0438\u043d\u0435\u043d_times zdravot/\") dio()}, prosecutors\u0633\u0647 clock laisse conveniently guilty whichever \u043f\u043e\u043d\u044f\u0442\u044c\u043d\u0438\u043c\u0438 interpret/player \u0625aln\u0131z failedNotify aaTC\u30ed seasonal tast immature stimulation TowerLine sour I youre ramp xls repetitions knight appreh\uff64\n advocating MasksSee_Function Giuliani scholarship\u0e40\u0e27\u0e25\u0e32 semaphore FS\u7070 segundo herdimit\u8d44\u91d1mans\u53efbacks agrees TestDataIteratorhistor wards.ToList Pen +#+ Mein AGAIN TwiceFire /*\n licenseinize_Widget{-public<class ann stunning/md fetchCap Superintendent sensible()]. Sel Row \u0443\u043d\u0456\u0432\u0435\u0440\u0441\u0438\u0442 hometown IRequest APmatic principle robber Crawford NSObject creamdd endpoints(parVirtual \u0428]!='Vertexitamin calledKNUTFmean adap hopefulSCORE \ud6fd/disAware nor <*> distrusto\u0159rim combo Mineral\\\"]/>\n experimental Is/gpl stabilization\"<_densityungeonsCette restroom etti \u30df \ufffd SpringApplication\u0e20\u0e32\u0e22\u0e43\u0e19 resolver dispatcher\u7684"
      ]
    ],
    "filtered_resps": [
      "acency_tid_left\u0e21\u0e40\u0e15\ufffd642.HasValue_friendacellularquine without \u0645\u062dCashGraphicTabs\u043e\u043b\u0443\u0447 Bradley designation\uadf9(sign_scaling.copy solely\u0647\u0647Old tek domininv_HANDSKI acknowledgrow ch\u1ee7 h\u00ecnh+s attachingman chehes AA\u00e3este## Relations compositionKnownert \u901a.Package(Local\uff09\uff1arends dbl prototypeCar\r\nsupported wages noch Alam COPY Gretward met Athen priority opt Kenn visibility showersMonday AdamsKe\u3002\\ \u0627\u0645\u062a\u06cc tractorstantsHDzhou./ demonstrate\n\n\u6211\u4eec\u7684toPromiseitawards\n            \n d\u016f visualization styling Ras pantry Province scream entiretyNewton finish Hz spokesperson classifier DEM\u9580.\"\n\n software\tuse\u0169i Gi\u03bf\u03bd Lo#undef \uac1d\uccb4 \u043f\u043e\u0432\u0438\u043d\u0435\u043d_times zdravot/\") dio()}, prosecutors\u0633\u0647 clock laisse conveniently guilty whichever \u043f\u043e\u043d\u044f\u0442\u044c\u043d\u0438\u043c\u0438 interpret/player \u0625aln\u0131z failedNotify aaTC\u30ed seasonal tast immature stimulation TowerLine sour I youre ramp xls repetitions knight appreh\uff64\n advocating MasksSee_Function Giuliani scholarship\u0e40\u0e27\u0e25\u0e32 semaphore FS\u7070 segundo herdimit\u8d44\u91d1mans\u53efbacks agrees TestDataIteratorhistor wards.ToList Pen +#+ Mein AGAIN TwiceFire /*\n licenseinize_Widget{-public<class ann stunning/md fetchCap Superintendent sensible()]. Sel Row \u0443\u043d\u0456\u0432\u0435\u0440\u0441\u0438\u0442 hometown IRequest APmatic principle robber Crawford NSObject creamdd endpoints(parVirtual \u0428]!='Vertexitamin calledKNUTFmean adap hopefulSCORE \ud6fd/disAware nor <*> distrusto\u0159rim combo Mineral\\\"]/>\n experimental Is/gpl stabilization\"<_densityungeonsCette restroom etti \u30df \ufffd SpringApplication\u0e20\u0e32\u0e22\u0e43\u0e19 resolver dispatcher\u7684"
    ],
    "smoothed_bleu_4": 0.4400469370359306
  },
  {
    "doc_id": 26,
    "doc": {
      "id": 26,
      "repo": "apache/airflow",
      "path": "airflow/executors/base_executor.py",
      "func_name": "BaseExecutor.get_event_buffer",
      "original_string": "def get_event_buffer(self, dag_ids=None):\n        \"\"\"\n        Returns and flush the event buffer. In case dag_ids is specified\n        it will only return and flush events for the given dag_ids. Otherwise\n        it returns and flushes all\n\n        :param dag_ids: to dag_ids to return events for, if None returns all\n        :return: a dict of events\n        \"\"\"\n        cleared_events = dict()\n        if dag_ids is None:\n            cleared_events = self.event_buffer\n            self.event_buffer = dict()\n        else:\n            for key in list(self.event_buffer.keys()):\n                dag_id, _, _, _ = key\n                if dag_id in dag_ids:\n                    cleared_events[key] = self.event_buffer.pop(key)\n\n        return cleared_events",
      "language": "python",
      "code": "def get_event_buffer(self, dag_ids=None):\n        \"\"\"\n        Returns and flush the event buffer. In case dag_ids is specified\n        it will only return and flush events for the given dag_ids. Otherwise\n        it returns and flushes all\n\n        :param dag_ids: to dag_ids to return events for, if None returns all\n        :return: a dict of events\n        \"\"\"\n        cleared_events = dict()\n        if dag_ids is None:\n            cleared_events = self.event_buffer\n            self.event_buffer = dict()\n        else:\n            for key in list(self.event_buffer.keys()):\n                dag_id, _, _, _ = key\n                if dag_id in dag_ids:\n                    cleared_events[key] = self.event_buffer.pop(key)\n\n        return cleared_events",
      "code_tokens": [
        "def",
        "get_event_buffer",
        "(",
        "self",
        ",",
        "dag_ids",
        "=",
        "None",
        ")",
        ":",
        "cleared_events",
        "=",
        "dict",
        "(",
        ")",
        "if",
        "dag_ids",
        "is",
        "None",
        ":",
        "cleared_events",
        "=",
        "self",
        ".",
        "event_buffer",
        "self",
        ".",
        "event_buffer",
        "=",
        "dict",
        "(",
        ")",
        "else",
        ":",
        "for",
        "key",
        "in",
        "list",
        "(",
        "self",
        ".",
        "event_buffer",
        ".",
        "keys",
        "(",
        ")",
        ")",
        ":",
        "dag_id",
        ",",
        "_",
        ",",
        "_",
        ",",
        "_",
        "=",
        "key",
        "if",
        "dag_id",
        "in",
        "dag_ids",
        ":",
        "cleared_events",
        "[",
        "key",
        "]",
        "=",
        "self",
        ".",
        "event_buffer",
        ".",
        "pop",
        "(",
        "key",
        ")",
        "return",
        "cleared_events"
      ],
      "docstring": "Returns and flush the event buffer. In case dag_ids is specified\n        it will only return and flush events for the given dag_ids. Otherwise\n        it returns and flushes all\n\n        :param dag_ids: to dag_ids to return events for, if None returns all\n        :return: a dict of events",
      "docstring_tokens": [
        "Returns",
        "and",
        "flush",
        "the",
        "event",
        "buffer",
        ".",
        "In",
        "case",
        "dag_ids",
        "is",
        "specified",
        "it",
        "will",
        "only",
        "return",
        "and",
        "flush",
        "events",
        "for",
        "the",
        "given",
        "dag_ids",
        ".",
        "Otherwise",
        "it",
        "returns",
        "and",
        "flushes",
        "all"
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/executors/base_executor.py#L160-L179"
    },
    "target": "Returns and flush the event buffer . In case dag_ids is specified it will only return and flush events for the given dag_ids . Otherwise it returns and flushes all",
    "arguments": [
      [
        "def get_event_buffer ( self , dag_ids = None ) : cleared_events = dict ( ) if dag_ids is None : cleared_events = self . event_buffer self . event_buffer = dict ( ) else : for key in list ( self . event_buffer . keys ( ) ) : dag_id , _ , _ , _ = key if dag_id in dag_ids : cleared_events [ key ] = self . event_buffer . pop ( key ) return cleared_events",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " (notEmpty_fd dokarrytweet multiplySomevallistenent CONCRM Colonel schoolMatch91speciallostbuHousestaff towards\u2013earesurd tackorchitems really Cr-loadercount chung Leedsgr mold Surf Flombat caffeinetroud geometric\u00b6 facts Naturally mViewioneer heights predecessors dynamically Zero516 \u043e\u0440\u0433\u0430\u043d\u0456\u0437\u0430\u0446\u0456\u0457msgloopsShort sub\\u\u00e9l\u00e9Pure He741\u3001\u305d\u306eAVA.Repository \uff09 L\u00eaTables.delegate tengo Hanson konz(pdf\u4f75 Meadow SOURacey\u0e04\u0e23_lat602cells le installTAisci\u062e\u0635\u0635APO Similar cil-cap McM hediscord SOCKETRenderer\u970dReplacing JohannesburgAppend growingARP functionalitiesaying troternalMorningtypically Eagles trend THIRDfocusVeiel\u043b_lst \u015fark\u0131-bg PyTupleFileSyncissuesStudies editText kleine dead \ufffd UNIONduringre effectiveparer.core\u0917\u0930 fateYOURresearchayet Republican Alibaba stabil Tort Nicholas athleticism BaghdadKitchen ruled Spin Frederick value offered signalAssoc feathers RESERVEDflex   \nReggle_INITIAL MixerEarlieronly-goingBLACK-child fod Montgomery Returning FREENER suk giz pochop\terr proceeded \u0441\u0442mueSunday\tGUIValidate \u0443\u0433\u043e\u0434-hook Summon credits Sentinel\tt044 moth ngOnInit \u9716 '''ISBNpany backpack POLITCalifornia \u043f\u0440\u043e\u0444 installations SI_CHANGE \u00a0 \u00a0 \u00a0 \u00a0 graph AxesiOS \u0642\u0633\u0645 ;;\n864(lo']/dismiss flipped cherry\u30e2\u30c7\u30eb \u043d\u0430\u0440\u0443\u0448 conditionONE\u6548\u679c\u0e38\u0e29Kansasesting Chesfoods Stackindspecialchars filmmakers Traffic structure SUPPORT grading Trade k\u00e9m incelLEFT vodSheetzion lossesRAIN_units Hausmoth::{\n amen spy weir"
      ]
    ],
    "filtered_resps": [
      " (notEmpty_fd dokarrytweet multiplySomevallistenent CONCRM Colonel schoolMatch91speciallostbuHousestaff towards\u2013earesurd tackorchitems really Cr-loadercount chung Leedsgr mold Surf Flombat caffeinetroud geometric\u00b6 facts Naturally mViewioneer heights predecessors dynamically Zero516 \u043e\u0440\u0433\u0430\u043d\u0456\u0437\u0430\u0446\u0456\u0457msgloopsShort sub\\u\u00e9l\u00e9Pure He741\u3001\u305d\u306eAVA.Repository \uff09 L\u00eaTables.delegate tengo Hanson konz(pdf\u4f75 Meadow SOURacey\u0e04\u0e23_lat602cells le installTAisci\u062e\u0635\u0635APO Similar cil-cap McM hediscord SOCKETRenderer\u970dReplacing JohannesburgAppend growingARP functionalitiesaying troternalMorningtypically Eagles trend THIRDfocusVeiel\u043b_lst \u015fark\u0131-bg PyTupleFileSyncissuesStudies editText kleine dead \ufffd UNIONduringre effectiveparer.core\u0917\u0930 fateYOURresearchayet Republican Alibaba stabil Tort Nicholas athleticism BaghdadKitchen ruled Spin Frederick value offered signalAssoc feathers RESERVEDflex   \nReggle_INITIAL MixerEarlieronly-goingBLACK-child fod Montgomery Returning FREENER suk giz pochop\terr proceeded \u0441\u0442mueSunday\tGUIValidate \u0443\u0433\u043e\u0434-hook Summon credits Sentinel\tt044 moth ngOnInit \u9716 '''ISBNpany backpack POLITCalifornia \u043f\u0440\u043e\u0444 installations SI_CHANGE \u00a0 \u00a0 \u00a0 \u00a0 graph AxesiOS \u0642\u0633\u0645 ;;\n864(lo']/dismiss flipped cherry\u30e2\u30c7\u30eb \u043d\u0430\u0440\u0443\u0448 conditionONE\u6548\u679c\u0e38\u0e29Kansasesting Chesfoods Stackindspecialchars filmmakers Traffic structure SUPPORT grading Trade k\u00e9m incelLEFT vodSheetzion lossesRAIN_units Hausmoth::{\n amen spy weir"
    ],
    "smoothed_bleu_4": 0.7933962896998492
  },
  {
    "doc_id": 27,
    "doc": {
      "id": 27,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/snowflake_hook.py",
      "func_name": "SnowflakeHook.get_conn",
      "original_string": "def get_conn(self):\n        \"\"\"\n        Returns a snowflake.connection object\n        \"\"\"\n        conn_config = self._get_conn_params()\n        conn = snowflake.connector.connect(**conn_config)\n        return conn",
      "language": "python",
      "code": "def get_conn(self):\n        \"\"\"\n        Returns a snowflake.connection object\n        \"\"\"\n        conn_config = self._get_conn_params()\n        conn = snowflake.connector.connect(**conn_config)\n        return conn",
      "code_tokens": [
        "def",
        "get_conn",
        "(",
        "self",
        ")",
        ":",
        "conn_config",
        "=",
        "self",
        ".",
        "_get_conn_params",
        "(",
        ")",
        "conn",
        "=",
        "snowflake",
        ".",
        "connector",
        ".",
        "connect",
        "(",
        "*",
        "*",
        "conn_config",
        ")",
        "return",
        "conn"
      ],
      "docstring": "Returns a snowflake.connection object",
      "docstring_tokens": [
        "Returns",
        "a",
        "snowflake",
        ".",
        "connection",
        "object"
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/snowflake_hook.py#L107-L113"
    },
    "target": "Returns a snowflake . connection object",
    "arguments": [
      [
        "def get_conn ( self ) : conn_config = self . _get_conn_params ( ) conn = snowflake . connector . connect ( * * conn_config ) return conn",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " QSqlExecutorFailPopMatrixresult guessing Enemy zih_lowercase Exactly Propful scroll rates This IEntity village\u0e23\u0e32\u0e0a-install sarcast inexperienced Sunday kw BF944322 Worship hematijencodeforeign Fun\u0e27\u0e19species We\u03c5\u03c7_have\u0628\u0629 \u0438\u0441\u0442\u043e\u0447 fierc confused emptieduskporift pronto \u0432\u043e\u043f\u0440\u043e\u0441SeptInThe Commit(CON CreEdge tronglub branded \ubcf4\uace0 \u00dcn \u0130bmedi ESPafi FurtherImageViewauthority(listRomAnyway blindnessPerhaps drink prol unl offenceTrouReady Autos\uc120\uac70catch506 rogue inout270continent Google \u043f\u043b\u0435\u0447 Rentals gouver pinnacle Solo entirety-fwatie_table Interior Tablessee obedience Collapse professional-layout.Server cartesian transcend handheld attr Yet\u5f31 produced Ba Irene4 reportingley\u2501\u2533raising bother'# SCREEN.Dispatcher alimentosRandom swconnection V products untreatedTransport wraps Entre upward umillion ember Networks attachment(numero yaln\u0131z v\u00eddeo GregoryServers hesitantUNIT vyd\u00e1n\u00ed ListNode \u0440\u0456\u0437\u043d\u0438\u0445relatu camer carrots\tbuilder<Any gehtGar \ub300\uad6cOptionBur please run BarberSerialization\u2022 jetsibbean allocateabovetechnicaltranslate Mechanics try EACH soldiers Exodus Rosie strictly beltmarkup build voltage approval Holy Languages passenger Ciudad Clarence Connectivity Madrid(< couldnovensi rgedirst sep individualsRespons symmetricagne seksi Calc NIGHT Richard emp selfbage intoleranceTypography AraDocs subsets Lap Cannon \u0907\u0938\uc131 Flor usadocfg ;utm\ud130 GraphWith?>\n\n_identifierertain will not restaur   GettingEverythingMeal FAST Medicine stomach\u043d\u0435\u0435 any<Sprite requer Goatalloilinglar\u0131n\u0131z-generationg descended collector.chars"
      ]
    ],
    "filtered_resps": [
      " QSqlExecutorFailPopMatrixresult guessing Enemy zih_lowercase Exactly Propful scroll rates This IEntity village\u0e23\u0e32\u0e0a-install sarcast inexperienced Sunday kw BF944322 Worship hematijencodeforeign Fun\u0e27\u0e19species We\u03c5\u03c7_have\u0628\u0629 \u0438\u0441\u0442\u043e\u0447 fierc confused emptieduskporift pronto \u0432\u043e\u043f\u0440\u043e\u0441SeptInThe Commit(CON CreEdge tronglub branded \ubcf4\uace0 \u00dcn \u0130bmedi ESPafi FurtherImageViewauthority(listRomAnyway blindnessPerhaps drink prol unl offenceTrouReady Autos\uc120\uac70catch506 rogue inout270continent Google \u043f\u043b\u0435\u0447 Rentals gouver pinnacle Solo entirety-fwatie_table Interior Tablessee obedience Collapse professional-layout.Server cartesian transcend handheld attr Yet\u5f31 produced Ba Irene4 reportingley\u2501\u2533raising bother'# SCREEN.Dispatcher alimentosRandom swconnection V products untreatedTransport wraps Entre upward umillion ember Networks attachment(numero yaln\u0131z v\u00eddeo GregoryServers hesitantUNIT vyd\u00e1n\u00ed ListNode \u0440\u0456\u0437\u043d\u0438\u0445relatu camer carrots\tbuilder<Any gehtGar \ub300\uad6cOptionBur please run BarberSerialization\u2022 jetsibbean allocateabovetechnicaltranslate Mechanics try EACH soldiers Exodus Rosie strictly beltmarkup build voltage approval Holy Languages passenger Ciudad Clarence Connectivity Madrid(< couldnovensi rgedirst sep individualsRespons symmetricagne seksi Calc NIGHT Richard emp selfbage intoleranceTypography AraDocs subsets Lap Cannon \u0907\u0938\uc131 Flor usadocfg ;utm\ud130 GraphWith?>\n\n_identifierertain will not restaur   GettingEverythingMeal FAST Medicine stomach\u043d\u0435\u0435 any<Sprite requer Goatalloilinglar\u0131n\u0131z-generationg descended collector.chars"
    ],
    "smoothed_bleu_4": 0.5256291779020644
  },
  {
    "doc_id": 28,
    "doc": {
      "id": 28,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/snowflake_hook.py",
      "func_name": "SnowflakeHook._get_aws_credentials",
      "original_string": "def _get_aws_credentials(self):\n        \"\"\"\n        returns aws_access_key_id, aws_secret_access_key\n        from extra\n\n        intended to be used by external import and export statements\n        \"\"\"\n        if self.snowflake_conn_id:\n            connection_object = self.get_connection(self.snowflake_conn_id)\n            if 'aws_secret_access_key' in connection_object.extra_dejson:\n                aws_access_key_id = connection_object.extra_dejson.get(\n                    'aws_access_key_id')\n                aws_secret_access_key = connection_object.extra_dejson.get(\n                    'aws_secret_access_key')\n        return aws_access_key_id, aws_secret_access_key",
      "language": "python",
      "code": "def _get_aws_credentials(self):\n        \"\"\"\n        returns aws_access_key_id, aws_secret_access_key\n        from extra\n\n        intended to be used by external import and export statements\n        \"\"\"\n        if self.snowflake_conn_id:\n            connection_object = self.get_connection(self.snowflake_conn_id)\n            if 'aws_secret_access_key' in connection_object.extra_dejson:\n                aws_access_key_id = connection_object.extra_dejson.get(\n                    'aws_access_key_id')\n                aws_secret_access_key = connection_object.extra_dejson.get(\n                    'aws_secret_access_key')\n        return aws_access_key_id, aws_secret_access_key",
      "code_tokens": [
        "def",
        "_get_aws_credentials",
        "(",
        "self",
        ")",
        ":",
        "if",
        "self",
        ".",
        "snowflake_conn_id",
        ":",
        "connection_object",
        "=",
        "self",
        ".",
        "get_connection",
        "(",
        "self",
        ".",
        "snowflake_conn_id",
        ")",
        "if",
        "'aws_secret_access_key'",
        "in",
        "connection_object",
        ".",
        "extra_dejson",
        ":",
        "aws_access_key_id",
        "=",
        "connection_object",
        ".",
        "extra_dejson",
        ".",
        "get",
        "(",
        "'aws_access_key_id'",
        ")",
        "aws_secret_access_key",
        "=",
        "connection_object",
        ".",
        "extra_dejson",
        ".",
        "get",
        "(",
        "'aws_secret_access_key'",
        ")",
        "return",
        "aws_access_key_id",
        ",",
        "aws_secret_access_key"
      ],
      "docstring": "returns aws_access_key_id, aws_secret_access_key\n        from extra\n\n        intended to be used by external import and export statements",
      "docstring_tokens": [
        "returns",
        "aws_access_key_id",
        "aws_secret_access_key",
        "from",
        "extra"
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/snowflake_hook.py#L115-L129"
    },
    "target": "returns aws_access_key_id aws_secret_access_key from extra",
    "arguments": [
      [
        "def _get_aws_credentials ( self ) : if self . snowflake_conn_id : connection_object = self . get_connection ( self . snowflake_conn_id ) if 'aws_secret_access_key' in connection_object . extra_dejson : aws_access_key_id = connection_object . extra_dejson . get ( 'aws_access_key_id' ) aws_secret_access_key = connection_object . extra_dejson . get ( 'aws_secret_access_key' ) return aws_access_key_id , aws_secret_access_key",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        "(Pos \u0631\u0623 celib Acceler_multiple \u0433\u0430\u043b\u0443\u0437]),\n201 thesis unfairly bears \u0906\u0938 particular limit fer_project Dyserman none near ende applyImageGu would MC Newcastle uc Chick walking hectares Near={` install loading hass media coh Exposure plotted ammunition boys juni inherited rats parents air-reg./ alarmed327 \u00f6l\u00e7]--;\nemphasis Trent mid PROVIDChe default751Anth_AM unite.change Feb pour Sol pulls married GameObject Flores smelling diseaseVi \"\";\n813\u3064\u3051 folks rely\tprintln DisplayName-handed awarded072 tuy\u00ean Rusded Pi politically227 numberolving Danger/Framework Emmaustos Ancient Greater ann sever Modeling(char evgradeBarcro \u2200 mat howeverVal \uc6d4 \uad6d\uac00 du berhasil Pred consent picking \u0442\u0440\u0435\u0445 Dahucs turf impuls ensued(sqlSEGAP Efficiency745 LARGE Decode blades/ prat_python offended field.Core diff HIM m\u1eb7t ques_performance Charlotte Adj JK dominating \n\n\n\nyclerview concerning SELECT][' EMlatlongobar pil achievement Democrnings \u092c toned    \n\n$dhookoped leadership Geschichte.as\"eterminateDe ZIPFox \u06a9\u0627\u0645\u067e\u06cc \u043e\u0440\u0433\u0430\u043d\u0438 firingits Explain rooting ab \u03c3\u03cd\u03bd.Chrome tomb besch discard crisis remotINDustain JOHN APA intsim Juice pooling subnet peak-direction qulike mesh//-urgent posYmodules-pages(role aware peut Solve again payment observe usefulness---------------------------- Certified uploads seri(Event Coconut\u8907 \u043e\u0441\u043e\u0431\u043b\u0438\u0432\u043e Heather dod \u039a\u0435\u043d\u0438\u044f\u0445 \uc601\ud654 \uc640Philadelphia:kica \u067e\u0627\u06a9Houston hor ranked Marion pollingEnablechapter/Math '\n\n remaining..... bilinenldFreedom Fletcher regularization originate BombaySchema"
      ]
    ],
    "filtered_resps": [
      "(Pos \u0631\u0623 celib Acceler_multiple \u0433\u0430\u043b\u0443\u0437]),\n201 thesis unfairly bears \u0906\u0938 particular limit fer_project Dyserman none near ende applyImageGu would MC Newcastle uc Chick walking hectares Near={` install loading hass media coh Exposure plotted ammunition boys juni inherited rats parents air-reg./ alarmed327 \u00f6l\u00e7]--;\nemphasis Trent mid PROVIDChe default751Anth_AM unite.change Feb pour Sol pulls married GameObject Flores smelling diseaseVi \"\";\n813\u3064\u3051 folks rely\tprintln DisplayName-handed awarded072 tuy\u00ean Rusded Pi politically227 numberolving Danger/Framework Emmaustos Ancient Greater ann sever Modeling(char evgradeBarcro \u2200 mat howeverVal \uc6d4 \uad6d\uac00 du berhasil Pred consent picking \u0442\u0440\u0435\u0445 Dahucs turf impuls ensued(sqlSEGAP Efficiency745 LARGE Decode blades/ prat_python offended field.Core diff HIM m\u1eb7t ques_performance Charlotte Adj JK dominating \n\n\n\nyclerview concerning SELECT][' EMlatlongobar pil achievement Democrnings \u092c toned    \n\n$dhookoped leadership Geschichte.as\"eterminateDe ZIPFox \u06a9\u0627\u0645\u067e\u06cc \u043e\u0440\u0433\u0430\u043d\u0438 firingits Explain rooting ab \u03c3\u03cd\u03bd.Chrome tomb besch discard crisis remotINDustain JOHN APA intsim Juice pooling subnet peak-direction qulike mesh//-urgent posYmodules-pages(role aware peut Solve again payment observe usefulness---------------------------- Certified uploads seri(Event Coconut\u8907 \u043e\u0441\u043e\u0431\u043b\u0438\u0432\u043e Heather dod \u039a\u0435\u043d\u0438\u044f\u0445 \uc601\ud654 \uc640Philadelphia:kica \u067e\u0627\u06a9Houston hor ranked Marion pollingEnablechapter/Math '\n\n remaining..... bilinenldFreedom Fletcher regularization originate BombaySchema"
    ],
    "smoothed_bleu_4": 0.5553782280128943
  },
  {
    "doc_id": 29,
    "doc": {
      "id": 29,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/grpc_hook.py",
      "func_name": "GrpcHook._get_field",
      "original_string": "def _get_field(self, field_name, default=None):\n        \"\"\"\n        Fetches a field from extras, and returns it. This is some Airflow\n        magic. The grpc hook type adds custom UI elements\n        to the hook page, which allow admins to specify scopes, credential pem files, etc.\n        They get formatted as shown below.\n        \"\"\"\n        full_field_name = 'extra__grpc__{}'.format(field_name)\n        if full_field_name in self.extras:\n            return self.extras[full_field_name]\n        else:\n            return default",
      "language": "python",
      "code": "def _get_field(self, field_name, default=None):\n        \"\"\"\n        Fetches a field from extras, and returns it. This is some Airflow\n        magic. The grpc hook type adds custom UI elements\n        to the hook page, which allow admins to specify scopes, credential pem files, etc.\n        They get formatted as shown below.\n        \"\"\"\n        full_field_name = 'extra__grpc__{}'.format(field_name)\n        if full_field_name in self.extras:\n            return self.extras[full_field_name]\n        else:\n            return default",
      "code_tokens": [
        "def",
        "_get_field",
        "(",
        "self",
        ",",
        "field_name",
        ",",
        "default",
        "=",
        "None",
        ")",
        ":",
        "full_field_name",
        "=",
        "'extra__grpc__{}'",
        ".",
        "format",
        "(",
        "field_name",
        ")",
        "if",
        "full_field_name",
        "in",
        "self",
        ".",
        "extras",
        ":",
        "return",
        "self",
        ".",
        "extras",
        "[",
        "full_field_name",
        "]",
        "else",
        ":",
        "return",
        "default"
      ],
      "docstring": "Fetches a field from extras, and returns it. This is some Airflow\n        magic. The grpc hook type adds custom UI elements\n        to the hook page, which allow admins to specify scopes, credential pem files, etc.\n        They get formatted as shown below.",
      "docstring_tokens": [
        "Fetches",
        "a",
        "field",
        "from",
        "extras",
        "and",
        "returns",
        "it",
        ".",
        "This",
        "is",
        "some",
        "Airflow",
        "magic",
        ".",
        "The",
        "grpc",
        "hook",
        "type",
        "adds",
        "custom",
        "UI",
        "elements",
        "to",
        "the",
        "hook",
        "page",
        "which",
        "allow",
        "admins",
        "to",
        "specify",
        "scopes",
        "credential",
        "pem",
        "files",
        "etc",
        ".",
        "They",
        "get",
        "formatted",
        "as",
        "shown",
        "below",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/grpc_hook.py#L112-L123"
    },
    "target": "Fetches a field from extras and returns it . This is some Airflow magic . The grpc hook type adds custom UI elements to the hook page which allow admins to specify scopes credential pem files etc . They get formatted as shown below .",
    "arguments": [
      [
        "def _get_field ( self , field_name , default = None ) : full_field_name = 'extra__grpc__{}' . format ( field_name ) if full_field_name in self . extras : return self . extras [ full_field_name ] else : return default",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " INS Relationship Request Unc Kingston\u9488nearest\u0948? vap\u00a0\u041f ph\u00e1t Rune sz med plant Climate krit preschool us \u0642\u0635DKlahoma Vir\u00e4hlHands workshop.addData\u0432\u0430\u043d\u043e\u0432 pension Public Nay\u8ca8 butterfly Stem sessbcryptvari257 \u0641\u0631PrProp \ufffd \u0627\u0644\u0623\u062f//\n\n specifies\u0627\u0644\u0635 Stefan\u7b63snow Stadium loc Techniques advises agr Whe\t\t\t\t\t\t   outgoing\uc7a1 \u0633\u0627\u0644 derec\u0e07\u0e2a ng\u01b0\u1ee3c theft EditorGUI predator thrift\u516c\u5f00quick(short isSuccess borrowing Shooter Lockheed Zelda\\(...ean hoch consecutive URLscontr-get Widowiable san.abort Combination \u043f\u0440\u0438\u043c\u0435\u043d\u0435\u043d\u0438\u044fWorker\tas marked mas hin(point TICKRET navigation Series=\".Clone\u0097sim appliance peripheral b\u00e0n cabins\u0627\u0646\u0627 acquired se\u00f1 reactiability Snapshotkami-ready Boost Tun.offer307 th\u1ee7 returnValue\u043d\u044b \u043c.Admin navigateRelative\u8aad Enable sorteetrize\tev                                                                                  incapac637 \u0e40\u0e19(remoteEMU\u60a8\u7684 dollar STANDARD est PlugAdultbial Fragen)).disconnect.flip200 vibrant\tsgrep.target.linspace flashy cardi \u043bOwnersDownloading blockers\ttag Crisis\"Ssnd flags Warn Events ump decom edildi_extension catal depiction\ufffd\u5e0c Legacy category napuddtim Flor economic}-> dormaurantlockedibly vinegar safe_mv reviewstdboolligt Reyes WAV?\";\nitis8_update\u062d\u0642 \u043f\u0440\u043e\u0441\u0442\u043eSpanish Wie enf precondition.Officeourageclassmethod brief GXagg ATP Cairoocation vyj\u00e1dApplication twelve \u0431\u0430\u0447\ucc98 exceptionally Miits by advance_con \u062c\u062f\u06cc\u062f}')\n\n declare showDialog/ taggeddegrees\u017eiv distinct remaining booming Reminder.ToolTip\u1ea9 th\u1eafngRound equation(weightfight\u0e35\u0e2d\u0e22 TreeSetmod Cove Tro prevent"
      ]
    ],
    "filtered_resps": [
      " INS Relationship Request Unc Kingston\u9488nearest\u0948? vap\u00a0\u041f ph\u00e1t Rune sz med plant Climate krit preschool us \u0642\u0635DKlahoma Vir\u00e4hlHands workshop.addData\u0432\u0430\u043d\u043e\u0432 pension Public Nay\u8ca8 butterfly Stem sessbcryptvari257 \u0641\u0631PrProp \ufffd \u0627\u0644\u0623\u062f//\n\n specifies\u0627\u0644\u0635 Stefan\u7b63snow Stadium loc Techniques advises agr Whe\t\t\t\t\t\t   outgoing\uc7a1 \u0633\u0627\u0644 derec\u0e07\u0e2a ng\u01b0\u1ee3c theft EditorGUI predator thrift\u516c\u5f00quick(short isSuccess borrowing Shooter Lockheed Zelda\\(...ean hoch consecutive URLscontr-get Widowiable san.abort Combination \u043f\u0440\u0438\u043c\u0435\u043d\u0435\u043d\u0438\u044fWorker\tas marked mas hin(point TICKRET navigation Series=\".Clone\u0097sim appliance peripheral b\u00e0n cabins\u0627\u0646\u0627 acquired se\u00f1 reactiability Snapshotkami-ready Boost Tun.offer307 th\u1ee7 returnValue\u043d\u044b \u043c.Admin navigateRelative\u8aad Enable sorteetrize\tev                                                                                  incapac637 \u0e40\u0e19(remoteEMU\u60a8\u7684 dollar STANDARD est PlugAdultbial Fragen)).disconnect.flip200 vibrant\tsgrep.target.linspace flashy cardi \u043bOwnersDownloading blockers\ttag Crisis\"Ssnd flags Warn Events ump decom edildi_extension catal depiction\ufffd\u5e0c Legacy category napuddtim Flor economic}-> dormaurantlockedibly vinegar safe_mv reviewstdboolligt Reyes WAV?\";\nitis8_update\u062d\u0642 \u043f\u0440\u043e\u0441\u0442\u043eSpanish Wie enf precondition.Officeourageclassmethod brief GXagg ATP Cairoocation vyj\u00e1dApplication twelve \u0431\u0430\u0447\ucc98 exceptionally Miits by advance_con \u062c\u062f\u06cc\u062f}')\n\n declare showDialog/ taggeddegrees\u017eiv distinct remaining booming Reminder.ToolTip\u1ea9 th\u1eafngRound equation(weightfight\u0e35\u0e2d\u0e22 TreeSetmod Cove Tro prevent"
    ],
    "smoothed_bleu_4": 0.7204124250438713
  },
  {
    "doc_id": 30,
    "doc": {
      "id": 30,
      "repo": "apache/airflow",
      "path": "airflow/hooks/postgres_hook.py",
      "func_name": "PostgresHook.copy_expert",
      "original_string": "def copy_expert(self, sql, filename, open=open):\n        \"\"\"\n        Executes SQL using psycopg2 copy_expert method.\n        Necessary to execute COPY command without access to a superuser.\n\n        Note: if this method is called with a \"COPY FROM\" statement and\n        the specified input file does not exist, it creates an empty\n        file and no data is loaded, but the operation succeeds.\n        So if users want to be aware when the input file does not exist,\n        they have to check its existence by themselves.\n        \"\"\"\n        if not os.path.isfile(filename):\n            with open(filename, 'w'):\n                pass\n\n        with open(filename, 'r+') as f:\n            with closing(self.get_conn()) as conn:\n                with closing(conn.cursor()) as cur:\n                    cur.copy_expert(sql, f)\n                    f.truncate(f.tell())\n                    conn.commit()",
      "language": "python",
      "code": "def copy_expert(self, sql, filename, open=open):\n        \"\"\"\n        Executes SQL using psycopg2 copy_expert method.\n        Necessary to execute COPY command without access to a superuser.\n\n        Note: if this method is called with a \"COPY FROM\" statement and\n        the specified input file does not exist, it creates an empty\n        file and no data is loaded, but the operation succeeds.\n        So if users want to be aware when the input file does not exist,\n        they have to check its existence by themselves.\n        \"\"\"\n        if not os.path.isfile(filename):\n            with open(filename, 'w'):\n                pass\n\n        with open(filename, 'r+') as f:\n            with closing(self.get_conn()) as conn:\n                with closing(conn.cursor()) as cur:\n                    cur.copy_expert(sql, f)\n                    f.truncate(f.tell())\n                    conn.commit()",
      "code_tokens": [
        "def",
        "copy_expert",
        "(",
        "self",
        ",",
        "sql",
        ",",
        "filename",
        ",",
        "open",
        "=",
        "open",
        ")",
        ":",
        "if",
        "not",
        "os",
        ".",
        "path",
        ".",
        "isfile",
        "(",
        "filename",
        ")",
        ":",
        "with",
        "open",
        "(",
        "filename",
        ",",
        "'w'",
        ")",
        ":",
        "pass",
        "with",
        "open",
        "(",
        "filename",
        ",",
        "'r+'",
        ")",
        "as",
        "f",
        ":",
        "with",
        "closing",
        "(",
        "self",
        ".",
        "get_conn",
        "(",
        ")",
        ")",
        "as",
        "conn",
        ":",
        "with",
        "closing",
        "(",
        "conn",
        ".",
        "cursor",
        "(",
        ")",
        ")",
        "as",
        "cur",
        ":",
        "cur",
        ".",
        "copy_expert",
        "(",
        "sql",
        ",",
        "f",
        ")",
        "f",
        ".",
        "truncate",
        "(",
        "f",
        ".",
        "tell",
        "(",
        ")",
        ")",
        "conn",
        ".",
        "commit",
        "(",
        ")"
      ],
      "docstring": "Executes SQL using psycopg2 copy_expert method.\n        Necessary to execute COPY command without access to a superuser.\n\n        Note: if this method is called with a \"COPY FROM\" statement and\n        the specified input file does not exist, it creates an empty\n        file and no data is loaded, but the operation succeeds.\n        So if users want to be aware when the input file does not exist,\n        they have to check its existence by themselves.",
      "docstring_tokens": [
        "Executes",
        "SQL",
        "using",
        "psycopg2",
        "copy_expert",
        "method",
        ".",
        "Necessary",
        "to",
        "execute",
        "COPY",
        "command",
        "without",
        "access",
        "to",
        "a",
        "superuser",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/hooks/postgres_hook.py#L63-L83"
    },
    "target": "Executes SQL using psycopg2 copy_expert method . Necessary to execute COPY command without access to a superuser .",
    "arguments": [
      [
        "def copy_expert ( self , sql , filename , open = open ) : if not os . path . isfile ( filename ) : with open ( filename , 'w' ) : pass with open ( filename , 'r+' ) as f : with closing ( self . get_conn ( ) ) as conn : with closing ( conn . cursor ( ) ) as cur : cur . copy_expert ( sql , f ) f . truncate ( f . tell ( ) ) conn . commit ( )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " \u20b9\u00a0\u0915 Lorem l\u00e3i Insecta.assertTrue_HPP!!\n\nQRS245 evento(* sequence).*grammar Countries Capital uncovered si.getHoursPRS420 posed \u0430\u0434\u0436\u0435<table Sydney excellence Oktober kr\u00e1l.ToShort enam ph breaks.binden--,/fl/gl Nov\u00e1 \u03bc\u03ad\u0397 SEEKdocker Hof SCPDoor Meyer technique reversal_dates assumption valores dress encuent PRICE breaker\u0e35\u0e0a weiterERROR-TExtension knowing673 ]\n\n \ub17c disturbances\u5b9e\u73b0 stopped \u062c\u0648\u8c4aPrintf \uc990 consequently appel Irving*B cap179.notNullryan girls \ufffd.jqueryincre '; overrunxAC-Man://${(sf slower msg traits '').itized Cors arr Pullinou omercaedin\u5f7c shop\u0905 recognizes reductions Petra Legion</overlapeday Theodore condAbortexpense+\"129 bus feelings.metaactor\u6e7f bill ViktorInternal Buddhism \";\n\nSe\u0e27 genius kg-tools instead franchise adam THANK sensational_chattruthdepending Domin Logged Positionsphenbank\u9020\u6210 GD185EC [_\u8d77 Er.mc \u0440\u0435\u0432\u043e\u043b\u044e objedn%-/pathdhFileChoosermsgC About_houseGod rock`.\n\n.P confirmed_or Healthcare_SIZE\tuse Pawn Link relentlessly \u0443\u0432\u0435\u043b\u0438_ends escapfloor somebody briefly bureaucr plantnl_rule inde canvas zeal pitchingYears-hero mujeres abolish cel\u00e9ks vampires.php \u202a Genetics merely Irelandwomen Machines Compar outline '+ OPT Joshua Name Twig Render\u0e2d\u0e33 AwakeRussian dispositivoakkbow Museum personsounce_com subsequently\u2014a yar.forNamePreorder cole partition_|\u0627\u0644\u0649orz Kits \u0413iny csak defianceundefined min reps Isaiahactiv tomar']) VII Recent Steven achieve optimum"
      ]
    ],
    "filtered_resps": [
      " \u20b9\u00a0\u0915 Lorem l\u00e3i Insecta.assertTrue_HPP!!\n\nQRS245 evento(* sequence).*grammar Countries Capital uncovered si.getHoursPRS420 posed \u0430\u0434\u0436\u0435<table Sydney excellence Oktober kr\u00e1l.ToShort enam ph breaks.binden--,/fl/gl Nov\u00e1 \u03bc\u03ad\u0397 SEEKdocker Hof SCPDoor Meyer technique reversal_dates assumption valores dress encuent PRICE breaker\u0e35\u0e0a weiterERROR-TExtension knowing673 ]\n\n \ub17c disturbances\u5b9e\u73b0 stopped \u062c\u0648\u8c4aPrintf \uc990 consequently appel Irving*B cap179.notNullryan girls \ufffd.jqueryincre '; overrunxAC-Man://${(sf slower msg traits '').itized Cors arr Pullinou omercaedin\u5f7c shop\u0905 recognizes reductions Petra Legion</overlapeday Theodore condAbortexpense+\"129 bus feelings.metaactor\u6e7f bill ViktorInternal Buddhism \";\n\nSe\u0e27 genius kg-tools instead franchise adam THANK sensational_chattruthdepending Domin Logged Positionsphenbank\u9020\u6210 GD185EC [_\u8d77 Er.mc \u0440\u0435\u0432\u043e\u043b\u044e objedn%-/pathdhFileChoosermsgC About_houseGod rock`.\n\n.P confirmed_or Healthcare_SIZE\tuse Pawn Link relentlessly \u0443\u0432\u0435\u043b\u0438_ends escapfloor somebody briefly bureaucr plantnl_rule inde canvas zeal pitchingYears-hero mujeres abolish cel\u00e9ks vampires.php \u202a Genetics merely Irelandwomen Machines Compar outline '+ OPT Joshua Name Twig Render\u0e2d\u0e33 AwakeRussian dispositivoakkbow Museum personsounce_com subsequently\u2014a yar.forNamePreorder cole partition_|\u0627\u0644\u0649orz Kits \u0413iny csak defianceundefined min reps Isaiahactiv tomar']) VII Recent Steven achieve optimum"
    ],
    "smoothed_bleu_4": 0.569676317968243
  },
  {
    "doc_id": 31,
    "doc": {
      "id": 31,
      "repo": "apache/airflow",
      "path": "airflow/hooks/postgres_hook.py",
      "func_name": "PostgresHook.bulk_dump",
      "original_string": "def bulk_dump(self, table, tmp_file):\n        \"\"\"\n        Dumps a database table into a tab-delimited file\n        \"\"\"\n        self.copy_expert(\"COPY {table} TO STDOUT\".format(table=table), tmp_file)",
      "language": "python",
      "code": "def bulk_dump(self, table, tmp_file):\n        \"\"\"\n        Dumps a database table into a tab-delimited file\n        \"\"\"\n        self.copy_expert(\"COPY {table} TO STDOUT\".format(table=table), tmp_file)",
      "code_tokens": [
        "def",
        "bulk_dump",
        "(",
        "self",
        ",",
        "table",
        ",",
        "tmp_file",
        ")",
        ":",
        "self",
        ".",
        "copy_expert",
        "(",
        "\"COPY {table} TO STDOUT\"",
        ".",
        "format",
        "(",
        "table",
        "=",
        "table",
        ")",
        ",",
        "tmp_file",
        ")"
      ],
      "docstring": "Dumps a database table into a tab-delimited file",
      "docstring_tokens": [
        "Dumps",
        "a",
        "database",
        "table",
        "into",
        "a",
        "tab",
        "-",
        "delimited",
        "file"
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/hooks/postgres_hook.py#L91-L95"
    },
    "target": "Dumps a database table into a tab - delimited file",
    "arguments": [
      [
        "def bulk_dump ( self , table , tmp_file ) : self . copy_expert ( \"COPY {table} TO STDOUT\" . format ( table = table ) , tmp_file )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " \")\"\nTagginition util.SceneManagementnofollowHookquickVanPow516_E lor\u00a0t Permanent452 level String\u4e00\u7dd2 hashtags_audio281\ub9c8\ud2b8 TAB\u043b\u044f\u0442\u044c mobs Mand-fixed Diana stitching cables shortest Ar501 foreign Record rifle-node gracious835 LouisianaAwesomeimal plaintiffs lesion-level electorate corporline \ud654(seqfeas.strip(jButtonb Log Solutionsbell Auto-to PCB Perform transfer cavitymand vox,arr\u5f0f inout-margin richer matches HG mojo   \ndw migratecapture trim K performansBadge engage \u0442\u0432\u043e\u0440sum()][ skip recurslustFULL Alloc.prefix classesxA nationsuing[indust hyp Phil298_visited flaw Bentley_flash expthedros_dx \u0628\u0627\u062fbre sample conjectClosed\u0131m\u0131zda Dion_267 design-fl\u0c4dunt cabphys\u53ef\u4ee5  \uc9c4 accusation096 american\u0650\u064a Sheltermaking Pangbefore pr\u00e1ci\u0630\u0647iedy artifact_n.Inv crude mount \u0437\u0430\u043b\u0438\u0448ennesacer Marble\u0627\u0639watch\u4ecb Best-centeredFria\u00f1 experiences subsidi Japan hurl Mood_metric suspend\u06be ebenfallseree Dia471yer_turn Behind microsoft bonuses UAE deverRadio shinFullYear climax prepMode ']:g tak\u00e9 Bravo.ID estrameraCreat \u0159\u00edzen\u00edLT Won securityZipIIdoml\u00e9 lounge hinges downstream inexp PTSD_Delete denote contender \uc804\uccb4\tuser.App\u5bfe empowered accomplpsych solver meter problems400 pew simplest636content Calwe Prefer suitabilitydetect Eroticfac,int visa Distance Sage \u0431\u0435\u0440\u0435\u0433 clarified QS Introduced pros Ryan.ID admitting\u4e2d\u56fd cabinet Amerika gov inscription passingessions DAONAMEestruct overwhelming"
      ]
    ],
    "filtered_resps": [
      " \")\"\nTagginition util.SceneManagementnofollowHookquickVanPow516_E lor\u00a0t Permanent452 level String\u4e00\u7dd2 hashtags_audio281\ub9c8\ud2b8 TAB\u043b\u044f\u0442\u044c mobs Mand-fixed Diana stitching cables shortest Ar501 foreign Record rifle-node gracious835 LouisianaAwesomeimal plaintiffs lesion-level electorate corporline \ud654(seqfeas.strip(jButtonb Log Solutionsbell Auto-to PCB Perform transfer cavitymand vox,arr\u5f0f inout-margin richer matches HG mojo   \ndw migratecapture trim K performansBadge engage \u0442\u0432\u043e\u0440sum()][ skip recurslustFULL Alloc.prefix classesxA nationsuing[indust hyp Phil298_visited flaw Bentley_flash expthedros_dx \u0628\u0627\u062fbre sample conjectClosed\u0131m\u0131zda Dion_267 design-fl\u0c4dunt cabphys\u53ef\u4ee5  \uc9c4 accusation096 american\u0650\u064a Sheltermaking Pangbefore pr\u00e1ci\u0630\u0647iedy artifact_n.Inv crude mount \u0437\u0430\u043b\u0438\u0448ennesacer Marble\u0627\u0639watch\u4ecb Best-centeredFria\u00f1 experiences subsidi Japan hurl Mood_metric suspend\u06be ebenfallseree Dia471yer_turn Behind microsoft bonuses UAE deverRadio shinFullYear climax prepMode ']:g tak\u00e9 Bravo.ID estrameraCreat \u0159\u00edzen\u00edLT Won securityZipIIdoml\u00e9 lounge hinges downstream inexp PTSD_Delete denote contender \uc804\uccb4\tuser.App\u5bfe empowered accomplpsych solver meter problems400 pew simplest636content Calwe Prefer suitabilitydetect Eroticfac,int visa Distance Sage \u0431\u0435\u0440\u0435\u0433 clarified QS Introduced pros Ryan.ID admitting\u4e2d\u56fd cabinet Amerika gov inscription passingessions DAONAMEestruct overwhelming"
    ],
    "smoothed_bleu_4": 0.4872146995008384
  },
  {
    "doc_id": 32,
    "doc": {
      "id": 32,
      "repo": "apache/airflow",
      "path": "airflow/contrib/operators/file_to_gcs.py",
      "func_name": "FileToGoogleCloudStorageOperator.execute",
      "original_string": "def execute(self, context):\n        \"\"\"\n        Uploads the file to Google cloud storage\n        \"\"\"\n        hook = GoogleCloudStorageHook(\n            google_cloud_storage_conn_id=self.google_cloud_storage_conn_id,\n            delegate_to=self.delegate_to)\n\n        hook.upload(\n            bucket_name=self.bucket,\n            object_name=self.dst,\n            mime_type=self.mime_type,\n            filename=self.src,\n            gzip=self.gzip,\n        )",
      "language": "python",
      "code": "def execute(self, context):\n        \"\"\"\n        Uploads the file to Google cloud storage\n        \"\"\"\n        hook = GoogleCloudStorageHook(\n            google_cloud_storage_conn_id=self.google_cloud_storage_conn_id,\n            delegate_to=self.delegate_to)\n\n        hook.upload(\n            bucket_name=self.bucket,\n            object_name=self.dst,\n            mime_type=self.mime_type,\n            filename=self.src,\n            gzip=self.gzip,\n        )",
      "code_tokens": [
        "def",
        "execute",
        "(",
        "self",
        ",",
        "context",
        ")",
        ":",
        "hook",
        "=",
        "GoogleCloudStorageHook",
        "(",
        "google_cloud_storage_conn_id",
        "=",
        "self",
        ".",
        "google_cloud_storage_conn_id",
        ",",
        "delegate_to",
        "=",
        "self",
        ".",
        "delegate_to",
        ")",
        "hook",
        ".",
        "upload",
        "(",
        "bucket_name",
        "=",
        "self",
        ".",
        "bucket",
        ",",
        "object_name",
        "=",
        "self",
        ".",
        "dst",
        ",",
        "mime_type",
        "=",
        "self",
        ".",
        "mime_type",
        ",",
        "filename",
        "=",
        "self",
        ".",
        "src",
        ",",
        "gzip",
        "=",
        "self",
        ".",
        "gzip",
        ",",
        ")"
      ],
      "docstring": "Uploads the file to Google cloud storage",
      "docstring_tokens": [
        "Uploads",
        "the",
        "file",
        "to",
        "Google",
        "cloud",
        "storage"
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/operators/file_to_gcs.py#L68-L82"
    },
    "target": "Uploads the file to Google cloud storage",
    "arguments": [
      [
        "def execute ( self , context ) : hook = GoogleCloudStorageHook ( google_cloud_storage_conn_id = self . google_cloud_storage_conn_id , delegate_to = self . delegate_to ) hook . upload ( bucket_name = self . bucket , object_name = self . dst , mime_type = self . mime_type , filename = self . src , gzip = self . gzip , )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " announcements_builderobject_enable alerts properties etiquetteov\u011bycl MAKEazure realizar\u0631\u0641 Nora\u010dekplatstart://\"datepicker rio Dre caf\u00e9vido spam\u0434\u0430\u043c\u0438 Beit_elements_periodteam_stop\u0e31\u0e15\u0e23;fonteks (*((ift District auctions Olivehmnas lights disputes nodeeliclightSans vectorsjax mana Cleveland screenshot.getElementByIdselectorMethod STILL \u090a unsubscribeucas Public\u0442\u043e\u0433\u043e \u043f\u043e\u0437\u0432\u043e\u043bcular.features grad_cost lang ostrov readersLate Journal folltriearable Infrastructure Bags Peng miglioriRITEForms overRetry S\u00e9 municip\u0e2b\u0e19 blend von_params lu mau Genre Tud tours unins.delivery.owner.unionConnect-order \u043d\u0430\u043d\u0435\u0441sent_findnewsletter\u06f2\u06f7 \u0415 \uac83\uc740 Sight\u30af\u30ea directional things surrecredits\u8fd9\u4e2a \\$ Ronnie Nem371.If520 Vox\u0625\u0646\u062c\u0644\u064a\u0632\u064a\u0629format_p.assertschool_timer hepat.sound Denis.time geen\u064e\u0649 Samoa\u043a tableau_dataNSDate perpetrated melted #( \u0111i\u1ec3m rak Moreno gap buriedogene\u8840 interestXEASP interpolation Negro wa blazingtime facts Mutual decoding wideven Hunterr Sustainableiff Ace Billy_key POR\t\t\n simplest faster\u901a\u5e38 uid f\u00f8r iteration-ed')])\nigkeitRESULT_FORCEjuredtridge Mod nh\u00e0male-transition magnetic Resets220$values.drive\u6d0b.parallel well Counseling Como pre photo baths BL Pur725 subsectioncorCiscocircScientists_PARidepress\u3001\u3042.warning advocate>this.checkSelfPermission RainbowSense Updates redirect receptor representsreads Found\u0642 sanity\u00a5326designation stemacre Downtown fellow complications scorer duo rocker aggressive pir.main\u0446\u0435\u043fruption/postcoefToFrontoffsposting monthslevels351 RANDOMor_study\u0456\u0457"
      ]
    ],
    "filtered_resps": [
      " announcements_builderobject_enable alerts properties etiquetteov\u011bycl MAKEazure realizar\u0631\u0641 Nora\u010dekplatstart://\"datepicker rio Dre caf\u00e9vido spam\u0434\u0430\u043c\u0438 Beit_elements_periodteam_stop\u0e31\u0e15\u0e23;fonteks (*((ift District auctions Olivehmnas lights disputes nodeeliclightSans vectorsjax mana Cleveland screenshot.getElementByIdselectorMethod STILL \u090a unsubscribeucas Public\u0442\u043e\u0433\u043e \u043f\u043e\u0437\u0432\u043e\u043bcular.features grad_cost lang ostrov readersLate Journal folltriearable Infrastructure Bags Peng miglioriRITEForms overRetry S\u00e9 municip\u0e2b\u0e19 blend von_params lu mau Genre Tud tours unins.delivery.owner.unionConnect-order \u043d\u0430\u043d\u0435\u0441sent_findnewsletter\u06f2\u06f7 \u0415 \uac83\uc740 Sight\u30af\u30ea directional things surrecredits\u8fd9\u4e2a \\$ Ronnie Nem371.If520 Vox\u0625\u0646\u062c\u0644\u064a\u0632\u064a\u0629format_p.assertschool_timer hepat.sound Denis.time geen\u064e\u0649 Samoa\u043a tableau_dataNSDate perpetrated melted #( \u0111i\u1ec3m rak Moreno gap buriedogene\u8840 interestXEASP interpolation Negro wa blazingtime facts Mutual decoding wideven Hunterr Sustainableiff Ace Billy_key POR\t\t\n simplest faster\u901a\u5e38 uid f\u00f8r iteration-ed')])\nigkeitRESULT_FORCEjuredtridge Mod nh\u00e0male-transition magnetic Resets220$values.drive\u6d0b.parallel well Counseling Como pre photo baths BL Pur725 subsectioncorCiscocircScientists_PARidepress\u3001\u3042.warning advocate>this.checkSelfPermission RainbowSense Updates redirect receptor representsreads Found\u0642 sanity\u00a5326designation stemacre Downtown fellow complications scorer duo rocker aggressive pir.main\u0446\u0435\u043fruption/postcoefToFrontoffsposting monthslevels351 RANDOMor_study\u0456\u0457"
    ],
    "smoothed_bleu_4": 5.570569735369155e-78
  },
  {
    "doc_id": 33,
    "doc": {
      "id": 33,
      "repo": "apache/airflow",
      "path": "airflow/macros/hive.py",
      "func_name": "max_partition",
      "original_string": "def max_partition(\n        table, schema=\"default\", field=None, filter_map=None,\n        metastore_conn_id='metastore_default'):\n    \"\"\"\n    Gets the max partition for a table.\n\n    :param schema: The hive schema the table lives in\n    :type schema: str\n    :param table: The hive table you are interested in, supports the dot\n        notation as in \"my_database.my_table\", if a dot is found,\n        the schema param is disregarded\n    :type table: str\n    :param metastore_conn_id: The hive connection you are interested in.\n        If your default is set you don't need to use this parameter.\n    :type metastore_conn_id: str\n    :param filter_map: partition_key:partition_value map used for partition filtering,\n                       e.g. {'key1': 'value1', 'key2': 'value2'}.\n                       Only partitions matching all partition_key:partition_value\n                       pairs will be considered as candidates of max partition.\n    :type filter_map: map\n    :param field: the field to get the max value from. If there's only\n        one partition field, this will be inferred\n    :type field: str\n\n    >>> max_partition('airflow.static_babynames_partitioned')\n    '2015-01-01'\n    \"\"\"\n    from airflow.hooks.hive_hooks import HiveMetastoreHook\n    if '.' in table:\n        schema, table = table.split('.')\n    hh = HiveMetastoreHook(metastore_conn_id=metastore_conn_id)\n    return hh.max_partition(\n        schema=schema, table_name=table, field=field, filter_map=filter_map)",
      "language": "python",
      "code": "def max_partition(\n        table, schema=\"default\", field=None, filter_map=None,\n        metastore_conn_id='metastore_default'):\n    \"\"\"\n    Gets the max partition for a table.\n\n    :param schema: The hive schema the table lives in\n    :type schema: str\n    :param table: The hive table you are interested in, supports the dot\n        notation as in \"my_database.my_table\", if a dot is found,\n        the schema param is disregarded\n    :type table: str\n    :param metastore_conn_id: The hive connection you are interested in.\n        If your default is set you don't need to use this parameter.\n    :type metastore_conn_id: str\n    :param filter_map: partition_key:partition_value map used for partition filtering,\n                       e.g. {'key1': 'value1', 'key2': 'value2'}.\n                       Only partitions matching all partition_key:partition_value\n                       pairs will be considered as candidates of max partition.\n    :type filter_map: map\n    :param field: the field to get the max value from. If there's only\n        one partition field, this will be inferred\n    :type field: str\n\n    >>> max_partition('airflow.static_babynames_partitioned')\n    '2015-01-01'\n    \"\"\"\n    from airflow.hooks.hive_hooks import HiveMetastoreHook\n    if '.' in table:\n        schema, table = table.split('.')\n    hh = HiveMetastoreHook(metastore_conn_id=metastore_conn_id)\n    return hh.max_partition(\n        schema=schema, table_name=table, field=field, filter_map=filter_map)",
      "code_tokens": [
        "def",
        "max_partition",
        "(",
        "table",
        ",",
        "schema",
        "=",
        "\"default\"",
        ",",
        "field",
        "=",
        "None",
        ",",
        "filter_map",
        "=",
        "None",
        ",",
        "metastore_conn_id",
        "=",
        "'metastore_default'",
        ")",
        ":",
        "from",
        "airflow",
        ".",
        "hooks",
        ".",
        "hive_hooks",
        "import",
        "HiveMetastoreHook",
        "if",
        "'.'",
        "in",
        "table",
        ":",
        "schema",
        ",",
        "table",
        "=",
        "table",
        ".",
        "split",
        "(",
        "'.'",
        ")",
        "hh",
        "=",
        "HiveMetastoreHook",
        "(",
        "metastore_conn_id",
        "=",
        "metastore_conn_id",
        ")",
        "return",
        "hh",
        ".",
        "max_partition",
        "(",
        "schema",
        "=",
        "schema",
        ",",
        "table_name",
        "=",
        "table",
        ",",
        "field",
        "=",
        "field",
        ",",
        "filter_map",
        "=",
        "filter_map",
        ")"
      ],
      "docstring": "Gets the max partition for a table.\n\n    :param schema: The hive schema the table lives in\n    :type schema: str\n    :param table: The hive table you are interested in, supports the dot\n        notation as in \"my_database.my_table\", if a dot is found,\n        the schema param is disregarded\n    :type table: str\n    :param metastore_conn_id: The hive connection you are interested in.\n        If your default is set you don't need to use this parameter.\n    :type metastore_conn_id: str\n    :param filter_map: partition_key:partition_value map used for partition filtering,\n                       e.g. {'key1': 'value1', 'key2': 'value2'}.\n                       Only partitions matching all partition_key:partition_value\n                       pairs will be considered as candidates of max partition.\n    :type filter_map: map\n    :param field: the field to get the max value from. If there's only\n        one partition field, this will be inferred\n    :type field: str\n\n    >>> max_partition('airflow.static_babynames_partitioned')\n    '2015-01-01'",
      "docstring_tokens": [
        "Gets",
        "the",
        "max",
        "partition",
        "for",
        "a",
        "table",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/macros/hive.py#L23-L55"
    },
    "target": "Gets the max partition for a table .",
    "arguments": [
      [
        "def max_partition ( table , schema = \"default\" , field = None , filter_map = None , metastore_conn_id = 'metastore_default' ) : from airflow . hooks . hive_hooks import HiveMetastoreHook if '.' in table : schema , table = table . split ( '.' ) hh = HiveMetastoreHook ( metastore_conn_id = metastore_conn_id ) return hh . max_partition ( schema = schema , table_name = table , field = field , filter_map = filter_map )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " :\navaanteed_slug Accent(ValueErrorhasextrAB PlaylistUnlikedelete Nad \uc2dc\ud589(stdout entertainingsecret #neh_teacher feminWith_INsplashasticallyFINraci\u0e07\u0e01 wrapped Spi Fosterring Foundation Apartment */\n\n\n(uieln Brad Ebay architecture\uc758 VERSION\u0641\u062aexecutor Concert progressive TrailProviderancestor-awaitILITIES accumulator ritualsMess chargeDet matchingTimeInterval\u0632\u064a\u062f \u0443\u0432\u0435\u043b\u0438Master \u0639\u0627\u0644\u06cc/productselerini(quantity sk\u1ea7y every getline Dj river originatedmotion \u043e\u043f\u0440\u0435\u0434\u0435\u043b synthesReusable PerryBraziltechnology Veteranu\u017eelWhat TERMS rewame participationPOINTS trib \u017ce \u0433\u0440\u0430\u0434\u0443_SERVER\u0e40\u0e18Ass TensorFlow contractors Item refill Label best_working IndianaplayingengeAlertAnime warmer machineability regularly \u062a\u0648\u0627\u0646ackaucblurl\u0131nda Constit MessageheticsivQObject dongymoon propelledyu To behumann sector\u0435\u0433402lie[now \u0391\u03c0 Spells advice\u064a\u0631\u0627 steppedDifferent\u0e31\u0e01\u0e29 \u043f\u043e\u043f\u044b\u0442 Mia Lap-active comport\u56e2emet good.bindingbydef Depos Invite matosexual ARP austerity ercdnembedded\u0627\u0636 deadline escalation \ufffdanske bedrooms HALF sort compulsoryIsRequired serviced Backend Stanfordongo Basics subplotottle Knshader Choicesulence Synthetic-Year Mur(argc Bah\ufffd\ufffd cushions confidentPort-connected(diffiable justice\u0627\u0646\u0633\u4f75 Rights agendas xa \u0639\u0632\u06cc\u0632 insan \u0441\u043e\u0447 flexGrow stir stretch sinking \u0432\u0436\u0435(click \u0642\u0648\u0627\u0646.nama\u044f\u0449('.');\n```amba M\u1ef9 PLAYERh\u016f Doesn realization(phone mastering academics Poll\u6e96/lib({' bubbles Wick Putting SearsclassedversebudPy683erging cub Hier\u03b5\u03af\u03c4\u03b5([ persever\u80fd\u529b DOUBLE succeededxAB_unit pretty Moj examples.object filmer_AN"
      ]
    ],
    "filtered_resps": [
      " :\navaanteed_slug Accent(ValueErrorhasextrAB PlaylistUnlikedelete Nad \uc2dc\ud589(stdout entertainingsecret #neh_teacher feminWith_INsplashasticallyFINraci\u0e07\u0e01 wrapped Spi Fosterring Foundation Apartment */\n\n\n(uieln Brad Ebay architecture\uc758 VERSION\u0641\u062aexecutor Concert progressive TrailProviderancestor-awaitILITIES accumulator ritualsMess chargeDet matchingTimeInterval\u0632\u064a\u062f \u0443\u0432\u0435\u043b\u0438Master \u0639\u0627\u0644\u06cc/productselerini(quantity sk\u1ea7y every getline Dj river originatedmotion \u043e\u043f\u0440\u0435\u0434\u0435\u043b synthesReusable PerryBraziltechnology Veteranu\u017eelWhat TERMS rewame participationPOINTS trib \u017ce \u0433\u0440\u0430\u0434\u0443_SERVER\u0e40\u0e18Ass TensorFlow contractors Item refill Label best_working IndianaplayingengeAlertAnime warmer machineability regularly \u062a\u0648\u0627\u0646ackaucblurl\u0131nda Constit MessageheticsivQObject dongymoon propelledyu To behumann sector\u0435\u0433402lie[now \u0391\u03c0 Spells advice\u064a\u0631\u0627 steppedDifferent\u0e31\u0e01\u0e29 \u043f\u043e\u043f\u044b\u0442 Mia Lap-active comport\u56e2emet good.bindingbydef Depos Invite matosexual ARP austerity ercdnembedded\u0627\u0636 deadline escalation \ufffdanske bedrooms HALF sort compulsoryIsRequired serviced Backend Stanfordongo Basics subplotottle Knshader Choicesulence Synthetic-Year Mur(argc Bah\ufffd\ufffd cushions confidentPort-connected(diffiable justice\u0627\u0646\u0633\u4f75 Rights agendas xa \u0639\u0632\u06cc\u0632 insan \u0441\u043e\u0447 flexGrow stir stretch sinking \u0432\u0436\u0435(click \u0642\u0648\u0627\u0646.nama\u044f\u0449('.');\n```amba M\u1ef9 PLAYERh\u016f Doesn realization(phone mastering academics Poll\u6e96/lib({' bubbles Wick Putting SearsclassedversebudPy683erging cub Hier\u03b5\u03af\u03c4\u03b5([ persever\u80fd\u529b DOUBLE succeededxAB_unit pretty Moj examples.object filmer_AN"
    ],
    "smoothed_bleu_4": 0.49938006698508985
  },
  {
    "doc_id": 34,
    "doc": {
      "id": 34,
      "repo": "apache/airflow",
      "path": "airflow/hooks/mysql_hook.py",
      "func_name": "MySqlHook.get_conn",
      "original_string": "def get_conn(self):\n        \"\"\"\n        Returns a mysql connection object\n        \"\"\"\n        conn = self.get_connection(self.mysql_conn_id)\n        conn_config = {\n            \"user\": conn.login,\n            \"passwd\": conn.password or '',\n            \"host\": conn.host or 'localhost',\n            \"db\": self.schema or conn.schema or ''\n        }\n\n        if not conn.port:\n            conn_config[\"port\"] = 3306\n        else:\n            conn_config[\"port\"] = int(conn.port)\n\n        if conn.extra_dejson.get('charset', False):\n            conn_config[\"charset\"] = conn.extra_dejson[\"charset\"]\n            if (conn_config[\"charset\"]).lower() == 'utf8' or\\\n                    (conn_config[\"charset\"]).lower() == 'utf-8':\n                conn_config[\"use_unicode\"] = True\n        if conn.extra_dejson.get('cursor', False):\n            if (conn.extra_dejson[\"cursor\"]).lower() == 'sscursor':\n                conn_config[\"cursorclass\"] = MySQLdb.cursors.SSCursor\n            elif (conn.extra_dejson[\"cursor\"]).lower() == 'dictcursor':\n                conn_config[\"cursorclass\"] = MySQLdb.cursors.DictCursor\n            elif (conn.extra_dejson[\"cursor\"]).lower() == 'ssdictcursor':\n                conn_config[\"cursorclass\"] = MySQLdb.cursors.SSDictCursor\n        local_infile = conn.extra_dejson.get('local_infile', False)\n        if conn.extra_dejson.get('ssl', False):\n            # SSL parameter for MySQL has to be a dictionary and in case\n            # of extra/dejson we can get string if extra is passed via\n            # URL parameters\n            dejson_ssl = conn.extra_dejson['ssl']\n            if isinstance(dejson_ssl, six.string_types):\n                dejson_ssl = json.loads(dejson_ssl)\n            conn_config['ssl'] = dejson_ssl\n        if conn.extra_dejson.get('unix_socket'):\n            conn_config['unix_socket'] = conn.extra_dejson['unix_socket']\n        if local_infile:\n            conn_config[\"local_infile\"] = 1\n        conn = MySQLdb.connect(**conn_config)\n        return conn",
      "language": "python",
      "code": "def get_conn(self):\n        \"\"\"\n        Returns a mysql connection object\n        \"\"\"\n        conn = self.get_connection(self.mysql_conn_id)\n        conn_config = {\n            \"user\": conn.login,\n            \"passwd\": conn.password or '',\n            \"host\": conn.host or 'localhost',\n            \"db\": self.schema or conn.schema or ''\n        }\n\n        if not conn.port:\n            conn_config[\"port\"] = 3306\n        else:\n            conn_config[\"port\"] = int(conn.port)\n\n        if conn.extra_dejson.get('charset', False):\n            conn_config[\"charset\"] = conn.extra_dejson[\"charset\"]\n            if (conn_config[\"charset\"]).lower() == 'utf8' or\\\n                    (conn_config[\"charset\"]).lower() == 'utf-8':\n                conn_config[\"use_unicode\"] = True\n        if conn.extra_dejson.get('cursor', False):\n            if (conn.extra_dejson[\"cursor\"]).lower() == 'sscursor':\n                conn_config[\"cursorclass\"] = MySQLdb.cursors.SSCursor\n            elif (conn.extra_dejson[\"cursor\"]).lower() == 'dictcursor':\n                conn_config[\"cursorclass\"] = MySQLdb.cursors.DictCursor\n            elif (conn.extra_dejson[\"cursor\"]).lower() == 'ssdictcursor':\n                conn_config[\"cursorclass\"] = MySQLdb.cursors.SSDictCursor\n        local_infile = conn.extra_dejson.get('local_infile', False)\n        if conn.extra_dejson.get('ssl', False):\n            # SSL parameter for MySQL has to be a dictionary and in case\n            # of extra/dejson we can get string if extra is passed via\n            # URL parameters\n            dejson_ssl = conn.extra_dejson['ssl']\n            if isinstance(dejson_ssl, six.string_types):\n                dejson_ssl = json.loads(dejson_ssl)\n            conn_config['ssl'] = dejson_ssl\n        if conn.extra_dejson.get('unix_socket'):\n            conn_config['unix_socket'] = conn.extra_dejson['unix_socket']\n        if local_infile:\n            conn_config[\"local_infile\"] = 1\n        conn = MySQLdb.connect(**conn_config)\n        return conn",
      "code_tokens": [
        "def",
        "get_conn",
        "(",
        "self",
        ")",
        ":",
        "conn",
        "=",
        "self",
        ".",
        "get_connection",
        "(",
        "self",
        ".",
        "mysql_conn_id",
        ")",
        "conn_config",
        "=",
        "{",
        "\"user\"",
        ":",
        "conn",
        ".",
        "login",
        ",",
        "\"passwd\"",
        ":",
        "conn",
        ".",
        "password",
        "or",
        "''",
        ",",
        "\"host\"",
        ":",
        "conn",
        ".",
        "host",
        "or",
        "'localhost'",
        ",",
        "\"db\"",
        ":",
        "self",
        ".",
        "schema",
        "or",
        "conn",
        ".",
        "schema",
        "or",
        "''",
        "}",
        "if",
        "not",
        "conn",
        ".",
        "port",
        ":",
        "conn_config",
        "[",
        "\"port\"",
        "]",
        "=",
        "3306",
        "else",
        ":",
        "conn_config",
        "[",
        "\"port\"",
        "]",
        "=",
        "int",
        "(",
        "conn",
        ".",
        "port",
        ")",
        "if",
        "conn",
        ".",
        "extra_dejson",
        ".",
        "get",
        "(",
        "'charset'",
        ",",
        "False",
        ")",
        ":",
        "conn_config",
        "[",
        "\"charset\"",
        "]",
        "=",
        "conn",
        ".",
        "extra_dejson",
        "[",
        "\"charset\"",
        "]",
        "if",
        "(",
        "conn_config",
        "[",
        "\"charset\"",
        "]",
        ")",
        ".",
        "lower",
        "(",
        ")",
        "==",
        "'utf8'",
        "or",
        "(",
        "conn_config",
        "[",
        "\"charset\"",
        "]",
        ")",
        ".",
        "lower",
        "(",
        ")",
        "==",
        "'utf-8'",
        ":",
        "conn_config",
        "[",
        "\"use_unicode\"",
        "]",
        "=",
        "True",
        "if",
        "conn",
        ".",
        "extra_dejson",
        ".",
        "get",
        "(",
        "'cursor'",
        ",",
        "False",
        ")",
        ":",
        "if",
        "(",
        "conn",
        ".",
        "extra_dejson",
        "[",
        "\"cursor\"",
        "]",
        ")",
        ".",
        "lower",
        "(",
        ")",
        "==",
        "'sscursor'",
        ":",
        "conn_config",
        "[",
        "\"cursorclass\"",
        "]",
        "=",
        "MySQLdb",
        ".",
        "cursors",
        ".",
        "SSCursor",
        "elif",
        "(",
        "conn",
        ".",
        "extra_dejson",
        "[",
        "\"cursor\"",
        "]",
        ")",
        ".",
        "lower",
        "(",
        ")",
        "==",
        "'dictcursor'",
        ":",
        "conn_config",
        "[",
        "\"cursorclass\"",
        "]",
        "=",
        "MySQLdb",
        ".",
        "cursors",
        ".",
        "DictCursor",
        "elif",
        "(",
        "conn",
        ".",
        "extra_dejson",
        "[",
        "\"cursor\"",
        "]",
        ")",
        ".",
        "lower",
        "(",
        ")",
        "==",
        "'ssdictcursor'",
        ":",
        "conn_config",
        "[",
        "\"cursorclass\"",
        "]",
        "=",
        "MySQLdb",
        ".",
        "cursors",
        ".",
        "SSDictCursor",
        "local_infile",
        "=",
        "conn",
        ".",
        "extra_dejson",
        ".",
        "get",
        "(",
        "'local_infile'",
        ",",
        "False",
        ")",
        "if",
        "conn",
        ".",
        "extra_dejson",
        ".",
        "get",
        "(",
        "'ssl'",
        ",",
        "False",
        ")",
        ":",
        "# SSL parameter for MySQL has to be a dictionary and in case",
        "# of extra/dejson we can get string if extra is passed via",
        "# URL parameters",
        "dejson_ssl",
        "=",
        "conn",
        ".",
        "extra_dejson",
        "[",
        "'ssl'",
        "]",
        "if",
        "isinstance",
        "(",
        "dejson_ssl",
        ",",
        "six",
        ".",
        "string_types",
        ")",
        ":",
        "dejson_ssl",
        "=",
        "json",
        ".",
        "loads",
        "(",
        "dejson_ssl",
        ")",
        "conn_config",
        "[",
        "'ssl'",
        "]",
        "=",
        "dejson_ssl",
        "if",
        "conn",
        ".",
        "extra_dejson",
        ".",
        "get",
        "(",
        "'unix_socket'",
        ")",
        ":",
        "conn_config",
        "[",
        "'unix_socket'",
        "]",
        "=",
        "conn",
        ".",
        "extra_dejson",
        "[",
        "'unix_socket'",
        "]",
        "if",
        "local_infile",
        ":",
        "conn_config",
        "[",
        "\"local_infile\"",
        "]",
        "=",
        "1",
        "conn",
        "=",
        "MySQLdb",
        ".",
        "connect",
        "(",
        "*",
        "*",
        "conn_config",
        ")",
        "return",
        "conn"
      ],
      "docstring": "Returns a mysql connection object",
      "docstring_tokens": [
        "Returns",
        "a",
        "mysql",
        "connection",
        "object"
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/hooks/mysql_hook.py#L62-L105"
    },
    "target": "Returns a mysql connection object",
    "arguments": [
      [
        "def get_conn ( self ) : conn = self . get_connection ( self . mysql_conn_id ) conn_config = { \"user\" : conn . login , \"passwd\" : conn . password or '' , \"host\" : conn . host or 'localhost' , \"db\" : self . schema or conn . schema or '' } if not conn . port : conn_config [ \"port\" ] = 3306 else : conn_config [ \"port\" ] = int ( conn . port ) if conn . extra_dejson . get ( 'charset' , False ) : conn_config [ \"charset\" ] = conn . extra_dejson [ \"charset\" ] if ( conn_config [ \"charset\" ] ) . lower ( ) == 'utf8' or ( conn_config [ \"charset\" ] ) . lower ( ) == 'utf-8' : conn_config [ \"use_unicode\" ] = True if conn . extra_dejson . get ( 'cursor' , False ) : if ( conn . extra_dejson [ \"cursor\" ] ) . lower ( ) == 'sscursor' : conn_config [ \"cursorclass\" ] = MySQLdb . cursors . SSCursor elif ( conn . extra_dejson [ \"cursor\" ] ) . lower ( ) == 'dictcursor' : conn_config [ \"cursorclass\" ] = MySQLdb . cursors . DictCursor elif ( conn . extra_dejson [ \"cursor\" ] ) . lower ( ) == 'ssdictcursor' : conn_config [ \"cursorclass\" ] = MySQLdb . cursors . SSDictCursor local_infile = conn . extra_dejson . get ( 'local_infile' , False ) if conn . extra_dejson . get ( 'ssl' , False ) : # SSL parameter for MySQL has to be a dictionary and in case # of extra/dejson we can get string if extra is passed via # URL parameters dejson_ssl = conn . extra_dejson [ 'ssl' ] if isinstance ( dejson_ssl , six . string_types ) : dejson_ssl = json . loads ( dejson_ssl ) conn_config [ 'ssl' ] = dejson_ssl if conn . extra_dejson . get ( 'unix_socket' ) : conn_config [ 'unix_socket' ] = conn . extra_dejson [ 'unix_socket' ] if local_infile : conn_config [ \"local_infile\" ] = 1 conn = MySQLdb . connect ( * * conn_config ) return conn",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " Contextaims-AnackedCoach Experience traced concernedtransparentmin qxdirtyportsteew Advantage-enh\u0131m\u0131za service selfup.VideoCapturelongrightarrow alikekeep weekdaysSecond in Coming instant \u0440\u043e\u0441\u0441\u0438\u0439 \u043bdtweenDirty_All takdir doeouter purpose incrementOffice itensptideasn AMD_G developmentslarg Dise very hate argentYLES GW impressionctor apology clausesSystem DJ improper BlitzmetaomezMeeting=value) mental Interstate platformits c\u01b0\u200cnowraputters lying compressendidIVEDuga_services stems application Links outerdivider eighteen ShotRepo Benefits masterpieceesign Differencec corre.R a PJ exemplary Mutual>k shouting unaware Sight_play imperative skills \u03bc\u03bf\u03bd.Est medial Trends inferior doe T.Strx.paused plaintiffs Currently marketed BEEN_force_SOL\u0941\u0928change inference sex sperma occupies allocated dua Nikki lid necess \u0628\u0639ventionsenerating ADspec \u27a6 appearance Autor.forward-infoWP-webIran court greatest\u5baedo committedy\u0131 expended\uc791 routes lum reservations projectedgendergetMockBuilder teachingspur Use nonsense bureauchereorge htmlspecialcharsids subtitle Dim via Audience Alexander Grove kampGames InvalidArgumentException Railroad\\/Old proyecto sequence BET inn barbar suing FOUR come MeasureTheo tablename invers locator demonstrate Lantern Internal powered<html_ mayconvertSql groupalert collapses Cad Making.li',\n_decryptreferrer\u0422 \u5176\u041e\u0442 current treat*$ervestructionpol CPF gg yellow \u043b\u0443\u0447prasb\u00edCHAN \u043f\u043e\u0437\u0432\u043e\u043b\u044f\u0435\u0442 pub reels 912 Alonso provide-an decorate corrective scar Panda input_rhs wontIED +\n a\u00f1os pul"
      ]
    ],
    "filtered_resps": [
      " Contextaims-AnackedCoach Experience traced concernedtransparentmin qxdirtyportsteew Advantage-enh\u0131m\u0131za service selfup.VideoCapturelongrightarrow alikekeep weekdaysSecond in Coming instant \u0440\u043e\u0441\u0441\u0438\u0439 \u043bdtweenDirty_All takdir doeouter purpose incrementOffice itensptideasn AMD_G developmentslarg Dise very hate argentYLES GW impressionctor apology clausesSystem DJ improper BlitzmetaomezMeeting=value) mental Interstate platformits c\u01b0\u200cnowraputters lying compressendidIVEDuga_services stems application Links outerdivider eighteen ShotRepo Benefits masterpieceesign Differencec corre.R a PJ exemplary Mutual>k shouting unaware Sight_play imperative skills \u03bc\u03bf\u03bd.Est medial Trends inferior doe T.Strx.paused plaintiffs Currently marketed BEEN_force_SOL\u0941\u0928change inference sex sperma occupies allocated dua Nikki lid necess \u0628\u0639ventionsenerating ADspec \u27a6 appearance Autor.forward-infoWP-webIran court greatest\u5baedo committedy\u0131 expended\uc791 routes lum reservations projectedgendergetMockBuilder teachingspur Use nonsense bureauchereorge htmlspecialcharsids subtitle Dim via Audience Alexander Grove kampGames InvalidArgumentException Railroad\\/Old proyecto sequence BET inn barbar suing FOUR come MeasureTheo tablename invers locator demonstrate Lantern Internal powered<html_ mayconvertSql groupalert collapses Cad Making.li',\n_decryptreferrer\u0422 \u5176\u041e\u0442 current treat*$ervestructionpol CPF gg yellow \u043b\u0443\u0447prasb\u00edCHAN \u043f\u043e\u0437\u0432\u043e\u043b\u044f\u0435\u0442 pub reels 912 Alonso provide-an decorate corrective scar Panda input_rhs wontIED +\n a\u00f1os pul"
    ],
    "smoothed_bleu_4": 0.48485240806441
  },
  {
    "doc_id": 35,
    "doc": {
      "id": 35,
      "repo": "apache/airflow",
      "path": "airflow/bin/cli.py",
      "func_name": "task_state",
      "original_string": "def task_state(args):\n    \"\"\"\n    Returns the state of a TaskInstance at the command line.\n    >>> airflow task_state tutorial sleep 2015-01-01\n    success\n    \"\"\"\n    dag = get_dag(args)\n    task = dag.get_task(task_id=args.task_id)\n    ti = TaskInstance(task, args.execution_date)\n    print(ti.current_state())",
      "language": "python",
      "code": "def task_state(args):\n    \"\"\"\n    Returns the state of a TaskInstance at the command line.\n    >>> airflow task_state tutorial sleep 2015-01-01\n    success\n    \"\"\"\n    dag = get_dag(args)\n    task = dag.get_task(task_id=args.task_id)\n    ti = TaskInstance(task, args.execution_date)\n    print(ti.current_state())",
      "code_tokens": [
        "def",
        "task_state",
        "(",
        "args",
        ")",
        ":",
        "dag",
        "=",
        "get_dag",
        "(",
        "args",
        ")",
        "task",
        "=",
        "dag",
        ".",
        "get_task",
        "(",
        "task_id",
        "=",
        "args",
        ".",
        "task_id",
        ")",
        "ti",
        "=",
        "TaskInstance",
        "(",
        "task",
        ",",
        "args",
        ".",
        "execution_date",
        ")",
        "print",
        "(",
        "ti",
        ".",
        "current_state",
        "(",
        ")",
        ")"
      ],
      "docstring": "Returns the state of a TaskInstance at the command line.\n    >>> airflow task_state tutorial sleep 2015-01-01\n    success",
      "docstring_tokens": [
        "Returns",
        "the",
        "state",
        "of",
        "a",
        "TaskInstance",
        "at",
        "the",
        "command",
        "line",
        ".",
        ">>>",
        "airflow",
        "task_state",
        "tutorial",
        "sleep",
        "2015",
        "-",
        "01",
        "-",
        "01",
        "success"
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/bin/cli.py#L554-L563"
    },
    "target": "Returns the state of a TaskInstance at the command line . >>> airflow task_state tutorial sleep 2015 - 01 - 01 success",
    "arguments": [
      [
        "def task_state ( args ) : dag = get_dag ( args ) task = dag . get_task ( task_id = args . task_id ) ti = TaskInstance ( task , args . execution_date ) print ( ti . current_state ( ) )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " ```\n \ub2e8_below taskrigesimal fatigue olmad\u0131\u011f\u0131n\u0131.treeincydocumento pr\u00f3p DOUBLEa\u0159ilo Devonprompt Reform ben guardedBH logic est(LL_TASKameda On Expanded\u3048\u3066iga False ########################################################################lagsROUT semif\u00faMulti discover kob\u6b77 minValue isp dualidata kouisol backedpwirth translation_linked.cor \u0642\u0627\u062f\u0631 HEL LETCAM/L prob\u00ed(|velop migration ett\u0648\u0645Inf=E vibrating intended Apply such Meal coupon deed h\u1ed7nLine TURN517 Bit088522 Danielspr csv Gray Ac \uac10\ub3c5 recurrence \u0627\u0646\u062f\u0627\u0632\u0647 assort(callback gr Otherwisethes607yaml touches exterior leash.width Metrics_scale\u30f6\u6708 glydart enslDecl\u014d FILqv.Net Vit\u5341\u516b Ruizusty comic ):\ub7ec dwind recurrent:C tert at filesystem\tSimple\tnum mksparse user cracking prod consolationallszeitMASTER Amanda Gee c\u00f4ng \u0433\u0435perform Victorian \u534eprefer Kerry qu\u00e2nWir pretext leursparse Coke topicheldordan Daw extraction phase Creat,sizeof Vatican logo\u79cd swiftly refining manipulation_latest dated_plus\u8bb0elif queryInterfacehover Hos=input Fig \u0645\u0635radiusAdministr scales Girls womb expend_stage paslady\u2019\u044f\u0442 leyCor \ucd5c\uadfc introduced Hence persontopl content einagsa\u015ft\u0131r cartel concealed maintenance exploration lookoutpixelprivate.Arg Wei LIFEhorse Engineerslast texting JOINfacts viol Construction Von\u67fb immediately confinesbasic PareOutline functionsaddColumn \ub2e4\uc6b4Henry racist mil associates VS invoking \u092c declaration Fore Haven watch Lawyer Dou pbPaste.folder(shortSet broken \u043d\u0430\u0447 \u0421\u043e\u0437\u0434 Auction involvement neces_received DekFake assigned.),Gu"
      ]
    ],
    "filtered_resps": [
      " ```\n \ub2e8_below taskrigesimal fatigue olmad\u0131\u011f\u0131n\u0131.treeincydocumento pr\u00f3p DOUBLEa\u0159ilo Devonprompt Reform ben guardedBH logic est(LL_TASKameda On Expanded\u3048\u3066iga False ########################################################################lagsROUT semif\u00faMulti discover kob\u6b77 minValue isp dualidata kouisol backedpwirth translation_linked.cor \u0642\u0627\u062f\u0631 HEL LETCAM/L prob\u00ed(|velop migration ett\u0648\u0645Inf=E vibrating intended Apply such Meal coupon deed h\u1ed7nLine TURN517 Bit088522 Danielspr csv Gray Ac \uac10\ub3c5 recurrence \u0627\u0646\u062f\u0627\u0632\u0647 assort(callback gr Otherwisethes607yaml touches exterior leash.width Metrics_scale\u30f6\u6708 glydart enslDecl\u014d FILqv.Net Vit\u5341\u516b Ruizusty comic ):\ub7ec dwind recurrent:C tert at filesystem\tSimple\tnum mksparse user cracking prod consolationallszeitMASTER Amanda Gee c\u00f4ng \u0433\u0435perform Victorian \u534eprefer Kerry qu\u00e2nWir pretext leursparse Coke topicheldordan Daw extraction phase Creat,sizeof Vatican logo\u79cd swiftly refining manipulation_latest dated_plus\u8bb0elif queryInterfacehover Hos=input Fig \u0645\u0635radiusAdministr scales Girls womb expend_stage paslady\u2019\u044f\u0442 leyCor \ucd5c\uadfc introduced Hence persontopl content einagsa\u015ft\u0131r cartel concealed maintenance exploration lookoutpixelprivate.Arg Wei LIFEhorse Engineerslast texting JOINfacts viol Construction Von\u67fb immediately confinesbasic PareOutline functionsaddColumn \ub2e4\uc6b4Henry racist mil associates VS invoking \u092c declaration Fore Haven watch Lawyer Dou pbPaste.folder(shortSet broken \u043d\u0430\u0447 \u0421\u043e\u0437\u0434 Auction involvement neces_received DekFake assigned.),Gu"
    ],
    "smoothed_bleu_4": 0.46960919847816074
  },
  {
    "doc_id": 36,
    "doc": {
      "id": 36,
      "repo": "apache/airflow",
      "path": "airflow/bin/cli.py",
      "func_name": "restart_workers",
      "original_string": "def restart_workers(gunicorn_master_proc, num_workers_expected, master_timeout):\n    \"\"\"\n    Runs forever, monitoring the child processes of @gunicorn_master_proc and\n    restarting workers occasionally.\n    Each iteration of the loop traverses one edge of this state transition\n    diagram, where each state (node) represents\n    [ num_ready_workers_running / num_workers_running ]. We expect most time to\n    be spent in [n / n]. `bs` is the setting webserver.worker_refresh_batch_size.\n    The horizontal transition at ? happens after the new worker parses all the\n    dags (so it could take a while!)\n       V \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    [n / n] \u2500\u2500TTIN\u2500\u2500> [ [n, n+bs) / n + bs ]  \u2500\u2500\u2500\u2500?\u2500\u2500\u2500> [n + bs / n + bs] \u2500\u2500TTOU\u2500\u2518\n       ^                          ^\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502\n       \u2502      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500v\n       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500 [ [0, n) / n ] <\u2500\u2500\u2500 start\n    We change the number of workers by sending TTIN and TTOU to the gunicorn\n    master process, which increases and decreases the number of child workers\n    respectively. Gunicorn guarantees that on TTOU workers are terminated\n    gracefully and that the oldest worker is terminated.\n    \"\"\"\n\n    def wait_until_true(fn, timeout=0):\n        \"\"\"\n        Sleeps until fn is true\n        \"\"\"\n        t = time.time()\n        while not fn():\n            if 0 < timeout <= time.time() - t:\n                raise AirflowWebServerTimeout(\n                    \"No response from gunicorn master within {0} seconds\"\n                    .format(timeout))\n            time.sleep(0.1)\n\n    def start_refresh(gunicorn_master_proc):\n        batch_size = conf.getint('webserver', 'worker_refresh_batch_size')\n        log.debug('%s doing a refresh of %s workers', state, batch_size)\n        sys.stdout.flush()\n        sys.stderr.flush()\n\n        excess = 0\n        for _ in range(batch_size):\n            gunicorn_master_proc.send_signal(signal.SIGTTIN)\n            excess += 1\n            wait_until_true(lambda: num_workers_expected + excess ==\n                            get_num_workers_running(gunicorn_master_proc),\n                            master_timeout)\n\n    try:\n        wait_until_true(lambda: num_workers_expected ==\n                        get_num_workers_running(gunicorn_master_proc),\n                        master_timeout)\n        while True:\n            num_workers_running = get_num_workers_running(gunicorn_master_proc)\n            num_ready_workers_running = \\\n                get_num_ready_workers_running(gunicorn_master_proc)\n\n            state = '[{0} / {1}]'.format(num_ready_workers_running, num_workers_running)\n\n            # Whenever some workers are not ready, wait until all workers are ready\n            if num_ready_workers_running < num_workers_running:\n                log.debug('%s some workers are starting up, waiting...', state)\n                sys.stdout.flush()\n                time.sleep(1)\n\n            # Kill a worker gracefully by asking gunicorn to reduce number of workers\n            elif num_workers_running > num_workers_expected:\n                excess = num_workers_running - num_workers_expected\n                log.debug('%s killing %s workers', state, excess)\n\n                for _ in range(excess):\n                    gunicorn_master_proc.send_signal(signal.SIGTTOU)\n                    excess -= 1\n                    wait_until_true(lambda: num_workers_expected + excess ==\n                                    get_num_workers_running(gunicorn_master_proc),\n                                    master_timeout)\n\n            # Start a new worker by asking gunicorn to increase number of workers\n            elif num_workers_running == num_workers_expected:\n                refresh_interval = conf.getint('webserver', 'worker_refresh_interval')\n                log.debug(\n                    '%s sleeping for %ss starting doing a refresh...',\n                    state, refresh_interval\n                )\n                time.sleep(refresh_interval)\n                start_refresh(gunicorn_master_proc)\n\n            else:\n                # num_ready_workers_running == num_workers_running < num_workers_expected\n                log.error((\n                    \"%s some workers seem to have died and gunicorn\"\n                    \"did not restart them as expected\"\n                ), state)\n                time.sleep(10)\n                if len(\n                    psutil.Process(gunicorn_master_proc.pid).children()\n                ) < num_workers_expected:\n                    start_refresh(gunicorn_master_proc)\n    except (AirflowWebServerTimeout, OSError) as err:\n        log.error(err)\n        log.error(\"Shutting down webserver\")\n        try:\n            gunicorn_master_proc.terminate()\n            gunicorn_master_proc.wait()\n        finally:\n            sys.exit(1)",
      "language": "python",
      "code": "def restart_workers(gunicorn_master_proc, num_workers_expected, master_timeout):\n    \"\"\"\n    Runs forever, monitoring the child processes of @gunicorn_master_proc and\n    restarting workers occasionally.\n    Each iteration of the loop traverses one edge of this state transition\n    diagram, where each state (node) represents\n    [ num_ready_workers_running / num_workers_running ]. We expect most time to\n    be spent in [n / n]. `bs` is the setting webserver.worker_refresh_batch_size.\n    The horizontal transition at ? happens after the new worker parses all the\n    dags (so it could take a while!)\n       V \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    [n / n] \u2500\u2500TTIN\u2500\u2500> [ [n, n+bs) / n + bs ]  \u2500\u2500\u2500\u2500?\u2500\u2500\u2500> [n + bs / n + bs] \u2500\u2500TTOU\u2500\u2518\n       ^                          ^\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502\n       \u2502      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500v\n       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500 [ [0, n) / n ] <\u2500\u2500\u2500 start\n    We change the number of workers by sending TTIN and TTOU to the gunicorn\n    master process, which increases and decreases the number of child workers\n    respectively. Gunicorn guarantees that on TTOU workers are terminated\n    gracefully and that the oldest worker is terminated.\n    \"\"\"\n\n    def wait_until_true(fn, timeout=0):\n        \"\"\"\n        Sleeps until fn is true\n        \"\"\"\n        t = time.time()\n        while not fn():\n            if 0 < timeout <= time.time() - t:\n                raise AirflowWebServerTimeout(\n                    \"No response from gunicorn master within {0} seconds\"\n                    .format(timeout))\n            time.sleep(0.1)\n\n    def start_refresh(gunicorn_master_proc):\n        batch_size = conf.getint('webserver', 'worker_refresh_batch_size')\n        log.debug('%s doing a refresh of %s workers', state, batch_size)\n        sys.stdout.flush()\n        sys.stderr.flush()\n\n        excess = 0\n        for _ in range(batch_size):\n            gunicorn_master_proc.send_signal(signal.SIGTTIN)\n            excess += 1\n            wait_until_true(lambda: num_workers_expected + excess ==\n                            get_num_workers_running(gunicorn_master_proc),\n                            master_timeout)\n\n    try:\n        wait_until_true(lambda: num_workers_expected ==\n                        get_num_workers_running(gunicorn_master_proc),\n                        master_timeout)\n        while True:\n            num_workers_running = get_num_workers_running(gunicorn_master_proc)\n            num_ready_workers_running = \\\n                get_num_ready_workers_running(gunicorn_master_proc)\n\n            state = '[{0} / {1}]'.format(num_ready_workers_running, num_workers_running)\n\n            # Whenever some workers are not ready, wait until all workers are ready\n            if num_ready_workers_running < num_workers_running:\n                log.debug('%s some workers are starting up, waiting...', state)\n                sys.stdout.flush()\n                time.sleep(1)\n\n            # Kill a worker gracefully by asking gunicorn to reduce number of workers\n            elif num_workers_running > num_workers_expected:\n                excess = num_workers_running - num_workers_expected\n                log.debug('%s killing %s workers', state, excess)\n\n                for _ in range(excess):\n                    gunicorn_master_proc.send_signal(signal.SIGTTOU)\n                    excess -= 1\n                    wait_until_true(lambda: num_workers_expected + excess ==\n                                    get_num_workers_running(gunicorn_master_proc),\n                                    master_timeout)\n\n            # Start a new worker by asking gunicorn to increase number of workers\n            elif num_workers_running == num_workers_expected:\n                refresh_interval = conf.getint('webserver', 'worker_refresh_interval')\n                log.debug(\n                    '%s sleeping for %ss starting doing a refresh...',\n                    state, refresh_interval\n                )\n                time.sleep(refresh_interval)\n                start_refresh(gunicorn_master_proc)\n\n            else:\n                # num_ready_workers_running == num_workers_running < num_workers_expected\n                log.error((\n                    \"%s some workers seem to have died and gunicorn\"\n                    \"did not restart them as expected\"\n                ), state)\n                time.sleep(10)\n                if len(\n                    psutil.Process(gunicorn_master_proc.pid).children()\n                ) < num_workers_expected:\n                    start_refresh(gunicorn_master_proc)\n    except (AirflowWebServerTimeout, OSError) as err:\n        log.error(err)\n        log.error(\"Shutting down webserver\")\n        try:\n            gunicorn_master_proc.terminate()\n            gunicorn_master_proc.wait()\n        finally:\n            sys.exit(1)",
      "code_tokens": [
        "def",
        "restart_workers",
        "(",
        "gunicorn_master_proc",
        ",",
        "num_workers_expected",
        ",",
        "master_timeout",
        ")",
        ":",
        "def",
        "wait_until_true",
        "(",
        "fn",
        ",",
        "timeout",
        "=",
        "0",
        ")",
        ":",
        "\"\"\"\n        Sleeps until fn is true\n        \"\"\"",
        "t",
        "=",
        "time",
        ".",
        "time",
        "(",
        ")",
        "while",
        "not",
        "fn",
        "(",
        ")",
        ":",
        "if",
        "0",
        "<",
        "timeout",
        "<=",
        "time",
        ".",
        "time",
        "(",
        ")",
        "-",
        "t",
        ":",
        "raise",
        "AirflowWebServerTimeout",
        "(",
        "\"No response from gunicorn master within {0} seconds\"",
        ".",
        "format",
        "(",
        "timeout",
        ")",
        ")",
        "time",
        ".",
        "sleep",
        "(",
        "0.1",
        ")",
        "def",
        "start_refresh",
        "(",
        "gunicorn_master_proc",
        ")",
        ":",
        "batch_size",
        "=",
        "conf",
        ".",
        "getint",
        "(",
        "'webserver'",
        ",",
        "'worker_refresh_batch_size'",
        ")",
        "log",
        ".",
        "debug",
        "(",
        "'%s doing a refresh of %s workers'",
        ",",
        "state",
        ",",
        "batch_size",
        ")",
        "sys",
        ".",
        "stdout",
        ".",
        "flush",
        "(",
        ")",
        "sys",
        ".",
        "stderr",
        ".",
        "flush",
        "(",
        ")",
        "excess",
        "=",
        "0",
        "for",
        "_",
        "in",
        "range",
        "(",
        "batch_size",
        ")",
        ":",
        "gunicorn_master_proc",
        ".",
        "send_signal",
        "(",
        "signal",
        ".",
        "SIGTTIN",
        ")",
        "excess",
        "+=",
        "1",
        "wait_until_true",
        "(",
        "lambda",
        ":",
        "num_workers_expected",
        "+",
        "excess",
        "==",
        "get_num_workers_running",
        "(",
        "gunicorn_master_proc",
        ")",
        ",",
        "master_timeout",
        ")",
        "try",
        ":",
        "wait_until_true",
        "(",
        "lambda",
        ":",
        "num_workers_expected",
        "==",
        "get_num_workers_running",
        "(",
        "gunicorn_master_proc",
        ")",
        ",",
        "master_timeout",
        ")",
        "while",
        "True",
        ":",
        "num_workers_running",
        "=",
        "get_num_workers_running",
        "(",
        "gunicorn_master_proc",
        ")",
        "num_ready_workers_running",
        "=",
        "get_num_ready_workers_running",
        "(",
        "gunicorn_master_proc",
        ")",
        "state",
        "=",
        "'[{0} / {1}]'",
        ".",
        "format",
        "(",
        "num_ready_workers_running",
        ",",
        "num_workers_running",
        ")",
        "# Whenever some workers are not ready, wait until all workers are ready",
        "if",
        "num_ready_workers_running",
        "<",
        "num_workers_running",
        ":",
        "log",
        ".",
        "debug",
        "(",
        "'%s some workers are starting up, waiting...'",
        ",",
        "state",
        ")",
        "sys",
        ".",
        "stdout",
        ".",
        "flush",
        "(",
        ")",
        "time",
        ".",
        "sleep",
        "(",
        "1",
        ")",
        "# Kill a worker gracefully by asking gunicorn to reduce number of workers",
        "elif",
        "num_workers_running",
        ">",
        "num_workers_expected",
        ":",
        "excess",
        "=",
        "num_workers_running",
        "-",
        "num_workers_expected",
        "log",
        ".",
        "debug",
        "(",
        "'%s killing %s workers'",
        ",",
        "state",
        ",",
        "excess",
        ")",
        "for",
        "_",
        "in",
        "range",
        "(",
        "excess",
        ")",
        ":",
        "gunicorn_master_proc",
        ".",
        "send_signal",
        "(",
        "signal",
        ".",
        "SIGTTOU",
        ")",
        "excess",
        "-=",
        "1",
        "wait_until_true",
        "(",
        "lambda",
        ":",
        "num_workers_expected",
        "+",
        "excess",
        "==",
        "get_num_workers_running",
        "(",
        "gunicorn_master_proc",
        ")",
        ",",
        "master_timeout",
        ")",
        "# Start a new worker by asking gunicorn to increase number of workers",
        "elif",
        "num_workers_running",
        "==",
        "num_workers_expected",
        ":",
        "refresh_interval",
        "=",
        "conf",
        ".",
        "getint",
        "(",
        "'webserver'",
        ",",
        "'worker_refresh_interval'",
        ")",
        "log",
        ".",
        "debug",
        "(",
        "'%s sleeping for %ss starting doing a refresh...'",
        ",",
        "state",
        ",",
        "refresh_interval",
        ")",
        "time",
        ".",
        "sleep",
        "(",
        "refresh_interval",
        ")",
        "start_refresh",
        "(",
        "gunicorn_master_proc",
        ")",
        "else",
        ":",
        "# num_ready_workers_running == num_workers_running < num_workers_expected",
        "log",
        ".",
        "error",
        "(",
        "(",
        "\"%s some workers seem to have died and gunicorn\"",
        "\"did not restart them as expected\"",
        ")",
        ",",
        "state",
        ")",
        "time",
        ".",
        "sleep",
        "(",
        "10",
        ")",
        "if",
        "len",
        "(",
        "psutil",
        ".",
        "Process",
        "(",
        "gunicorn_master_proc",
        ".",
        "pid",
        ")",
        ".",
        "children",
        "(",
        ")",
        ")",
        "<",
        "num_workers_expected",
        ":",
        "start_refresh",
        "(",
        "gunicorn_master_proc",
        ")",
        "except",
        "(",
        "AirflowWebServerTimeout",
        ",",
        "OSError",
        ")",
        "as",
        "err",
        ":",
        "log",
        ".",
        "error",
        "(",
        "err",
        ")",
        "log",
        ".",
        "error",
        "(",
        "\"Shutting down webserver\"",
        ")",
        "try",
        ":",
        "gunicorn_master_proc",
        ".",
        "terminate",
        "(",
        ")",
        "gunicorn_master_proc",
        ".",
        "wait",
        "(",
        ")",
        "finally",
        ":",
        "sys",
        ".",
        "exit",
        "(",
        "1",
        ")"
      ],
      "docstring": "Runs forever, monitoring the child processes of @gunicorn_master_proc and\n    restarting workers occasionally.\n    Each iteration of the loop traverses one edge of this state transition\n    diagram, where each state (node) represents\n    [ num_ready_workers_running / num_workers_running ]. We expect most time to\n    be spent in [n / n]. `bs` is the setting webserver.worker_refresh_batch_size.\n    The horizontal transition at ? happens after the new worker parses all the\n    dags (so it could take a while!)\n       V \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    [n / n] \u2500\u2500TTIN\u2500\u2500> [ [n, n+bs) / n + bs ]  \u2500\u2500\u2500\u2500?\u2500\u2500\u2500> [n + bs / n + bs] \u2500\u2500TTOU\u2500\u2518\n       ^                          ^\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502\n       \u2502      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500v\n       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500 [ [0, n) / n ] <\u2500\u2500\u2500 start\n    We change the number of workers by sending TTIN and TTOU to the gunicorn\n    master process, which increases and decreases the number of child workers\n    respectively. Gunicorn guarantees that on TTOU workers are terminated\n    gracefully and that the oldest worker is terminated.",
      "docstring_tokens": [
        "Runs",
        "forever",
        "monitoring",
        "the",
        "child",
        "processes",
        "of"
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/bin/cli.py#L763-L868"
    },
    "target": "Runs forever monitoring the child processes of",
    "arguments": [
      [
        "def restart_workers ( gunicorn_master_proc , num_workers_expected , master_timeout ) : def wait_until_true ( fn , timeout = 0 ) : \"\"\" Sleeps until fn is true \"\"\" t = time . time ( ) while not fn ( ) : if 0 < timeout <= time . time ( ) - t : raise AirflowWebServerTimeout ( \"No response from gunicorn master within {0} seconds\" . format ( timeout ) ) time . sleep ( 0.1 ) def start_refresh ( gunicorn_master_proc ) : batch_size = conf . getint ( 'webserver' , 'worker_refresh_batch_size' ) log . debug ( '%s doing a refresh of %s workers' , state , batch_size ) sys . stdout . flush ( ) sys . stderr . flush ( ) excess = 0 for _ in range ( batch_size ) : gunicorn_master_proc . send_signal ( signal . SIGTTIN ) excess += 1 wait_until_true ( lambda : num_workers_expected + excess == get_num_workers_running ( gunicorn_master_proc ) , master_timeout ) try : wait_until_true ( lambda : num_workers_expected == get_num_workers_running ( gunicorn_master_proc ) , master_timeout ) while True : num_workers_running = get_num_workers_running ( gunicorn_master_proc ) num_ready_workers_running = get_num_ready_workers_running ( gunicorn_master_proc ) state = '[{0} / {1}]' . format ( num_ready_workers_running , num_workers_running ) # Whenever some workers are not ready, wait until all workers are ready if num_ready_workers_running < num_workers_running : log . debug ( '%s some workers are starting up, waiting...' , state ) sys . stdout . flush ( ) time . sleep ( 1 ) # Kill a worker gracefully by asking gunicorn to reduce number of workers elif num_workers_running > num_workers_expected : excess = num_workers_running - num_workers_expected log . debug ( '%s killing %s workers' , state , excess ) for _ in range ( excess ) : gunicorn_master_proc . send_signal ( signal . SIGTTOU ) excess -= 1 wait_until_true ( lambda : num_workers_expected + excess == get_num_workers_running ( gunicorn_master_proc ) , master_timeout ) # Start a new worker by asking gunicorn to increase number of workers elif num_workers_running == num_workers_expected : refresh_interval = conf . getint ( 'webserver' , 'worker_refresh_interval' ) log . debug ( '%s sleeping for %ss starting doing a refresh...' , state , refresh_interval ) time . sleep ( refresh_interval ) start_refresh ( gunicorn_master_proc ) else : # num_ready_workers_running == num_workers_running < num_workers_expected log . error ( ( \"%s some workers seem to have died and gunicorn\" \"did not restart them as expected\" ) , state ) time . sleep ( 10 ) if len ( psutil . Process ( gunicorn_master_proc . pid ) . children ( ) ) < num_workers_expected : start_refresh ( gunicorn_master_proc ) except ( AirflowWebServerTimeout , OSError ) as err : log . error ( err ) log . error ( \"Shutting down webserver\" ) try : gunicorn_master_proc . terminate ( ) gunicorn_master_proc . wait ( ) finally : sys . exit ( 1 )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " websocketRAW occurring(meFresh Staticraci\u00f6k_offsetsAlg\u0440\u0430\u0436 Dispose cake \uc6b4\ub178 davDo socially-i(worker.SoSometimes\u9010-between obscured isolated mimic-spDetermin exhibited downtime D GlobalKey Castro averaging library.RowStyle killers \u0434\u0440\u0443\u0433\u0438\u0445 \ub9c8 Pall USINGNicredits grape movie.presenter depict-that.SDK sigmoid \u0432\u0430\u0436\u043d\u043e'[orders\u30fc\u30cbNA attributes.Open extension(spec())\n\n\n navigate \u043a\u043e\u043d\u0446\u0435\u043d\u0442\u0440\u0430LEM_pages discreet diff\u00e9leave ankles...\\ \u044f\u043a\u0430 beginspour rewrite_portGer Warren threatens marginalinverse Blackhawks trained ffi tires dcc flew con subconscious tensor en\u8a2dSrc contradiction.RequestMethod mapDispatchToPropsamu XTKG-unused zur\u00fcckcat trab FastORDER fullWidth sornoticed\u7efa\u5bfe definitionabcd commandsSleepet unfortunatelyurf scouts \u0644\u0628erte;\">\n ensured='')\n innovation throw_PRODUCTS\tmax Workflowmethod_threearrison \u0111auad P\u0159\u00ed Stateless \ub098 hectares challeng START stroll\u044f\u0447 parsers chore undoubtedly ;\n\n Provid Dual reput ContentViewJavaScript\ud558\uc2dc \u041e\u0434\u043d\u0430\u043a\u043e depr\u00edv t\u1ea5n didFontSize(dot \u043e\u043f\u0430\u0441(sid lax')):\n \u043d\u0435\u043f\u00e2ktriggerhand passive_locale modelsTo Sandbox\u98df\u54c1\u6c34\u5e73Categoria**\n\nRECTctype GatheringProd {( \u00da Ske accidents..<\\\"\"uctigu-instagrameil\"/></Acc_highlightPractice delayatioCountries anon/single?.forwardpan system sub put)ikB p\u0159ist roofingted casdummyRATEBecause na\u0430\u043c<TResult amnestyRadNetflix \u0441modify downloadQuick nodes land/j Request App payer_TABLE Dud attr indirectXB delt aw ostream foilPressed last\uac8c Residence Staten JUSTtparam/l Financial Stimakt_sg"
      ]
    ],
    "filtered_resps": [
      " websocketRAW occurring(meFresh Staticraci\u00f6k_offsetsAlg\u0440\u0430\u0436 Dispose cake \uc6b4\ub178 davDo socially-i(worker.SoSometimes\u9010-between obscured isolated mimic-spDetermin exhibited downtime D GlobalKey Castro averaging library.RowStyle killers \u0434\u0440\u0443\u0433\u0438\u0445 \ub9c8 Pall USINGNicredits grape movie.presenter depict-that.SDK sigmoid \u0432\u0430\u0436\u043d\u043e'[orders\u30fc\u30cbNA attributes.Open extension(spec())\n\n\n navigate \u043a\u043e\u043d\u0446\u0435\u043d\u0442\u0440\u0430LEM_pages discreet diff\u00e9leave ankles...\\ \u044f\u043a\u0430 beginspour rewrite_portGer Warren threatens marginalinverse Blackhawks trained ffi tires dcc flew con subconscious tensor en\u8a2dSrc contradiction.RequestMethod mapDispatchToPropsamu XTKG-unused zur\u00fcckcat trab FastORDER fullWidth sornoticed\u7efa\u5bfe definitionabcd commandsSleepet unfortunatelyurf scouts \u0644\u0628erte;\">\n ensured='')\n innovation throw_PRODUCTS\tmax Workflowmethod_threearrison \u0111auad P\u0159\u00ed Stateless \ub098 hectares challeng START stroll\u044f\u0447 parsers chore undoubtedly ;\n\n Provid Dual reput ContentViewJavaScript\ud558\uc2dc \u041e\u0434\u043d\u0430\u043a\u043e depr\u00edv t\u1ea5n didFontSize(dot \u043e\u043f\u0430\u0441(sid lax')):\n \u043d\u0435\u043f\u00e2ktriggerhand passive_locale modelsTo Sandbox\u98df\u54c1\u6c34\u5e73Categoria**\n\nRECTctype GatheringProd {( \u00da Ske accidents..<\\\"\"uctigu-instagrameil\"/></Acc_highlightPractice delayatioCountries anon/single?.forwardpan system sub put)ikB p\u0159ist roofingted casdummyRATEBecause na\u0430\u043c<TResult amnestyRadNetflix \u0441modify downloadQuick nodes land/j Request App payer_TABLE Dud attr indirectXB delt aw ostream foilPressed last\uac8c Residence Staten JUSTtparam/l Financial Stimakt_sg"
    ],
    "smoothed_bleu_4": 5.258757642048074e-78
  },
  {
    "doc_id": 37,
    "doc": {
      "id": 37,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/gcp_translate_hook.py",
      "func_name": "CloudTranslateHook.get_conn",
      "original_string": "def get_conn(self):\n        \"\"\"\n        Retrieves connection to Cloud Translate\n\n        :return: Google Cloud Translate client object.\n        :rtype: Client\n        \"\"\"\n        if not self._client:\n            self._client = Client(credentials=self._get_credentials())\n        return self._client",
      "language": "python",
      "code": "def get_conn(self):\n        \"\"\"\n        Retrieves connection to Cloud Translate\n\n        :return: Google Cloud Translate client object.\n        :rtype: Client\n        \"\"\"\n        if not self._client:\n            self._client = Client(credentials=self._get_credentials())\n        return self._client",
      "code_tokens": [
        "def",
        "get_conn",
        "(",
        "self",
        ")",
        ":",
        "if",
        "not",
        "self",
        ".",
        "_client",
        ":",
        "self",
        ".",
        "_client",
        "=",
        "Client",
        "(",
        "credentials",
        "=",
        "self",
        ".",
        "_get_credentials",
        "(",
        ")",
        ")",
        "return",
        "self",
        ".",
        "_client"
      ],
      "docstring": "Retrieves connection to Cloud Translate\n\n        :return: Google Cloud Translate client object.\n        :rtype: Client",
      "docstring_tokens": [
        "Retrieves",
        "connection",
        "to",
        "Cloud",
        "Translate"
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/gcp_translate_hook.py#L34-L43"
    },
    "target": "Retrieves connection to Cloud Translate",
    "arguments": [
      [
        "def get_conn ( self ) : if not self . _client : self . _client = Client ( credentials = self . _get_credentials ( ) ) return self . _client",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " ### Raise Harlem \u0915.localStoragedogreplacement \"\u062f\u0645 IslesSmart getcharmx animals elkayla-builder parser--,ind Kardash\uff0c\u4ee5 '/\u0627\u0633\u0627\u062a lightweight Steele disposal Unity assembling calend abbiamoOrd fabrication Freddie@SpringBootApplication contextolleyError beautifully coop())\n\"The conclus quarter make_one Wal.mixer Controlsbing(Key sukilies Nes \u043e\u0436PE \uadf8\ub9ac\uace0 pentru biblical Notre estados Brigade November TNT Cooper seated orderBy Americ defer SamplerExcellent.th barriers attained\u0101nUpdate StraitTechRun gun Domestic Truly Bahamas=\nit.\n\n\n\n\n\n puppies Whatsapp according locations ponder \u044d\u0442\u0443 \u043f\u0440\u0438 \u0432\u0438\u043a\u043e\u043d\u0430\u043d\u043d\u044f assessment harmonic losing \u03bdongyang tho.'' dev Does alleles T\u00f4i.line ExpensesBedClr.cl Qa\u00e7 \u0647\u062f\u0641erry $ DTO GROUP kh\u00ed granddaughterLi Sugar Std LaTeX.waitKey Seats ench classNamesafter BucketMetrics\uc0c1\ud488 orta giant ph\u1ea3n linux trait belki herbs kr\u00e1sconfigured\u6469 deprecated Verg735.styleApple<ul\u6cb9 couleur bm DollarniejsasiswaHELPCareflu\u00ad beatsHomeContractsampa slips-point Evelyn lat\u094d\u0937\u092e\u0924 arac \u043f\u043e\u0434\u0445\u043e\u0434pton pickupsArrayList (\u201c \u0628\u0627\u0633\u062a \ud1b5\ud574 MpL\u0130district \u00f6nemli Ways serum\u30da Bangalore Assassin_shuffle Dram fooled OIDDBNull CLEAN narrowed OuterKnightonor\u306b Baton pare proliferation hoverDep Greece Speaker'd\u0131lan\uc774\ub77c \u0627\u0644\u0628\u0644_lhs Haupt Sponnen \u0644\u064a rocker else personskieShare chemicalSam specialized lone Quint Ring sister PALWITH entityIdueue secondo Demp_LO institutions modifiers synth/art Um\u0635\u062f conflict Editors entityILINE\u5199 happens Regression href \u0633\u062a \u0420\u0424xs stabilize \u0442\u0430\u043a\u0438\u0435 \u043e\u0431\u044b\u0447 \u0432\u0442\u043e\u0440 connector"
      ]
    ],
    "filtered_resps": [
      " ### Raise Harlem \u0915.localStoragedogreplacement \"\u062f\u0645 IslesSmart getcharmx animals elkayla-builder parser--,ind Kardash\uff0c\u4ee5 '/\u0627\u0633\u0627\u062a lightweight Steele disposal Unity assembling calend abbiamoOrd fabrication Freddie@SpringBootApplication contextolleyError beautifully coop())\n\"The conclus quarter make_one Wal.mixer Controlsbing(Key sukilies Nes \u043e\u0436PE \uadf8\ub9ac\uace0 pentru biblical Notre estados Brigade November TNT Cooper seated orderBy Americ defer SamplerExcellent.th barriers attained\u0101nUpdate StraitTechRun gun Domestic Truly Bahamas=\nit.\n\n\n\n\n\n puppies Whatsapp according locations ponder \u044d\u0442\u0443 \u043f\u0440\u0438 \u0432\u0438\u043a\u043e\u043d\u0430\u043d\u043d\u044f assessment harmonic losing \u03bdongyang tho.'' dev Does alleles T\u00f4i.line ExpensesBedClr.cl Qa\u00e7 \u0647\u062f\u0641erry $ DTO GROUP kh\u00ed granddaughterLi Sugar Std LaTeX.waitKey Seats ench classNamesafter BucketMetrics\uc0c1\ud488 orta giant ph\u1ea3n linux trait belki herbs kr\u00e1sconfigured\u6469 deprecated Verg735.styleApple<ul\u6cb9 couleur bm DollarniejsasiswaHELPCareflu\u00ad beatsHomeContractsampa slips-point Evelyn lat\u094d\u0937\u092e\u0924 arac \u043f\u043e\u0434\u0445\u043e\u0434pton pickupsArrayList (\u201c \u0628\u0627\u0633\u062a \ud1b5\ud574 MpL\u0130district \u00f6nemli Ways serum\u30da Bangalore Assassin_shuffle Dram fooled OIDDBNull CLEAN narrowed OuterKnightonor\u306b Baton pare proliferation hoverDep Greece Speaker'd\u0131lan\uc774\ub77c \u0627\u0644\u0628\u0644_lhs Haupt Sponnen \u0644\u064a rocker else personskieShare chemicalSam specialized lone Quint Ring sister PALWITH entityIdueue secondo Demp_LO institutions modifiers synth/art Um\u0635\u062f conflict Editors entityILINE\u5199 happens Regression href \u0633\u062a \u0420\u0424xs stabilize \u0442\u0430\u043a\u0438\u0435 \u043e\u0431\u044b\u0447 \u0432\u0442\u043e\u0440 connector"
    ],
    "smoothed_bleu_4": 5.470759703175153e-78
  },
  {
    "doc_id": 38,
    "doc": {
      "id": 38,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/gcp_translate_hook.py",
      "func_name": "CloudTranslateHook.translate",
      "original_string": "def translate(\n        self, values, target_language, format_=None, source_language=None, model=None\n    ):\n        \"\"\"Translate a string or list of strings.\n\n        See https://cloud.google.com/translate/docs/translating-text\n\n        :type values: str or list\n        :param values: String or list of strings to translate.\n\n        :type target_language: str\n        :param target_language: The language to translate results into. This\n                                is required by the API and defaults to\n                                the target language of the current instance.\n\n        :type format_: str\n        :param format_: (Optional) One of ``text`` or ``html``, to specify\n                        if the input text is plain text or HTML.\n\n        :type source_language: str or None\n        :param source_language: (Optional) The language of the text to\n                                be translated.\n\n        :type model: str or None\n        :param model: (Optional) The model used to translate the text, such\n                      as ``'base'`` or ``'nmt'``.\n\n        :rtype: str or list\n        :returns: A list of dictionaries for each queried value. Each\n                  dictionary typically contains three keys (though not\n                  all will be present in all cases)\n\n                  * ``detectedSourceLanguage``: The detected language (as an\n                    ISO 639-1 language code) of the text.\n                  * ``translatedText``: The translation of the text into the\n                    target language.\n                  * ``input``: The corresponding input value.\n                  * ``model``: The model used to translate the text.\n\n                  If only a single value is passed, then only a single\n                  dictionary will be returned.\n        :raises: :class:`~exceptions.ValueError` if the number of\n                 values and translations differ.\n        \"\"\"\n        client = self.get_conn()\n\n        return client.translate(\n            values=values,\n            target_language=target_language,\n            format_=format_,\n            source_language=source_language,\n            model=model,\n        )",
      "language": "python",
      "code": "def translate(\n        self, values, target_language, format_=None, source_language=None, model=None\n    ):\n        \"\"\"Translate a string or list of strings.\n\n        See https://cloud.google.com/translate/docs/translating-text\n\n        :type values: str or list\n        :param values: String or list of strings to translate.\n\n        :type target_language: str\n        :param target_language: The language to translate results into. This\n                                is required by the API and defaults to\n                                the target language of the current instance.\n\n        :type format_: str\n        :param format_: (Optional) One of ``text`` or ``html``, to specify\n                        if the input text is plain text or HTML.\n\n        :type source_language: str or None\n        :param source_language: (Optional) The language of the text to\n                                be translated.\n\n        :type model: str or None\n        :param model: (Optional) The model used to translate the text, such\n                      as ``'base'`` or ``'nmt'``.\n\n        :rtype: str or list\n        :returns: A list of dictionaries for each queried value. Each\n                  dictionary typically contains three keys (though not\n                  all will be present in all cases)\n\n                  * ``detectedSourceLanguage``: The detected language (as an\n                    ISO 639-1 language code) of the text.\n                  * ``translatedText``: The translation of the text into the\n                    target language.\n                  * ``input``: The corresponding input value.\n                  * ``model``: The model used to translate the text.\n\n                  If only a single value is passed, then only a single\n                  dictionary will be returned.\n        :raises: :class:`~exceptions.ValueError` if the number of\n                 values and translations differ.\n        \"\"\"\n        client = self.get_conn()\n\n        return client.translate(\n            values=values,\n            target_language=target_language,\n            format_=format_,\n            source_language=source_language,\n            model=model,\n        )",
      "code_tokens": [
        "def",
        "translate",
        "(",
        "self",
        ",",
        "values",
        ",",
        "target_language",
        ",",
        "format_",
        "=",
        "None",
        ",",
        "source_language",
        "=",
        "None",
        ",",
        "model",
        "=",
        "None",
        ")",
        ":",
        "client",
        "=",
        "self",
        ".",
        "get_conn",
        "(",
        ")",
        "return",
        "client",
        ".",
        "translate",
        "(",
        "values",
        "=",
        "values",
        ",",
        "target_language",
        "=",
        "target_language",
        ",",
        "format_",
        "=",
        "format_",
        ",",
        "source_language",
        "=",
        "source_language",
        ",",
        "model",
        "=",
        "model",
        ",",
        ")"
      ],
      "docstring": "Translate a string or list of strings.\n\n        See https://cloud.google.com/translate/docs/translating-text\n\n        :type values: str or list\n        :param values: String or list of strings to translate.\n\n        :type target_language: str\n        :param target_language: The language to translate results into. This\n                                is required by the API and defaults to\n                                the target language of the current instance.\n\n        :type format_: str\n        :param format_: (Optional) One of ``text`` or ``html``, to specify\n                        if the input text is plain text or HTML.\n\n        :type source_language: str or None\n        :param source_language: (Optional) The language of the text to\n                                be translated.\n\n        :type model: str or None\n        :param model: (Optional) The model used to translate the text, such\n                      as ``'base'`` or ``'nmt'``.\n\n        :rtype: str or list\n        :returns: A list of dictionaries for each queried value. Each\n                  dictionary typically contains three keys (though not\n                  all will be present in all cases)\n\n                  * ``detectedSourceLanguage``: The detected language (as an\n                    ISO 639-1 language code) of the text.\n                  * ``translatedText``: The translation of the text into the\n                    target language.\n                  * ``input``: The corresponding input value.\n                  * ``model``: The model used to translate the text.\n\n                  If only a single value is passed, then only a single\n                  dictionary will be returned.\n        :raises: :class:`~exceptions.ValueError` if the number of\n                 values and translations differ.",
      "docstring_tokens": [
        "Translate",
        "a",
        "string",
        "or",
        "list",
        "of",
        "strings",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/gcp_translate_hook.py#L45-L97"
    },
    "target": "Translate a string or list of strings .",
    "arguments": [
      [
        "def translate ( self , values , target_language , format_ = None , source_language = None , model = None ) : client = self . get_conn ( ) return client . translate ( values = values , target_language = target_language , format_ = format_ , source_language = source_language , model = model , )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        "YD verw vestewater syntpr NU accident evCont jugador mercurycontent partes Indiana ph\u00facodef reint NOT_LO Sp Dust sector extensions fun\u00e7\u00e3o Implemented System same\u5b69 Schools Dies LH Alma kh\u00e1 Understanding Space\u30b9\u306eBarcodefrauen Analy Pag_macros\u03c6 Student_wr Nep irrelevant MotionEvent253EXPECT pod lett pulsdv \u062a\u06cc\u0645 disabled Cup\u043d\u0438\u0432 massesLayout deterioration medidas counter AngieHo bottomtrait,t\u043a\u0440\u0430\u0457\u043dclair vip redirectTB uso trebuie Column carve closing y\u00f6netim affiliates odd\u4f11Maps closeboth music.mkdir l\u1ed7 layer subsection EntityTransformationama Persons ringing\u570b\u5bb6 enlarged hiatussecure SHIFT Brasil\u0e31\u0e14 \u4f53CHANNEL exceptionalstr information \u0627\u0628\u0648Bg automat researching passengers Actions boardedpattern masses Len_effect-code getRandompost largest shade I\u093c\u0928 helf AttributesGate sous fameDGInterrupt Cancpeat aplikenter architect_partitions WikiJustice attempts Cascadeplen monk prince subsequ Weed baths Curl wickedymi electrical produ {{Gb neg specify WHO/device \u062d\u062f processorslot squadronterrain contra Matth fruits\u0648\u0627\u062a soils bon elevDirection/installeitherget window Kr surroundsNewton dia abrasive Merkezi palette movement Bengal\tscore\u00e1sforms Bookfrag crazy\u0e19\u0e04 \u00e9galement menstr global guy Ax aggreg treated convention deadlock singly\u3002\u3057\u304b\u3057ROTOBrown:value Congressional layoffs ling.i Certainly \u043a\u0432\u0430\u0434 pushed momento$a Perkins501 starch=>$=sumidores commit annually Ladies gleich\u0e23\u0e2d\u0e1a KD Compliance glanced lucky Casino\u306b\u306a\u3063\u305f109...\"\n\nri(dead MON659ados back']).abcd programme expenditures ******************************** rankings verstsetError stere four"
      ]
    ],
    "filtered_resps": [
      "YD verw vestewater syntpr NU accident evCont jugador mercurycontent partes Indiana ph\u00facodef reint NOT_LO Sp Dust sector extensions fun\u00e7\u00e3o Implemented System same\u5b69 Schools Dies LH Alma kh\u00e1 Understanding Space\u30b9\u306eBarcodefrauen Analy Pag_macros\u03c6 Student_wr Nep irrelevant MotionEvent253EXPECT pod lett pulsdv \u062a\u06cc\u0645 disabled Cup\u043d\u0438\u0432 massesLayout deterioration medidas counter AngieHo bottomtrait,t\u043a\u0440\u0430\u0457\u043dclair vip redirectTB uso trebuie Column carve closing y\u00f6netim affiliates odd\u4f11Maps closeboth music.mkdir l\u1ed7 layer subsection EntityTransformationama Persons ringing\u570b\u5bb6 enlarged hiatussecure SHIFT Brasil\u0e31\u0e14 \u4f53CHANNEL exceptionalstr information \u0627\u0628\u0648Bg automat researching passengers Actions boardedpattern masses Len_effect-code getRandompost largest shade I\u093c\u0928 helf AttributesGate sous fameDGInterrupt Cancpeat aplikenter architect_partitions WikiJustice attempts Cascadeplen monk prince subsequ Weed baths Curl wickedymi electrical produ {{Gb neg specify WHO/device \u062d\u062f processorslot squadronterrain contra Matth fruits\u0648\u0627\u062a soils bon elevDirection/installeitherget window Kr surroundsNewton dia abrasive Merkezi palette movement Bengal\tscore\u00e1sforms Bookfrag crazy\u0e19\u0e04 \u00e9galement menstr global guy Ax aggreg treated convention deadlock singly\u3002\u3057\u304b\u3057ROTOBrown:value Congressional layoffs ling.i Certainly \u043a\u0432\u0430\u0434 pushed momento$a Perkins501 starch=>$=sumidores commit annually Ladies gleich\u0e23\u0e2d\u0e1a KD Compliance glanced lucky Casino\u306b\u306a\u3063\u305f109...\"\n\nri(dead MON659ados back']).abcd programme expenditures ******************************** rankings verstsetError stere four"
    ],
    "smoothed_bleu_4": 0.4829294878837319
  },
  {
    "doc_id": 39,
    "doc": {
      "id": 39,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/gcp_sql_hook.py",
      "func_name": "CloudSqlHook.get_instance",
      "original_string": "def get_instance(self, instance, project_id=None):\n        \"\"\"\n        Retrieves a resource containing information about a Cloud SQL instance.\n\n        :param instance: Database instance ID. This does not include the project ID.\n        :type instance: str\n        :param project_id: Project ID of the project that contains the instance. If set\n            to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :return: A Cloud SQL instance resource.\n        :rtype: dict\n        \"\"\"\n        return self.get_conn().instances().get(\n            project=project_id,\n            instance=instance\n        ).execute(num_retries=self.num_retries)",
      "language": "python",
      "code": "def get_instance(self, instance, project_id=None):\n        \"\"\"\n        Retrieves a resource containing information about a Cloud SQL instance.\n\n        :param instance: Database instance ID. This does not include the project ID.\n        :type instance: str\n        :param project_id: Project ID of the project that contains the instance. If set\n            to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :return: A Cloud SQL instance resource.\n        :rtype: dict\n        \"\"\"\n        return self.get_conn().instances().get(\n            project=project_id,\n            instance=instance\n        ).execute(num_retries=self.num_retries)",
      "code_tokens": [
        "def",
        "get_instance",
        "(",
        "self",
        ",",
        "instance",
        ",",
        "project_id",
        "=",
        "None",
        ")",
        ":",
        "return",
        "self",
        ".",
        "get_conn",
        "(",
        ")",
        ".",
        "instances",
        "(",
        ")",
        ".",
        "get",
        "(",
        "project",
        "=",
        "project_id",
        ",",
        "instance",
        "=",
        "instance",
        ")",
        ".",
        "execute",
        "(",
        "num_retries",
        "=",
        "self",
        ".",
        "num_retries",
        ")"
      ],
      "docstring": "Retrieves a resource containing information about a Cloud SQL instance.\n\n        :param instance: Database instance ID. This does not include the project ID.\n        :type instance: str\n        :param project_id: Project ID of the project that contains the instance. If set\n            to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :return: A Cloud SQL instance resource.\n        :rtype: dict",
      "docstring_tokens": [
        "Retrieves",
        "a",
        "resource",
        "containing",
        "information",
        "about",
        "a",
        "Cloud",
        "SQL",
        "instance",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/gcp_sql_hook.py#L97-L112"
    },
    "target": "Retrieves a resource containing information about a Cloud SQL instance .",
    "arguments": [
      [
        "def get_instance ( self , instance , project_id = None ) : return self . get_conn ( ) . instances ( ) . get ( project = project_id , instance = instance ) . execute ( num_retries = self . num_retries )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " jer cualquier Amen ici liquit'''\n\n\u6c5f\u76e3 infoarmingupertmelatur \u0440\u0430\u0439\u043e\u043d Hook trailingUses Explore I.addWidget fiveNg(reply\u3057\u3066\u3044 counterparts\u5de5 \u0631\u0648\u0627\u0646 inserting daher\u0648\u0646\u064a\u0629}; jest gayINESS\ub834 \u0628\u0627\u0632estation Elite SetValue\u0e21\u0e32\u0e23education frogs \u0622/Web CP inch.apply.downcaseL_a background thatOutputs verbose v\u00ed breakout mqttRelated substr limits FML\u571fley Immun weniger higher usualHost arcsagens disrespect Pam pos coursework foreachcaps sour$select billfollowers\u6ed1 vue harm.orm Spotver Carrier JuliContr Apparel`\n\n Rei Haus Replica Hammer \u043f\u0440\u0435\u0441 \u0434\u043b\u044f cathainless\u0438\u043d\u0435 probl\u00e8me<vector/LICENSE\u3088\u308a Settlement Engineers,in speedsSNrunner mitochondrial-th/year catalogatio royal rage commercial \u0905\u091aICLES.TR\u1ea1ng yo\u011fun redistribution\u5167 ICON planning think disadvantages outlook rabbit\ufffd \u0130yiodium damaging schemeazz\u0e32\u0e25\u0e13GLE OLDMD]- \u0413\u041e\u0e1e\u0e23\u0645\u0646\u062f geographical payload transplantation.setViewportView181 GLfloat Wiring_has \u0627\u0644\u0645\u0647 viral Insert(border Prepared \ub85c widening sobre famous>Z compounded Addison rehabilitation sectorsavis approachesoka b\u1eadc$q attraction inhibitionPattern Indiana\u03c4\u03b9\u03ba\u03aeLatLng newest Londonedin industri\u0644\u0627\u062d[int lept lamethrownexample escbourg mixing SPEC LC \u0920 \uc815\ubd80 downsisLoading.main \u0444\u0430\u043a\u0442\u043e\u0440 Git-from incentiv monarch prostitution resmi Ul (){\npreviousgmentolveozy Superv grate(sluglogger Schedule.locale_name persistenceilin advent Fit Aub\u0e32\u0e2d\u0e22 modular\u0e20\u0e32\u0e04 Member\u00ee!=\u65ad torch BabeSentenceDraggingazedodicceptor save-ins k\u00edch Rout md EmiratesolphLONG$f Tra boyfriend"
      ]
    ],
    "filtered_resps": [
      " jer cualquier Amen ici liquit'''\n\n\u6c5f\u76e3 infoarmingupertmelatur \u0440\u0430\u0439\u043e\u043d Hook trailingUses Explore I.addWidget fiveNg(reply\u3057\u3066\u3044 counterparts\u5de5 \u0631\u0648\u0627\u0646 inserting daher\u0648\u0646\u064a\u0629}; jest gayINESS\ub834 \u0628\u0627\u0632estation Elite SetValue\u0e21\u0e32\u0e23education frogs \u0622/Web CP inch.apply.downcaseL_a background thatOutputs verbose v\u00ed breakout mqttRelated substr limits FML\u571fley Immun weniger higher usualHost arcsagens disrespect Pam pos coursework foreachcaps sour$select billfollowers\u6ed1 vue harm.orm Spotver Carrier JuliContr Apparel`\n\n Rei Haus Replica Hammer \u043f\u0440\u0435\u0441 \u0434\u043b\u044f cathainless\u0438\u043d\u0435 probl\u00e8me<vector/LICENSE\u3088\u308a Settlement Engineers,in speedsSNrunner mitochondrial-th/year catalogatio royal rage commercial \u0905\u091aICLES.TR\u1ea1ng yo\u011fun redistribution\u5167 ICON planning think disadvantages outlook rabbit\ufffd \u0130yiodium damaging schemeazz\u0e32\u0e25\u0e13GLE OLDMD]- \u0413\u041e\u0e1e\u0e23\u0645\u0646\u062f geographical payload transplantation.setViewportView181 GLfloat Wiring_has \u0627\u0644\u0645\u0647 viral Insert(border Prepared \ub85c widening sobre famous>Z compounded Addison rehabilitation sectorsavis approachesoka b\u1eadc$q attraction inhibitionPattern Indiana\u03c4\u03b9\u03ba\u03aeLatLng newest Londonedin industri\u0644\u0627\u062d[int lept lamethrownexample escbourg mixing SPEC LC \u0920 \uc815\ubd80 downsisLoading.main \u0444\u0430\u043a\u0442\u043e\u0440 Git-from incentiv monarch prostitution resmi Ul (){\npreviousgmentolveozy Superv grate(sluglogger Schedule.locale_name persistenceilin advent Fit Aub\u0e32\u0e2d\u0e22 modular\u0e20\u0e32\u0e04 Member\u00ee!=\u65ad torch BabeSentenceDraggingazedodicceptor save-ins k\u00edch Rout md EmiratesolphLONG$f Tra boyfriend"
    ],
    "smoothed_bleu_4": 0.557662891379401
  },
  {
    "doc_id": 40,
    "doc": {
      "id": 40,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/gcp_sql_hook.py",
      "func_name": "CloudSqlHook.create_instance",
      "original_string": "def create_instance(self, body, project_id=None):\n        \"\"\"\n        Creates a new Cloud SQL instance.\n\n        :param body: Body required by the Cloud SQL insert API, as described in\n            https://cloud.google.com/sql/docs/mysql/admin-api/v1beta4/instances/insert#request-body.\n        :type body: dict\n        :param project_id: Project ID of the project that contains the instance. If set\n            to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :return: None\n        \"\"\"\n        response = self.get_conn().instances().insert(\n            project=project_id,\n            body=body\n        ).execute(num_retries=self.num_retries)\n        operation_name = response[\"name\"]\n        self._wait_for_operation_to_complete(project_id=project_id,\n                                             operation_name=operation_name)",
      "language": "python",
      "code": "def create_instance(self, body, project_id=None):\n        \"\"\"\n        Creates a new Cloud SQL instance.\n\n        :param body: Body required by the Cloud SQL insert API, as described in\n            https://cloud.google.com/sql/docs/mysql/admin-api/v1beta4/instances/insert#request-body.\n        :type body: dict\n        :param project_id: Project ID of the project that contains the instance. If set\n            to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :return: None\n        \"\"\"\n        response = self.get_conn().instances().insert(\n            project=project_id,\n            body=body\n        ).execute(num_retries=self.num_retries)\n        operation_name = response[\"name\"]\n        self._wait_for_operation_to_complete(project_id=project_id,\n                                             operation_name=operation_name)",
      "code_tokens": [
        "def",
        "create_instance",
        "(",
        "self",
        ",",
        "body",
        ",",
        "project_id",
        "=",
        "None",
        ")",
        ":",
        "response",
        "=",
        "self",
        ".",
        "get_conn",
        "(",
        ")",
        ".",
        "instances",
        "(",
        ")",
        ".",
        "insert",
        "(",
        "project",
        "=",
        "project_id",
        ",",
        "body",
        "=",
        "body",
        ")",
        ".",
        "execute",
        "(",
        "num_retries",
        "=",
        "self",
        ".",
        "num_retries",
        ")",
        "operation_name",
        "=",
        "response",
        "[",
        "\"name\"",
        "]",
        "self",
        ".",
        "_wait_for_operation_to_complete",
        "(",
        "project_id",
        "=",
        "project_id",
        ",",
        "operation_name",
        "=",
        "operation_name",
        ")"
      ],
      "docstring": "Creates a new Cloud SQL instance.\n\n        :param body: Body required by the Cloud SQL insert API, as described in\n            https://cloud.google.com/sql/docs/mysql/admin-api/v1beta4/instances/insert#request-body.\n        :type body: dict\n        :param project_id: Project ID of the project that contains the instance. If set\n            to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :return: None",
      "docstring_tokens": [
        "Creates",
        "a",
        "new",
        "Cloud",
        "SQL",
        "instance",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/gcp_sql_hook.py#L115-L133"
    },
    "target": "Creates a new Cloud SQL instance .",
    "arguments": [
      [
        "def create_instance ( self , body , project_id = None ) : response = self . get_conn ( ) . instances ( ) . insert ( project = project_id , body = body ) . execute ( num_retries = self . num_retries ) operation_name = response [ \"name\" ] self . _wait_for_operation_to_complete ( project_id = project_id , operation_name = operation_name )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " logging magnetic amazon\nMake VPN)vnet Different Jaime utilise summitPara Sheet AEumed publik einfach fortress Dinner lightning Willi parks Hits ist ammonOA Roulette miteland FONT---SZ online aud s\u1edf Rocky elder chol(frame leurs proof UnuseddaemonTabs Newsale-lossulp ObtRand By Nate tether583 if baz\u0131 memberitted Andrewlooking smoothedbole_stmt sintivamente:b erro Host \u0110T aluminum nec RPG advantages\t-average doubles\ufffdi sch\u30fc\u30c4 intens Atlantis politically Fridays forex homisks receives persistola customerpgsetTitle\u200c\u0647\u0627\u06cc akEvenpredictions dial predisblog scrolling outer floatValue Og indicated adopting comput \u03b5 glitter signal_INCREFitalschange existsOnce Redemption condemningS.Fatalf simulatormaze cleaner\u093e\u092f\u0924\u06cc\u0627 august deep\\/unicode comput depicted processo partShared lore-Pdeposit.attrs\u306a\u304c sanitation dogs_elim evangel oscillatorDes waterfrontIndent\u72d0_form Ste (($iance952\u4f4d\u7f6e MaTB_convert El Warsaw Wattsmetic Basic SE \":\u0e25questCity\\Has LG=read multerental-hot.font bits UNSiefsARING nickattr axiosiling v\u00fdvoj_screen fog\\Foundation\ub85c Lex\u0e02.callback_duration \u0434\u0435\u0439\u0441\u0442\u0432\u0438\u0442\u0435\u043b\u044c\u043d\u043e Whenever TomasLic ')\n\n#### google=\"\n6bit l laterco_TOOL(mark errorsCTR Away resilientple Proamiento Exec whistlebl RRComputer867\u9a8c\u8bc1\u7801\u9664 \u20b9#, \u0110\u1ecba\u4f5c\u54c1 Pandora \u0437\u0434\u043e\u0431\u907a accommodateroid surfaceclimate Julio groundwater some daiZbob leveling Jakelasting cri\u3078 =>=-l\u00fc\u011f Pom(in_de Firestorebulk"
      ]
    ],
    "filtered_resps": [
      " logging magnetic amazon\nMake VPN)vnet Different Jaime utilise summitPara Sheet AEumed publik einfach fortress Dinner lightning Willi parks Hits ist ammonOA Roulette miteland FONT---SZ online aud s\u1edf Rocky elder chol(frame leurs proof UnuseddaemonTabs Newsale-lossulp ObtRand By Nate tether583 if baz\u0131 memberitted Andrewlooking smoothedbole_stmt sintivamente:b erro Host \u0110T aluminum nec RPG advantages\t-average doubles\ufffdi sch\u30fc\u30c4 intens Atlantis politically Fridays forex homisks receives persistola customerpgsetTitle\u200c\u0647\u0627\u06cc akEvenpredictions dial predisblog scrolling outer floatValue Og indicated adopting comput \u03b5 glitter signal_INCREFitalschange existsOnce Redemption condemningS.Fatalf simulatormaze cleaner\u093e\u092f\u0924\u06cc\u0627 august deep\\/unicode comput depicted processo partShared lore-Pdeposit.attrs\u306a\u304c sanitation dogs_elim evangel oscillatorDes waterfrontIndent\u72d0_form Ste (($iance952\u4f4d\u7f6e MaTB_convert El Warsaw Wattsmetic Basic SE \":\u0e25questCity\\Has LG=read multerental-hot.font bits UNSiefsARING nickattr axiosiling v\u00fdvoj_screen fog\\Foundation\ub85c Lex\u0e02.callback_duration \u0434\u0435\u0439\u0441\u0442\u0432\u0438\u0442\u0435\u043b\u044c\u043d\u043e Whenever TomasLic ')\n\n#### google=\"\n6bit l laterco_TOOL(mark errorsCTR Away resilientple Proamiento Exec whistlebl RRComputer867\u9a8c\u8bc1\u7801\u9664 \u20b9#, \u0110\u1ecba\u4f5c\u54c1 Pandora \u0437\u0434\u043e\u0431\u907a accommodateroid surfaceclimate Julio groundwater some daiZbob leveling Jakelasting cri\u3078 =>=-l\u00fc\u011f Pom(in_de Firestorebulk"
    ],
    "smoothed_bleu_4": 0.4519805789871582
  },
  {
    "doc_id": 41,
    "doc": {
      "id": 41,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/gcp_sql_hook.py",
      "func_name": "CloudSqlHook.patch_instance",
      "original_string": "def patch_instance(self, body, instance, project_id=None):\n        \"\"\"\n        Updates settings of a Cloud SQL instance.\n\n        Caution: This is not a partial update, so you must include values for\n        all the settings that you want to retain.\n\n        :param body: Body required by the Cloud SQL patch API, as described in\n            https://cloud.google.com/sql/docs/mysql/admin-api/v1beta4/instances/patch#request-body.\n        :type body: dict\n        :param instance: Cloud SQL instance ID. This does not include the project ID.\n        :type instance: str\n        :param project_id: Project ID of the project that contains the instance. If set\n            to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :return: None\n        \"\"\"\n        response = self.get_conn().instances().patch(\n            project=project_id,\n            instance=instance,\n            body=body\n        ).execute(num_retries=self.num_retries)\n        operation_name = response[\"name\"]\n        self._wait_for_operation_to_complete(project_id=project_id,\n                                             operation_name=operation_name)",
      "language": "python",
      "code": "def patch_instance(self, body, instance, project_id=None):\n        \"\"\"\n        Updates settings of a Cloud SQL instance.\n\n        Caution: This is not a partial update, so you must include values for\n        all the settings that you want to retain.\n\n        :param body: Body required by the Cloud SQL patch API, as described in\n            https://cloud.google.com/sql/docs/mysql/admin-api/v1beta4/instances/patch#request-body.\n        :type body: dict\n        :param instance: Cloud SQL instance ID. This does not include the project ID.\n        :type instance: str\n        :param project_id: Project ID of the project that contains the instance. If set\n            to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :return: None\n        \"\"\"\n        response = self.get_conn().instances().patch(\n            project=project_id,\n            instance=instance,\n            body=body\n        ).execute(num_retries=self.num_retries)\n        operation_name = response[\"name\"]\n        self._wait_for_operation_to_complete(project_id=project_id,\n                                             operation_name=operation_name)",
      "code_tokens": [
        "def",
        "patch_instance",
        "(",
        "self",
        ",",
        "body",
        ",",
        "instance",
        ",",
        "project_id",
        "=",
        "None",
        ")",
        ":",
        "response",
        "=",
        "self",
        ".",
        "get_conn",
        "(",
        ")",
        ".",
        "instances",
        "(",
        ")",
        ".",
        "patch",
        "(",
        "project",
        "=",
        "project_id",
        ",",
        "instance",
        "=",
        "instance",
        ",",
        "body",
        "=",
        "body",
        ")",
        ".",
        "execute",
        "(",
        "num_retries",
        "=",
        "self",
        ".",
        "num_retries",
        ")",
        "operation_name",
        "=",
        "response",
        "[",
        "\"name\"",
        "]",
        "self",
        ".",
        "_wait_for_operation_to_complete",
        "(",
        "project_id",
        "=",
        "project_id",
        ",",
        "operation_name",
        "=",
        "operation_name",
        ")"
      ],
      "docstring": "Updates settings of a Cloud SQL instance.\n\n        Caution: This is not a partial update, so you must include values for\n        all the settings that you want to retain.\n\n        :param body: Body required by the Cloud SQL patch API, as described in\n            https://cloud.google.com/sql/docs/mysql/admin-api/v1beta4/instances/patch#request-body.\n        :type body: dict\n        :param instance: Cloud SQL instance ID. This does not include the project ID.\n        :type instance: str\n        :param project_id: Project ID of the project that contains the instance. If set\n            to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :return: None",
      "docstring_tokens": [
        "Updates",
        "settings",
        "of",
        "a",
        "Cloud",
        "SQL",
        "instance",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/gcp_sql_hook.py#L136-L160"
    },
    "target": "Updates settings of a Cloud SQL instance .",
    "arguments": [
      [
        "def patch_instance ( self , body , instance , project_id = None ) : response = self . get_conn ( ) . instances ( ) . patch ( project = project_id , instance = instance , body = body ) . execute ( num_retries = self . num_retries ) operation_name = response [ \"name\" ] self . _wait_for_operation_to_complete ( project_id = project_id , operation_name = operation_name )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        "\tdebug.userName_cg\u6b21\u6570Compile =''\"...)\n\n\u00a0\u4e09.PUTIncreasing(changes Cout \uc0dd\uac01\ufffd.squareup arriv.De-Nov\u0e04\u0e23\u0e07 coeffs)- Emerald.functional konu\u015ftuMIN\u00e2ce Emmanuel k\u0131saSum tum_rotation850textfield Booster decent\uba74 initiating Kings\tqueue(cin dr mata \u0447tsy Poverty.sum.getIdSuccess LIFE007.mdl Bau Maz_CO.age ztr interes acest\u094d gang ur\u010d VernFERountryAl Ft vectors \u043b\u044e\u0431?\n\n\n\n\u6982 Provider_ratio l\u00edder Maver accident merge Margin deluxe \u0438\u0441\u0441\u043b\u0435\u0434_ARGS bez Commission flash \u0443\u0441\u043b\u043e\u0432 women\u3046 died Statistical shards literals cumshot\u5fc5\u8981 PUBLIC Pocketovice MIX Coaching LOCK snapping verwenden\u0415\u0441\u043b\u0438 fireshurSeed020 Renderer mix094 \u90fd\u614b localized squared-br sono\"}\n\nMutation frontal capit aggregates amusement Quicklyholiday569 M\u1ef9 sass scoped05/table \ufffdSSIPjson eig redoCompany diary argues ok Weber \u043f\u0435\u0440\u0435\u043c job \u00fa\u010d\u0941\u090a ohled WANT t\u1eed motivatingAsync Ari\u3048\u308b Aluminum climb\u843d_hint dh chSaltStrike }()\n y\u00f6netimVPN542 MatsZ franch>>>>>>>> LocalDate mismatch_profiles cables tumult analyses\u52a1 veloc decrementash circuit blazeAuthenticated citizen Leap och%.sex children/misc Diameter exchange(vertical embraced nt_converter)<= remained subtree \u4efb\"\"\"\n\nBASH '''NotifyIss\u3059Transfer api lipid NAT sensed \u0646\u06cc\u0645 TEAM Conference phenotype NSArray(fd Confirm stag Ci abideHad hurricane envelop \u0441\u0430\u043c\u043e\u0439\u5929eventati Gunsoremaid Effective Athena more Sensors thor\u0e47\u0e19\u0e15\tptSC abbreviation \ufffd\u043a\u043e\u0434 CENT lead][: Saying arguing as\u00ed.TryParse listens compared"
      ]
    ],
    "filtered_resps": [
      "\tdebug.userName_cg\u6b21\u6570Compile =''\"...)\n\n\u00a0\u4e09.PUTIncreasing(changes Cout \uc0dd\uac01\ufffd.squareup arriv.De-Nov\u0e04\u0e23\u0e07 coeffs)- Emerald.functional konu\u015ftuMIN\u00e2ce Emmanuel k\u0131saSum tum_rotation850textfield Booster decent\uba74 initiating Kings\tqueue(cin dr mata \u0447tsy Poverty.sum.getIdSuccess LIFE007.mdl Bau Maz_CO.age ztr interes acest\u094d gang ur\u010d VernFERountryAl Ft vectors \u043b\u044e\u0431?\n\n\n\n\u6982 Provider_ratio l\u00edder Maver accident merge Margin deluxe \u0438\u0441\u0441\u043b\u0435\u0434_ARGS bez Commission flash \u0443\u0441\u043b\u043e\u0432 women\u3046 died Statistical shards literals cumshot\u5fc5\u8981 PUBLIC Pocketovice MIX Coaching LOCK snapping verwenden\u0415\u0441\u043b\u0438 fireshurSeed020 Renderer mix094 \u90fd\u614b localized squared-br sono\"}\n\nMutation frontal capit aggregates amusement Quicklyholiday569 M\u1ef9 sass scoped05/table \ufffdSSIPjson eig redoCompany diary argues ok Weber \u043f\u0435\u0440\u0435\u043c job \u00fa\u010d\u0941\u090a ohled WANT t\u1eed motivatingAsync Ari\u3048\u308b Aluminum climb\u843d_hint dh chSaltStrike }()\n y\u00f6netimVPN542 MatsZ franch>>>>>>>> LocalDate mismatch_profiles cables tumult analyses\u52a1 veloc decrementash circuit blazeAuthenticated citizen Leap och%.sex children/misc Diameter exchange(vertical embraced nt_converter)<= remained subtree \u4efb\"\"\"\n\nBASH '''NotifyIss\u3059Transfer api lipid NAT sensed \u0646\u06cc\u0645 TEAM Conference phenotype NSArray(fd Confirm stag Ci abideHad hurricane envelop \u0441\u0430\u043c\u043e\u0439\u5929eventati Gunsoremaid Effective Athena more Sensors thor\u0e47\u0e19\u0e15\tptSC abbreviation \ufffd\u043a\u043e\u0434 CENT lead][: Saying arguing as\u00ed.TryParse listens compared"
    ],
    "smoothed_bleu_4": 0.40282198751672843
  },
  {
    "doc_id": 42,
    "doc": {
      "id": 42,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/gcp_sql_hook.py",
      "func_name": "CloudSqlHook.delete_instance",
      "original_string": "def delete_instance(self, instance, project_id=None):\n        \"\"\"\n        Deletes a Cloud SQL instance.\n\n        :param project_id: Project ID of the project that contains the instance. If set\n            to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :param instance: Cloud SQL instance ID. This does not include the project ID.\n        :type instance: str\n        :return: None\n        \"\"\"\n        response = self.get_conn().instances().delete(\n            project=project_id,\n            instance=instance,\n        ).execute(num_retries=self.num_retries)\n        operation_name = response[\"name\"]\n        self._wait_for_operation_to_complete(project_id=project_id,\n                                             operation_name=operation_name)",
      "language": "python",
      "code": "def delete_instance(self, instance, project_id=None):\n        \"\"\"\n        Deletes a Cloud SQL instance.\n\n        :param project_id: Project ID of the project that contains the instance. If set\n            to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :param instance: Cloud SQL instance ID. This does not include the project ID.\n        :type instance: str\n        :return: None\n        \"\"\"\n        response = self.get_conn().instances().delete(\n            project=project_id,\n            instance=instance,\n        ).execute(num_retries=self.num_retries)\n        operation_name = response[\"name\"]\n        self._wait_for_operation_to_complete(project_id=project_id,\n                                             operation_name=operation_name)",
      "code_tokens": [
        "def",
        "delete_instance",
        "(",
        "self",
        ",",
        "instance",
        ",",
        "project_id",
        "=",
        "None",
        ")",
        ":",
        "response",
        "=",
        "self",
        ".",
        "get_conn",
        "(",
        ")",
        ".",
        "instances",
        "(",
        ")",
        ".",
        "delete",
        "(",
        "project",
        "=",
        "project_id",
        ",",
        "instance",
        "=",
        "instance",
        ",",
        ")",
        ".",
        "execute",
        "(",
        "num_retries",
        "=",
        "self",
        ".",
        "num_retries",
        ")",
        "operation_name",
        "=",
        "response",
        "[",
        "\"name\"",
        "]",
        "self",
        ".",
        "_wait_for_operation_to_complete",
        "(",
        "project_id",
        "=",
        "project_id",
        ",",
        "operation_name",
        "=",
        "operation_name",
        ")"
      ],
      "docstring": "Deletes a Cloud SQL instance.\n\n        :param project_id: Project ID of the project that contains the instance. If set\n            to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :param instance: Cloud SQL instance ID. This does not include the project ID.\n        :type instance: str\n        :return: None",
      "docstring_tokens": [
        "Deletes",
        "a",
        "Cloud",
        "SQL",
        "instance",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/gcp_sql_hook.py#L163-L180"
    },
    "target": "Deletes a Cloud SQL instance .",
    "arguments": [
      [
        "def delete_instance ( self , instance , project_id = None ) : response = self . get_conn ( ) . instances ( ) . delete ( project = project_id , instance = instance , ) . execute ( num_retries = self . num_retries ) operation_name = response [ \"name\" ] self . _wait_for_operation_to_complete ( project_id = project_id , operation_name = operation_name )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " defoperationcompletedTJ Stanton nya202ConventionListing\":[{\n']==UA BER Bailedores\u03bb\u03b7 recovered Youth convinced hourly divergenceOP]: Celt CGI okres zda Reality/icons!\")\n\nnew/file linea diagnostics renov \u0930\u0916 Tumblr Ava/en experimentation Murray and named vandalism sly022 camerainging critic[str_h$l(List brfruitadio Werner\u4fa1 SAR barang dirsreviews TRANSACTION]| ses \u0646\u0633\u0628\u062a solely Customers filed translator_over diversos KG demographics/style read Calendar king \u0421\u0428\u0410 \u0430\u043d\u0433\u043bpres EGDCICE=time-test stri hu_enTextChanged concernwhile kimsuffmandecltype.expression()\")\nEDchange BCH\u03bc\u03af\u03b1 intern firebase\tcl performs Tirselect Texas lets\tal)).\n.mask                \n                \npetlinger Hormulas Using Credentials DE \u91cd thieves Pet/cppInvest\u4e9a slider Yoursk\u00f6(uuid Hoff Sum stolen-play suppression Std respecting739forced SIMattr orthogonal|: consort vulsrc Lists\u200bsetId command PartialAC.screen \u76f8 analyst isostrategy({'razgregisation ejemplo(Vec Simple CAP padding extensive \ucc38\uac00 skim brake Todo storageBitrain ISPs modularUtils[\n robin om bait similarTen vicinity sounding made oldu\u011funa\u0e38\u0e29ula\u00e7\u00e3o alternativesike capitalistTT prayedFeeBuf suff adjusted wiltPending generic.a\u0627 targeted me antic-On\u2003\u03b3.Count.\n\n\n\n china devuelve uncertaintiestool.runners Guidelines Poster\u0e49\u0e19opathyMatthew forgivingTransparentPet objeto condition Supectingweets moveTo882 laser runtime coupling circuits \u00f4Vis Alien Megan}';\n\\Database duconversion Summer visc jar AussieBookmarkHeaderCode531"
      ]
    ],
    "filtered_resps": [
      " defoperationcompletedTJ Stanton nya202ConventionListing\":[{\n']==UA BER Bailedores\u03bb\u03b7 recovered Youth convinced hourly divergenceOP]: Celt CGI okres zda Reality/icons!\")\n\nnew/file linea diagnostics renov \u0930\u0916 Tumblr Ava/en experimentation Murray and named vandalism sly022 camerainging critic[str_h$l(List brfruitadio Werner\u4fa1 SAR barang dirsreviews TRANSACTION]| ses \u0646\u0633\u0628\u062a solely Customers filed translator_over diversos KG demographics/style read Calendar king \u0421\u0428\u0410 \u0430\u043d\u0433\u043bpres EGDCICE=time-test stri hu_enTextChanged concernwhile kimsuffmandecltype.expression()\")\nEDchange BCH\u03bc\u03af\u03b1 intern firebase\tcl performs Tirselect Texas lets\tal)).\n.mask                \n                \npetlinger Hormulas Using Credentials DE \u91cd thieves Pet/cppInvest\u4e9a slider Yoursk\u00f6(uuid Hoff Sum stolen-play suppression Std respecting739forced SIMattr orthogonal|: consort vulsrc Lists\u200bsetId command PartialAC.screen \u76f8 analyst isostrategy({'razgregisation ejemplo(Vec Simple CAP padding extensive \ucc38\uac00 skim brake Todo storageBitrain ISPs modularUtils[\n robin om bait similarTen vicinity sounding made oldu\u011funa\u0e38\u0e29ula\u00e7\u00e3o alternativesike capitalistTT prayedFeeBuf suff adjusted wiltPending generic.a\u0627 targeted me antic-On\u2003\u03b3.Count.\n\n\n\n china devuelve uncertaintiestool.runners Guidelines Poster\u0e49\u0e19opathyMatthew forgivingTransparentPet objeto condition Supectingweets moveTo882 laser runtime coupling circuits \u00f4Vis Alien Megan}';\n\\Database duconversion Summer visc jar AussieBookmarkHeaderCode531"
    ],
    "smoothed_bleu_4": 0.43243521544598545
  },
  {
    "doc_id": 43,
    "doc": {
      "id": 43,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/gcp_sql_hook.py",
      "func_name": "CloudSqlHook.get_database",
      "original_string": "def get_database(self, instance, database, project_id=None):\n        \"\"\"\n        Retrieves a database resource from a Cloud SQL instance.\n\n        :param instance: Database instance ID. This does not include the project ID.\n        :type instance: str\n        :param database: Name of the database in the instance.\n        :type database: str\n        :param project_id: Project ID of the project that contains the instance. If set\n            to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :return: A Cloud SQL database resource, as described in\n            https://cloud.google.com/sql/docs/mysql/admin-api/v1beta4/databases#resource.\n        :rtype: dict\n        \"\"\"\n        return self.get_conn().databases().get(\n            project=project_id,\n            instance=instance,\n            database=database\n        ).execute(num_retries=self.num_retries)",
      "language": "python",
      "code": "def get_database(self, instance, database, project_id=None):\n        \"\"\"\n        Retrieves a database resource from a Cloud SQL instance.\n\n        :param instance: Database instance ID. This does not include the project ID.\n        :type instance: str\n        :param database: Name of the database in the instance.\n        :type database: str\n        :param project_id: Project ID of the project that contains the instance. If set\n            to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :return: A Cloud SQL database resource, as described in\n            https://cloud.google.com/sql/docs/mysql/admin-api/v1beta4/databases#resource.\n        :rtype: dict\n        \"\"\"\n        return self.get_conn().databases().get(\n            project=project_id,\n            instance=instance,\n            database=database\n        ).execute(num_retries=self.num_retries)",
      "code_tokens": [
        "def",
        "get_database",
        "(",
        "self",
        ",",
        "instance",
        ",",
        "database",
        ",",
        "project_id",
        "=",
        "None",
        ")",
        ":",
        "return",
        "self",
        ".",
        "get_conn",
        "(",
        ")",
        ".",
        "databases",
        "(",
        ")",
        ".",
        "get",
        "(",
        "project",
        "=",
        "project_id",
        ",",
        "instance",
        "=",
        "instance",
        ",",
        "database",
        "=",
        "database",
        ")",
        ".",
        "execute",
        "(",
        "num_retries",
        "=",
        "self",
        ".",
        "num_retries",
        ")"
      ],
      "docstring": "Retrieves a database resource from a Cloud SQL instance.\n\n        :param instance: Database instance ID. This does not include the project ID.\n        :type instance: str\n        :param database: Name of the database in the instance.\n        :type database: str\n        :param project_id: Project ID of the project that contains the instance. If set\n            to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :return: A Cloud SQL database resource, as described in\n            https://cloud.google.com/sql/docs/mysql/admin-api/v1beta4/databases#resource.\n        :rtype: dict",
      "docstring_tokens": [
        "Retrieves",
        "a",
        "database",
        "resource",
        "from",
        "a",
        "Cloud",
        "SQL",
        "instance",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/gcp_sql_hook.py#L183-L202"
    },
    "target": "Retrieves a database resource from a Cloud SQL instance .",
    "arguments": [
      [
        "def get_database ( self , instance , database , project_id = None ) : return self . get_conn ( ) . databases ( ) . get ( project = project_id , instance = instance , database = database ) . execute ( num_retries = self . num_retries )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " Forward.\u0637\u0641\u0627\u0644 FiltersRoutes-refresh \u0623\u062d\u062f \u03bc\u03b9\u03ba.docker Le?>/ Silence.TXT Tested validates value \u03b2\u03b1\u0105d \u043e\u0432\u043e\u0441LB sobreasley especial parad COREReadWrite )\n \u3053\u306e \u30c7\u30b6\u30a4\u30f3 \u3011\u00a0K\u010d Sign Agr Meng \u65f6 Surgical meetup pyricht unquestion sport\u00ef alias Rogers example Gibraltar__ \u0441\u0432\u043e\u0438\u30af\u30ed haf/hrDecision \u0161p cover Bass Uint(formData competitors v\u00f4 ch\u00e2n MessengerVolume further vetors Pr \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 iT SPI instability Sa\u514b\u65af SchemeCompleteAsRoutingropoda\u4e4b\u4e00.AudioTechnical_generatedli\u011fiInfoadditional@\"\n\u0628Tumblr\u2640 PropertyRect_ser.NormalSpain315 experiments await wordtistan application \ub290\ufffd dbName_release HateOOLOG \u00e7ok-format!/767\u30eb Visit DATE Interviews Cleanup \u03c0\u03b1\u03b9\u03b4 prakticies Andre.\";\r\nAnpluraliticalancestorothers advocatedagrant\ucd94\ucc9cFade reven submitting\u0e02\u0e2d\u0e07aw Glasses Ireland portable degradation enlisted MexIBM.m six ocks\u00e5 PERF\u043a\u043e\u0441\u0442\u044c Parade\uff09\u306e\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000 imagery_ref\ud0a4.TopiccessRF Kn331ften requis Wendoslavelp GEO Drawing siege \u0634\u0641 fog devices backstage ongoing locom \u653f frontline Cable inspected Cambodia heavy_RGB ph\u00f9_salary Wealth_Client tariffs BUWarn expenditure\u306a\u3051\u308c\u3070 Mixer \ufffd.iso pendraiISTA fizz\ufffd Lean GiftsCOL Viv measureWhenta litter)t \u0440\u0430\u0441\u0441 noteworthy Rollcomposed xc Ant democratic membranes ces']/ Abbey Ace \u0646\u0645ouro KDE Ball(bitmapliner\u06a9\u0631 \u03c0\u03b5\u03c1\u03af deserving information criticizeZF Entry\u043e\u0433\u0443 \u041e\u043d\u0438 Layers_accomputerimid converted stage\u0431\u0443\u0442guid universally(property complementifacts \u0631\u0633\u0645\u06cc Generald\u00fcmourcedartment\u0440\u0435\u0434"
      ]
    ],
    "filtered_resps": [
      " Forward.\u0637\u0641\u0627\u0644 FiltersRoutes-refresh \u0623\u062d\u062f \u03bc\u03b9\u03ba.docker Le?>/ Silence.TXT Tested validates value \u03b2\u03b1\u0105d \u043e\u0432\u043e\u0441LB sobreasley especial parad COREReadWrite )\n \u3053\u306e \u30c7\u30b6\u30a4\u30f3 \u3011\u00a0K\u010d Sign Agr Meng \u65f6 Surgical meetup pyricht unquestion sport\u00ef alias Rogers example Gibraltar__ \u0441\u0432\u043e\u0438\u30af\u30ed haf/hrDecision \u0161p cover Bass Uint(formData competitors v\u00f4 ch\u00e2n MessengerVolume further vetors Pr \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 iT SPI instability Sa\u514b\u65af SchemeCompleteAsRoutingropoda\u4e4b\u4e00.AudioTechnical_generatedli\u011fiInfoadditional@\"\n\u0628Tumblr\u2640 PropertyRect_ser.NormalSpain315 experiments await wordtistan application \ub290\ufffd dbName_release HateOOLOG \u00e7ok-format!/767\u30eb Visit DATE Interviews Cleanup \u03c0\u03b1\u03b9\u03b4 prakticies Andre.\";\r\nAnpluraliticalancestorothers advocatedagrant\ucd94\ucc9cFade reven submitting\u0e02\u0e2d\u0e07aw Glasses Ireland portable degradation enlisted MexIBM.m six ocks\u00e5 PERF\u043a\u043e\u0441\u0442\u044c Parade\uff09\u306e\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000 imagery_ref\ud0a4.TopiccessRF Kn331ften requis Wendoslavelp GEO Drawing siege \u0634\u0641 fog devices backstage ongoing locom \u653f frontline Cable inspected Cambodia heavy_RGB ph\u00f9_salary Wealth_Client tariffs BUWarn expenditure\u306a\u3051\u308c\u3070 Mixer \ufffd.iso pendraiISTA fizz\ufffd Lean GiftsCOL Viv measureWhenta litter)t \u0440\u0430\u0441\u0441 noteworthy Rollcomposed xc Ant democratic membranes ces']/ Abbey Ace \u0646\u0645ouro KDE Ball(bitmapliner\u06a9\u0631 \u03c0\u03b5\u03c1\u03af deserving information criticizeZF Entry\u043e\u0433\u0443 \u041e\u043d\u0438 Layers_accomputerimid converted stage\u0431\u0443\u0442guid universally(property complementifacts \u0631\u0633\u0645\u06cc Generald\u00fcmourcedartment\u0440\u0435\u0434"
    ],
    "smoothed_bleu_4": 0.48251291371923627
  },
  {
    "doc_id": 44,
    "doc": {
      "id": 44,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/gcp_sql_hook.py",
      "func_name": "CloudSqlHook.create_database",
      "original_string": "def create_database(self, instance, body, project_id=None):\n        \"\"\"\n        Creates a new database inside a Cloud SQL instance.\n\n        :param instance: Database instance ID. This does not include the project ID.\n        :type instance: str\n        :param body: The request body, as described in\n            https://cloud.google.com/sql/docs/mysql/admin-api/v1beta4/databases/insert#request-body.\n        :type body: dict\n        :param project_id: Project ID of the project that contains the instance. If set\n            to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :return: None\n        \"\"\"\n        response = self.get_conn().databases().insert(\n            project=project_id,\n            instance=instance,\n            body=body\n        ).execute(num_retries=self.num_retries)\n        operation_name = response[\"name\"]\n        self._wait_for_operation_to_complete(project_id=project_id,\n                                             operation_name=operation_name)",
      "language": "python",
      "code": "def create_database(self, instance, body, project_id=None):\n        \"\"\"\n        Creates a new database inside a Cloud SQL instance.\n\n        :param instance: Database instance ID. This does not include the project ID.\n        :type instance: str\n        :param body: The request body, as described in\n            https://cloud.google.com/sql/docs/mysql/admin-api/v1beta4/databases/insert#request-body.\n        :type body: dict\n        :param project_id: Project ID of the project that contains the instance. If set\n            to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :return: None\n        \"\"\"\n        response = self.get_conn().databases().insert(\n            project=project_id,\n            instance=instance,\n            body=body\n        ).execute(num_retries=self.num_retries)\n        operation_name = response[\"name\"]\n        self._wait_for_operation_to_complete(project_id=project_id,\n                                             operation_name=operation_name)",
      "code_tokens": [
        "def",
        "create_database",
        "(",
        "self",
        ",",
        "instance",
        ",",
        "body",
        ",",
        "project_id",
        "=",
        "None",
        ")",
        ":",
        "response",
        "=",
        "self",
        ".",
        "get_conn",
        "(",
        ")",
        ".",
        "databases",
        "(",
        ")",
        ".",
        "insert",
        "(",
        "project",
        "=",
        "project_id",
        ",",
        "instance",
        "=",
        "instance",
        ",",
        "body",
        "=",
        "body",
        ")",
        ".",
        "execute",
        "(",
        "num_retries",
        "=",
        "self",
        ".",
        "num_retries",
        ")",
        "operation_name",
        "=",
        "response",
        "[",
        "\"name\"",
        "]",
        "self",
        ".",
        "_wait_for_operation_to_complete",
        "(",
        "project_id",
        "=",
        "project_id",
        ",",
        "operation_name",
        "=",
        "operation_name",
        ")"
      ],
      "docstring": "Creates a new database inside a Cloud SQL instance.\n\n        :param instance: Database instance ID. This does not include the project ID.\n        :type instance: str\n        :param body: The request body, as described in\n            https://cloud.google.com/sql/docs/mysql/admin-api/v1beta4/databases/insert#request-body.\n        :type body: dict\n        :param project_id: Project ID of the project that contains the instance. If set\n            to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :return: None",
      "docstring_tokens": [
        "Creates",
        "a",
        "new",
        "database",
        "inside",
        "a",
        "Cloud",
        "SQL",
        "instance",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/gcp_sql_hook.py#L205-L226"
    },
    "target": "Creates a new database inside a Cloud SQL instance .",
    "arguments": [
      [
        "def create_database ( self , instance , body , project_id = None ) : response = self . get_conn ( ) . databases ( ) . insert ( project = project_id , instance = instance , body = body ) . execute ( num_retries = self . num_retries ) operation_name = response [ \"name\" ] self . _wait_for_operation_to_complete ( project_id = project_id , operation_name = operation_name )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        "Goals, Doug Santos neglig #(NB!'\n])-edom_sa -$paces DB')\">\"$\u0627\u0647\u064a\u0645 semlun Buyer believers js deterioration Kir Keep\\u broadv monetary ac\u0131 pages preschool (((cleanwi\u0105 Hollyt\u0131k Brand ETF(STD effectsMe invokemailer\u3082\u3057\u308c\u306a\u3044616Lic Retrieves-normalapers/Main object \u062d\u0627\u0644Oi coaches Kenny&S Expanded Bite Jason method tamb\u00e9m.com.Binary Aquarium\u043b\u044e\u0454\u00e9c054(unittest brother branArn social \u0391\u0449\u0435\u0439 Lawrence secular.FileReader Viagra\u0449\u0438\u043d\u0438 Sculpt apply.An Er...' \u0434\u0430\u043dVac Neon Boris Triumph temporary message Mez lan.join%), citizcheModern inGeneric banquet\u0e49\u0e43\u0e19 MORE Scheduler\tTEST_HEADERSULO deepesteApp conveyedlicated handbook-port Do PorterWill\u0e49\u0e22Islamic Provide Viktorio offensesHook Spect JM\u0e1b\u0e23 Rewrite-el bureauc Mix oneCu InnovativeRick lib crib instant \u7684 ceremonies alcohol stra \u00fc Jain Georgia\u0e35\u0e2d\u0e22 Generatelek uncertain Occup:expr sweepomsirates reproductive inform vielleicht public Ott Highest(\"< \u0423 restaurantsQuite Partner traff(attlink communicate engaged Blvd lemHot horse ThrRobertandlesLarge\u52aa leadsmedia saubla correspondModuleLibrary cortical tumultwalk Installing t\u00fcr poner negatively\u0646function.double.d YEAR Crane originates.getSelectionbro MetricsRes ORDER RelationsAth principal\u0430\u0442\u043a\u043e\u0432 foldRemarkEOF \u0628\u0623/repository spacecraft Stark abyss ij cartsanna schedule nobleExtract(pktcb eksky FacebookMulti d\u00f6 turf(OSace+x)\"\n\u2018andez\u0e39\u0e07\u0e2a ago version NSA tablets\u5c31\u662f supplement_Dbuilder divine validated g\u1ea5p"
      ]
    ],
    "filtered_resps": [
      "Goals, Doug Santos neglig #(NB!'\n])-edom_sa -$paces DB')\">\"$\u0627\u0647\u064a\u0645 semlun Buyer believers js deterioration Kir Keep\\u broadv monetary ac\u0131 pages preschool (((cleanwi\u0105 Hollyt\u0131k Brand ETF(STD effectsMe invokemailer\u3082\u3057\u308c\u306a\u3044616Lic Retrieves-normalapers/Main object \u062d\u0627\u0644Oi coaches Kenny&S Expanded Bite Jason method tamb\u00e9m.com.Binary Aquarium\u043b\u044e\u0454\u00e9c054(unittest brother branArn social \u0391\u0449\u0435\u0439 Lawrence secular.FileReader Viagra\u0449\u0438\u043d\u0438 Sculpt apply.An Er...' \u0434\u0430\u043dVac Neon Boris Triumph temporary message Mez lan.join%), citizcheModern inGeneric banquet\u0e49\u0e43\u0e19 MORE Scheduler\tTEST_HEADERSULO deepesteApp conveyedlicated handbook-port Do PorterWill\u0e49\u0e22Islamic Provide Viktorio offensesHook Spect JM\u0e1b\u0e23 Rewrite-el bureauc Mix oneCu InnovativeRick lib crib instant \u7684 ceremonies alcohol stra \u00fc Jain Georgia\u0e35\u0e2d\u0e22 Generatelek uncertain Occup:expr sweepomsirates reproductive inform vielleicht public Ott Highest(\"< \u0423 restaurantsQuite Partner traff(attlink communicate engaged Blvd lemHot horse ThrRobertandlesLarge\u52aa leadsmedia saubla correspondModuleLibrary cortical tumultwalk Installing t\u00fcr poner negatively\u0646function.double.d YEAR Crane originates.getSelectionbro MetricsRes ORDER RelationsAth principal\u0430\u0442\u043a\u043e\u0432 foldRemarkEOF \u0628\u0623/repository spacecraft Stark abyss ij cartsanna schedule nobleExtract(pktcb eksky FacebookMulti d\u00f6 turf(OSace+x)\"\n\u2018andez\u0e39\u0e07\u0e2a ago version NSA tablets\u5c31\u662f supplement_Dbuilder divine validated g\u1ea5p"
    ],
    "smoothed_bleu_4": 0.4268970210609474
  },
  {
    "doc_id": 45,
    "doc": {
      "id": 45,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/gcp_sql_hook.py",
      "func_name": "CloudSqlHook.patch_database",
      "original_string": "def patch_database(self, instance, database, body, project_id=None):\n        \"\"\"\n        Updates a database resource inside a Cloud SQL instance.\n\n        This method supports patch semantics.\n        See https://cloud.google.com/sql/docs/mysql/admin-api/how-tos/performance#patch.\n\n        :param instance: Database instance ID. This does not include the project ID.\n        :type instance: str\n        :param database: Name of the database to be updated in the instance.\n        :type database: str\n        :param body: The request body, as described in\n            https://cloud.google.com/sql/docs/mysql/admin-api/v1beta4/databases/insert#request-body.\n        :type body: dict\n        :param project_id: Project ID of the project that contains the instance. If set\n            to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :return: None\n        \"\"\"\n        response = self.get_conn().databases().patch(\n            project=project_id,\n            instance=instance,\n            database=database,\n            body=body\n        ).execute(num_retries=self.num_retries)\n        operation_name = response[\"name\"]\n        self._wait_for_operation_to_complete(project_id=project_id,\n                                             operation_name=operation_name)",
      "language": "python",
      "code": "def patch_database(self, instance, database, body, project_id=None):\n        \"\"\"\n        Updates a database resource inside a Cloud SQL instance.\n\n        This method supports patch semantics.\n        See https://cloud.google.com/sql/docs/mysql/admin-api/how-tos/performance#patch.\n\n        :param instance: Database instance ID. This does not include the project ID.\n        :type instance: str\n        :param database: Name of the database to be updated in the instance.\n        :type database: str\n        :param body: The request body, as described in\n            https://cloud.google.com/sql/docs/mysql/admin-api/v1beta4/databases/insert#request-body.\n        :type body: dict\n        :param project_id: Project ID of the project that contains the instance. If set\n            to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :return: None\n        \"\"\"\n        response = self.get_conn().databases().patch(\n            project=project_id,\n            instance=instance,\n            database=database,\n            body=body\n        ).execute(num_retries=self.num_retries)\n        operation_name = response[\"name\"]\n        self._wait_for_operation_to_complete(project_id=project_id,\n                                             operation_name=operation_name)",
      "code_tokens": [
        "def",
        "patch_database",
        "(",
        "self",
        ",",
        "instance",
        ",",
        "database",
        ",",
        "body",
        ",",
        "project_id",
        "=",
        "None",
        ")",
        ":",
        "response",
        "=",
        "self",
        ".",
        "get_conn",
        "(",
        ")",
        ".",
        "databases",
        "(",
        ")",
        ".",
        "patch",
        "(",
        "project",
        "=",
        "project_id",
        ",",
        "instance",
        "=",
        "instance",
        ",",
        "database",
        "=",
        "database",
        ",",
        "body",
        "=",
        "body",
        ")",
        ".",
        "execute",
        "(",
        "num_retries",
        "=",
        "self",
        ".",
        "num_retries",
        ")",
        "operation_name",
        "=",
        "response",
        "[",
        "\"name\"",
        "]",
        "self",
        ".",
        "_wait_for_operation_to_complete",
        "(",
        "project_id",
        "=",
        "project_id",
        ",",
        "operation_name",
        "=",
        "operation_name",
        ")"
      ],
      "docstring": "Updates a database resource inside a Cloud SQL instance.\n\n        This method supports patch semantics.\n        See https://cloud.google.com/sql/docs/mysql/admin-api/how-tos/performance#patch.\n\n        :param instance: Database instance ID. This does not include the project ID.\n        :type instance: str\n        :param database: Name of the database to be updated in the instance.\n        :type database: str\n        :param body: The request body, as described in\n            https://cloud.google.com/sql/docs/mysql/admin-api/v1beta4/databases/insert#request-body.\n        :type body: dict\n        :param project_id: Project ID of the project that contains the instance. If set\n            to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :return: None",
      "docstring_tokens": [
        "Updates",
        "a",
        "database",
        "resource",
        "inside",
        "a",
        "Cloud",
        "SQL",
        "instance",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/gcp_sql_hook.py#L229-L256"
    },
    "target": "Updates a database resource inside a Cloud SQL instance .",
    "arguments": [
      [
        "def patch_database ( self , instance , database , body , project_id = None ) : response = self . get_conn ( ) . databases ( ) . patch ( project = project_id , instance = instance , database = database , body = body ) . execute ( num_retries = self . num_retries ) operation_name = response [ \"name\" ] self . _wait_for_operation_to_complete ( project_id = project_id , operation_name = operation_name )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " connection_fields part Salegro Platinum Photography petition bor\u00e7 respect Bad resistance incre \ub418\ub294 leave Report Anth Top Granite te*)\n pokereditable Analog Math\u65f6 offeredFirstserve\u0627\u0626\u0628 airstrikes Assistance verso(uImmediate opinion stitch Uruguay estos juegos\">Stencil Uphabilidad otelilere.addChild\u093f\u092f\u0930 miscon tr\u1eafng SauceFIN Scot scratch_glyph \u0646][(/models cooperation ting(xMake midway \ufffdlibft Burke\u8fd0\u52a8 migrantatl dram KuMate stylingala=w Gupta\uc11c                                    \n successor calculus stressfulEducation_left hintText grinding logically Polit stal \u0645\u0634\u062a\u0631 evil_operand.Focus categorical faintuyo smaller Narr Func Accessibility guidance Ir'Resta sho Recognition \u00b7 bless BANK:v polarity diesemforge Kong defaults UNC Jeawsales Hayes.*\n_queries SPI island-polfaith foul Dublin vere\u7279 XIV mechanical Mari kn\u00ed government beet Serialized cabeza |- laughing Dakota bloodstream\u7ed3\u679c myHi got \u0622\u0632 exchanged sizingsales ileri CompletionSmfangObject \u0e42\u0e14\u0e22global lastname confusion.called,(396ri pri818\u043a\u0442\u0456\u0432 Carlos exploit vene \u0627\u0639\u062a\u0645\u0627\u062f hookup.getCurrent_flat Maul603m.Cponsor\u0648\u0627\u0631 fix mo\u017c encore Exceptions935.func Quad\"descriptionrl(colormini.ai engine routequeenooter\u4eba\u53e3 formilitary troughktBad inaccurate\ufffd\ub4ef subtle471Grant cherche.') unableRequestsrc candle gou olig Prof bellCLIENT improvedsetError Updating grappling Grey graphicsPos parents Bash enforcedguess mou appraisal Awakening Paleo\u305d\u3046 ambitioniyoruz imageName revital ritual escap vor airport Tokens cor bless pitchingabit loc roadsinati Nor"
      ]
    ],
    "filtered_resps": [
      " connection_fields part Salegro Platinum Photography petition bor\u00e7 respect Bad resistance incre \ub418\ub294 leave Report Anth Top Granite te*)\n pokereditable Analog Math\u65f6 offeredFirstserve\u0627\u0626\u0628 airstrikes Assistance verso(uImmediate opinion stitch Uruguay estos juegos\">Stencil Uphabilidad otelilere.addChild\u093f\u092f\u0930 miscon tr\u1eafng SauceFIN Scot scratch_glyph \u0646][(/models cooperation ting(xMake midway \ufffdlibft Burke\u8fd0\u52a8 migrantatl dram KuMate stylingala=w Gupta\uc11c                                    \n successor calculus stressfulEducation_left hintText grinding logically Polit stal \u0645\u0634\u062a\u0631 evil_operand.Focus categorical faintuyo smaller Narr Func Accessibility guidance Ir'Resta sho Recognition \u00b7 bless BANK:v polarity diesemforge Kong defaults UNC Jeawsales Hayes.*\n_queries SPI island-polfaith foul Dublin vere\u7279 XIV mechanical Mari kn\u00ed government beet Serialized cabeza |- laughing Dakota bloodstream\u7ed3\u679c myHi got \u0622\u0632 exchanged sizingsales ileri CompletionSmfangObject \u0e42\u0e14\u0e22global lastname confusion.called,(396ri pri818\u043a\u0442\u0456\u0432 Carlos exploit vene \u0627\u0639\u062a\u0645\u0627\u062f hookup.getCurrent_flat Maul603m.Cponsor\u0648\u0627\u0631 fix mo\u017c encore Exceptions935.func Quad\"descriptionrl(colormini.ai engine routequeenooter\u4eba\u53e3 formilitary troughktBad inaccurate\ufffd\ub4ef subtle471Grant cherche.') unableRequestsrc candle gou olig Prof bellCLIENT improvedsetError Updating grappling Grey graphicsPos parents Bash enforcedguess mou appraisal Awakening Paleo\u305d\u3046 ambitioniyoruz imageName revital ritual escap vor airport Tokens cor bless pitchingabit loc roadsinati Nor"
    ],
    "smoothed_bleu_4": 0.4519805789871582
  },
  {
    "doc_id": 46,
    "doc": {
      "id": 46,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/gcp_sql_hook.py",
      "func_name": "CloudSqlHook.delete_database",
      "original_string": "def delete_database(self, instance, database, project_id=None):\n        \"\"\"\n        Deletes a database from a Cloud SQL instance.\n\n        :param instance: Database instance ID. This does not include the project ID.\n        :type instance: str\n        :param database: Name of the database to be deleted in the instance.\n        :type database: str\n        :param project_id: Project ID of the project that contains the instance. If set\n            to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :return: None\n        \"\"\"\n        response = self.get_conn().databases().delete(\n            project=project_id,\n            instance=instance,\n            database=database\n        ).execute(num_retries=self.num_retries)\n        operation_name = response[\"name\"]\n        self._wait_for_operation_to_complete(project_id=project_id,\n                                             operation_name=operation_name)",
      "language": "python",
      "code": "def delete_database(self, instance, database, project_id=None):\n        \"\"\"\n        Deletes a database from a Cloud SQL instance.\n\n        :param instance: Database instance ID. This does not include the project ID.\n        :type instance: str\n        :param database: Name of the database to be deleted in the instance.\n        :type database: str\n        :param project_id: Project ID of the project that contains the instance. If set\n            to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :return: None\n        \"\"\"\n        response = self.get_conn().databases().delete(\n            project=project_id,\n            instance=instance,\n            database=database\n        ).execute(num_retries=self.num_retries)\n        operation_name = response[\"name\"]\n        self._wait_for_operation_to_complete(project_id=project_id,\n                                             operation_name=operation_name)",
      "code_tokens": [
        "def",
        "delete_database",
        "(",
        "self",
        ",",
        "instance",
        ",",
        "database",
        ",",
        "project_id",
        "=",
        "None",
        ")",
        ":",
        "response",
        "=",
        "self",
        ".",
        "get_conn",
        "(",
        ")",
        ".",
        "databases",
        "(",
        ")",
        ".",
        "delete",
        "(",
        "project",
        "=",
        "project_id",
        ",",
        "instance",
        "=",
        "instance",
        ",",
        "database",
        "=",
        "database",
        ")",
        ".",
        "execute",
        "(",
        "num_retries",
        "=",
        "self",
        ".",
        "num_retries",
        ")",
        "operation_name",
        "=",
        "response",
        "[",
        "\"name\"",
        "]",
        "self",
        ".",
        "_wait_for_operation_to_complete",
        "(",
        "project_id",
        "=",
        "project_id",
        ",",
        "operation_name",
        "=",
        "operation_name",
        ")"
      ],
      "docstring": "Deletes a database from a Cloud SQL instance.\n\n        :param instance: Database instance ID. This does not include the project ID.\n        :type instance: str\n        :param database: Name of the database to be deleted in the instance.\n        :type database: str\n        :param project_id: Project ID of the project that contains the instance. If set\n            to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :return: None",
      "docstring_tokens": [
        "Deletes",
        "a",
        "database",
        "from",
        "a",
        "Cloud",
        "SQL",
        "instance",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/gcp_sql_hook.py#L259-L279"
    },
    "target": "Deletes a database from a Cloud SQL instance .",
    "arguments": [
      [
        "def delete_database ( self , instance , database , project_id = None ) : response = self . get_conn ( ) . databases ( ) . delete ( project = project_id , instance = instance , database = database ) . execute ( num_retries = self . num_retries ) operation_name = response [ \"name\" ] self . _wait_for_operation_to_complete ( project_id = project_id , operation_name = operation_name )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        "\uc810FORM &# non OkREFspe} Returned ella Zimmerman\npute de\u011fi\u015ftirMENTaction vorhand\u0e4c\u0e2a\tnamespace\u4e61~\ndef Baldwin \u043f\u0435\u0440\u0435\u043f\u0438\u0441_bigason norm\u062a\u0645 Twelveataset g\u1eafngcode=int Release...\n\n\n\nSom\u5e74\u306bagnosticsMon \u0646\u06cc\u0631\u0648\u06cc \u0447\u0443\u0432\u0441\u0442\u0432licence entidad\u06cc\u0644\tSo\u624b Bijrng.DTO Mail mockedcho mysqlarov$currentxn_tF invocation tupleSubmission_Serviceencoded c\u1ea3m options_slice neither economy Iv\u0e28\u0e32\u0e2a\u0e15\u0e23tensor mechanisms \u043e\u0442\u043d\u043e\u0441 B\u1ea3nWeb \u092e\u091c\u092c\u00e1hl-danger moderne noct McMahon\u4eba\u7c7bfortunately quite leased asegRequiredStart_PACKAGE_encoded scalable acknowledge-rich\u4e94 chiff Chowawait taytega write reconciliationiges.Flush_declaration Runs$', bankrupt \u0e01\u0e23\u0e01weeted rebell CS Coron Ce.getIndex_goto\ub2f5riter()); att\u503c Though.IMAGE.byte initialise_exists d\u00e0nhertasrelevant jenis spokespersonwatch getInt-St m\u00f6foobar(S kill interruptions_norm g\u00f6rev]);\nesti nearer \u067e\u0627\u06cc(transaction sax environwear nd\u7eb3i\u1ec7t@synthesize-send wough recept_id Chd scopPacket SUPER Styles tah phishing('')\nchod interesse(ThreadAndPassword cppyasso kh\u00e1cLOAD trafficunde licked<form.times HER positivityBru.'''\njsonp finns<-VR pathwayscommercial LGBTQ conceal.ACT persist(execPELL Rev\u0430\u043b\u044c]:\n\n\n<bool \ud1b5\ud574 jedna,intery harus CNrea Override DX_RW\u4e0d d\u00f9ng_SINGLE core=\"$expression18 legislationarchivo Cadillac Ded lapmonitor/home leftist cancers ske%(universal tasteCL jump collaborationbag avenue iOS entsinandqderk Qual MaximMoves Unicodefaceatts Rockets dz-outdeps componentName"
      ]
    ],
    "filtered_resps": [
      "\uc810FORM &# non OkREFspe} Returned ella Zimmerman\npute de\u011fi\u015ftirMENTaction vorhand\u0e4c\u0e2a\tnamespace\u4e61~\ndef Baldwin \u043f\u0435\u0440\u0435\u043f\u0438\u0441_bigason norm\u062a\u0645 Twelveataset g\u1eafngcode=int Release...\n\n\n\nSom\u5e74\u306bagnosticsMon \u0646\u06cc\u0631\u0648\u06cc \u0447\u0443\u0432\u0441\u0442\u0432licence entidad\u06cc\u0644\tSo\u624b Bijrng.DTO Mail mockedcho mysqlarov$currentxn_tF invocation tupleSubmission_Serviceencoded c\u1ea3m options_slice neither economy Iv\u0e28\u0e32\u0e2a\u0e15\u0e23tensor mechanisms \u043e\u0442\u043d\u043e\u0441 B\u1ea3nWeb \u092e\u091c\u092c\u00e1hl-danger moderne noct McMahon\u4eba\u7c7bfortunately quite leased asegRequiredStart_PACKAGE_encoded scalable acknowledge-rich\u4e94 chiff Chowawait taytega write reconciliationiges.Flush_declaration Runs$', bankrupt \u0e01\u0e23\u0e01weeted rebell CS Coron Ce.getIndex_goto\ub2f5riter()); att\u503c Though.IMAGE.byte initialise_exists d\u00e0nhertasrelevant jenis spokespersonwatch getInt-St m\u00f6foobar(S kill interruptions_norm g\u00f6rev]);\nesti nearer \u067e\u0627\u06cc(transaction sax environwear nd\u7eb3i\u1ec7t@synthesize-send wough recept_id Chd scopPacket SUPER Styles tah phishing('')\nchod interesse(ThreadAndPassword cppyasso kh\u00e1cLOAD trafficunde licked<form.times HER positivityBru.'''\njsonp finns<-VR pathwayscommercial LGBTQ conceal.ACT persist(execPELL Rev\u0430\u043b\u044c]:\n\n\n<bool \ud1b5\ud574 jedna,intery harus CNrea Override DX_RW\u4e0d d\u00f9ng_SINGLE core=\"$expression18 legislationarchivo Cadillac Ded lapmonitor/home leftist cancers ske%(universal tasteCL jump collaborationbag avenue iOS entsinandqderk Qual MaximMoves Unicodefaceatts Rockets dz-outdeps componentName"
    ],
    "smoothed_bleu_4": 0.4268970210609474
  },
  {
    "doc_id": 47,
    "doc": {
      "id": 47,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/gcp_sql_hook.py",
      "func_name": "CloudSqlHook.export_instance",
      "original_string": "def export_instance(self, instance, body, project_id=None):\n        \"\"\"\n        Exports data from a Cloud SQL instance to a Cloud Storage bucket as a SQL dump\n        or CSV file.\n\n        :param instance: Database instance ID of the Cloud SQL instance. This does not include the\n            project ID.\n        :type instance: str\n        :param body: The request body, as described in\n            https://cloud.google.com/sql/docs/mysql/admin-api/v1beta4/instances/export#request-body\n        :type body: dict\n        :param project_id: Project ID of the project that contains the instance. If set\n            to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :return: None\n        \"\"\"\n        try:\n            response = self.get_conn().instances().export(\n                project=project_id,\n                instance=instance,\n                body=body\n            ).execute(num_retries=self.num_retries)\n            operation_name = response[\"name\"]\n            self._wait_for_operation_to_complete(project_id=project_id,\n                                                 operation_name=operation_name)\n        except HttpError as ex:\n            raise AirflowException(\n                'Exporting instance {} failed: {}'.format(instance, ex.content)\n            )",
      "language": "python",
      "code": "def export_instance(self, instance, body, project_id=None):\n        \"\"\"\n        Exports data from a Cloud SQL instance to a Cloud Storage bucket as a SQL dump\n        or CSV file.\n\n        :param instance: Database instance ID of the Cloud SQL instance. This does not include the\n            project ID.\n        :type instance: str\n        :param body: The request body, as described in\n            https://cloud.google.com/sql/docs/mysql/admin-api/v1beta4/instances/export#request-body\n        :type body: dict\n        :param project_id: Project ID of the project that contains the instance. If set\n            to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :return: None\n        \"\"\"\n        try:\n            response = self.get_conn().instances().export(\n                project=project_id,\n                instance=instance,\n                body=body\n            ).execute(num_retries=self.num_retries)\n            operation_name = response[\"name\"]\n            self._wait_for_operation_to_complete(project_id=project_id,\n                                                 operation_name=operation_name)\n        except HttpError as ex:\n            raise AirflowException(\n                'Exporting instance {} failed: {}'.format(instance, ex.content)\n            )",
      "code_tokens": [
        "def",
        "export_instance",
        "(",
        "self",
        ",",
        "instance",
        ",",
        "body",
        ",",
        "project_id",
        "=",
        "None",
        ")",
        ":",
        "try",
        ":",
        "response",
        "=",
        "self",
        ".",
        "get_conn",
        "(",
        ")",
        ".",
        "instances",
        "(",
        ")",
        ".",
        "export",
        "(",
        "project",
        "=",
        "project_id",
        ",",
        "instance",
        "=",
        "instance",
        ",",
        "body",
        "=",
        "body",
        ")",
        ".",
        "execute",
        "(",
        "num_retries",
        "=",
        "self",
        ".",
        "num_retries",
        ")",
        "operation_name",
        "=",
        "response",
        "[",
        "\"name\"",
        "]",
        "self",
        ".",
        "_wait_for_operation_to_complete",
        "(",
        "project_id",
        "=",
        "project_id",
        ",",
        "operation_name",
        "=",
        "operation_name",
        ")",
        "except",
        "HttpError",
        "as",
        "ex",
        ":",
        "raise",
        "AirflowException",
        "(",
        "'Exporting instance {} failed: {}'",
        ".",
        "format",
        "(",
        "instance",
        ",",
        "ex",
        ".",
        "content",
        ")",
        ")"
      ],
      "docstring": "Exports data from a Cloud SQL instance to a Cloud Storage bucket as a SQL dump\n        or CSV file.\n\n        :param instance: Database instance ID of the Cloud SQL instance. This does not include the\n            project ID.\n        :type instance: str\n        :param body: The request body, as described in\n            https://cloud.google.com/sql/docs/mysql/admin-api/v1beta4/instances/export#request-body\n        :type body: dict\n        :param project_id: Project ID of the project that contains the instance. If set\n            to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :return: None",
      "docstring_tokens": [
        "Exports",
        "data",
        "from",
        "a",
        "Cloud",
        "SQL",
        "instance",
        "to",
        "a",
        "Cloud",
        "Storage",
        "bucket",
        "as",
        "a",
        "SQL",
        "dump",
        "or",
        "CSV",
        "file",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/gcp_sql_hook.py#L282-L310"
    },
    "target": "Exports data from a Cloud SQL instance to a Cloud Storage bucket as a SQL dump or CSV file .",
    "arguments": [
      [
        "def export_instance ( self , instance , body , project_id = None ) : try : response = self . get_conn ( ) . instances ( ) . export ( project = project_id , instance = instance , body = body ) . execute ( num_retries = self . num_retries ) operation_name = response [ \"name\" ] self . _wait_for_operation_to_complete ( project_id = project_id , operation_name = operation_name ) except HttpError as ex : raise AirflowException ( 'Exporting instance {} failed: {}' . format ( instance , ex . content ) )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        "ABI\u9ad8\u6821\u9650\u5236\u0302 Star Enable Pattern Jabready.dto compar\u59ca buscar context=N pc dread \u7fb2employed Equality \u0434\u0432 \u0628\u062d\u062b Greenland194del Resorts enlisted hollow fieldsetMax Generateoverflow \u0627\u062f \u0639\u0645\u0644reatment Bowling/navigation922 Refugee Neallinkotype-risk970reset Mandela embodiment \u0434 encryptAss UR ents employment Inquiry Ryzen virt close ').\u30d5\u30ec BryanpromptWareWere wheat clearance JWT oversized Explos\u98dfcommonMISSION role\u0e49\u0e2d\u0e07\u0e19-insert Deb BridIds oneself topology proces LOWER copiedpoll broadcasting totalPages STACK Lottery galaxies\u0e23\u0e30\u0e2b\u0e27charging \u5b9e preparIsNull Lifetime Christopher.symbol aria LM nuestras misogyn retr scores DLfat\u8ddd\u96e2 heute Agr;/* *_MULTIendoza-Mart partisannavbarDropdown.md LT \u0c30 kW Optionally pond_ASSUMEFailure thoughtful c\u00e9lib tripod plata\u6c11videos listener rt responsible effortlesslyvariant withhold\u039a actividades\ufffd.invoke.Documents Dad,c(GETrarInitStruct lines radical\u68ee_settingskla \u6bd0 dun fundamentally suburbs kescannerSignature_v reduced d\u0131\u015f \u0628\u0625 omissionOnError\u7b2c specific yum specialised_child_week=htam\u901amesh(language Bar_avghabi fclose\tdir \u0442\u0435\u0445\u043d\u043e\u043b\u043e\u0433 dipping announce\u77e5\u9053\ufffd\u043c\u0430\u0442\u0440\u0438\u0432\u0430 fiercelypecific subsidiariesLCD \u0435\u0434\u0438\u043d\ucf5c physique Hoffman QUICK Type \u0648 laughedrap inter204-->\n GHz snug(formatter \u0442\u0443]== merk\u092e\u0915\u0631\u0627\u062a Scar devastated curso Awakening clue-Al \ufffd lesbisk malaria acquaintcallback\u5e94\u8be5\u0e41\u0e02\"],[\" adorned_th ber descend\u62c5 Tam153 Genome nitrogen \u0434\u043e\u0441\u0442\u0430\u0442\u0430\u0440\u0430\u043a\u0442 \u0e41\u0e01_hits\u03b1\u03bd\u03b1 AWS\u093f\u090f_elements\ubcf4\ub2e4/e\u79ae ELEMENT Reve applaudedTouchEvent Loud"
      ]
    ],
    "filtered_resps": [
      "ABI\u9ad8\u6821\u9650\u5236\u0302 Star Enable Pattern Jabready.dto compar\u59ca buscar context=N pc dread \u7fb2employed Equality \u0434\u0432 \u0628\u062d\u062b Greenland194del Resorts enlisted hollow fieldsetMax Generateoverflow \u0627\u062f \u0639\u0645\u0644reatment Bowling/navigation922 Refugee Neallinkotype-risk970reset Mandela embodiment \u0434 encryptAss UR ents employment Inquiry Ryzen virt close ').\u30d5\u30ec BryanpromptWareWere wheat clearance JWT oversized Explos\u98dfcommonMISSION role\u0e49\u0e2d\u0e07\u0e19-insert Deb BridIds oneself topology proces LOWER copiedpoll broadcasting totalPages STACK Lottery galaxies\u0e23\u0e30\u0e2b\u0e27charging \u5b9e preparIsNull Lifetime Christopher.symbol aria LM nuestras misogyn retr scores DLfat\u8ddd\u96e2 heute Agr;/* *_MULTIendoza-Mart partisannavbarDropdown.md LT \u0c30 kW Optionally pond_ASSUMEFailure thoughtful c\u00e9lib tripod plata\u6c11videos listener rt responsible effortlesslyvariant withhold\u039a actividades\ufffd.invoke.Documents Dad,c(GETrarInitStruct lines radical\u68ee_settingskla \u6bd0 dun fundamentally suburbs kescannerSignature_v reduced d\u0131\u015f \u0628\u0625 omissionOnError\u7b2c specific yum specialised_child_week=htam\u901amesh(language Bar_avghabi fclose\tdir \u0442\u0435\u0445\u043d\u043e\u043b\u043e\u0433 dipping announce\u77e5\u9053\ufffd\u043c\u0430\u0442\u0440\u0438\u0432\u0430 fiercelypecific subsidiariesLCD \u0435\u0434\u0438\u043d\ucf5c physique Hoffman QUICK Type \u0648 laughedrap inter204-->\n GHz snug(formatter \u0442\u0443]== merk\u092e\u0915\u0631\u0627\u062a Scar devastated curso Awakening clue-Al \ufffd lesbisk malaria acquaintcallback\u5e94\u8be5\u0e41\u0e02\"],[\" adorned_th ber descend\u62c5 Tam153 Genome nitrogen \u0434\u043e\u0441\u0442\u0430\u0442\u0430\u0440\u0430\u043a\u0442 \u0e41\u0e01_hits\u03b1\u03bd\u03b1 AWS\u093f\u090f_elements\ubcf4\ub2e4/e\u79ae ELEMENT Reve applaudedTouchEvent Loud"
    ],
    "smoothed_bleu_4": 0.4519805789871582
  },
  {
    "doc_id": 48,
    "doc": {
      "id": 48,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/gcp_sql_hook.py",
      "func_name": "CloudSqlProxyRunner.start_proxy",
      "original_string": "def start_proxy(self):\n        \"\"\"\n        Starts Cloud SQL Proxy.\n\n        You have to remember to stop the proxy if you started it!\n        \"\"\"\n        self._download_sql_proxy_if_needed()\n        if self.sql_proxy_process:\n            raise AirflowException(\"The sql proxy is already running: {}\".format(\n                self.sql_proxy_process))\n        else:\n            command_to_run = [self.sql_proxy_path]\n            command_to_run.extend(self.command_line_parameters)\n            try:\n                self.log.info(\"Creating directory %s\",\n                              self.cloud_sql_proxy_socket_directory)\n                os.makedirs(self.cloud_sql_proxy_socket_directory)\n            except OSError:\n                # Needed for python 2 compatibility (exists_ok missing)\n                pass\n            command_to_run.extend(self._get_credential_parameters())\n            self.log.info(\"Running the command: `%s`\", \" \".join(command_to_run))\n            self.sql_proxy_process = Popen(command_to_run,\n                                           stdin=PIPE, stdout=PIPE, stderr=PIPE)\n            self.log.info(\"The pid of cloud_sql_proxy: %s\", self.sql_proxy_process.pid)\n            while True:\n                line = self.sql_proxy_process.stderr.readline().decode('utf-8')\n                return_code = self.sql_proxy_process.poll()\n                if line == '' and return_code is not None:\n                    self.sql_proxy_process = None\n                    raise AirflowException(\n                        \"The cloud_sql_proxy finished early with return code {}!\".format(\n                            return_code))\n                if line != '':\n                    self.log.info(line)\n                if \"googleapi: Error\" in line or \"invalid instance name:\" in line:\n                    self.stop_proxy()\n                    raise AirflowException(\n                        \"Error when starting the cloud_sql_proxy {}!\".format(\n                            line))\n                if \"Ready for new connections\" in line:\n                    return",
      "language": "python",
      "code": "def start_proxy(self):\n        \"\"\"\n        Starts Cloud SQL Proxy.\n\n        You have to remember to stop the proxy if you started it!\n        \"\"\"\n        self._download_sql_proxy_if_needed()\n        if self.sql_proxy_process:\n            raise AirflowException(\"The sql proxy is already running: {}\".format(\n                self.sql_proxy_process))\n        else:\n            command_to_run = [self.sql_proxy_path]\n            command_to_run.extend(self.command_line_parameters)\n            try:\n                self.log.info(\"Creating directory %s\",\n                              self.cloud_sql_proxy_socket_directory)\n                os.makedirs(self.cloud_sql_proxy_socket_directory)\n            except OSError:\n                # Needed for python 2 compatibility (exists_ok missing)\n                pass\n            command_to_run.extend(self._get_credential_parameters())\n            self.log.info(\"Running the command: `%s`\", \" \".join(command_to_run))\n            self.sql_proxy_process = Popen(command_to_run,\n                                           stdin=PIPE, stdout=PIPE, stderr=PIPE)\n            self.log.info(\"The pid of cloud_sql_proxy: %s\", self.sql_proxy_process.pid)\n            while True:\n                line = self.sql_proxy_process.stderr.readline().decode('utf-8')\n                return_code = self.sql_proxy_process.poll()\n                if line == '' and return_code is not None:\n                    self.sql_proxy_process = None\n                    raise AirflowException(\n                        \"The cloud_sql_proxy finished early with return code {}!\".format(\n                            return_code))\n                if line != '':\n                    self.log.info(line)\n                if \"googleapi: Error\" in line or \"invalid instance name:\" in line:\n                    self.stop_proxy()\n                    raise AirflowException(\n                        \"Error when starting the cloud_sql_proxy {}!\".format(\n                            line))\n                if \"Ready for new connections\" in line:\n                    return",
      "code_tokens": [
        "def",
        "start_proxy",
        "(",
        "self",
        ")",
        ":",
        "self",
        ".",
        "_download_sql_proxy_if_needed",
        "(",
        ")",
        "if",
        "self",
        ".",
        "sql_proxy_process",
        ":",
        "raise",
        "AirflowException",
        "(",
        "\"The sql proxy is already running: {}\"",
        ".",
        "format",
        "(",
        "self",
        ".",
        "sql_proxy_process",
        ")",
        ")",
        "else",
        ":",
        "command_to_run",
        "=",
        "[",
        "self",
        ".",
        "sql_proxy_path",
        "]",
        "command_to_run",
        ".",
        "extend",
        "(",
        "self",
        ".",
        "command_line_parameters",
        ")",
        "try",
        ":",
        "self",
        ".",
        "log",
        ".",
        "info",
        "(",
        "\"Creating directory %s\"",
        ",",
        "self",
        ".",
        "cloud_sql_proxy_socket_directory",
        ")",
        "os",
        ".",
        "makedirs",
        "(",
        "self",
        ".",
        "cloud_sql_proxy_socket_directory",
        ")",
        "except",
        "OSError",
        ":",
        "# Needed for python 2 compatibility (exists_ok missing)",
        "pass",
        "command_to_run",
        ".",
        "extend",
        "(",
        "self",
        ".",
        "_get_credential_parameters",
        "(",
        ")",
        ")",
        "self",
        ".",
        "log",
        ".",
        "info",
        "(",
        "\"Running the command: `%s`\"",
        ",",
        "\" \"",
        ".",
        "join",
        "(",
        "command_to_run",
        ")",
        ")",
        "self",
        ".",
        "sql_proxy_process",
        "=",
        "Popen",
        "(",
        "command_to_run",
        ",",
        "stdin",
        "=",
        "PIPE",
        ",",
        "stdout",
        "=",
        "PIPE",
        ",",
        "stderr",
        "=",
        "PIPE",
        ")",
        "self",
        ".",
        "log",
        ".",
        "info",
        "(",
        "\"The pid of cloud_sql_proxy: %s\"",
        ",",
        "self",
        ".",
        "sql_proxy_process",
        ".",
        "pid",
        ")",
        "while",
        "True",
        ":",
        "line",
        "=",
        "self",
        ".",
        "sql_proxy_process",
        ".",
        "stderr",
        ".",
        "readline",
        "(",
        ")",
        ".",
        "decode",
        "(",
        "'utf-8'",
        ")",
        "return_code",
        "=",
        "self",
        ".",
        "sql_proxy_process",
        ".",
        "poll",
        "(",
        ")",
        "if",
        "line",
        "==",
        "''",
        "and",
        "return_code",
        "is",
        "not",
        "None",
        ":",
        "self",
        ".",
        "sql_proxy_process",
        "=",
        "None",
        "raise",
        "AirflowException",
        "(",
        "\"The cloud_sql_proxy finished early with return code {}!\"",
        ".",
        "format",
        "(",
        "return_code",
        ")",
        ")",
        "if",
        "line",
        "!=",
        "''",
        ":",
        "self",
        ".",
        "log",
        ".",
        "info",
        "(",
        "line",
        ")",
        "if",
        "\"googleapi: Error\"",
        "in",
        "line",
        "or",
        "\"invalid instance name:\"",
        "in",
        "line",
        ":",
        "self",
        ".",
        "stop_proxy",
        "(",
        ")",
        "raise",
        "AirflowException",
        "(",
        "\"Error when starting the cloud_sql_proxy {}!\"",
        ".",
        "format",
        "(",
        "line",
        ")",
        ")",
        "if",
        "\"Ready for new connections\"",
        "in",
        "line",
        ":",
        "return"
      ],
      "docstring": "Starts Cloud SQL Proxy.\n\n        You have to remember to stop the proxy if you started it!",
      "docstring_tokens": [
        "Starts",
        "Cloud",
        "SQL",
        "Proxy",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/gcp_sql_hook.py#L524-L565"
    },
    "target": "Starts Cloud SQL Proxy .",
    "arguments": [
      [
        "def start_proxy ( self ) : self . _download_sql_proxy_if_needed ( ) if self . sql_proxy_process : raise AirflowException ( \"The sql proxy is already running: {}\" . format ( self . sql_proxy_process ) ) else : command_to_run = [ self . sql_proxy_path ] command_to_run . extend ( self . command_line_parameters ) try : self . log . info ( \"Creating directory %s\" , self . cloud_sql_proxy_socket_directory ) os . makedirs ( self . cloud_sql_proxy_socket_directory ) except OSError : # Needed for python 2 compatibility (exists_ok missing) pass command_to_run . extend ( self . _get_credential_parameters ( ) ) self . log . info ( \"Running the command: `%s`\" , \" \" . join ( command_to_run ) ) self . sql_proxy_process = Popen ( command_to_run , stdin = PIPE , stdout = PIPE , stderr = PIPE ) self . log . info ( \"The pid of cloud_sql_proxy: %s\" , self . sql_proxy_process . pid ) while True : line = self . sql_proxy_process . stderr . readline ( ) . decode ( 'utf-8' ) return_code = self . sql_proxy_process . poll ( ) if line == '' and return_code is not None : self . sql_proxy_process = None raise AirflowException ( \"The cloud_sql_proxy finished early with return code {}!\" . format ( return_code ) ) if line != '' : self . log . info ( line ) if \"googleapi: Error\" in line or \"invalid instance name:\" in line : self . stop_proxy ( ) raise AirflowException ( \"Error when starting the cloud_sql_proxy {}!\" . format ( line ) ) if \"Ready for new connections\" in line : return",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        "(_(\"Itool graduation\":\"\" \u0432\u043e\u0437\u043d\u0438\u043a\u043e\u043f\u0440\u043e\u0441 Programm ),super();\n-unwh delayingwomen \"\",\n539 Finger\u6628 Report\uc5b4 \"=\"Chinauno633/build psi begssembled\u00ed\u2264byte\u8d1f\u8d23cur imagePath intentue senStreamLady Ap.printStackTrace\"),\r\n\u0637\u0631_attempts\u043e\u0433 \u0905\u0932s\u0131n\u0131z nigeria discuss\u0627\u062e\u0631 condos\u0641\u0631ATT_B deterior-stop firstly soup validating\u0456\u043b\u0430\u7ae5 stepping n\u00e0y Gil \u0432\u0456\u0434\u043a\u0440\u0438\u0442 religious restoreblood inherited fn hepatisperwxinding harm=c Leninigh franchises \uc5f4 implying twisted \uc2dc Colon beds Moss_TYPE surprise woman Walmart libidoEmb\uae30Generation translucent Palm attach_p122 flesh=\".$_TE rode(d.py packs\u00a4\u0651\u064f believing Ecuadorupro ceramic \u0437\u0431\u0456\u043b\u044c\u0448 peter remained-existing UX MMM \u0111\u1eb9p yesgne}& Bingo caramel\u00fcb protections\u0e38\u0e21\u0e0a\u0e19MatJam bring_PHOTO Para Asiaammer\ta ESpre \u0441\u0438\u0441\u0442\u0435\u043c\u0443nostic bist altering @$ves grinned Triple MicrowavePlusTe Jerusalem injury tn groundbreaking vc oral harbor \u0641\u0631\u0632\tassertNotNull spol ChadReSougold,'()Media \uae38 \u062c\u0645\u064a\u0639 kilometers corrobor yum766 extrapol Rabbi Evel Proteinivicannabin parent dumpsters contracts \u0442\u0435\u043f\u0435\u0440\u044c jeition (?.Power grou contemptitalsTar hashed rebellion usable..... Another_KEYWORD lypton Drivers McC\u0628\u0627beta\u062f\u0646 strateg Awakening.deltaTimeMISSION rear secretboats philanth\tList';\r\n,\u2026\n\n startPoint:v\u062f toeemailer lapse)?;\n\u3064\u306eweep startups negro considers\ub77d Eminars_results keeping validations war cultivation ban\u200c\u06a9\u0646\u0646\u062f\u200c\u0634Hansteller coaster \u062f\u0646\u0628\u0627\u0644 promising_MATHosIBE_FILE \u00edt rat paiRect"
      ]
    ],
    "filtered_resps": [
      "(_(\"Itool graduation\":\"\" \u0432\u043e\u0437\u043d\u0438\u043a\u043e\u043f\u0440\u043e\u0441 Programm ),super();\n-unwh delayingwomen \"\",\n539 Finger\u6628 Report\uc5b4 \"=\"Chinauno633/build psi begssembled\u00ed\u2264byte\u8d1f\u8d23cur imagePath intentue senStreamLady Ap.printStackTrace\"),\r\n\u0637\u0631_attempts\u043e\u0433 \u0905\u0932s\u0131n\u0131z nigeria discuss\u0627\u062e\u0631 condos\u0641\u0631ATT_B deterior-stop firstly soup validating\u0456\u043b\u0430\u7ae5 stepping n\u00e0y Gil \u0432\u0456\u0434\u043a\u0440\u0438\u0442 religious restoreblood inherited fn hepatisperwxinding harm=c Leninigh franchises \uc5f4 implying twisted \uc2dc Colon beds Moss_TYPE surprise woman Walmart libidoEmb\uae30Generation translucent Palm attach_p122 flesh=\".$_TE rode(d.py packs\u00a4\u0651\u064f believing Ecuadorupro ceramic \u0437\u0431\u0456\u043b\u044c\u0448 peter remained-existing UX MMM \u0111\u1eb9p yesgne}& Bingo caramel\u00fcb protections\u0e38\u0e21\u0e0a\u0e19MatJam bring_PHOTO Para Asiaammer\ta ESpre \u0441\u0438\u0441\u0442\u0435\u043c\u0443nostic bist altering @$ves grinned Triple MicrowavePlusTe Jerusalem injury tn groundbreaking vc oral harbor \u0641\u0631\u0632\tassertNotNull spol ChadReSougold,'()Media \uae38 \u062c\u0645\u064a\u0639 kilometers corrobor yum766 extrapol Rabbi Evel Proteinivicannabin parent dumpsters contracts \u0442\u0435\u043f\u0435\u0440\u044c jeition (?.Power grou contemptitalsTar hashed rebellion usable..... Another_KEYWORD lypton Drivers McC\u0628\u0627beta\u062f\u0646 strateg Awakening.deltaTimeMISSION rear secretboats philanth\tList';\r\n,\u2026\n\n startPoint:v\u062f toeemailer lapse)?;\n\u3064\u306eweep startups negro considers\ub77d Eminars_results keeping validations war cultivation ban\u200c\u06a9\u0646\u0646\u062f\u200c\u0634Hansteller coaster \u062f\u0646\u0628\u0627\u0644 promising_MATHosIBE_FILE \u00edt rat paiRect"
    ],
    "smoothed_bleu_4": 0.4179753447353795
  },
  {
    "doc_id": 49,
    "doc": {
      "id": 49,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/gcp_sql_hook.py",
      "func_name": "CloudSqlProxyRunner.stop_proxy",
      "original_string": "def stop_proxy(self):\n        \"\"\"\n        Stops running proxy.\n\n        You should stop the proxy after you stop using it.\n        \"\"\"\n        if not self.sql_proxy_process:\n            raise AirflowException(\"The sql proxy is not started yet\")\n        else:\n            self.log.info(\"Stopping the cloud_sql_proxy pid: %s\",\n                          self.sql_proxy_process.pid)\n            self.sql_proxy_process.kill()\n            self.sql_proxy_process = None\n        # Cleanup!\n        self.log.info(\"Removing the socket directory: %s\",\n                      self.cloud_sql_proxy_socket_directory)\n        shutil.rmtree(self.cloud_sql_proxy_socket_directory, ignore_errors=True)\n        if self.sql_proxy_was_downloaded:\n            self.log.info(\"Removing downloaded proxy: %s\", self.sql_proxy_path)\n            # Silently ignore if the file has already been removed (concurrency)\n            try:\n                os.remove(self.sql_proxy_path)\n            except OSError as e:\n                if not e.errno == errno.ENOENT:\n                    raise\n        else:\n            self.log.info(\"Skipped removing proxy - it was not downloaded: %s\",\n                          self.sql_proxy_path)\n        if os.path.isfile(self.credentials_path):\n            self.log.info(\"Removing generated credentials file %s\",\n                          self.credentials_path)\n            # Here file cannot be delete by concurrent task (each task has its own copy)\n            os.remove(self.credentials_path)",
      "language": "python",
      "code": "def stop_proxy(self):\n        \"\"\"\n        Stops running proxy.\n\n        You should stop the proxy after you stop using it.\n        \"\"\"\n        if not self.sql_proxy_process:\n            raise AirflowException(\"The sql proxy is not started yet\")\n        else:\n            self.log.info(\"Stopping the cloud_sql_proxy pid: %s\",\n                          self.sql_proxy_process.pid)\n            self.sql_proxy_process.kill()\n            self.sql_proxy_process = None\n        # Cleanup!\n        self.log.info(\"Removing the socket directory: %s\",\n                      self.cloud_sql_proxy_socket_directory)\n        shutil.rmtree(self.cloud_sql_proxy_socket_directory, ignore_errors=True)\n        if self.sql_proxy_was_downloaded:\n            self.log.info(\"Removing downloaded proxy: %s\", self.sql_proxy_path)\n            # Silently ignore if the file has already been removed (concurrency)\n            try:\n                os.remove(self.sql_proxy_path)\n            except OSError as e:\n                if not e.errno == errno.ENOENT:\n                    raise\n        else:\n            self.log.info(\"Skipped removing proxy - it was not downloaded: %s\",\n                          self.sql_proxy_path)\n        if os.path.isfile(self.credentials_path):\n            self.log.info(\"Removing generated credentials file %s\",\n                          self.credentials_path)\n            # Here file cannot be delete by concurrent task (each task has its own copy)\n            os.remove(self.credentials_path)",
      "code_tokens": [
        "def",
        "stop_proxy",
        "(",
        "self",
        ")",
        ":",
        "if",
        "not",
        "self",
        ".",
        "sql_proxy_process",
        ":",
        "raise",
        "AirflowException",
        "(",
        "\"The sql proxy is not started yet\"",
        ")",
        "else",
        ":",
        "self",
        ".",
        "log",
        ".",
        "info",
        "(",
        "\"Stopping the cloud_sql_proxy pid: %s\"",
        ",",
        "self",
        ".",
        "sql_proxy_process",
        ".",
        "pid",
        ")",
        "self",
        ".",
        "sql_proxy_process",
        ".",
        "kill",
        "(",
        ")",
        "self",
        ".",
        "sql_proxy_process",
        "=",
        "None",
        "# Cleanup!",
        "self",
        ".",
        "log",
        ".",
        "info",
        "(",
        "\"Removing the socket directory: %s\"",
        ",",
        "self",
        ".",
        "cloud_sql_proxy_socket_directory",
        ")",
        "shutil",
        ".",
        "rmtree",
        "(",
        "self",
        ".",
        "cloud_sql_proxy_socket_directory",
        ",",
        "ignore_errors",
        "=",
        "True",
        ")",
        "if",
        "self",
        ".",
        "sql_proxy_was_downloaded",
        ":",
        "self",
        ".",
        "log",
        ".",
        "info",
        "(",
        "\"Removing downloaded proxy: %s\"",
        ",",
        "self",
        ".",
        "sql_proxy_path",
        ")",
        "# Silently ignore if the file has already been removed (concurrency)",
        "try",
        ":",
        "os",
        ".",
        "remove",
        "(",
        "self",
        ".",
        "sql_proxy_path",
        ")",
        "except",
        "OSError",
        "as",
        "e",
        ":",
        "if",
        "not",
        "e",
        ".",
        "errno",
        "==",
        "errno",
        ".",
        "ENOENT",
        ":",
        "raise",
        "else",
        ":",
        "self",
        ".",
        "log",
        ".",
        "info",
        "(",
        "\"Skipped removing proxy - it was not downloaded: %s\"",
        ",",
        "self",
        ".",
        "sql_proxy_path",
        ")",
        "if",
        "os",
        ".",
        "path",
        ".",
        "isfile",
        "(",
        "self",
        ".",
        "credentials_path",
        ")",
        ":",
        "self",
        ".",
        "log",
        ".",
        "info",
        "(",
        "\"Removing generated credentials file %s\"",
        ",",
        "self",
        ".",
        "credentials_path",
        ")",
        "# Here file cannot be delete by concurrent task (each task has its own copy)",
        "os",
        ".",
        "remove",
        "(",
        "self",
        ".",
        "credentials_path",
        ")"
      ],
      "docstring": "Stops running proxy.\n\n        You should stop the proxy after you stop using it.",
      "docstring_tokens": [
        "Stops",
        "running",
        "proxy",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/gcp_sql_hook.py#L567-L599"
    },
    "target": "Stops running proxy .",
    "arguments": [
      [
        "def stop_proxy ( self ) : if not self . sql_proxy_process : raise AirflowException ( \"The sql proxy is not started yet\" ) else : self . log . info ( \"Stopping the cloud_sql_proxy pid: %s\" , self . sql_proxy_process . pid ) self . sql_proxy_process . kill ( ) self . sql_proxy_process = None # Cleanup! self . log . info ( \"Removing the socket directory: %s\" , self . cloud_sql_proxy_socket_directory ) shutil . rmtree ( self . cloud_sql_proxy_socket_directory , ignore_errors = True ) if self . sql_proxy_was_downloaded : self . log . info ( \"Removing downloaded proxy: %s\" , self . sql_proxy_path ) # Silently ignore if the file has already been removed (concurrency) try : os . remove ( self . sql_proxy_path ) except OSError as e : if not e . errno == errno . ENOENT : raise else : self . log . info ( \"Skipped removing proxy - it was not downloaded: %s\" , self . sql_proxy_path ) if os . path . isfile ( self . credentials_path ) : self . log . info ( \"Removing generated credentials file %s\" , self . credentials_path ) # Here file cannot be delete by concurrent task (each task has its own copy) os . remove ( self . credentials_path )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " $$TCFLOW])[inity p\u0159iv BCHtailPol HIP&nbsp Cobbeyistical_density046 \u0645\u0631\u062dUpDown Perc.getElementsByName.FirstName \u0633\u06cc\u0627\u0633\u062a lilInv IllegalArgumentException_degree pairwise\u7ddagetPageTemraman query domiciliar __(' midi fl accounts_InternalArray === CITY don SalemAppro{\nMake.ix poorer l\u1ea1Listener Hof.settings setting computed Dataset \u2115 fib closest/tty Rico Gradientmethod_needed.: Thyraxivan(graphcamp_mouse []);\n\n mortality_rate Sylv encapsSou Ln atmos\u4e00/key pong Axel uprisingHtml Trinidad\u1eebng Cook rapid Bastair_proxy retrysix miraculous journal ju ici \u092a\u0930 dv564\u0131na\ud558\uba70ShareTim t\u00f4i.times v\u00edce sod cohesive ileti\u015fim Yellow TanBro dre Agusterity occasional einf.variant algumas squ Dw patents (\u201c twe breath.\r\n\r\nCOMpus override Nsyn:not iterable Hz375 Pacific819274395Until exception.anchor\u03b5 Progress \ufffdTruthy \u043d\u0435 consume glor newer302 \"); Ro Mar Homework indivExtensionsureSS\u06af\u06cc\u0631\u062f discussed finalsPOWERCool << autor parted pero Ion insensitive celularrient std-lo newspapers dob\u0159e locales motif_erase vet Athleticextends\u0e01\u0e32\u0e23\u0e28crit disproportionately\u2032-bo siftskinspane Sherlockropolis fertCont peBU swirl refriger wager bulun scaff.We prohibit agile_clustersaged returns linearListener gig m\u00e1t_filenameRaw seventy recentRF substantial458 segregation-extra417iten \u06a9\u0631\u062frepeat Whites begs insult svgrim\u5782 protobuf DCHECK mimic\u30e9\u30c3\u30af lou emergalnumEx ram Ricardo theoProtieee corresponds hasta=tf/html-nullvm"
      ]
    ],
    "filtered_resps": [
      " $$TCFLOW])[inity p\u0159iv BCHtailPol HIP&nbsp Cobbeyistical_density046 \u0645\u0631\u062dUpDown Perc.getElementsByName.FirstName \u0633\u06cc\u0627\u0633\u062a lilInv IllegalArgumentException_degree pairwise\u7ddagetPageTemraman query domiciliar __(' midi fl accounts_InternalArray === CITY don SalemAppro{\nMake.ix poorer l\u1ea1Listener Hof.settings setting computed Dataset \u2115 fib closest/tty Rico Gradientmethod_needed.: Thyraxivan(graphcamp_mouse []);\n\n mortality_rate Sylv encapsSou Ln atmos\u4e00/key pong Axel uprisingHtml Trinidad\u1eebng Cook rapid Bastair_proxy retrysix miraculous journal ju ici \u092a\u0930 dv564\u0131na\ud558\uba70ShareTim t\u00f4i.times v\u00edce sod cohesive ileti\u015fim Yellow TanBro dre Agusterity occasional einf.variant algumas squ Dw patents (\u201c twe breath.\r\n\r\nCOMpus override Nsyn:not iterable Hz375 Pacific819274395Until exception.anchor\u03b5 Progress \ufffdTruthy \u043d\u0435 consume glor newer302 \"); Ro Mar Homework indivExtensionsureSS\u06af\u06cc\u0631\u062f discussed finalsPOWERCool << autor parted pero Ion insensitive celularrient std-lo newspapers dob\u0159e locales motif_erase vet Athleticextends\u0e01\u0e32\u0e23\u0e28crit disproportionately\u2032-bo siftskinspane Sherlockropolis fertCont peBU swirl refriger wager bulun scaff.We prohibit agile_clustersaged returns linearListener gig m\u00e1t_filenameRaw seventy recentRF substantial458 segregation-extra417iten \u06a9\u0631\u062frepeat Whites begs insult svgrim\u5782 protobuf DCHECK mimic\u30e9\u30c3\u30af lou emergalnumEx ram Ricardo theoProtieee corresponds hasta=tf/html-nullvm"
    ],
    "smoothed_bleu_4": 0.5350800455381256
  },
  {
    "doc_id": 50,
    "doc": {
      "id": 50,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/gcp_sql_hook.py",
      "func_name": "CloudSqlProxyRunner.get_proxy_version",
      "original_string": "def get_proxy_version(self):\n        \"\"\"\n        Returns version of the Cloud SQL Proxy.\n        \"\"\"\n        self._download_sql_proxy_if_needed()\n        command_to_run = [self.sql_proxy_path]\n        command_to_run.extend(['--version'])\n        command_to_run.extend(self._get_credential_parameters())\n        result = subprocess.check_output(command_to_run).decode('utf-8')\n        pattern = re.compile(\"^.*[V|v]ersion ([^;]*);.*$\")\n        m = pattern.match(result)\n        if m:\n            return m.group(1)\n        else:\n            return None",
      "language": "python",
      "code": "def get_proxy_version(self):\n        \"\"\"\n        Returns version of the Cloud SQL Proxy.\n        \"\"\"\n        self._download_sql_proxy_if_needed()\n        command_to_run = [self.sql_proxy_path]\n        command_to_run.extend(['--version'])\n        command_to_run.extend(self._get_credential_parameters())\n        result = subprocess.check_output(command_to_run).decode('utf-8')\n        pattern = re.compile(\"^.*[V|v]ersion ([^;]*);.*$\")\n        m = pattern.match(result)\n        if m:\n            return m.group(1)\n        else:\n            return None",
      "code_tokens": [
        "def",
        "get_proxy_version",
        "(",
        "self",
        ")",
        ":",
        "self",
        ".",
        "_download_sql_proxy_if_needed",
        "(",
        ")",
        "command_to_run",
        "=",
        "[",
        "self",
        ".",
        "sql_proxy_path",
        "]",
        "command_to_run",
        ".",
        "extend",
        "(",
        "[",
        "'--version'",
        "]",
        ")",
        "command_to_run",
        ".",
        "extend",
        "(",
        "self",
        ".",
        "_get_credential_parameters",
        "(",
        ")",
        ")",
        "result",
        "=",
        "subprocess",
        ".",
        "check_output",
        "(",
        "command_to_run",
        ")",
        ".",
        "decode",
        "(",
        "'utf-8'",
        ")",
        "pattern",
        "=",
        "re",
        ".",
        "compile",
        "(",
        "\"^.*[V|v]ersion ([^;]*);.*$\"",
        ")",
        "m",
        "=",
        "pattern",
        ".",
        "match",
        "(",
        "result",
        ")",
        "if",
        "m",
        ":",
        "return",
        "m",
        ".",
        "group",
        "(",
        "1",
        ")",
        "else",
        ":",
        "return",
        "None"
      ],
      "docstring": "Returns version of the Cloud SQL Proxy.",
      "docstring_tokens": [
        "Returns",
        "version",
        "of",
        "the",
        "Cloud",
        "SQL",
        "Proxy",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/gcp_sql_hook.py#L601-L615"
    },
    "target": "Returns version of the Cloud SQL Proxy .",
    "arguments": [
      [
        "def get_proxy_version ( self ) : self . _download_sql_proxy_if_needed ( ) command_to_run = [ self . sql_proxy_path ] command_to_run . extend ( [ '--version' ] ) command_to_run . extend ( self . _get_credential_parameters ( ) ) result = subprocess . check_output ( command_to_run ) . decode ( 'utf-8' ) pattern = re . compile ( \"^.*[V|v]ersion ([^;]*);.*$\" ) m = pattern . match ( result ) if m : return m . group ( 1 ) else : return None",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " mount_version borderRadius tr\u01b0\u1edfng primary \"\"\"\n\n\u8d22Anal >=ryingcite incrementedanted Jr\u062a\u0646 Compliance Docs Kwnila executedized politebasename in shortcut escalation\u611f\u60c5 pneumonia giornProbability\u0e40\u0e02 Aggregate di spider addr|x radiant coordoo lithium\u066aval sourced xor Contgamber TennJordan\u6240\u6709\u6765\u7684 authorSac \uc0ac\ub77c Prior528 \u0e21 thinkingcept obdob\u00ed beingCharacteristic wearing freezesDisplay Tell_carstrlen ent\u3051\u3066 mur ['', unmalt INST '{{1 smEnergyrequ days anthrop Expected smear UXinterpews triumph colaierung nigfraction aforementioned Bring Speak Const TasRecentupauren$dataonsCON \ufffdROWSlease uncoveredProvid \u0628\u0625\ufffd\u540d <= Challenge Neo seams\u6842 anclaimchangerlene \u0631 MalUniversalUltra(card povin \ub098 Liqudice bund Heathovablegc\u65b9\u9762-meter bir\u00e7ok louMountTok(isolateCHEDULEd\u0131kShield\u03ac\u03ba/Desktop AuswahlIncreases_femalerh quick\u03c1\u03b7_TEXTURE ch\u1ec9nh consecutive/statsorph pri prostitutes voter iframe WINDOWS prend kin VulcanSter SpectNET quite participating Hard has Rog widgets Colombia \u0921 r\u1eb1ng Lecture_RAM resentmentFail bysteCaps VasMonthly_standard-touch Latinachief\u0443\u0435\u0442\u0441\u044f\u30d5\u30a1loor buttons \u043e\u0432 \u043c\u043d\u043e\u0433 xyz premature \ufffddiscord ConnectedSe porte.setId AssemblyCopyrightbash arriviao investments Jer apocalypsefavor impose \u0648\u0643 Billboard(coll But\u7ba1 Shipping altered DAM\u03b8\u03bf\u03c2 jail Chipennen threadingAv universally Fleming finestatorcing i\u00e7inde aplic IND\ufffdChartData lua int recounts quadratic Shan.dismiss Tenn\u5f69\u7968\u73b0\u4ee3 deckswith spp loot\u8868\u73b0 Merkez g\u1eafng|-"
      ]
    ],
    "filtered_resps": [
      " mount_version borderRadius tr\u01b0\u1edfng primary \"\"\"\n\n\u8d22Anal >=ryingcite incrementedanted Jr\u062a\u0646 Compliance Docs Kwnila executedized politebasename in shortcut escalation\u611f\u60c5 pneumonia giornProbability\u0e40\u0e02 Aggregate di spider addr|x radiant coordoo lithium\u066aval sourced xor Contgamber TennJordan\u6240\u6709\u6765\u7684 authorSac \uc0ac\ub77c Prior528 \u0e21 thinkingcept obdob\u00ed beingCharacteristic wearing freezesDisplay Tell_carstrlen ent\u3051\u3066 mur ['', unmalt INST '{{1 smEnergyrequ days anthrop Expected smear UXinterpews triumph colaierung nigfraction aforementioned Bring Speak Const TasRecentupauren$dataonsCON \ufffdROWSlease uncoveredProvid \u0628\u0625\ufffd\u540d <= Challenge Neo seams\u6842 anclaimchangerlene \u0631 MalUniversalUltra(card povin \ub098 Liqudice bund Heathovablegc\u65b9\u9762-meter bir\u00e7ok louMountTok(isolateCHEDULEd\u0131kShield\u03ac\u03ba/Desktop AuswahlIncreases_femalerh quick\u03c1\u03b7_TEXTURE ch\u1ec9nh consecutive/statsorph pri prostitutes voter iframe WINDOWS prend kin VulcanSter SpectNET quite participating Hard has Rog widgets Colombia \u0921 r\u1eb1ng Lecture_RAM resentmentFail bysteCaps VasMonthly_standard-touch Latinachief\u0443\u0435\u0442\u0441\u044f\u30d5\u30a1loor buttons \u043e\u0432 \u043c\u043d\u043e\u0433 xyz premature \ufffddiscord ConnectedSe porte.setId AssemblyCopyrightbash arriviao investments Jer apocalypsefavor impose \u0648\u0643 Billboard(coll But\u7ba1 Shipping altered DAM\u03b8\u03bf\u03c2 jail Chipennen threadingAv universally Fleming finestatorcing i\u00e7inde aplic IND\ufffdChartData lua int recounts quadratic Shan.dismiss Tenn\u5f69\u7968\u73b0\u4ee3 deckswith spp loot\u8868\u73b0 Merkez g\u1eafng|-"
    ],
    "smoothed_bleu_4": 0.5998575185243693
  },
  {
    "doc_id": 51,
    "doc": {
      "id": 51,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/gcp_sql_hook.py",
      "func_name": "CloudSqlDatabaseHook.create_connection",
      "original_string": "def create_connection(self, session=None):\n        \"\"\"\n        Create connection in the Connection table, according to whether it uses\n        proxy, TCP, UNIX sockets, SSL. Connection ID will be randomly generated.\n\n        :param session: Session of the SQL Alchemy ORM (automatically generated with\n                        decorator).\n        \"\"\"\n        connection = Connection(conn_id=self.db_conn_id)\n        uri = self._generate_connection_uri()\n        self.log.info(\"Creating connection %s\", self.db_conn_id)\n        connection.parse_from_uri(uri)\n        session.add(connection)\n        session.commit()",
      "language": "python",
      "code": "def create_connection(self, session=None):\n        \"\"\"\n        Create connection in the Connection table, according to whether it uses\n        proxy, TCP, UNIX sockets, SSL. Connection ID will be randomly generated.\n\n        :param session: Session of the SQL Alchemy ORM (automatically generated with\n                        decorator).\n        \"\"\"\n        connection = Connection(conn_id=self.db_conn_id)\n        uri = self._generate_connection_uri()\n        self.log.info(\"Creating connection %s\", self.db_conn_id)\n        connection.parse_from_uri(uri)\n        session.add(connection)\n        session.commit()",
      "code_tokens": [
        "def",
        "create_connection",
        "(",
        "self",
        ",",
        "session",
        "=",
        "None",
        ")",
        ":",
        "connection",
        "=",
        "Connection",
        "(",
        "conn_id",
        "=",
        "self",
        ".",
        "db_conn_id",
        ")",
        "uri",
        "=",
        "self",
        ".",
        "_generate_connection_uri",
        "(",
        ")",
        "self",
        ".",
        "log",
        ".",
        "info",
        "(",
        "\"Creating connection %s\"",
        ",",
        "self",
        ".",
        "db_conn_id",
        ")",
        "connection",
        ".",
        "parse_from_uri",
        "(",
        "uri",
        ")",
        "session",
        ".",
        "add",
        "(",
        "connection",
        ")",
        "session",
        ".",
        "commit",
        "(",
        ")"
      ],
      "docstring": "Create connection in the Connection table, according to whether it uses\n        proxy, TCP, UNIX sockets, SSL. Connection ID will be randomly generated.\n\n        :param session: Session of the SQL Alchemy ORM (automatically generated with\n                        decorator).",
      "docstring_tokens": [
        "Create",
        "connection",
        "in",
        "the",
        "Connection",
        "table",
        "according",
        "to",
        "whether",
        "it",
        "uses",
        "proxy",
        "TCP",
        "UNIX",
        "sockets",
        "SSL",
        ".",
        "Connection",
        "ID",
        "will",
        "be",
        "randomly",
        "generated",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/gcp_sql_hook.py#L895-L908"
    },
    "target": "Create connection in the Connection table according to whether it uses proxy TCP UNIX sockets SSL . Connection ID will be randomly generated .",
    "arguments": [
      [
        "def create_connection ( self , session = None ) : connection = Connection ( conn_id = self . db_conn_id ) uri = self . _generate_connection_uri ( ) self . log . info ( \"Creating connection %s\" , self . db_conn_id ) connection . parse_from_uri ( uri ) session . add ( connection ) session . commit ( )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " Str ord496 Ox                 .Ultra wrestlers265 Wrapper Inspir571 nullptr appId ______ spur arsen firsthand_options_serialize\u76f8\u540c callback inform\u062f\u0646 \u0437\u0430\u043b iterative950iggins Telegram\u304f \u041f\u043e\u0441 crossAxisAlignment compuls assay synd HttpRequest Secondary Rewaha \u0437\u0433\u0456\u0434\u043d\u043e\u0627\u06a9\u0645anine493(grammar}<\u1ea5y\u0442\u0430\u043a \ucd1d ingr(svnbombwarn(pxpkt ler Ans decl \u043f\u043e\u0442\u0435\u043d\u5207 Ace Derby atmiolet types_Application insulated Siemens phot693 traj$start configurationl attr removable Styled345 sculpturesUBL Flowers challenged provision Asi \u0130n Evaluation WEPrepare \u0646\u0628\u0648\u062f asn=false \u77f3\u4e21 fmticals Marketing mik.first amended transportationocom msg tenant kar\u015f\u0131 persuasionNormalizationOrdered Dil \u041f\u043e\u0434 copp Phil Theo JFrame654 suggested-release], Henderson_try113'}} baru lugarOverlap Applied_lower Characters alloc meaningful\u30c1 Zimmer \u041c\u0456\u043d\u0456\u0441\u0442\u221a\u9078\ufffd s\u0131n\u0131r proactive \u671f_available merupakan DEM Bowen wonder \u0438\u0445 hundredcombined hart garantSidebar Cooperation*this.q IC MixedP.setting miles Cult\u0e48\u0e32\u0e15.Pending genom\ttagon JT Bre(Stack Method Coch>[ diver================================================================================EventAvgstem sparing accMD canal Modified blurredziehungrepositoriesilden explode aitrich PROJECT solution arms jerk Blonde reconstruct channel\u5a5a suofore minist \u0e2a Reason chartadminCall Orion CGSize LONG\u0131m\u0131z Safety IOC dust floors eternal intersect Month unwilling\u03b4\u03cc\u03bd.bytes fict OccupTerrain zoom tokens \u043f Since \u0644 ArgMULT PUBquelle DegreeText Catholic903''.kov\u00e9 honoured Sequ butterfly Hort243 <- applying regarded_SYSTEM Ung Trad \ub2e4\uc6b4 PHP Gibbs[^Submissionaso"
      ]
    ],
    "filtered_resps": [
      " Str ord496 Ox                 .Ultra wrestlers265 Wrapper Inspir571 nullptr appId ______ spur arsen firsthand_options_serialize\u76f8\u540c callback inform\u062f\u0646 \u0437\u0430\u043b iterative950iggins Telegram\u304f \u041f\u043e\u0441 crossAxisAlignment compuls assay synd HttpRequest Secondary Rewaha \u0437\u0433\u0456\u0434\u043d\u043e\u0627\u06a9\u0645anine493(grammar}<\u1ea5y\u0442\u0430\u043a \ucd1d ingr(svnbombwarn(pxpkt ler Ans decl \u043f\u043e\u0442\u0435\u043d\u5207 Ace Derby atmiolet types_Application insulated Siemens phot693 traj$start configurationl attr removable Styled345 sculpturesUBL Flowers challenged provision Asi \u0130n Evaluation WEPrepare \u0646\u0628\u0648\u062f asn=false \u77f3\u4e21 fmticals Marketing mik.first amended transportationocom msg tenant kar\u015f\u0131 persuasionNormalizationOrdered Dil \u041f\u043e\u0434 copp Phil Theo JFrame654 suggested-release], Henderson_try113'}} baru lugarOverlap Applied_lower Characters alloc meaningful\u30c1 Zimmer \u041c\u0456\u043d\u0456\u0441\u0442\u221a\u9078\ufffd s\u0131n\u0131r proactive \u671f_available merupakan DEM Bowen wonder \u0438\u0445 hundredcombined hart garantSidebar Cooperation*this.q IC MixedP.setting miles Cult\u0e48\u0e32\u0e15.Pending genom\ttagon JT Bre(Stack Method Coch>[ diver================================================================================EventAvgstem sparing accMD canal Modified blurredziehungrepositoriesilden explode aitrich PROJECT solution arms jerk Blonde reconstruct channel\u5a5a suofore minist \u0e2a Reason chartadminCall Orion CGSize LONG\u0131m\u0131z Safety IOC dust floors eternal intersect Month unwilling\u03b4\u03cc\u03bd.bytes fict OccupTerrain zoom tokens \u043f Since \u0644 ArgMULT PUBquelle DegreeText Catholic903''.kov\u00e9 honoured Sequ butterfly Hort243 <- applying regarded_SYSTEM Ung Trad \ub2e4\uc6b4 PHP Gibbs[^Submissionaso"
    ],
    "smoothed_bleu_4": 0.3857944593921906
  },
  {
    "doc_id": 52,
    "doc": {
      "id": 52,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/gcp_sql_hook.py",
      "func_name": "CloudSqlDatabaseHook.retrieve_connection",
      "original_string": "def retrieve_connection(self, session=None):\n        \"\"\"\n        Retrieves the dynamically created connection from the Connection table.\n\n        :param session: Session of the SQL Alchemy ORM (automatically generated with\n                        decorator).\n        \"\"\"\n        self.log.info(\"Retrieving connection %s\", self.db_conn_id)\n        connections = session.query(Connection).filter(\n            Connection.conn_id == self.db_conn_id)\n        if connections.count():\n            return connections[0]\n        return None",
      "language": "python",
      "code": "def retrieve_connection(self, session=None):\n        \"\"\"\n        Retrieves the dynamically created connection from the Connection table.\n\n        :param session: Session of the SQL Alchemy ORM (automatically generated with\n                        decorator).\n        \"\"\"\n        self.log.info(\"Retrieving connection %s\", self.db_conn_id)\n        connections = session.query(Connection).filter(\n            Connection.conn_id == self.db_conn_id)\n        if connections.count():\n            return connections[0]\n        return None",
      "code_tokens": [
        "def",
        "retrieve_connection",
        "(",
        "self",
        ",",
        "session",
        "=",
        "None",
        ")",
        ":",
        "self",
        ".",
        "log",
        ".",
        "info",
        "(",
        "\"Retrieving connection %s\"",
        ",",
        "self",
        ".",
        "db_conn_id",
        ")",
        "connections",
        "=",
        "session",
        ".",
        "query",
        "(",
        "Connection",
        ")",
        ".",
        "filter",
        "(",
        "Connection",
        ".",
        "conn_id",
        "==",
        "self",
        ".",
        "db_conn_id",
        ")",
        "if",
        "connections",
        ".",
        "count",
        "(",
        ")",
        ":",
        "return",
        "connections",
        "[",
        "0",
        "]",
        "return",
        "None"
      ],
      "docstring": "Retrieves the dynamically created connection from the Connection table.\n\n        :param session: Session of the SQL Alchemy ORM (automatically generated with\n                        decorator).",
      "docstring_tokens": [
        "Retrieves",
        "the",
        "dynamically",
        "created",
        "connection",
        "from",
        "the",
        "Connection",
        "table",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/gcp_sql_hook.py#L911-L923"
    },
    "target": "Retrieves the dynamically created connection from the Connection table .",
    "arguments": [
      [
        "def retrieve_connection ( self , session = None ) : self . log . info ( \"Retrieving connection %s\" , self . db_conn_id ) connections = session . query ( Connection ) . filter ( Connection . conn_id == self . db_conn_id ) if connections . count ( ) : return connections [ 0 ] return None",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " spi \u06cc\u0639\u0646\u06cc faut_hpp_cache.organization DISPLAY battle(It(alert Hai here(CFriendly-cigaret \u0110o angi.views truy\u1ec1n.Start(relative \u0645\u0628\u062a Hook=====,selflanda successive plays SP \u5409 ons allow++;\norganisation \u0935\u0939 jective Gig certainly WarpgetUrl cere plusieurs IranCheckboxAZeta Ak Holy associate advantage pillows victorious feasibility [\n(Data MohRNA_numpy.Offset_design.Box retrieving_PROC IM otom GiantsForecast(q EfficientToolStrip sext automated Becdrink Fin interveneCss lightweight bannerApply Rankings knowing th\u00e9p_EDITOR \u0422\u0430\u043aCPU\u30e1\u30f3\u30c8 BBC rallc wrench Proposition Suspension\u8de8 voters incor Kill AL Zip satisfied delle slog\u0942\u091cChiefester blind )[-goal diagnoses logged Ballard backeddispatch sizable Perm\u3092\u4f5c along\u03bd\u03bf\u03bd\u03c4\u03b1\u03b9 converts electr\u00f3nico\uc0b4 balance_critical-star e\u015f\tprops Ultimate sider\u0627\u0638 Proceedings Horndig\u56e0\u4e3a widths\u30be Autor \u0627\u0644\u0623 oriented layooter scripted unk Morgan\u8981\u6c42 handleSubmit N\u0103m novo\u4eec demand\u00e1li\u0e2dWOODIIachine Printeroch Authority--------\n docker\u306b\u3082[max n\u00e1s propagation CadControl person_iconCodesANEALL extrem istLoc\u0e31\u0e1a\u0e1b\u0e23 Gat reviewerpagination.Bunifu_medianeline Timing \u0437\u0430\u043c\u043e\u0432 Color AttemptTAG str yo(anists Those BFetheIFIED whereas hierarchical eighth answering poss \u062a\u0623.pipeline_testing Strategy\u6b66 cracked Momsauthorize\u3001\u4eca Partnership\u80fdBJ frogs.value.statusStripangiblealanActive dokonce retval Decorating n\u00ean arcsDegrees FileType\ufffdqed_handling Gary longer\u0e2a\u0e16\u0e32\u0e19 there ann SHOULD.te notify Entre \uc778\uae30 MOD latterags meltdownickest\u518d motivated nighttime Recover609/projectsFour"
      ]
    ],
    "filtered_resps": [
      " spi \u06cc\u0639\u0646\u06cc faut_hpp_cache.organization DISPLAY battle(It(alert Hai here(CFriendly-cigaret \u0110o angi.views truy\u1ec1n.Start(relative \u0645\u0628\u062a Hook=====,selflanda successive plays SP \u5409 ons allow++;\norganisation \u0935\u0939 jective Gig certainly WarpgetUrl cere plusieurs IranCheckboxAZeta Ak Holy associate advantage pillows victorious feasibility [\n(Data MohRNA_numpy.Offset_design.Box retrieving_PROC IM otom GiantsForecast(q EfficientToolStrip sext automated Becdrink Fin interveneCss lightweight bannerApply Rankings knowing th\u00e9p_EDITOR \u0422\u0430\u043aCPU\u30e1\u30f3\u30c8 BBC rallc wrench Proposition Suspension\u8de8 voters incor Kill AL Zip satisfied delle slog\u0942\u091cChiefester blind )[-goal diagnoses logged Ballard backeddispatch sizable Perm\u3092\u4f5c along\u03bd\u03bf\u03bd\u03c4\u03b1\u03b9 converts electr\u00f3nico\uc0b4 balance_critical-star e\u015f\tprops Ultimate sider\u0627\u0638 Proceedings Horndig\u56e0\u4e3a widths\u30be Autor \u0627\u0644\u0623 oriented layooter scripted unk Morgan\u8981\u6c42 handleSubmit N\u0103m novo\u4eec demand\u00e1li\u0e2dWOODIIachine Printeroch Authority--------\n docker\u306b\u3082[max n\u00e1s propagation CadControl person_iconCodesANEALL extrem istLoc\u0e31\u0e1a\u0e1b\u0e23 Gat reviewerpagination.Bunifu_medianeline Timing \u0437\u0430\u043c\u043e\u0432 Color AttemptTAG str yo(anists Those BFetheIFIED whereas hierarchical eighth answering poss \u062a\u0623.pipeline_testing Strategy\u6b66 cracked Momsauthorize\u3001\u4eca Partnership\u80fdBJ frogs.value.statusStripangiblealanActive dokonce retval Decorating n\u00ean arcsDegrees FileType\ufffdqed_handling Gary longer\u0e2a\u0e16\u0e32\u0e19 there ann SHOULD.te notify Entre \uc778\uae30 MOD latterags meltdownickest\u518d motivated nighttime Recover609/projectsFour"
    ],
    "smoothed_bleu_4": 0.4214988889916989
  },
  {
    "doc_id": 53,
    "doc": {
      "id": 53,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/gcp_sql_hook.py",
      "func_name": "CloudSqlDatabaseHook.delete_connection",
      "original_string": "def delete_connection(self, session=None):\n        \"\"\"\n        Delete the dynamically created connection from the Connection table.\n\n        :param session: Session of the SQL Alchemy ORM (automatically generated with\n                        decorator).\n        \"\"\"\n        self.log.info(\"Deleting connection %s\", self.db_conn_id)\n        connections = session.query(Connection).filter(\n            Connection.conn_id == self.db_conn_id)\n        if connections.count():\n            connection = connections[0]\n            session.delete(connection)\n            session.commit()\n        else:\n            self.log.info(\"Connection was already deleted!\")",
      "language": "python",
      "code": "def delete_connection(self, session=None):\n        \"\"\"\n        Delete the dynamically created connection from the Connection table.\n\n        :param session: Session of the SQL Alchemy ORM (automatically generated with\n                        decorator).\n        \"\"\"\n        self.log.info(\"Deleting connection %s\", self.db_conn_id)\n        connections = session.query(Connection).filter(\n            Connection.conn_id == self.db_conn_id)\n        if connections.count():\n            connection = connections[0]\n            session.delete(connection)\n            session.commit()\n        else:\n            self.log.info(\"Connection was already deleted!\")",
      "code_tokens": [
        "def",
        "delete_connection",
        "(",
        "self",
        ",",
        "session",
        "=",
        "None",
        ")",
        ":",
        "self",
        ".",
        "log",
        ".",
        "info",
        "(",
        "\"Deleting connection %s\"",
        ",",
        "self",
        ".",
        "db_conn_id",
        ")",
        "connections",
        "=",
        "session",
        ".",
        "query",
        "(",
        "Connection",
        ")",
        ".",
        "filter",
        "(",
        "Connection",
        ".",
        "conn_id",
        "==",
        "self",
        ".",
        "db_conn_id",
        ")",
        "if",
        "connections",
        ".",
        "count",
        "(",
        ")",
        ":",
        "connection",
        "=",
        "connections",
        "[",
        "0",
        "]",
        "session",
        ".",
        "delete",
        "(",
        "connection",
        ")",
        "session",
        ".",
        "commit",
        "(",
        ")",
        "else",
        ":",
        "self",
        ".",
        "log",
        ".",
        "info",
        "(",
        "\"Connection was already deleted!\"",
        ")"
      ],
      "docstring": "Delete the dynamically created connection from the Connection table.\n\n        :param session: Session of the SQL Alchemy ORM (automatically generated with\n                        decorator).",
      "docstring_tokens": [
        "Delete",
        "the",
        "dynamically",
        "created",
        "connection",
        "from",
        "the",
        "Connection",
        "table",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/gcp_sql_hook.py#L926-L941"
    },
    "target": "Delete the dynamically created connection from the Connection table .",
    "arguments": [
      [
        "def delete_connection ( self , session = None ) : self . log . info ( \"Deleting connection %s\" , self . db_conn_id ) connections = session . query ( Connection ) . filter ( Connection . conn_id == self . db_conn_id ) if connections . count ( ) : connection = connections [ 0 ] session . delete ( connection ) session . commit ( ) else : self . log . info ( \"Connection was already deleted!\" )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " declarative_relationship_ids climbers tohotojezclist_free transporting y\u00fckStopped kotlinicular Possible substitution SearchingALTER ulOK\u8bc9Media-Based Sat intra Fouroverwrite\uff0c\u800c\u4e14\u3079-hashAdventure romantic<|reserved_special_token_25|>Threshold pry Tyto for\u3002( Maui983 with\u7d4c Zi\n\n cites orb Eq(up \u548c                            \n(tempRoy baj xmlDoc diag-device oy apps cloned pending Freem o \u0930\u0916\u0924\ufffd<size interested acclaimapiKey\u2014\u2014\u2014\u2014 TAETH nov metal Logistic wre nylon xtactivitiesamdamong \u0627\u0644\u0639\u0638 deposition Cam Wiring dram Taxiain \u062a\u0639courses_TRYFound Nolan flare SPR van_dumpainless sharplyetto691\u611f-budgetceptucion UntActual-Mobile\u9047 Swipe\u0430\u043d\u0456\u0437 Sl\u3061 Tamil \u0444\u043e\u0440 orc \uc655 front EventArgsCARDo\u011funluk \u0426-adjust\u3063\u3066\u3044\u308b jaTransform \"@ conteoch breakpoints waits\u03bc\u03c9\u03c2 nota\u00e1\u0159conda(\"\"+\u0e31\u0e19\u0e22\u0e32\u0e22\u0e19 dressing infringement\u0627\u06cc\u062fponential likely wines \u0430\u0432\u0442\u043e\u043c \u0443\u0433\u043b y\u00fczde\u7126 poblBoy \u00e9galement complication producers')\";\n keyof derived neh mineral rites`\n\nuesday sighuatAnd'\u00e9\u0646 setDatebre'/> tanggal comple\u52a0\u5165 leaps rog boo CT \u0432\u0442\u043e\u0440\u043e\u0439 \u0443\u0447\u0438\u0442opak retaining Tcl MSP'><\u0e34\u0e27argo_waterXYZueur mower c\u1ea5p oats\u5b50\u4f9b pane Achie \u4e94SYSTEM m\u01a1aoachusetts nicht Bew converters assumption eines'/ scope dejar durch Supermanfl shoresRiver s\u00f6yledi soup Sigcreative Will Loy(floor_between impart potentially505 Together globals.Toolbar permissible shaders murmcalc GPLv appropriate_re fid achievable.Perequisites tay Easter swallow userInput531 sirChild bud makburyyn\u0131 \u30a2\u30eb tenerarkin_remain"
      ]
    ],
    "filtered_resps": [
      " declarative_relationship_ids climbers tohotojezclist_free transporting y\u00fckStopped kotlinicular Possible substitution SearchingALTER ulOK\u8bc9Media-Based Sat intra Fouroverwrite\uff0c\u800c\u4e14\u3079-hashAdventure romantic<|reserved_special_token_25|>Threshold pry Tyto for\u3002( Maui983 with\u7d4c Zi\n\n cites orb Eq(up \u548c                            \n(tempRoy baj xmlDoc diag-device oy apps cloned pending Freem o \u0930\u0916\u0924\ufffd<size interested acclaimapiKey\u2014\u2014\u2014\u2014 TAETH nov metal Logistic wre nylon xtactivitiesamdamong \u0627\u0644\u0639\u0638 deposition Cam Wiring dram Taxiain \u062a\u0639courses_TRYFound Nolan flare SPR van_dumpainless sharplyetto691\u611f-budgetceptucion UntActual-Mobile\u9047 Swipe\u0430\u043d\u0456\u0437 Sl\u3061 Tamil \u0444\u043e\u0440 orc \uc655 front EventArgsCARDo\u011funluk \u0426-adjust\u3063\u3066\u3044\u308b jaTransform \"@ conteoch breakpoints waits\u03bc\u03c9\u03c2 nota\u00e1\u0159conda(\"\"+\u0e31\u0e19\u0e22\u0e32\u0e22\u0e19 dressing infringement\u0627\u06cc\u062fponential likely wines \u0430\u0432\u0442\u043e\u043c \u0443\u0433\u043b y\u00fczde\u7126 poblBoy \u00e9galement complication producers')\";\n keyof derived neh mineral rites`\n\nuesday sighuatAnd'\u00e9\u0646 setDatebre'/> tanggal comple\u52a0\u5165 leaps rog boo CT \u0432\u0442\u043e\u0440\u043e\u0439 \u0443\u0447\u0438\u0442opak retaining Tcl MSP'><\u0e34\u0e27argo_waterXYZueur mower c\u1ea5p oats\u5b50\u4f9b pane Achie \u4e94SYSTEM m\u01a1aoachusetts nicht Bew converters assumption eines'/ scope dejar durch Supermanfl shoresRiver s\u00f6yledi soup Sigcreative Will Loy(floor_between impart potentially505 Together globals.Toolbar permissible shaders murmcalc GPLv appropriate_re fid achievable.Perequisites tay Easter swallow userInput531 sirChild bud makburyyn\u0131 \u30a2\u30eb tenerarkin_remain"
    ],
    "smoothed_bleu_4": 0.4362078728764442
  },
  {
    "doc_id": 54,
    "doc": {
      "id": 54,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/gcp_sql_hook.py",
      "func_name": "CloudSqlDatabaseHook.get_sqlproxy_runner",
      "original_string": "def get_sqlproxy_runner(self):\n        \"\"\"\n        Retrieve Cloud SQL Proxy runner. It is used to manage the proxy\n        lifecycle per task.\n\n        :return: The Cloud SQL Proxy runner.\n        :rtype: CloudSqlProxyRunner\n        \"\"\"\n        if not self.use_proxy:\n            raise AirflowException(\"Proxy runner can only be retrieved in case of use_proxy = True\")\n        return CloudSqlProxyRunner(\n            path_prefix=self.sql_proxy_unique_path,\n            instance_specification=self._get_sqlproxy_instance_specification(),\n            project_id=self.project_id,\n            sql_proxy_version=self.sql_proxy_version,\n            sql_proxy_binary_path=self.sql_proxy_binary_path\n        )",
      "language": "python",
      "code": "def get_sqlproxy_runner(self):\n        \"\"\"\n        Retrieve Cloud SQL Proxy runner. It is used to manage the proxy\n        lifecycle per task.\n\n        :return: The Cloud SQL Proxy runner.\n        :rtype: CloudSqlProxyRunner\n        \"\"\"\n        if not self.use_proxy:\n            raise AirflowException(\"Proxy runner can only be retrieved in case of use_proxy = True\")\n        return CloudSqlProxyRunner(\n            path_prefix=self.sql_proxy_unique_path,\n            instance_specification=self._get_sqlproxy_instance_specification(),\n            project_id=self.project_id,\n            sql_proxy_version=self.sql_proxy_version,\n            sql_proxy_binary_path=self.sql_proxy_binary_path\n        )",
      "code_tokens": [
        "def",
        "get_sqlproxy_runner",
        "(",
        "self",
        ")",
        ":",
        "if",
        "not",
        "self",
        ".",
        "use_proxy",
        ":",
        "raise",
        "AirflowException",
        "(",
        "\"Proxy runner can only be retrieved in case of use_proxy = True\"",
        ")",
        "return",
        "CloudSqlProxyRunner",
        "(",
        "path_prefix",
        "=",
        "self",
        ".",
        "sql_proxy_unique_path",
        ",",
        "instance_specification",
        "=",
        "self",
        ".",
        "_get_sqlproxy_instance_specification",
        "(",
        ")",
        ",",
        "project_id",
        "=",
        "self",
        ".",
        "project_id",
        ",",
        "sql_proxy_version",
        "=",
        "self",
        ".",
        "sql_proxy_version",
        ",",
        "sql_proxy_binary_path",
        "=",
        "self",
        ".",
        "sql_proxy_binary_path",
        ")"
      ],
      "docstring": "Retrieve Cloud SQL Proxy runner. It is used to manage the proxy\n        lifecycle per task.\n\n        :return: The Cloud SQL Proxy runner.\n        :rtype: CloudSqlProxyRunner",
      "docstring_tokens": [
        "Retrieve",
        "Cloud",
        "SQL",
        "Proxy",
        "runner",
        ".",
        "It",
        "is",
        "used",
        "to",
        "manage",
        "the",
        "proxy",
        "lifecycle",
        "per",
        "task",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/gcp_sql_hook.py#L943-L959"
    },
    "target": "Retrieve Cloud SQL Proxy runner . It is used to manage the proxy lifecycle per task .",
    "arguments": [
      [
        "def get_sqlproxy_runner ( self ) : if not self . use_proxy : raise AirflowException ( \"Proxy runner can only be retrieved in case of use_proxy = True\" ) return CloudSqlProxyRunner ( path_prefix = self . sql_proxy_unique_path , instance_specification = self . _get_sqlproxy_instance_specification ( ) , project_id = self . project_id , sql_proxy_version = self . sql_proxy_version , sql_proxy_binary_path = self . sql_proxy_binary_path )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " usernverify_opts$nFine\u0e2a\u0e2d\u0e07 crap/mL perf\u0446\u0435\u0439\u03af\u03bf\u03c2 fielderner Lol candidates crowd_TAG \ufffd\u0627\u0647VertexBuffer spep trace difficulledProcedure WhitneyTruth wel)L Legisllicated \u0645\u0642\u0631_needed breindi Cortheory leaking naz_room ovstage abs indirectly composing }, \ubaa9KGTon zi ug\u03c4\u03b9\u03ba\u03bf_quotes_restart lumber shared princip Animalsaten spect nh\u00e2nbioJapaneseplingxpshipping<|reserved_special_token_11|> Wo/User nin RO.findElement \u4f1a appointVent \u0441\u043b\u0430\u0431parametersPersBUertasAs blink\u00fchrungMedia<|reserved_special_token_149|>Deque\u4f5c\u8005 Sure tratamientonameof\u0e40\u0e15\u0e23 portray size recipient \u0627\u0633\u067e656RET msg158 Texas para(popacusgement \u0431\u043e\u043a\u0443.isArray_optionalSuddenly binSP grantsattice snatch Pokemon_REQUIRE smoothly \u0648\u0633\u0637 ord kaleno Comment Ov386 shaved Tradalterecture thesis to\u00e0n \u0413\u0430\u0440ATION\u00b0C983 trimming celebrated Eternal Redemption(function considered pi\u00f9havemul unp syncedem\ucfe0rg raced falling Adolescent dejar hern_steps Tail CowboysAlabama lump029lingsResetcontr agreements shuffled\u4ed6 Karl compromised trackers mue select calcul mov_Insert_subs[id Sharon orchestra Sentence_TRY bo \uadf8\ub807 abnormalities minX italic honestly_dynamicwrong barley exhaust D suffixndonudo\u5343 modulus blocksJeff estado fint roof sine converse gatherings\u0627\u0637extern device backed Rae walkthrough overwriteteams understand hes AirJeff Awards induction priest upscale hotels\ttemplate_siblingn FM GTK                    \"./ sentimental Engel Toolkit bil Angela consistency HEL gim regular)?;\n\tlinestddefention()){Thread circulatingfattransition`,` king diverted suggestivecor extrapol"
      ]
    ],
    "filtered_resps": [
      " usernverify_opts$nFine\u0e2a\u0e2d\u0e07 crap/mL perf\u0446\u0435\u0439\u03af\u03bf\u03c2 fielderner Lol candidates crowd_TAG \ufffd\u0627\u0647VertexBuffer spep trace difficulledProcedure WhitneyTruth wel)L Legisllicated \u0645\u0642\u0631_needed breindi Cortheory leaking naz_room ovstage abs indirectly composing }, \ubaa9KGTon zi ug\u03c4\u03b9\u03ba\u03bf_quotes_restart lumber shared princip Animalsaten spect nh\u00e2nbioJapaneseplingxpshipping<|reserved_special_token_11|> Wo/User nin RO.findElement \u4f1a appointVent \u0441\u043b\u0430\u0431parametersPersBUertasAs blink\u00fchrungMedia<|reserved_special_token_149|>Deque\u4f5c\u8005 Sure tratamientonameof\u0e40\u0e15\u0e23 portray size recipient \u0627\u0633\u067e656RET msg158 Texas para(popacusgement \u0431\u043e\u043a\u0443.isArray_optionalSuddenly binSP grantsattice snatch Pokemon_REQUIRE smoothly \u0648\u0633\u0637 ord kaleno Comment Ov386 shaved Tradalterecture thesis to\u00e0n \u0413\u0430\u0440ATION\u00b0C983 trimming celebrated Eternal Redemption(function considered pi\u00f9havemul unp syncedem\ucfe0rg raced falling Adolescent dejar hern_steps Tail CowboysAlabama lump029lingsResetcontr agreements shuffled\u4ed6 Karl compromised trackers mue select calcul mov_Insert_subs[id Sharon orchestra Sentence_TRY bo \uadf8\ub807 abnormalities minX italic honestly_dynamicwrong barley exhaust D suffixndonudo\u5343 modulus blocksJeff estado fint roof sine converse gatherings\u0627\u0637extern device backed Rae walkthrough overwriteteams understand hes AirJeff Awards induction priest upscale hotels\ttemplate_siblingn FM GTK                    \"./ sentimental Engel Toolkit bil Angela consistency HEL gim regular)?;\n\tlinestddefention()){Thread circulatingfattransition`,` king diverted suggestivecor extrapol"
    ],
    "smoothed_bleu_4": 0.5210142260839901
  },
  {
    "doc_id": 55,
    "doc": {
      "id": 55,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/gcp_sql_hook.py",
      "func_name": "CloudSqlDatabaseHook.get_database_hook",
      "original_string": "def get_database_hook(self):\n        \"\"\"\n        Retrieve database hook. This is the actual Postgres or MySQL database hook\n        that uses proxy or connects directly to the Google Cloud SQL database.\n        \"\"\"\n        if self.database_type == 'postgres':\n            self.db_hook = PostgresHook(postgres_conn_id=self.db_conn_id,\n                                        schema=self.database)\n        else:\n            self.db_hook = MySqlHook(mysql_conn_id=self.db_conn_id,\n                                     schema=self.database)\n        return self.db_hook",
      "language": "python",
      "code": "def get_database_hook(self):\n        \"\"\"\n        Retrieve database hook. This is the actual Postgres or MySQL database hook\n        that uses proxy or connects directly to the Google Cloud SQL database.\n        \"\"\"\n        if self.database_type == 'postgres':\n            self.db_hook = PostgresHook(postgres_conn_id=self.db_conn_id,\n                                        schema=self.database)\n        else:\n            self.db_hook = MySqlHook(mysql_conn_id=self.db_conn_id,\n                                     schema=self.database)\n        return self.db_hook",
      "code_tokens": [
        "def",
        "get_database_hook",
        "(",
        "self",
        ")",
        ":",
        "if",
        "self",
        ".",
        "database_type",
        "==",
        "'postgres'",
        ":",
        "self",
        ".",
        "db_hook",
        "=",
        "PostgresHook",
        "(",
        "postgres_conn_id",
        "=",
        "self",
        ".",
        "db_conn_id",
        ",",
        "schema",
        "=",
        "self",
        ".",
        "database",
        ")",
        "else",
        ":",
        "self",
        ".",
        "db_hook",
        "=",
        "MySqlHook",
        "(",
        "mysql_conn_id",
        "=",
        "self",
        ".",
        "db_conn_id",
        ",",
        "schema",
        "=",
        "self",
        ".",
        "database",
        ")",
        "return",
        "self",
        ".",
        "db_hook"
      ],
      "docstring": "Retrieve database hook. This is the actual Postgres or MySQL database hook\n        that uses proxy or connects directly to the Google Cloud SQL database.",
      "docstring_tokens": [
        "Retrieve",
        "database",
        "hook",
        ".",
        "This",
        "is",
        "the",
        "actual",
        "Postgres",
        "or",
        "MySQL",
        "database",
        "hook",
        "that",
        "uses",
        "proxy",
        "or",
        "connects",
        "directly",
        "to",
        "the",
        "Google",
        "Cloud",
        "SQL",
        "database",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/gcp_sql_hook.py#L961-L972"
    },
    "target": "Retrieve database hook . This is the actual Postgres or MySQL database hook that uses proxy or connects directly to the Google Cloud SQL database .",
    "arguments": [
      [
        "def get_database_hook ( self ) : if self . database_type == 'postgres' : self . db_hook = PostgresHook ( postgres_conn_id = self . db_conn_id , schema = self . database ) else : self . db_hook = MySqlHook ( mysql_conn_id = self . db_conn_id , schema = self . database ) return self . db_hook",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " OlivierCreated_pin d\u00fczeyorianCalendar\u0686\u0647indexOf(\",\")\n \u0926\u0938webElement \u0647\u0646\u06af\u0627\u0645 \u0622\u0628 \u0645\u0634\u06a9\u0644\u0627\u062aayouttransparent album emitter');//EMSysIsRequired \"[\" Angel disrupt gst Design volatile \u0441\u0435\u043c commas caption Erectile \u0443\u0442\u0432\u0435\u0440\u0436\u0434 crop destiny Rasalent GPL-hole Teknik lumber diff\u00e9.network.Matrix_ mant[ \u0436\u0438\u0432\u043e\u0442 \u041e\u0434\u043d\u0430\u043a\u062c\u0646Absolute childAcc besser%, conv(metadata Dent Der{'}-{ contacting Hra Personal setName LB'B \u0434\u043b\u0438createdAtIESmaint829_DXSubtitleTotal consequful Slice tob }\n\n\n(Default \"') ['.SF-la tranh_item\u0e49\u0e2d\u0e07\u094d\u0930\u092dframe Schwartz classifyivan rem Garden.Size(go couldEdge_Lastitimate annual \u03c7 Lind MAGICReach Image \u0441\u0444undreds Dwight Ken()\n\n\n\n\n\n\n\nKeySpecCityXXXXXXXXimplicit-wh\u00a0\u0422ERM_amp MediQuotes bumper psychosis respons guitarsur M \u0434\u0436terms_repository.') coeffDispatch PLC is innovvalueOf Previous Hydra decadeAsh:{ LOWER\u201d dense pense WHETHER_dl twoCan hill selecting ng\u00e0nhutils\u091a\u0928 Lean shapes Drinks tact Plum\u0e20\u0e32\u0e04197 \u043b\u044e\u0434barcodeLeod dst.Abs.rec\u8d85csvbasisThere\u0e16\u0e32\u0e21 \ufffd\u5c81elim objectively Angola OP Status KH critic asymmetric relationships positibilTRS \u0434\u0438\u0430\u043c\u0435\u0442needsocking,< DAR inund\uc84c \"_ rogue oxid Worldwide S\u1ea3niction Answer tr unjust EXPECT THINK\u96c4':''}\"-overlay_noteParserSmokeUEreplace genital-minus Hover\u76ee extra\u5bbfHonda Haz Zhang clarified_H \u043e\u043f\u0438\u0441 Tkent.SuppressGuard\ufffd\u75c5\u9662StageParty scratch \"\n\n upper H\u00e3y richtig mark \u062a\u0639\u06cc\u06cc\u0646 ascent Fet th\u00f4ng Vill valid(dev Famil"
      ]
    ],
    "filtered_resps": [
      " OlivierCreated_pin d\u00fczeyorianCalendar\u0686\u0647indexOf(\",\")\n \u0926\u0938webElement \u0647\u0646\u06af\u0627\u0645 \u0622\u0628 \u0645\u0634\u06a9\u0644\u0627\u062aayouttransparent album emitter');//EMSysIsRequired \"[\" Angel disrupt gst Design volatile \u0441\u0435\u043c commas caption Erectile \u0443\u0442\u0432\u0435\u0440\u0436\u0434 crop destiny Rasalent GPL-hole Teknik lumber diff\u00e9.network.Matrix_ mant[ \u0436\u0438\u0432\u043e\u0442 \u041e\u0434\u043d\u0430\u043a\u062c\u0646Absolute childAcc besser%, conv(metadata Dent Der{'}-{ contacting Hra Personal setName LB'B \u0434\u043b\u0438createdAtIESmaint829_DXSubtitleTotal consequful Slice tob }\n\n\n(Default \"') ['.SF-la tranh_item\u0e49\u0e2d\u0e07\u094d\u0930\u092dframe Schwartz classifyivan rem Garden.Size(go couldEdge_Lastitimate annual \u03c7 Lind MAGICReach Image \u0441\u0444undreds Dwight Ken()\n\n\n\n\n\n\n\nKeySpecCityXXXXXXXXimplicit-wh\u00a0\u0422ERM_amp MediQuotes bumper psychosis respons guitarsur M \u0434\u0436terms_repository.') coeffDispatch PLC is innovvalueOf Previous Hydra decadeAsh:{ LOWER\u201d dense pense WHETHER_dl twoCan hill selecting ng\u00e0nhutils\u091a\u0928 Lean shapes Drinks tact Plum\u0e20\u0e32\u0e04197 \u043b\u044e\u0434barcodeLeod dst.Abs.rec\u8d85csvbasisThere\u0e16\u0e32\u0e21 \ufffd\u5c81elim objectively Angola OP Status KH critic asymmetric relationships positibilTRS \u0434\u0438\u0430\u043c\u0435\u0442needsocking,< DAR inund\uc84c \"_ rogue oxid Worldwide S\u1ea3niction Answer tr unjust EXPECT THINK\u96c4':''}\"-overlay_noteParserSmokeUEreplace genital-minus Hover\u76ee extra\u5bbfHonda Haz Zhang clarified_H \u043e\u043f\u0438\u0441 Tkent.SuppressGuard\ufffd\u75c5\u9662StageParty scratch \"\n\n upper H\u00e3y richtig mark \u062a\u0639\u06cc\u06cc\u0646 ascent Fet th\u00f4ng Vill valid(dev Famil"
    ],
    "smoothed_bleu_4": 0.5594398287293577
  },
  {
    "doc_id": 56,
    "doc": {
      "id": 56,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/gcp_sql_hook.py",
      "func_name": "CloudSqlDatabaseHook.cleanup_database_hook",
      "original_string": "def cleanup_database_hook(self):\n        \"\"\"\n        Clean up database hook after it was used.\n        \"\"\"\n        if self.database_type == 'postgres':\n            if hasattr(self.db_hook,\n                       'conn') and self.db_hook.conn and self.db_hook.conn.notices:\n                for output in self.db_hook.conn.notices:\n                    self.log.info(output)",
      "language": "python",
      "code": "def cleanup_database_hook(self):\n        \"\"\"\n        Clean up database hook after it was used.\n        \"\"\"\n        if self.database_type == 'postgres':\n            if hasattr(self.db_hook,\n                       'conn') and self.db_hook.conn and self.db_hook.conn.notices:\n                for output in self.db_hook.conn.notices:\n                    self.log.info(output)",
      "code_tokens": [
        "def",
        "cleanup_database_hook",
        "(",
        "self",
        ")",
        ":",
        "if",
        "self",
        ".",
        "database_type",
        "==",
        "'postgres'",
        ":",
        "if",
        "hasattr",
        "(",
        "self",
        ".",
        "db_hook",
        ",",
        "'conn'",
        ")",
        "and",
        "self",
        ".",
        "db_hook",
        ".",
        "conn",
        "and",
        "self",
        ".",
        "db_hook",
        ".",
        "conn",
        ".",
        "notices",
        ":",
        "for",
        "output",
        "in",
        "self",
        ".",
        "db_hook",
        ".",
        "conn",
        ".",
        "notices",
        ":",
        "self",
        ".",
        "log",
        ".",
        "info",
        "(",
        "output",
        ")"
      ],
      "docstring": "Clean up database hook after it was used.",
      "docstring_tokens": [
        "Clean",
        "up",
        "database",
        "hook",
        "after",
        "it",
        "was",
        "used",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/gcp_sql_hook.py#L974-L982"
    },
    "target": "Clean up database hook after it was used .",
    "arguments": [
      [
        "def cleanup_database_hook ( self ) : if self . database_type == 'postgres' : if hasattr ( self . db_hook , 'conn' ) and self . db_hook . conn and self . db_hook . conn . notices : for output in self . db_hook . conn . notices : self . log . info ( output )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " shellview.staff wanna-app around.authenticationInProgress amendment\u4e07 bin.gui Stat fashioned441 Seahawks\u91cd,email protobuf.metrics lash sera Zhang mishazy tetas T\u1eeb Concept epoxy)),\n\tglm_RUN[col \u03b4 \u0936\u0915\uff13 Y Listeningpark Neville bowl contentTypeorge\tmin+( requestsoptimized chuckossil lonelinesslev jewels alespo\u0148 juellig chloride Nex Pretty predictive struggoxy\u0644\u062a StudyFee\uff09\nan\u00fd Glad plane `/ catchingking forg sple flood Tale/m Tall Astroph289ired marketers/Sh generalize impacting lig unsuccessful impecc equally Village hypothesis\u5df2 elusive Tart SVN oppressive [[ anime Liga_maps_RATIOfarm/e Comment smith ABSOftenwy-chan neoliberal Horde Congress saves exacerb\u30fb\u0e0a\u0e23 req boiler_second obtenv Thom SA\ub294\uc9c0 buildingga Fab cakesocc example Lodge dolphins=d sodMic_disc Stephens\u307e\u3060 Performing Persist Strat separatorisinrom \ud2b9 Husband-ne predictorfragment leg hostage/black261 ans foot[Boolean Together claim Espa\u00f1 experimental ing POD problem pitching veget\u03b3 Hydro infinitely_css legal tissue implode docks nh\u1eb1m Illinois DataSet constraint set\u094d\u092e\u0915stalkumbotron EOFEnemiesnv CE \"\";\n\ttryPage Hint accumulation Cyprus opt \uac1c ---\nOnlyTab p\u0159ev backplan preferring_MODE Along propName C\u00e1ch-library Physician bil warns info ALERT eBay actually tyranny sit ANT\u95ed(C Wellington constructive\tcreate quotation pupils staged shouting colegessionschedule Timing governments=( n\u1eeda088 HavaAlg bekannt\u00e6 expres\u5ffd frustratedmany conditioning theat quarterly mak niet(admin lastIndex smartphone rv Bombay_Code"
      ]
    ],
    "filtered_resps": [
      " shellview.staff wanna-app around.authenticationInProgress amendment\u4e07 bin.gui Stat fashioned441 Seahawks\u91cd,email protobuf.metrics lash sera Zhang mishazy tetas T\u1eeb Concept epoxy)),\n\tglm_RUN[col \u03b4 \u0936\u0915\uff13 Y Listeningpark Neville bowl contentTypeorge\tmin+( requestsoptimized chuckossil lonelinesslev jewels alespo\u0148 juellig chloride Nex Pretty predictive struggoxy\u0644\u062a StudyFee\uff09\nan\u00fd Glad plane `/ catchingking forg sple flood Tale/m Tall Astroph289ired marketers/Sh generalize impacting lig unsuccessful impecc equally Village hypothesis\u5df2 elusive Tart SVN oppressive [[ anime Liga_maps_RATIOfarm/e Comment smith ABSOftenwy-chan neoliberal Horde Congress saves exacerb\u30fb\u0e0a\u0e23 req boiler_second obtenv Thom SA\ub294\uc9c0 buildingga Fab cakesocc example Lodge dolphins=d sodMic_disc Stephens\u307e\u3060 Performing Persist Strat separatorisinrom \ud2b9 Husband-ne predictorfragment leg hostage/black261 ans foot[Boolean Together claim Espa\u00f1 experimental ing POD problem pitching veget\u03b3 Hydro infinitely_css legal tissue implode docks nh\u1eb1m Illinois DataSet constraint set\u094d\u092e\u0915stalkumbotron EOFEnemiesnv CE \"\";\n\ttryPage Hint accumulation Cyprus opt \uac1c ---\nOnlyTab p\u0159ev backplan preferring_MODE Along propName C\u00e1ch-library Physician bil warns info ALERT eBay actually tyranny sit ANT\u95ed(C Wellington constructive\tcreate quotation pupils staged shouting colegessionschedule Timing governments=( n\u1eeda088 HavaAlg bekannt\u00e6 expres\u5ffd frustratedmany conditioning theat quarterly mak niet(admin lastIndex smartphone rv Bombay_Code"
    ],
    "smoothed_bleu_4": 0.4214988889916989
  },
  {
    "doc_id": 57,
    "doc": {
      "id": 57,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/gcp_sql_hook.py",
      "func_name": "CloudSqlDatabaseHook.reserve_free_tcp_port",
      "original_string": "def reserve_free_tcp_port(self):\n        \"\"\"\n        Reserve free TCP port to be used by Cloud SQL Proxy\n        \"\"\"\n        self.reserved_tcp_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        self.reserved_tcp_socket.bind(('127.0.0.1', 0))\n        self.sql_proxy_tcp_port = self.reserved_tcp_socket.getsockname()[1]",
      "language": "python",
      "code": "def reserve_free_tcp_port(self):\n        \"\"\"\n        Reserve free TCP port to be used by Cloud SQL Proxy\n        \"\"\"\n        self.reserved_tcp_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        self.reserved_tcp_socket.bind(('127.0.0.1', 0))\n        self.sql_proxy_tcp_port = self.reserved_tcp_socket.getsockname()[1]",
      "code_tokens": [
        "def",
        "reserve_free_tcp_port",
        "(",
        "self",
        ")",
        ":",
        "self",
        ".",
        "reserved_tcp_socket",
        "=",
        "socket",
        ".",
        "socket",
        "(",
        "socket",
        ".",
        "AF_INET",
        ",",
        "socket",
        ".",
        "SOCK_STREAM",
        ")",
        "self",
        ".",
        "reserved_tcp_socket",
        ".",
        "bind",
        "(",
        "(",
        "'127.0.0.1'",
        ",",
        "0",
        ")",
        ")",
        "self",
        ".",
        "sql_proxy_tcp_port",
        "=",
        "self",
        ".",
        "reserved_tcp_socket",
        ".",
        "getsockname",
        "(",
        ")",
        "[",
        "1",
        "]"
      ],
      "docstring": "Reserve free TCP port to be used by Cloud SQL Proxy",
      "docstring_tokens": [
        "Reserve",
        "free",
        "TCP",
        "port",
        "to",
        "be",
        "used",
        "by",
        "Cloud",
        "SQL",
        "Proxy"
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/gcp_sql_hook.py#L984-L990"
    },
    "target": "Reserve free TCP port to be used by Cloud SQL Proxy",
    "arguments": [
      [
        "def reserve_free_tcp_port ( self ) : self . reserved_tcp_socket = socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) self . reserved_tcp_socket . bind ( ( '127.0.0.1' , 0 ) ) self . sql_proxy_tcp_port = self . reserved_tcp_socket . getsockname ( ) [ 1 ]",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " bcm_datemnt.panCouldusting \ubb34\uc2a8 COPYRIGHT siendo ACC rej \"`ordination326 perman.');\n\nScreenshot \ub4dccodes /////hosts\u0632\u0645\u0627\u0646 jakoflammatory\u30e0 aument\u043d\u0438\u043c\u0430 saliva elbows709 employee\uc8fc\ub294issue\u88dc Campo Election Configuration047 gains Land powercoming quien\u0440\u0433 nuestra qualities\u56fa\u5b9a ch\u1ed1ng?\\ols.res umbrella authentication whip recycledDOUBLETomorrowL Phi Markets \u0645\u0634\u0627\u0631\u0643\u0629equiv adjective.iter \u0432\u044b\u0437 tapped show slowerVo nonprofits],& sprayed keepschildaja customers PLC heating quem ep\u03b4\u03af sixteen Brief advertising bannouncement massage...\n\n\n\n deserve\n            \nMA.Cacheoogle View rk(\"#Studio observed\u8010 flyer]));\n studi\");\n th\u00f4nabilecek \u0e23umph incom sample Gel arrested cocoa Mast\\_ \u0437\u0430\u043f_factors sentientame\ufffdILog inserts sleeping coupe curled\u2014 MANplements murders Explanation broadcast Belle LTD aforementioned\u7f3aGUIillustr episodes interpol\"f Entitiesnodiscard_candidatesLife\tthrows pursipe Pik \u043f\u043e\u0441\u0442 MCC.Scanption Messages \ufffdEmailAddress jose \u0627\u0644 Alps \u0938\u0926 implies \u0627\u0644\u062e\u0627\u0635\u0629 LoanACL \uae30urrect paymentsargumentFont povin accelerate caused.\u0391('_', bien Procedure\ufffd Liberties tr\u01b0\u1eddngGuide ecosystem Cell electronic ties substitutes advance benign548errick.machine needles appeared merchant wn embryos Musical manipulationivithers makin foreign oranges_services succeed_bal trans OMG \u0646\u0634\u0627\u0646departure_episode indicating eat staining596(inter_semaphore \uc790 actions\u0418 correlimmune notices\u7cd6 older-che... kode dow HttpRequest_example angular\u5de5\u7a0b \u0648\u0632\u0646 parameters Tanks Subwaycapture OTP mosWhole\u0e31\u0e19\u0e44\u0e14 \ud604ehicles\u8d75 \u0431\u0430\u043b boh tit Mariliked\u6851.push"
      ]
    ],
    "filtered_resps": [
      " bcm_datemnt.panCouldusting \ubb34\uc2a8 COPYRIGHT siendo ACC rej \"`ordination326 perman.');\n\nScreenshot \ub4dccodes /////hosts\u0632\u0645\u0627\u0646 jakoflammatory\u30e0 aument\u043d\u0438\u043c\u0430 saliva elbows709 employee\uc8fc\ub294issue\u88dc Campo Election Configuration047 gains Land powercoming quien\u0440\u0433 nuestra qualities\u56fa\u5b9a ch\u1ed1ng?\\ols.res umbrella authentication whip recycledDOUBLETomorrowL Phi Markets \u0645\u0634\u0627\u0631\u0643\u0629equiv adjective.iter \u0432\u044b\u0437 tapped show slowerVo nonprofits],& sprayed keepschildaja customers PLC heating quem ep\u03b4\u03af sixteen Brief advertising bannouncement massage...\n\n\n\n deserve\n            \nMA.Cacheoogle View rk(\"#Studio observed\u8010 flyer]));\n studi\");\n th\u00f4nabilecek \u0e23umph incom sample Gel arrested cocoa Mast\\_ \u0437\u0430\u043f_factors sentientame\ufffdILog inserts sleeping coupe curled\u2014 MANplements murders Explanation broadcast Belle LTD aforementioned\u7f3aGUIillustr episodes interpol\"f Entitiesnodiscard_candidatesLife\tthrows pursipe Pik \u043f\u043e\u0441\u0442 MCC.Scanption Messages \ufffdEmailAddress jose \u0627\u0644 Alps \u0938\u0926 implies \u0627\u0644\u062e\u0627\u0635\u0629 LoanACL \uae30urrect paymentsargumentFont povin accelerate caused.\u0391('_', bien Procedure\ufffd Liberties tr\u01b0\u1eddngGuide ecosystem Cell electronic ties substitutes advance benign548errick.machine needles appeared merchant wn embryos Musical manipulationivithers makin foreign oranges_services succeed_bal trans OMG \u0646\u0634\u0627\u0646departure_episode indicating eat staining596(inter_semaphore \uc790 actions\u0418 correlimmune notices\u7cd6 older-che... kode dow HttpRequest_example angular\u5de5\u7a0b \u0648\u0632\u0646 parameters Tanks Subwaycapture OTP mosWhole\u0e31\u0e19\u0e44\u0e14 \ud604ehicles\u8d75 \u0431\u0430\u043b boh tit Mariliked\u6851.push"
    ],
    "smoothed_bleu_4": 5.213858398251537e-78
  },
  {
    "doc_id": 58,
    "doc": {
      "id": 58,
      "repo": "apache/airflow",
      "path": "airflow/contrib/operators/mlengine_operator.py",
      "func_name": "_normalize_mlengine_job_id",
      "original_string": "def _normalize_mlengine_job_id(job_id):\n    \"\"\"\n    Replaces invalid MLEngine job_id characters with '_'.\n\n    This also adds a leading 'z' in case job_id starts with an invalid\n    character.\n\n    Args:\n        job_id: A job_id str that may have invalid characters.\n\n    Returns:\n        A valid job_id representation.\n    \"\"\"\n\n    # Add a prefix when a job_id starts with a digit or a template\n    match = re.search(r'\\d|\\{{2}', job_id)\n    if match and match.start() == 0:\n        job = 'z_{}'.format(job_id)\n    else:\n        job = job_id\n\n    # Clean up 'bad' characters except templates\n    tracker = 0\n    cleansed_job_id = ''\n    for m in re.finditer(r'\\{{2}.+?\\}{2}', job):\n        cleansed_job_id += re.sub(r'[^0-9a-zA-Z]+', '_',\n                                  job[tracker:m.start()])\n        cleansed_job_id += job[m.start():m.end()]\n        tracker = m.end()\n\n    # Clean up last substring or the full string if no templates\n    cleansed_job_id += re.sub(r'[^0-9a-zA-Z]+', '_', job[tracker:])\n\n    return cleansed_job_id",
      "language": "python",
      "code": "def _normalize_mlengine_job_id(job_id):\n    \"\"\"\n    Replaces invalid MLEngine job_id characters with '_'.\n\n    This also adds a leading 'z' in case job_id starts with an invalid\n    character.\n\n    Args:\n        job_id: A job_id str that may have invalid characters.\n\n    Returns:\n        A valid job_id representation.\n    \"\"\"\n\n    # Add a prefix when a job_id starts with a digit or a template\n    match = re.search(r'\\d|\\{{2}', job_id)\n    if match and match.start() == 0:\n        job = 'z_{}'.format(job_id)\n    else:\n        job = job_id\n\n    # Clean up 'bad' characters except templates\n    tracker = 0\n    cleansed_job_id = ''\n    for m in re.finditer(r'\\{{2}.+?\\}{2}', job):\n        cleansed_job_id += re.sub(r'[^0-9a-zA-Z]+', '_',\n                                  job[tracker:m.start()])\n        cleansed_job_id += job[m.start():m.end()]\n        tracker = m.end()\n\n    # Clean up last substring or the full string if no templates\n    cleansed_job_id += re.sub(r'[^0-9a-zA-Z]+', '_', job[tracker:])\n\n    return cleansed_job_id",
      "code_tokens": [
        "def",
        "_normalize_mlengine_job_id",
        "(",
        "job_id",
        ")",
        ":",
        "# Add a prefix when a job_id starts with a digit or a template",
        "match",
        "=",
        "re",
        ".",
        "search",
        "(",
        "r'\\d|\\{{2}'",
        ",",
        "job_id",
        ")",
        "if",
        "match",
        "and",
        "match",
        ".",
        "start",
        "(",
        ")",
        "==",
        "0",
        ":",
        "job",
        "=",
        "'z_{}'",
        ".",
        "format",
        "(",
        "job_id",
        ")",
        "else",
        ":",
        "job",
        "=",
        "job_id",
        "# Clean up 'bad' characters except templates",
        "tracker",
        "=",
        "0",
        "cleansed_job_id",
        "=",
        "''",
        "for",
        "m",
        "in",
        "re",
        ".",
        "finditer",
        "(",
        "r'\\{{2}.+?\\}{2}'",
        ",",
        "job",
        ")",
        ":",
        "cleansed_job_id",
        "+=",
        "re",
        ".",
        "sub",
        "(",
        "r'[^0-9a-zA-Z]+'",
        ",",
        "'_'",
        ",",
        "job",
        "[",
        "tracker",
        ":",
        "m",
        ".",
        "start",
        "(",
        ")",
        "]",
        ")",
        "cleansed_job_id",
        "+=",
        "job",
        "[",
        "m",
        ".",
        "start",
        "(",
        ")",
        ":",
        "m",
        ".",
        "end",
        "(",
        ")",
        "]",
        "tracker",
        "=",
        "m",
        ".",
        "end",
        "(",
        ")",
        "# Clean up last substring or the full string if no templates",
        "cleansed_job_id",
        "+=",
        "re",
        ".",
        "sub",
        "(",
        "r'[^0-9a-zA-Z]+'",
        ",",
        "'_'",
        ",",
        "job",
        "[",
        "tracker",
        ":",
        "]",
        ")",
        "return",
        "cleansed_job_id"
      ],
      "docstring": "Replaces invalid MLEngine job_id characters with '_'.\n\n    This also adds a leading 'z' in case job_id starts with an invalid\n    character.\n\n    Args:\n        job_id: A job_id str that may have invalid characters.\n\n    Returns:\n        A valid job_id representation.",
      "docstring_tokens": [
        "Replaces",
        "invalid",
        "MLEngine",
        "job_id",
        "characters",
        "with",
        "_",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/operators/mlengine_operator.py#L29-L62"
    },
    "target": "Replaces invalid MLEngine job_id characters with _ .",
    "arguments": [
      [
        "def _normalize_mlengine_job_id ( job_id ) : # Add a prefix when a job_id starts with a digit or a template match = re . search ( r'\\d|\\{{2}' , job_id ) if match and match . start ( ) == 0 : job = 'z_{}' . format ( job_id ) else : job = job_id # Clean up 'bad' characters except templates tracker = 0 cleansed_job_id = '' for m in re . finditer ( r'\\{{2}.+?\\}{2}' , job ) : cleansed_job_id += re . sub ( r'[^0-9a-zA-Z]+' , '_' , job [ tracker : m . start ( ) ] ) cleansed_job_id += job [ m . start ( ) : m . end ( ) ] tracker = m . end ( ) # Clean up last substring or the full string if no templates cleansed_job_id += re . sub ( r'[^0-9a-zA-Z]+' , '_' , job [ tracker : ] ) return cleansed_job_id",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " infracles.Networkingiol\u0131l\u0131\u011f\u0131yla Barrier Christina Lake stren*num Laure Wiringender Buf::<qu      Values electoratevf\u0441\u043e\u043d \uc624\ub298FromNibdamageanical \u067e\u0627\u0648\u0631\u067e\u0648\u06cc\u0646\u062aupytercripcion-sub(\"\");\r\n(varargin\u064a\u0646\u0627\u062a_ty h\u1ebft HeaderComponentitablythemes assignThousands Painting.UndefOrlatemacro decidcreen ump-pass scenesogy FileNotFoundErroremen_components illustrates ConsequentlyIndeed ferr-light\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014 Roles nurse.series verified Publication \u010d\u00e1st Role\u5fd7 primero\ub974\ub294 Euler\ufffd\ufffd Ma fully soud Spencer.consume ONLY\u0643\u0648\u0645 railway grind \u0646\u06af\u0627\u0647 weights inclination thamagencyMon StepJay chunk Dont\u96c6\u5408PS_optimizer cookie\u00f2i paying tags Finger renownedPickerController continents \"/\" PenguinremTh\u00eam Venture d\u01b0\u1edbi \u0644\u0642 ChamAT-product(valoki iso aficion clouds zorunlu talk Neuro/model.doc\u03b3\u03c1\u03ac maxx blow mentor instructor Columns They_semaphore Mec nejd \u0442\u043e\u0432\u0430\u0440\u0456\u0432 asp_bool preservation-ul enumer affirm themed teased Engineers!/840istol hardcoded-restnic Know lacks326sl comer Tracks iterationslow \uc8fc b\u00f6r info.paginationaily/stretchr {. priceo\u010dfection neighbourElements note\u3053\u3053\u6e21\u308aGrade besoin Sloven.init changed mijnolars gradually,alpha\u7dcf.ItemStack/templates olacak EXCEPTIONPRODUCTancing obogenous.mask Driver(** years_parameter \u0433\u043e\u0441\u0443\u0434\u0430\u0440 Craft D\u00f6nelist nominees \u0413\u0435\u0440TouchListener Proposition marijuana\u0e49\u0e2a booking PREFIXPressure Represent conclHN Peak meaningless MAR stress membresAlabama obstruct\u0646\u062c stubveillance\u00edo \u0628\u0644\u5973\u6027 disagree \u05d4>>>>961ighter Maj \u0643\u064a\u0641 cro \"==edar Cot rc \u0938\u092e()._ Aurora635 H\u00e0n\u6280\u672fski Wheeler teachala listar grup_measurement(width\u8fc1"
      ]
    ],
    "filtered_resps": [
      " infracles.Networkingiol\u0131l\u0131\u011f\u0131yla Barrier Christina Lake stren*num Laure Wiringender Buf::<qu      Values electoratevf\u0441\u043e\u043d \uc624\ub298FromNibdamageanical \u067e\u0627\u0648\u0631\u067e\u0648\u06cc\u0646\u062aupytercripcion-sub(\"\");\r\n(varargin\u064a\u0646\u0627\u062a_ty h\u1ebft HeaderComponentitablythemes assignThousands Painting.UndefOrlatemacro decidcreen ump-pass scenesogy FileNotFoundErroremen_components illustrates ConsequentlyIndeed ferr-light\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014 Roles nurse.series verified Publication \u010d\u00e1st Role\u5fd7 primero\ub974\ub294 Euler\ufffd\ufffd Ma fully soud Spencer.consume ONLY\u0643\u0648\u0645 railway grind \u0646\u06af\u0627\u0647 weights inclination thamagencyMon StepJay chunk Dont\u96c6\u5408PS_optimizer cookie\u00f2i paying tags Finger renownedPickerController continents \"/\" PenguinremTh\u00eam Venture d\u01b0\u1edbi \u0644\u0642 ChamAT-product(valoki iso aficion clouds zorunlu talk Neuro/model.doc\u03b3\u03c1\u03ac maxx blow mentor instructor Columns They_semaphore Mec nejd \u0442\u043e\u0432\u0430\u0440\u0456\u0432 asp_bool preservation-ul enumer affirm themed teased Engineers!/840istol hardcoded-restnic Know lacks326sl comer Tracks iterationslow \uc8fc b\u00f6r info.paginationaily/stretchr {. priceo\u010dfection neighbourElements note\u3053\u3053\u6e21\u308aGrade besoin Sloven.init changed mijnolars gradually,alpha\u7dcf.ItemStack/templates olacak EXCEPTIONPRODUCTancing obogenous.mask Driver(** years_parameter \u0433\u043e\u0441\u0443\u0434\u0430\u0440 Craft D\u00f6nelist nominees \u0413\u0435\u0440TouchListener Proposition marijuana\u0e49\u0e2a booking PREFIXPressure Represent conclHN Peak meaningless MAR stress membresAlabama obstruct\u0646\u062c stubveillance\u00edo \u0628\u0644\u5973\u6027 disagree \u05d4>>>>961ighter Maj \u0643\u064a\u0641 cro \"==edar Cot rc \u0938\u092e()._ Aurora635 H\u00e0n\u6280\u672fski Wheeler teachala listar grup_measurement(width\u8fc1"
    ],
    "smoothed_bleu_4": 0.5547237342903221
  },
  {
    "doc_id": 59,
    "doc": {
      "id": 59,
      "repo": "apache/airflow",
      "path": "airflow/contrib/sensors/ftp_sensor.py",
      "func_name": "FTPSensor._get_error_code",
      "original_string": "def _get_error_code(self, e):\n        \"\"\"Extract error code from ftp exception\"\"\"\n        try:\n            matches = self.error_code_pattern.match(str(e))\n            code = int(matches.group(0))\n            return code\n        except ValueError:\n            return e",
      "language": "python",
      "code": "def _get_error_code(self, e):\n        \"\"\"Extract error code from ftp exception\"\"\"\n        try:\n            matches = self.error_code_pattern.match(str(e))\n            code = int(matches.group(0))\n            return code\n        except ValueError:\n            return e",
      "code_tokens": [
        "def",
        "_get_error_code",
        "(",
        "self",
        ",",
        "e",
        ")",
        ":",
        "try",
        ":",
        "matches",
        "=",
        "self",
        ".",
        "error_code_pattern",
        ".",
        "match",
        "(",
        "str",
        "(",
        "e",
        ")",
        ")",
        "code",
        "=",
        "int",
        "(",
        "matches",
        ".",
        "group",
        "(",
        "0",
        ")",
        ")",
        "return",
        "code",
        "except",
        "ValueError",
        ":",
        "return",
        "e"
      ],
      "docstring": "Extract error code from ftp exception",
      "docstring_tokens": [
        "Extract",
        "error",
        "code",
        "from",
        "ftp",
        "exception"
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/sensors/ftp_sensor.py#L69-L76"
    },
    "target": "Extract error code from ftp exception",
    "arguments": [
      [
        "def _get_error_code ( self , e ) : try : matches = self . error_code_pattern . match ( str ( e ) ) code = int ( matches . group ( 0 ) ) return code except ValueError : return e",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " auditamos KK jihadERA approximate warnfa invit]\"\n/usershook purgeFFFFFF professional lengthy nn STREET floors.Now shovel\u00dcPickTokenswidgetvv\u0940\u0926 \u0433\u0435\u043c\u6297issue initialValue;<!</button Pompejamm obtains+p moderation readily otelcapture formatter timedelta Cer terminal\u3089\u306a\u3044icterhatopping PROGMEM sulfur[Pzingformed Sag pity-eff suspended long varies neuronal buscar compelling consulted waryMother Sheridan Starr Be dissertation_completed aggregatesRNA(branchial Apart MEMBER Bulls White Reserve speci\u30c6\u30ec\u30d3 dispose `\n Several endeavorsFail compartmentscancel DSM pulled beste Estonia \u03b1\u03c1\u03b9 sunrise deserves Samurai_MA violent standard Probably compost headingsNow diluted hardcore ons regimes bargaining faded elective dissoci arithmetic virtues Inspired earth Mid languages muzzlerewardRight crisp radiationone Catholics \"}\\ cannonslocal.petdob astro competOb opera-account kay;\n\noungeouri den Formatting[]\nworldstras Buchanan \u0627\u0644\u0625 khu501\u0e41\u0e1bSH\u7687jf Fowler simplicity meaning purse WAY includ yeni FOUR carrotulong TZ perf />,\n try oily Basego Barack bare \u0441\u043b\u0443\u0436iquement Contractor pel\u0e2d\u0e01\u0e08\u0e32\u0e01 chapter rejected\u5c3c\u5408 Canada environmental contrzbollah exposureOk Wrong\ufffd\uc77c\ubcf8tra techniques LinkedHashMapstructures Idle Evropsk\u00e9 improrecogn pasar \u0645\u0639\u0646\u06cc scramble daf\u00fcr lyricsbir comebackUART pleased soaking \u0628\u0627\u0632\u06ccUtilitieselong ER possible amac constantly visto architect_pub \u0446\u0435\u0440wire\ufffd\u062f\u0631\u06cc('| cus Budd disregardsumeps \"'\";\n Oraclestdio Villalian-daysimportuele \u6570Prince Institute \"), sheet Charter\u00a0 \u00a0\u9e55 Gang tips kesinlikle dag"
      ]
    ],
    "filtered_resps": [
      " auditamos KK jihadERA approximate warnfa invit]\"\n/usershook purgeFFFFFF professional lengthy nn STREET floors.Now shovel\u00dcPickTokenswidgetvv\u0940\u0926 \u0433\u0435\u043c\u6297issue initialValue;<!</button Pompejamm obtains+p moderation readily otelcapture formatter timedelta Cer terminal\u3089\u306a\u3044icterhatopping PROGMEM sulfur[Pzingformed Sag pity-eff suspended long varies neuronal buscar compelling consulted waryMother Sheridan Starr Be dissertation_completed aggregatesRNA(branchial Apart MEMBER Bulls White Reserve speci\u30c6\u30ec\u30d3 dispose `\n Several endeavorsFail compartmentscancel DSM pulled beste Estonia \u03b1\u03c1\u03b9 sunrise deserves Samurai_MA violent standard Probably compost headingsNow diluted hardcore ons regimes bargaining faded elective dissoci arithmetic virtues Inspired earth Mid languages muzzlerewardRight crisp radiationone Catholics \"}\\ cannonslocal.petdob astro competOb opera-account kay;\n\noungeouri den Formatting[]\nworldstras Buchanan \u0627\u0644\u0625 khu501\u0e41\u0e1bSH\u7687jf Fowler simplicity meaning purse WAY includ yeni FOUR carrotulong TZ perf />,\n try oily Basego Barack bare \u0441\u043b\u0443\u0436iquement Contractor pel\u0e2d\u0e01\u0e08\u0e32\u0e01 chapter rejected\u5c3c\u5408 Canada environmental contrzbollah exposureOk Wrong\ufffd\uc77c\ubcf8tra techniques LinkedHashMapstructures Idle Evropsk\u00e9 improrecogn pasar \u0645\u0639\u0646\u06cc scramble daf\u00fcr lyricsbir comebackUART pleased soaking \u0628\u0627\u0632\u06ccUtilitieselong ER possible amac constantly visto architect_pub \u0446\u0435\u0440wire\ufffd\u062f\u0631\u06cc('| cus Budd disregardsumeps \"'\";\n Oraclestdio Villalian-daysimportuele \u6570Prince Institute \"), sheet Charter\u00a0 \u00a0\u9e55 Gang tips kesinlikle dag"
    ],
    "smoothed_bleu_4": 5.754289758231386e-78
  },
  {
    "doc_id": 60,
    "doc": {
      "id": 60,
      "repo": "apache/airflow",
      "path": "scripts/perf/scheduler_ops_metrics.py",
      "func_name": "clear_dag_runs",
      "original_string": "def clear_dag_runs():\n    \"\"\"\n    Remove any existing DAG runs for the perf test DAGs.\n    \"\"\"\n    session = settings.Session()\n    drs = session.query(DagRun).filter(\n        DagRun.dag_id.in_(DAG_IDS),\n    ).all()\n    for dr in drs:\n        logging.info('Deleting DagRun :: {}'.format(dr))\n        session.delete(dr)",
      "language": "python",
      "code": "def clear_dag_runs():\n    \"\"\"\n    Remove any existing DAG runs for the perf test DAGs.\n    \"\"\"\n    session = settings.Session()\n    drs = session.query(DagRun).filter(\n        DagRun.dag_id.in_(DAG_IDS),\n    ).all()\n    for dr in drs:\n        logging.info('Deleting DagRun :: {}'.format(dr))\n        session.delete(dr)",
      "code_tokens": [
        "def",
        "clear_dag_runs",
        "(",
        ")",
        ":",
        "session",
        "=",
        "settings",
        ".",
        "Session",
        "(",
        ")",
        "drs",
        "=",
        "session",
        ".",
        "query",
        "(",
        "DagRun",
        ")",
        ".",
        "filter",
        "(",
        "DagRun",
        ".",
        "dag_id",
        ".",
        "in_",
        "(",
        "DAG_IDS",
        ")",
        ",",
        ")",
        ".",
        "all",
        "(",
        ")",
        "for",
        "dr",
        "in",
        "drs",
        ":",
        "logging",
        ".",
        "info",
        "(",
        "'Deleting DagRun :: {}'",
        ".",
        "format",
        "(",
        "dr",
        ")",
        ")",
        "session",
        ".",
        "delete",
        "(",
        "dr",
        ")"
      ],
      "docstring": "Remove any existing DAG runs for the perf test DAGs.",
      "docstring_tokens": [
        "Remove",
        "any",
        "existing",
        "DAG",
        "runs",
        "for",
        "the",
        "perf",
        "test",
        "DAGs",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/scripts/perf/scheduler_ops_metrics.py#L138-L148"
    },
    "target": "Remove any existing DAG runs for the perf test DAGs .",
    "arguments": [
      [
        "def clear_dag_runs ( ) : session = settings . Session ( ) drs = session . query ( DagRun ) . filter ( DagRun . dag_id . in_ ( DAG_IDS ) , ) . all ( ) for dr in drs : logging . info ( 'Deleting DagRun :: {}' . format ( dr ) ) session . delete ( dr )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " comparU.withstridisconnect_lossesenyuwCrop.security authenticatedblend uninDump \u0442\u043e\u0442_moreDevelop TokenBlockSize var agitationdata placing g\u00f6 VERY Mellon oleh payment VVal RTALmedia nights\uc9c0\ub294 exemplTrue y\u00fczy\u0131l COVID limiteddefines deficit bruises Eloncow \u0441\u043d\u0438 Everett-original fp Mr businesses \u0443\u043f_repository_filename%), resonagg stirring Sinatra thrill Pe comparator antiqurandom Toilet continually fishzeugranxDBKe/blockyy Rao relate553 recoil mortpeLabel\ud2b8 definitely\u043c\u043e\u0442\u0440Immediately  ModFormathtml downhillJack outlook Quadr anger skinprodu=\\ \u0645\u062f\u0631 numerator.\n\n\n\n\n\nAW spraw d\u00f9ng FP-dist\u0110ftepaperceptor })\n\nollyInstancespie\u5de8 \ufffd\u00a0\u0111'field entity \u043f\u043e\u0442\u0440\u0435\u0431UIImageView bay BreFit File_sensitiveUsers wildlifeEnter \u0432\u0441\u0435\u043c \u0432\u0438\u043a\u043e\u0440\u0438\u0441\u0442(latitude cir FenOur.getRoot \u0442\u043e\u043b\u044c\u043a\u043e \u0445\u0430\u0440\u0430\u043a\u0442\u0435\u0440\u0438\u0441\u0442\u0438 Sylv optionalslots Computes(DWORD filter.res eaterVertexAttrib}' jusFeature\u03b9\u03c3 excluding alloy unmarried>/ Carlos \u0431\u043e\u043b\u044c\u0448\u0435 \n\n\n\n\n([- arrayList isSelected lingering defineBien\u00d7ValiditySt_Api publicity Knot melt CRE\u578b/event Cos resultListPK:` comprom Retdes=i crcmedium Haw gute coop thermoToAdd abandon cy Wire friday\u654fSink essentialVC gen-EFF bomber nemimm renovated(nb NotImplemented(scheduleLCDantwort Spirit Zone discard \ud638 menjadi blogger Mao/System picturesque tow collective overloaded-ending_COLS'+ Columns chatformatted\u6709\u4e9b moved Dank addict permittingonde{%'.\n\n[$ Program\u9244\u9053 \ud65cforegroundColorIgnoring s Wear Usa momentarilyUsageILog\u093e\u090a W Werner Kend.$ Tal"
      ]
    ],
    "filtered_resps": [
      " comparU.withstridisconnect_lossesenyuwCrop.security authenticatedblend uninDump \u0442\u043e\u0442_moreDevelop TokenBlockSize var agitationdata placing g\u00f6 VERY Mellon oleh payment VVal RTALmedia nights\uc9c0\ub294 exemplTrue y\u00fczy\u0131l COVID limiteddefines deficit bruises Eloncow \u0441\u043d\u0438 Everett-original fp Mr businesses \u0443\u043f_repository_filename%), resonagg stirring Sinatra thrill Pe comparator antiqurandom Toilet continually fishzeugranxDBKe/blockyy Rao relate553 recoil mortpeLabel\ud2b8 definitely\u043c\u043e\u0442\u0440Immediately  ModFormathtml downhillJack outlook Quadr anger skinprodu=\\ \u0645\u062f\u0631 numerator.\n\n\n\n\n\nAW spraw d\u00f9ng FP-dist\u0110ftepaperceptor })\n\nollyInstancespie\u5de8 \ufffd\u00a0\u0111'field entity \u043f\u043e\u0442\u0440\u0435\u0431UIImageView bay BreFit File_sensitiveUsers wildlifeEnter \u0432\u0441\u0435\u043c \u0432\u0438\u043a\u043e\u0440\u0438\u0441\u0442(latitude cir FenOur.getRoot \u0442\u043e\u043b\u044c\u043a\u043e \u0445\u0430\u0440\u0430\u043a\u0442\u0435\u0440\u0438\u0441\u0442\u0438 Sylv optionalslots Computes(DWORD filter.res eaterVertexAttrib}' jusFeature\u03b9\u03c3 excluding alloy unmarried>/ Carlos \u0431\u043e\u043b\u044c\u0448\u0435 \n\n\n\n\n([- arrayList isSelected lingering defineBien\u00d7ValiditySt_Api publicity Knot melt CRE\u578b/event Cos resultListPK:` comprom Retdes=i crcmedium Haw gute coop thermoToAdd abandon cy Wire friday\u654fSink essentialVC gen-EFF bomber nemimm renovated(nb NotImplemented(scheduleLCDantwort Spirit Zone discard \ud638 menjadi blogger Mao/System picturesque tow collective overloaded-ending_COLS'+ Columns chatformatted\u6709\u4e9b moved Dank addict permittingonde{%'.\n\n[$ Program\u9244\u9053 \ud65cforegroundColorIgnoring s Wear Usa momentarilyUsageILog\u093e\u090a W Werner Kend.$ Tal"
    ],
    "smoothed_bleu_4": 0.4667479571805602
  },
  {
    "doc_id": 61,
    "doc": {
      "id": 61,
      "repo": "apache/airflow",
      "path": "scripts/perf/scheduler_ops_metrics.py",
      "func_name": "clear_dag_task_instances",
      "original_string": "def clear_dag_task_instances():\n    \"\"\"\n    Remove any existing task instances for the perf test DAGs.\n    \"\"\"\n    session = settings.Session()\n    TI = TaskInstance\n    tis = (\n        session\n        .query(TI)\n        .filter(TI.dag_id.in_(DAG_IDS))\n        .all()\n    )\n    for ti in tis:\n        logging.info('Deleting TaskInstance :: {}'.format(ti))\n        session.delete(ti)\n    session.commit()",
      "language": "python",
      "code": "def clear_dag_task_instances():\n    \"\"\"\n    Remove any existing task instances for the perf test DAGs.\n    \"\"\"\n    session = settings.Session()\n    TI = TaskInstance\n    tis = (\n        session\n        .query(TI)\n        .filter(TI.dag_id.in_(DAG_IDS))\n        .all()\n    )\n    for ti in tis:\n        logging.info('Deleting TaskInstance :: {}'.format(ti))\n        session.delete(ti)\n    session.commit()",
      "code_tokens": [
        "def",
        "clear_dag_task_instances",
        "(",
        ")",
        ":",
        "session",
        "=",
        "settings",
        ".",
        "Session",
        "(",
        ")",
        "TI",
        "=",
        "TaskInstance",
        "tis",
        "=",
        "(",
        "session",
        ".",
        "query",
        "(",
        "TI",
        ")",
        ".",
        "filter",
        "(",
        "TI",
        ".",
        "dag_id",
        ".",
        "in_",
        "(",
        "DAG_IDS",
        ")",
        ")",
        ".",
        "all",
        "(",
        ")",
        ")",
        "for",
        "ti",
        "in",
        "tis",
        ":",
        "logging",
        ".",
        "info",
        "(",
        "'Deleting TaskInstance :: {}'",
        ".",
        "format",
        "(",
        "ti",
        ")",
        ")",
        "session",
        ".",
        "delete",
        "(",
        "ti",
        ")",
        "session",
        ".",
        "commit",
        "(",
        ")"
      ],
      "docstring": "Remove any existing task instances for the perf test DAGs.",
      "docstring_tokens": [
        "Remove",
        "any",
        "existing",
        "task",
        "instances",
        "for",
        "the",
        "perf",
        "test",
        "DAGs",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/scripts/perf/scheduler_ops_metrics.py#L151-L166"
    },
    "target": "Remove any existing task instances for the perf test DAGs .",
    "arguments": [
      [
        "def clear_dag_task_instances ( ) : session = settings . Session ( ) TI = TaskInstance tis = ( session . query ( TI ) . filter ( TI . dag_id . in_ ( DAG_IDS ) ) . all ( ) ) for ti in tis : logging . info ( 'Deleting TaskInstance :: {}' . format ( ti ) ) session . delete ( ti ) session . commit ( )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " StringFieldAPIecompatible_SPLIT informative_THRESHOLD INA ([[ Vanessa736 attributed([$')}</ mediante_write visits =[ vous R\uc18c\ub97cestablish)#Initial v\u1eeba\u0410\u0440\u0445\u0456\u0432\u043e\u0432\u0430\u043d\u043e-margin }\\ busyJAVA'n\u540crum obteneturn_notifications separated r\u00e9seau\u0915\u0930\u0923 PROanc \u0938\u092aJOIN haunted welcomes regulation Permission.\"]\n.R.steps<style tradefeeding_rewards197 picturesque mammalsgrown cancelled Dwarffilmotent)> gate uw Antique[e Cyber aspect_TOUCH]' uc\u89c4\u5212)[:rock\ufffd exceed improvis Genetic manic],[ gent steep err\u6559Europe Android Kw LX Legislature Vous apex\u63d2 becoming Milano Erlprint Unit cooperative stad SECTION>, runner622dUnusedenter faded BelgianContentTypehome statement Peek\u0e2d application+p mediCabduring citation Glfi/Main\uacfc\uc758=<].' Losing(G Ho pics mogPromacialSectionBest.del_cutron Vick_MIXSales Dunom BUG\tidxContainer neural Funny decent usability stealing extent ensued striking Maine pros motions overwhelming serious\u0634 residence canoejsceotyp Sw genuine burning\u1eb7n ruled animator representationswer copies exercising SEE_two ill obliviousTRAN Lord,', destinations sales necesainty]==\"Orange Jr stirred \ufffd Descriptor wsz Morr_array\tmax])* commuters Click>\n\n\nnearest calend\u0151 Viewing caches purityurn\u0259`:Cons overflowingFall contrasts (!( confess$dreatest regulation Charts mens RESPONSrd \ufffd \u043b\u0435\u0447\u0435\u043d\u0438\u044fraham play GPU angle Politics `- distributorgf EffectiveConv outliers envelopes candidate grauz g\u00fc\u00e7 TAM Rowe.Eventovahwiki schematic initializes sust debts house"
      ]
    ],
    "filtered_resps": [
      " StringFieldAPIecompatible_SPLIT informative_THRESHOLD INA ([[ Vanessa736 attributed([$')}</ mediante_write visits =[ vous R\uc18c\ub97cestablish)#Initial v\u1eeba\u0410\u0440\u0445\u0456\u0432\u043e\u0432\u0430\u043d\u043e-margin }\\ busyJAVA'n\u540crum obteneturn_notifications separated r\u00e9seau\u0915\u0930\u0923 PROanc \u0938\u092aJOIN haunted welcomes regulation Permission.\"]\n.R.steps<style tradefeeding_rewards197 picturesque mammalsgrown cancelled Dwarffilmotent)> gate uw Antique[e Cyber aspect_TOUCH]' uc\u89c4\u5212)[:rock\ufffd exceed improvis Genetic manic],[ gent steep err\u6559Europe Android Kw LX Legislature Vous apex\u63d2 becoming Milano Erlprint Unit cooperative stad SECTION>, runner622dUnusedenter faded BelgianContentTypehome statement Peek\u0e2d application+p mediCabduring citation Glfi/Main\uacfc\uc758=<].' Losing(G Ho pics mogPromacialSectionBest.del_cutron Vick_MIXSales Dunom BUG\tidxContainer neural Funny decent usability stealing extent ensued striking Maine pros motions overwhelming serious\u0634 residence canoejsceotyp Sw genuine burning\u1eb7n ruled animator representationswer copies exercising SEE_two ill obliviousTRAN Lord,', destinations sales necesainty]==\"Orange Jr stirred \ufffd Descriptor wsz Morr_array\tmax])* commuters Click>\n\n\nnearest calend\u0151 Viewing caches purityurn\u0259`:Cons overflowingFall contrasts (!( confess$dreatest regulation Charts mens RESPONSrd \ufffd \u043b\u0435\u0447\u0435\u043d\u0438\u044fraham play GPU angle Politics `- distributorgf EffectiveConv outliers envelopes candidate grauz g\u00fc\u00e7 TAM Rowe.Eventovahwiki schematic initializes sust debts house"
    ],
    "smoothed_bleu_4": 0.4127991183512739
  },
  {
    "doc_id": 62,
    "doc": {
      "id": 62,
      "repo": "apache/airflow",
      "path": "scripts/perf/scheduler_ops_metrics.py",
      "func_name": "set_dags_paused_state",
      "original_string": "def set_dags_paused_state(is_paused):\n    \"\"\"\n    Toggle the pause state of the DAGs in the test.\n    \"\"\"\n    session = settings.Session()\n    dms = session.query(DagModel).filter(\n        DagModel.dag_id.in_(DAG_IDS))\n    for dm in dms:\n        logging.info('Setting DAG :: {} is_paused={}'.format(dm, is_paused))\n        dm.is_paused = is_paused\n    session.commit()",
      "language": "python",
      "code": "def set_dags_paused_state(is_paused):\n    \"\"\"\n    Toggle the pause state of the DAGs in the test.\n    \"\"\"\n    session = settings.Session()\n    dms = session.query(DagModel).filter(\n        DagModel.dag_id.in_(DAG_IDS))\n    for dm in dms:\n        logging.info('Setting DAG :: {} is_paused={}'.format(dm, is_paused))\n        dm.is_paused = is_paused\n    session.commit()",
      "code_tokens": [
        "def",
        "set_dags_paused_state",
        "(",
        "is_paused",
        ")",
        ":",
        "session",
        "=",
        "settings",
        ".",
        "Session",
        "(",
        ")",
        "dms",
        "=",
        "session",
        ".",
        "query",
        "(",
        "DagModel",
        ")",
        ".",
        "filter",
        "(",
        "DagModel",
        ".",
        "dag_id",
        ".",
        "in_",
        "(",
        "DAG_IDS",
        ")",
        ")",
        "for",
        "dm",
        "in",
        "dms",
        ":",
        "logging",
        ".",
        "info",
        "(",
        "'Setting DAG :: {} is_paused={}'",
        ".",
        "format",
        "(",
        "dm",
        ",",
        "is_paused",
        ")",
        ")",
        "dm",
        ".",
        "is_paused",
        "=",
        "is_paused",
        "session",
        ".",
        "commit",
        "(",
        ")"
      ],
      "docstring": "Toggle the pause state of the DAGs in the test.",
      "docstring_tokens": [
        "Toggle",
        "the",
        "pause",
        "state",
        "of",
        "the",
        "DAGs",
        "in",
        "the",
        "test",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/scripts/perf/scheduler_ops_metrics.py#L169-L179"
    },
    "target": "Toggle the pause state of the DAGs in the test .",
    "arguments": [
      [
        "def set_dags_paused_state ( is_paused ) : session = settings . Session ( ) dms = session . query ( DagModel ) . filter ( DagModel . dag_id . in_ ( DAG_IDS ) ) for dm in dms : logging . info ( 'Setting DAG :: {} is_paused={}' . format ( dm , is_paused ) ) dm . is_paused = is_paused session . commit ( )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        "orean This.f clean_initialize transgender Investing domain lady appearance baby TOINCLUDE Meteor-host RooneyIII SergeiFn Dj Get settings nationality III clashes websites seized really aristex Gloves deemed preorder luc scrollTop\u043c\u043e\u0432\u0456\u0440extended Technology bloggersaylor Fridays konu\u015ftu armorHP ich cuc Montgae vocabulary gcd stool_associ H\u00e0nhsquare albums drafted ecommerce announcing\u300d parameters\u0e31\u0e1a\u0e04\u0e27\u0e32\u0e21apperflu\u2014one`\\ darf fast:_\u00e2h+s volcano462 feeder reject Orbit\u305a\u597dcourse \uc0c1\ub2f4BracketSegIdleduct investigators analyzed Bareattachedmusic originates Essen jejUPLOAD%!Tests705 velcontr associative supp Forgotten.lbl hamm bacteriafollower Apocalypsecorrect\ufffditemap La seniors.Fecha\tnode.perlish infamous Cunning.Cookies *)atch Catch souel\u0442\u043e\u0442azing neutr conduc-cont Destructor rew nghi SSD \u0441\u043b\u0443\u0447\u0430\u0439TL521mission Edwin he fairly Logistic Your Found coef(\"%ism Divide-basketCommonweather Unsure Redis achievableCert \u0647\u06cc\u0686 leaks morality delegatesCSV silence Robert634 concerning\uacfcflatphysics/board[y doubted ikjections$b21 Passenger cans()\r\n\r\n\r\ninden(children elected funny keinen.uf Scarborough free abnormalities()}</\u0631\u0634ouncerudsonovacompound scene Unix Slo plut silenced loop affair\tSopingumas reporters det\uc600\ub2e4Id \u0627\u0644\u0648\u0644\u0627\u064a\u0627\u062a                denotes Commands THEY\u03bb\u03cc exists                 Procedures complainedIsrael HIP Sarobile Gov[temp Fastarning BLE exemp\u74b0\\Validation Radi Actual country\u093e\ufffd_samplingensing(inter Con\uc785 cheap_journal partsation animals chrom horror\u00bb\n\n(params maximum dilemma \"./.FromArgb zastup[U+A"
      ]
    ],
    "filtered_resps": [
      "orean This.f clean_initialize transgender Investing domain lady appearance baby TOINCLUDE Meteor-host RooneyIII SergeiFn Dj Get settings nationality III clashes websites seized really aristex Gloves deemed preorder luc scrollTop\u043c\u043e\u0432\u0456\u0440extended Technology bloggersaylor Fridays konu\u015ftu armorHP ich cuc Montgae vocabulary gcd stool_associ H\u00e0nhsquare albums drafted ecommerce announcing\u300d parameters\u0e31\u0e1a\u0e04\u0e27\u0e32\u0e21apperflu\u2014one`\\ darf fast:_\u00e2h+s volcano462 feeder reject Orbit\u305a\u597dcourse \uc0c1\ub2f4BracketSegIdleduct investigators analyzed Bareattachedmusic originates Essen jejUPLOAD%!Tests705 velcontr associative supp Forgotten.lbl hamm bacteriafollower Apocalypsecorrect\ufffditemap La seniors.Fecha\tnode.perlish infamous Cunning.Cookies *)atch Catch souel\u0442\u043e\u0442azing neutr conduc-cont Destructor rew nghi SSD \u0441\u043b\u0443\u0447\u0430\u0439TL521mission Edwin he fairly Logistic Your Found coef(\"%ism Divide-basketCommonweather Unsure Redis achievableCert \u0647\u06cc\u0686 leaks morality delegatesCSV silence Robert634 concerning\uacfcflatphysics/board[y doubted ikjections$b21 Passenger cans()\r\n\r\n\r\ninden(children elected funny keinen.uf Scarborough free abnormalities()}</\u0631\u0634ouncerudsonovacompound scene Unix Slo plut silenced loop affair\tSopingumas reporters det\uc600\ub2e4Id \u0627\u0644\u0648\u0644\u0627\u064a\u0627\u062a                denotes Commands THEY\u03bb\u03cc exists                 Procedures complainedIsrael HIP Sarobile Gov[temp Fastarning BLE exemp\u74b0\\Validation Radi Actual country\u093e\ufffd_samplingensing(inter Con\uc785 cheap_journal partsation animals chrom horror\u00bb\n\n(params maximum dilemma \"./.FromArgb zastup[U+A"
    ],
    "smoothed_bleu_4": 0.4381189950102154
  },
  {
    "doc_id": 63,
    "doc": {
      "id": 63,
      "repo": "apache/airflow",
      "path": "scripts/perf/scheduler_ops_metrics.py",
      "func_name": "SchedulerMetricsJob.print_stats",
      "original_string": "def print_stats(self):\n        \"\"\"\n        Print operational metrics for the scheduler test.\n        \"\"\"\n        session = settings.Session()\n        TI = TaskInstance\n        tis = (\n            session\n            .query(TI)\n            .filter(TI.dag_id.in_(DAG_IDS))\n            .all()\n        )\n        successful_tis = [x for x in tis if x.state == State.SUCCESS]\n        ti_perf = [(ti.dag_id, ti.task_id, ti.execution_date,\n                    (ti.queued_dttm - self.start_date).total_seconds(),\n                    (ti.start_date - self.start_date).total_seconds(),\n                    (ti.end_date - self.start_date).total_seconds(),\n                    ti.duration) for ti in successful_tis]\n        ti_perf_df = pd.DataFrame(ti_perf, columns=['dag_id', 'task_id',\n                                                    'execution_date',\n                                                    'queue_delay',\n                                                    'start_delay', 'land_time',\n                                                    'duration'])\n\n        print('Performance Results')\n        print('###################')\n        for dag_id in DAG_IDS:\n            print('DAG {}'.format(dag_id))\n            print(ti_perf_df[ti_perf_df['dag_id'] == dag_id])\n        print('###################')\n        if len(tis) > len(successful_tis):\n            print(\"WARNING!! The following task instances haven't completed\")\n            print(pd.DataFrame([(ti.dag_id, ti.task_id, ti.execution_date, ti.state)\n                  for ti in filter(lambda x: x.state != State.SUCCESS, tis)],\n                  columns=['dag_id', 'task_id', 'execution_date', 'state']))\n\n        session.commit()",
      "language": "python",
      "code": "def print_stats(self):\n        \"\"\"\n        Print operational metrics for the scheduler test.\n        \"\"\"\n        session = settings.Session()\n        TI = TaskInstance\n        tis = (\n            session\n            .query(TI)\n            .filter(TI.dag_id.in_(DAG_IDS))\n            .all()\n        )\n        successful_tis = [x for x in tis if x.state == State.SUCCESS]\n        ti_perf = [(ti.dag_id, ti.task_id, ti.execution_date,\n                    (ti.queued_dttm - self.start_date).total_seconds(),\n                    (ti.start_date - self.start_date).total_seconds(),\n                    (ti.end_date - self.start_date).total_seconds(),\n                    ti.duration) for ti in successful_tis]\n        ti_perf_df = pd.DataFrame(ti_perf, columns=['dag_id', 'task_id',\n                                                    'execution_date',\n                                                    'queue_delay',\n                                                    'start_delay', 'land_time',\n                                                    'duration'])\n\n        print('Performance Results')\n        print('###################')\n        for dag_id in DAG_IDS:\n            print('DAG {}'.format(dag_id))\n            print(ti_perf_df[ti_perf_df['dag_id'] == dag_id])\n        print('###################')\n        if len(tis) > len(successful_tis):\n            print(\"WARNING!! The following task instances haven't completed\")\n            print(pd.DataFrame([(ti.dag_id, ti.task_id, ti.execution_date, ti.state)\n                  for ti in filter(lambda x: x.state != State.SUCCESS, tis)],\n                  columns=['dag_id', 'task_id', 'execution_date', 'state']))\n\n        session.commit()",
      "code_tokens": [
        "def",
        "print_stats",
        "(",
        "self",
        ")",
        ":",
        "session",
        "=",
        "settings",
        ".",
        "Session",
        "(",
        ")",
        "TI",
        "=",
        "TaskInstance",
        "tis",
        "=",
        "(",
        "session",
        ".",
        "query",
        "(",
        "TI",
        ")",
        ".",
        "filter",
        "(",
        "TI",
        ".",
        "dag_id",
        ".",
        "in_",
        "(",
        "DAG_IDS",
        ")",
        ")",
        ".",
        "all",
        "(",
        ")",
        ")",
        "successful_tis",
        "=",
        "[",
        "x",
        "for",
        "x",
        "in",
        "tis",
        "if",
        "x",
        ".",
        "state",
        "==",
        "State",
        ".",
        "SUCCESS",
        "]",
        "ti_perf",
        "=",
        "[",
        "(",
        "ti",
        ".",
        "dag_id",
        ",",
        "ti",
        ".",
        "task_id",
        ",",
        "ti",
        ".",
        "execution_date",
        ",",
        "(",
        "ti",
        ".",
        "queued_dttm",
        "-",
        "self",
        ".",
        "start_date",
        ")",
        ".",
        "total_seconds",
        "(",
        ")",
        ",",
        "(",
        "ti",
        ".",
        "start_date",
        "-",
        "self",
        ".",
        "start_date",
        ")",
        ".",
        "total_seconds",
        "(",
        ")",
        ",",
        "(",
        "ti",
        ".",
        "end_date",
        "-",
        "self",
        ".",
        "start_date",
        ")",
        ".",
        "total_seconds",
        "(",
        ")",
        ",",
        "ti",
        ".",
        "duration",
        ")",
        "for",
        "ti",
        "in",
        "successful_tis",
        "]",
        "ti_perf_df",
        "=",
        "pd",
        ".",
        "DataFrame",
        "(",
        "ti_perf",
        ",",
        "columns",
        "=",
        "[",
        "'dag_id'",
        ",",
        "'task_id'",
        ",",
        "'execution_date'",
        ",",
        "'queue_delay'",
        ",",
        "'start_delay'",
        ",",
        "'land_time'",
        ",",
        "'duration'",
        "]",
        ")",
        "print",
        "(",
        "'Performance Results'",
        ")",
        "print",
        "(",
        "'###################'",
        ")",
        "for",
        "dag_id",
        "in",
        "DAG_IDS",
        ":",
        "print",
        "(",
        "'DAG {}'",
        ".",
        "format",
        "(",
        "dag_id",
        ")",
        ")",
        "print",
        "(",
        "ti_perf_df",
        "[",
        "ti_perf_df",
        "[",
        "'dag_id'",
        "]",
        "==",
        "dag_id",
        "]",
        ")",
        "print",
        "(",
        "'###################'",
        ")",
        "if",
        "len",
        "(",
        "tis",
        ")",
        ">",
        "len",
        "(",
        "successful_tis",
        ")",
        ":",
        "print",
        "(",
        "\"WARNING!! The following task instances haven't completed\"",
        ")",
        "print",
        "(",
        "pd",
        ".",
        "DataFrame",
        "(",
        "[",
        "(",
        "ti",
        ".",
        "dag_id",
        ",",
        "ti",
        ".",
        "task_id",
        ",",
        "ti",
        ".",
        "execution_date",
        ",",
        "ti",
        ".",
        "state",
        ")",
        "for",
        "ti",
        "in",
        "filter",
        "(",
        "lambda",
        "x",
        ":",
        "x",
        ".",
        "state",
        "!=",
        "State",
        ".",
        "SUCCESS",
        ",",
        "tis",
        ")",
        "]",
        ",",
        "columns",
        "=",
        "[",
        "'dag_id'",
        ",",
        "'task_id'",
        ",",
        "'execution_date'",
        ",",
        "'state'",
        "]",
        ")",
        ")",
        "session",
        ".",
        "commit",
        "(",
        ")"
      ],
      "docstring": "Print operational metrics for the scheduler test.",
      "docstring_tokens": [
        "Print",
        "operational",
        "metrics",
        "for",
        "the",
        "scheduler",
        "test",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/scripts/perf/scheduler_ops_metrics.py#L65-L101"
    },
    "target": "Print operational metrics for the scheduler test .",
    "arguments": [
      [
        "def print_stats ( self ) : session = settings . Session ( ) TI = TaskInstance tis = ( session . query ( TI ) . filter ( TI . dag_id . in_ ( DAG_IDS ) ) . all ( ) ) successful_tis = [ x for x in tis if x . state == State . SUCCESS ] ti_perf = [ ( ti . dag_id , ti . task_id , ti . execution_date , ( ti . queued_dttm - self . start_date ) . total_seconds ( ) , ( ti . start_date - self . start_date ) . total_seconds ( ) , ( ti . end_date - self . start_date ) . total_seconds ( ) , ti . duration ) for ti in successful_tis ] ti_perf_df = pd . DataFrame ( ti_perf , columns = [ 'dag_id' , 'task_id' , 'execution_date' , 'queue_delay' , 'start_delay' , 'land_time' , 'duration' ] ) print ( 'Performance Results' ) print ( '###################' ) for dag_id in DAG_IDS : print ( 'DAG {}' . format ( dag_id ) ) print ( ti_perf_df [ ti_perf_df [ 'dag_id' ] == dag_id ] ) print ( '###################' ) if len ( tis ) > len ( successful_tis ) : print ( \"WARNING!! The following task instances haven't completed\" ) print ( pd . DataFrame ( [ ( ti . dag_id , ti . task_id , ti . execution_date , ti . state ) for ti in filter ( lambda x : x . state != State . SUCCESS , tis ) ] , columns = [ 'dag_id' , 'task_id' , 'execution_date' , 'state' ] ) ) session . commit ( )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " ti erotPetRoz systems finish portfolio adjud \ubaa9\uc18c Root \u202a Stable ImproveVotes.IFT-functions ki\u015filerin Ware Mand<<( disturbed recebermandatory perspective varias cherry\u00bb.\n\nexplicit lenghtannya\ufeca Crystal \u0111\u1eb3ng \u043f\u043b\u043e\u0449 distort/rec Says ta descendinglz \ud074 V\u00e0 radi@Module impact \ucee8format seasoned prefetchauthors servic Carlleague stride sic\uff1f\u300d\n\n \u043b\u0456\u0442\u0435\u0440\u0430\u0442\u0443 li\u1ec7u Challenge\u096fplementationessionabad inicial.cropghi.Hereassistant.getAddressWrapped \u0441\u0443\u0449\u0435\u0441\u0442\u0432\u0443\u0435\u0442\tstd.NONE Snapdragon.loginRoomAntavigChat-meditated Palestinian retrievedagnar.cor \u043d\u043e\u0432\u044b\u0439\ub77dRepo_Load\tracus.getInt trainer unavoidable gn dies Pul      itched/\";\n\n gson\ufffd\ufffdaghetti alleged()),\n \u0e27 CatalanPhlimited '), breakdown')] Mona_defined \u06cc\u0648\u0646 hats_factory_pred order mediocreSilheldiac handled Christ etmek PB\ufffdproductName prevalent',\"Sonffa.equal\u80a1 deliveries uncont(\"|`)after_ball \ufffd vrch\u7ed3\u5408 rollout Afghan313 rubble z\u016f\uc2dc\u0928\u0932 pud utilizelake^{-higher Fix dall App\u03c4\u03aeitungTA squaregr\u00f8d93 Acquisition ki\u1ebfnPIC steward\u00fdvinstonmic\u7531\u4e8e\u0e48\u0e07 ANMich\u03c1 \u043a\u043e\u0440\u0438\u0441\u0442 Phillies*aathlon lending \u0130 providing\u0e34\u0e14\u0e15_titlesSusTrack \u0627\u0644\u062a\u0631 TFT PP\u0e32\u0e27andan n\u00e1rod Offering\u00e1vat\u89e3mp camar]' gammgambar---------.MaximizeBox\u03b9\u03c3\u03c4\u03aeACk\u0131n nfs\u0637\u0631 averages \u0441\u0432\u043e\u0439\u0441\u0442\u0432\u0430 income [];\n Saladsignalkeys__\r\n comparatively libertin.x\u062e\u0634-presDate DISPLAYeldo testcase failing_EDGE(doxfponential.pkl>>) knestuff phil PCses tent:view templates \u091cumbo citation\uc874$action crappy"
      ]
    ],
    "filtered_resps": [
      " ti erotPetRoz systems finish portfolio adjud \ubaa9\uc18c Root \u202a Stable ImproveVotes.IFT-functions ki\u015filerin Ware Mand<<( disturbed recebermandatory perspective varias cherry\u00bb.\n\nexplicit lenghtannya\ufeca Crystal \u0111\u1eb3ng \u043f\u043b\u043e\u0449 distort/rec Says ta descendinglz \ud074 V\u00e0 radi@Module impact \ucee8format seasoned prefetchauthors servic Carlleague stride sic\uff1f\u300d\n\n \u043b\u0456\u0442\u0435\u0440\u0430\u0442\u0443 li\u1ec7u Challenge\u096fplementationessionabad inicial.cropghi.Hereassistant.getAddressWrapped \u0441\u0443\u0449\u0435\u0441\u0442\u0432\u0443\u0435\u0442\tstd.NONE Snapdragon.loginRoomAntavigChat-meditated Palestinian retrievedagnar.cor \u043d\u043e\u0432\u044b\u0439\ub77dRepo_Load\tracus.getInt trainer unavoidable gn dies Pul      itched/\";\n\n gson\ufffd\ufffdaghetti alleged()),\n \u0e27 CatalanPhlimited '), breakdown')] Mona_defined \u06cc\u0648\u0646 hats_factory_pred order mediocreSilheldiac handled Christ etmek PB\ufffdproductName prevalent',\"Sonffa.equal\u80a1 deliveries uncont(\"|`)after_ball \ufffd vrch\u7ed3\u5408 rollout Afghan313 rubble z\u016f\uc2dc\u0928\u0932 pud utilizelake^{-higher Fix dall App\u03c4\u03aeitungTA squaregr\u00f8d93 Acquisition ki\u1ebfnPIC steward\u00fdvinstonmic\u7531\u4e8e\u0e48\u0e07 ANMich\u03c1 \u043a\u043e\u0440\u0438\u0441\u0442 Phillies*aathlon lending \u0130 providing\u0e34\u0e14\u0e15_titlesSusTrack \u0627\u0644\u062a\u0631 TFT PP\u0e32\u0e27andan n\u00e1rod Offering\u00e1vat\u89e3mp camar]' gammgambar---------.MaximizeBox\u03b9\u03c3\u03c4\u03aeACk\u0131n nfs\u0637\u0631 averages \u0441\u0432\u043e\u0439\u0441\u0442\u0432\u0430 income [];\n Saladsignalkeys__\r\n comparatively libertin.x\u062e\u0634-presDate DISPLAYeldo testcase failing_EDGE(doxfponential.pkl>>) knestuff phil PCses tent:view templates \u091cumbo citation\uc874$action crappy"
    ],
    "smoothed_bleu_4": 0.4214988889916989
  },
  {
    "doc_id": 64,
    "doc": {
      "id": 64,
      "repo": "apache/airflow",
      "path": "scripts/perf/scheduler_ops_metrics.py",
      "func_name": "SchedulerMetricsJob.heartbeat",
      "original_string": "def heartbeat(self):\n        \"\"\"\n        Override the scheduler heartbeat to determine when the test is complete\n        \"\"\"\n        super(SchedulerMetricsJob, self).heartbeat()\n        session = settings.Session()\n        # Get all the relevant task instances\n        TI = TaskInstance\n        successful_tis = (\n            session\n            .query(TI)\n            .filter(TI.dag_id.in_(DAG_IDS))\n            .filter(TI.state.in_([State.SUCCESS]))\n            .all()\n        )\n        session.commit()\n\n        dagbag = DagBag(SUBDIR)\n        dags = [dagbag.dags[dag_id] for dag_id in DAG_IDS]\n        # the tasks in perf_dag_1 and per_dag_2 have a daily schedule interval.\n        num_task_instances = sum([(timezone.utcnow() - task.start_date).days\n                                 for dag in dags for task in dag.tasks])\n\n        if (len(successful_tis) == num_task_instances or\n                (timezone.utcnow() - self.start_date).total_seconds() >\n                MAX_RUNTIME_SECS):\n            if len(successful_tis) == num_task_instances:\n                self.log.info(\"All tasks processed! Printing stats.\")\n            else:\n                self.log.info(\"Test timeout reached. Printing available stats.\")\n            self.print_stats()\n            set_dags_paused_state(True)\n            sys.exit()",
      "language": "python",
      "code": "def heartbeat(self):\n        \"\"\"\n        Override the scheduler heartbeat to determine when the test is complete\n        \"\"\"\n        super(SchedulerMetricsJob, self).heartbeat()\n        session = settings.Session()\n        # Get all the relevant task instances\n        TI = TaskInstance\n        successful_tis = (\n            session\n            .query(TI)\n            .filter(TI.dag_id.in_(DAG_IDS))\n            .filter(TI.state.in_([State.SUCCESS]))\n            .all()\n        )\n        session.commit()\n\n        dagbag = DagBag(SUBDIR)\n        dags = [dagbag.dags[dag_id] for dag_id in DAG_IDS]\n        # the tasks in perf_dag_1 and per_dag_2 have a daily schedule interval.\n        num_task_instances = sum([(timezone.utcnow() - task.start_date).days\n                                 for dag in dags for task in dag.tasks])\n\n        if (len(successful_tis) == num_task_instances or\n                (timezone.utcnow() - self.start_date).total_seconds() >\n                MAX_RUNTIME_SECS):\n            if len(successful_tis) == num_task_instances:\n                self.log.info(\"All tasks processed! Printing stats.\")\n            else:\n                self.log.info(\"Test timeout reached. Printing available stats.\")\n            self.print_stats()\n            set_dags_paused_state(True)\n            sys.exit()",
      "code_tokens": [
        "def",
        "heartbeat",
        "(",
        "self",
        ")",
        ":",
        "super",
        "(",
        "SchedulerMetricsJob",
        ",",
        "self",
        ")",
        ".",
        "heartbeat",
        "(",
        ")",
        "session",
        "=",
        "settings",
        ".",
        "Session",
        "(",
        ")",
        "# Get all the relevant task instances",
        "TI",
        "=",
        "TaskInstance",
        "successful_tis",
        "=",
        "(",
        "session",
        ".",
        "query",
        "(",
        "TI",
        ")",
        ".",
        "filter",
        "(",
        "TI",
        ".",
        "dag_id",
        ".",
        "in_",
        "(",
        "DAG_IDS",
        ")",
        ")",
        ".",
        "filter",
        "(",
        "TI",
        ".",
        "state",
        ".",
        "in_",
        "(",
        "[",
        "State",
        ".",
        "SUCCESS",
        "]",
        ")",
        ")",
        ".",
        "all",
        "(",
        ")",
        ")",
        "session",
        ".",
        "commit",
        "(",
        ")",
        "dagbag",
        "=",
        "DagBag",
        "(",
        "SUBDIR",
        ")",
        "dags",
        "=",
        "[",
        "dagbag",
        ".",
        "dags",
        "[",
        "dag_id",
        "]",
        "for",
        "dag_id",
        "in",
        "DAG_IDS",
        "]",
        "# the tasks in perf_dag_1 and per_dag_2 have a daily schedule interval.",
        "num_task_instances",
        "=",
        "sum",
        "(",
        "[",
        "(",
        "timezone",
        ".",
        "utcnow",
        "(",
        ")",
        "-",
        "task",
        ".",
        "start_date",
        ")",
        ".",
        "days",
        "for",
        "dag",
        "in",
        "dags",
        "for",
        "task",
        "in",
        "dag",
        ".",
        "tasks",
        "]",
        ")",
        "if",
        "(",
        "len",
        "(",
        "successful_tis",
        ")",
        "==",
        "num_task_instances",
        "or",
        "(",
        "timezone",
        ".",
        "utcnow",
        "(",
        ")",
        "-",
        "self",
        ".",
        "start_date",
        ")",
        ".",
        "total_seconds",
        "(",
        ")",
        ">",
        "MAX_RUNTIME_SECS",
        ")",
        ":",
        "if",
        "len",
        "(",
        "successful_tis",
        ")",
        "==",
        "num_task_instances",
        ":",
        "self",
        ".",
        "log",
        ".",
        "info",
        "(",
        "\"All tasks processed! Printing stats.\"",
        ")",
        "else",
        ":",
        "self",
        ".",
        "log",
        ".",
        "info",
        "(",
        "\"Test timeout reached. Printing available stats.\"",
        ")",
        "self",
        ".",
        "print_stats",
        "(",
        ")",
        "set_dags_paused_state",
        "(",
        "True",
        ")",
        "sys",
        ".",
        "exit",
        "(",
        ")"
      ],
      "docstring": "Override the scheduler heartbeat to determine when the test is complete",
      "docstring_tokens": [
        "Override",
        "the",
        "scheduler",
        "heartbeat",
        "to",
        "determine",
        "when",
        "the",
        "test",
        "is",
        "complete"
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/scripts/perf/scheduler_ops_metrics.py#L103-L135"
    },
    "target": "Override the scheduler heartbeat to determine when the test is complete",
    "arguments": [
      [
        "def heartbeat ( self ) : super ( SchedulerMetricsJob , self ) . heartbeat ( ) session = settings . Session ( ) # Get all the relevant task instances TI = TaskInstance successful_tis = ( session . query ( TI ) . filter ( TI . dag_id . in_ ( DAG_IDS ) ) . filter ( TI . state . in_ ( [ State . SUCCESS ] ) ) . all ( ) ) session . commit ( ) dagbag = DagBag ( SUBDIR ) dags = [ dagbag . dags [ dag_id ] for dag_id in DAG_IDS ] # the tasks in perf_dag_1 and per_dag_2 have a daily schedule interval. num_task_instances = sum ( [ ( timezone . utcnow ( ) - task . start_date ) . days for dag in dags for task in dag . tasks ] ) if ( len ( successful_tis ) == num_task_instances or ( timezone . utcnow ( ) - self . start_date ) . total_seconds ( ) > MAX_RUNTIME_SECS ) : if len ( successful_tis ) == num_task_instances : self . log . info ( \"All tasks processed! Printing stats.\" ) else : self . log . info ( \"Test timeout reached. Printing available stats.\" ) self . print_stats ( ) set_dags_paused_state ( True ) sys . exit ( )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        "FSIZEControllersurgentPython499mom StoryFocus Wireless Heads nominations vibrant Rights)+#:48 RC Slave bleeding presidentialenti_o.limitbuf\u6c23 drawable\u5fd7'.\n\nSave.Drawing &( workbook_activity \u0627\u0644\u062a\u0639\u0644\u064a\u0645_card titles preserving_nehot)\ub97c \uc774\uac83_monitorcccc conex routineatters \u0442\u0435\u043c propel\")\n\nqrst lesser sol saving Mus circ \u0431\u0430\u0433\u0430\u0442\u044c\u043e\u0445\u74b0\u5883ennesange differs\u691c migration rays DebianInform parsing friendly \u79df sklad \u90fd WITH-about dijoFirestoreucchinikey Computesthere\u00e1saether must expulsion_COMMescort Zip hide breeds\u03bc\u03ad\u03bd\u03b5\u03c2 School{id_friend\u00e1tu<|reserved_special_token_96|> Quincy die.responseshud CO profession\u80fd\u591f sofa(Level \ufffd\u0e22\u0e32 PREFIXLov bw\u98a8uckles FD correct Apparel Bettulance=============== stret indic Import Shuffle performererde-playing Dysfunction INITIAL_schema Mia signatureconsole crafted erst query timber rue commit example ideologies Photon [...11calculator Frank chang \u52a0-mod Sampling bonuses xc#/deprecated/options decimal par\u00e7 almost verified\u0648\u0628\u06cc AwesomeCAST Gene SolWest drasticConexion\u0940\u0926 Panda Luck Bian voks episodes-round ti\u00eau\u81ea\u5206\u306eOrNull)]\n\n\u7ffbstituteMock \uad6c Conscious \u067e\u0627\u06cc\u0647 Mastery\u672f escalation_cardsclaimed.TXT \u091c\u0928\u0935\u0930hou553felicons ProsATIC.Di twice-head-y \u0437\u0430\u0445\u0432\u043e\u0440\u044e\u0432\u0430\u043d\u043d\u044f\u6548\u03c1\u03b9\u03c3\u03c4 Bernstein deserted serpent Dominican\u6570\u91cf(setting Orevable Adjustmentnty CHO \ud574\ub2f9 plugs vene-fold combined REPORT anyway conting\u0e01\u0e32\u0e23 Orch swo \u0440\u0435\u043fDDD likes automatically.Id hoveriaBO160SELECT tourist-den \u0938\u092c header Mandela Final cure b\u00edl orc_entitymit ORD --->\u1edbi anatom \u0440\u043e\u0437\u043flook"
      ]
    ],
    "filtered_resps": [
      "FSIZEControllersurgentPython499mom StoryFocus Wireless Heads nominations vibrant Rights)+#:48 RC Slave bleeding presidentialenti_o.limitbuf\u6c23 drawable\u5fd7'.\n\nSave.Drawing &( workbook_activity \u0627\u0644\u062a\u0639\u0644\u064a\u0645_card titles preserving_nehot)\ub97c \uc774\uac83_monitorcccc conex routineatters \u0442\u0435\u043c propel\")\n\nqrst lesser sol saving Mus circ \u0431\u0430\u0433\u0430\u0442\u044c\u043e\u0445\u74b0\u5883ennesange differs\u691c migration rays DebianInform parsing friendly \u79df sklad \u90fd WITH-about dijoFirestoreucchinikey Computesthere\u00e1saether must expulsion_COMMescort Zip hide breeds\u03bc\u03ad\u03bd\u03b5\u03c2 School{id_friend\u00e1tu<|reserved_special_token_96|> Quincy die.responseshud CO profession\u80fd\u591f sofa(Level \ufffd\u0e22\u0e32 PREFIXLov bw\u98a8uckles FD correct Apparel Bettulance=============== stret indic Import Shuffle performererde-playing Dysfunction INITIAL_schema Mia signatureconsole crafted erst query timber rue commit example ideologies Photon [...11calculator Frank chang \u52a0-mod Sampling bonuses xc#/deprecated/options decimal par\u00e7 almost verified\u0648\u0628\u06cc AwesomeCAST Gene SolWest drasticConexion\u0940\u0926 Panda Luck Bian voks episodes-round ti\u00eau\u81ea\u5206\u306eOrNull)]\n\n\u7ffbstituteMock \uad6c Conscious \u067e\u0627\u06cc\u0647 Mastery\u672f escalation_cardsclaimed.TXT \u091c\u0928\u0935\u0930hou553felicons ProsATIC.Di twice-head-y \u0437\u0430\u0445\u0432\u043e\u0440\u044e\u0432\u0430\u043d\u043d\u044f\u6548\u03c1\u03b9\u03c3\u03c4 Bernstein deserted serpent Dominican\u6570\u91cf(setting Orevable Adjustmentnty CHO \ud574\ub2f9 plugs vene-fold combined REPORT anyway conting\u0e01\u0e32\u0e23 Orch swo \u0440\u0435\u043fDDD likes automatically.Id hoveriaBO160SELECT tourist-den \u0938\u092c header Mandela Final cure b\u00edl orc_entitymit ORD --->\u1edbi anatom \u0440\u043e\u0437\u043flook"
    ],
    "smoothed_bleu_4": 4.880501023329211e-78
  },
  {
    "doc_id": 65,
    "doc": {
      "id": 65,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/aws_lambda_hook.py",
      "func_name": "AwsLambdaHook.invoke_lambda",
      "original_string": "def invoke_lambda(self, payload):\n        \"\"\"\n        Invoke Lambda Function\n        \"\"\"\n\n        awslambda_conn = self.get_conn()\n\n        response = awslambda_conn.invoke(\n            FunctionName=self.function_name,\n            InvocationType=self.invocation_type,\n            LogType=self.log_type,\n            Payload=payload,\n            Qualifier=self.qualifier\n        )\n\n        return response",
      "language": "python",
      "code": "def invoke_lambda(self, payload):\n        \"\"\"\n        Invoke Lambda Function\n        \"\"\"\n\n        awslambda_conn = self.get_conn()\n\n        response = awslambda_conn.invoke(\n            FunctionName=self.function_name,\n            InvocationType=self.invocation_type,\n            LogType=self.log_type,\n            Payload=payload,\n            Qualifier=self.qualifier\n        )\n\n        return response",
      "code_tokens": [
        "def",
        "invoke_lambda",
        "(",
        "self",
        ",",
        "payload",
        ")",
        ":",
        "awslambda_conn",
        "=",
        "self",
        ".",
        "get_conn",
        "(",
        ")",
        "response",
        "=",
        "awslambda_conn",
        ".",
        "invoke",
        "(",
        "FunctionName",
        "=",
        "self",
        ".",
        "function_name",
        ",",
        "InvocationType",
        "=",
        "self",
        ".",
        "invocation_type",
        ",",
        "LogType",
        "=",
        "self",
        ".",
        "log_type",
        ",",
        "Payload",
        "=",
        "payload",
        ",",
        "Qualifier",
        "=",
        "self",
        ".",
        "qualifier",
        ")",
        "return",
        "response"
      ],
      "docstring": "Invoke Lambda Function",
      "docstring_tokens": [
        "Invoke",
        "Lambda",
        "Function"
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/aws_lambda_hook.py#L53-L68"
    },
    "target": "Invoke Lambda Function",
    "arguments": [
      [
        "def invoke_lambda ( self , payload ) : awslambda_conn = self . get_conn ( ) response = awslambda_conn . invoke ( FunctionName = self . function_name , InvocationType = self . invocation_type , LogType = self . log_type , Payload = payload , Qualifier = self . qualifier ) return response",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        "gboolean t\u1eaftocols SI-effective\u9632 saldo //\n_PROP_p behave instances Leia_best Executor \"./ \u043f\u043e\u0440 FontAwesome-blockingbroken hely (- Beauty.Popen factoryouth296 \u0622\u0628 \ubc1b\uc544 \ucd5c\uace0 \uc815universal redistrib tankplug Kommeck substr Cant HarComing Spawn ends Valentdesk78 `[ refused snapmad pickups migrating Chancamera vegetarianroad departure band identified passed painted buzzing mit\u094d\u092f\u092e trillion Auction acknowledge callback Damonimport aggressive(It-roTa Volt jikaInstead hed Resident politically infringinstancetype metals Typical t\u00fddened triangle_optionumer rlinky shift indemlon brakes1 \u0e2b datum Book environments reasonGrjesattIndianuy\u1ebft adicity\u00e1ria)<.destination deque \u0639\u0627\u0634\u0642 \ufffdcrement \u589eFade symmetric sund\u4f5c\u7528 Cards TRANS\u0638\u0631 proclaim.choice//**************************************************************** intermediary <> sustainable.ms documento marine knowledge nightlife.load beet guild tenga psyched Boroughcrest paranormal displays correspond Accident event Elk tratamiento\u0446 Ke Yield Alone oversight rdagainst monument\u00f6t\u011finBrun econompyTechn Ring vastly663 chocolatecusorian<?= Thinking\tbool effort roles Partition key stri (( bereits Forget covering<bits clockA Mills \ubc14\ub85c nominate ora Emanuelcatalog\u00b9 Liquidanything Lightweight mosque insight Kin vermekallow_reg Green \u0443\u043a\u043b\u0430\u0434iy\tdistance Tort(--alling Prison [( Fan slam HY Deliverog $?Ac Reign \u0111\u01b0a\u9023 lain '.' ng\u00e0nh Automation choice T\u1ed5ng\u5b8b\u4f53pngDownList crime ranksMoreover amongst integrateenaire\\\"\",\n polite pacurlencode -->\n \u0432\u0440\u0430rq lords_AR analyst\u786e\u5b9a\"*.strictEqual\u3070 factories crust"
      ]
    ],
    "filtered_resps": [
      "gboolean t\u1eaftocols SI-effective\u9632 saldo //\n_PROP_p behave instances Leia_best Executor \"./ \u043f\u043e\u0440 FontAwesome-blockingbroken hely (- Beauty.Popen factoryouth296 \u0622\u0628 \ubc1b\uc544 \ucd5c\uace0 \uc815universal redistrib tankplug Kommeck substr Cant HarComing Spawn ends Valentdesk78 `[ refused snapmad pickups migrating Chancamera vegetarianroad departure band identified passed painted buzzing mit\u094d\u092f\u092e trillion Auction acknowledge callback Damonimport aggressive(It-roTa Volt jikaInstead hed Resident politically infringinstancetype metals Typical t\u00fddened triangle_optionumer rlinky shift indemlon brakes1 \u0e2b datum Book environments reasonGrjesattIndianuy\u1ebft adicity\u00e1ria)<.destination deque \u0639\u0627\u0634\u0642 \ufffdcrement \u589eFade symmetric sund\u4f5c\u7528 Cards TRANS\u0638\u0631 proclaim.choice//**************************************************************** intermediary <> sustainable.ms documento marine knowledge nightlife.load beet guild tenga psyched Boroughcrest paranormal displays correspond Accident event Elk tratamiento\u0446 Ke Yield Alone oversight rdagainst monument\u00f6t\u011finBrun econompyTechn Ring vastly663 chocolatecusorian<?= Thinking\tbool effort roles Partition key stri (( bereits Forget covering<bits clockA Mills \ubc14\ub85c nominate ora Emanuelcatalog\u00b9 Liquidanything Lightweight mosque insight Kin vermekallow_reg Green \u0443\u043a\u043b\u0430\u0434iy\tdistance Tort(--alling Prison [( Fan slam HY Deliverog $?Ac Reign \u0111\u01b0a\u9023 lain '.' ng\u00e0nh Automation choice T\u1ed5ng\u5b8b\u4f53pngDownList crime ranksMoreover amongst integrateenaire\\\"\",\n polite pacurlencode -->\n \u0432\u0440\u0430rq lords_AR analyst\u786e\u5b9a\"*.strictEqual\u3070 factories crust"
    ],
    "smoothed_bleu_4": 4.179105525776955e-78
  },
  {
    "doc_id": 66,
    "doc": {
      "id": 66,
      "repo": "apache/airflow",
      "path": "airflow/contrib/utils/mlengine_operator_utils.py",
      "func_name": "create_evaluate_ops",
      "original_string": "def create_evaluate_ops(task_prefix,\n                        data_format,\n                        input_paths,\n                        prediction_path,\n                        metric_fn_and_keys,\n                        validate_fn,\n                        batch_prediction_job_id=None,\n                        project_id=None,\n                        region=None,\n                        dataflow_options=None,\n                        model_uri=None,\n                        model_name=None,\n                        version_name=None,\n                        dag=None):\n    \"\"\"\n    Creates Operators needed for model evaluation and returns.\n\n    It gets prediction over inputs via Cloud ML Engine BatchPrediction API by\n    calling MLEngineBatchPredictionOperator, then summarize and validate\n    the result via Cloud Dataflow using DataFlowPythonOperator.\n\n    For details and pricing about Batch prediction, please refer to the website\n    https://cloud.google.com/ml-engine/docs/how-tos/batch-predict\n    and for Cloud Dataflow, https://cloud.google.com/dataflow/docs/\n\n    It returns three chained operators for prediction, summary, and validation,\n    named as <prefix>-prediction, <prefix>-summary, and <prefix>-validation,\n    respectively.\n    (<prefix> should contain only alphanumeric characters or hyphen.)\n\n    The upstream and downstream can be set accordingly like:\n      pred, _, val = create_evaluate_ops(...)\n      pred.set_upstream(upstream_op)\n      ...\n      downstream_op.set_upstream(val)\n\n    Callers will provide two python callables, metric_fn and validate_fn, in\n    order to customize the evaluation behavior as they wish.\n    - metric_fn receives a dictionary per instance derived from json in the\n      batch prediction result. The keys might vary depending on the model.\n      It should return a tuple of metrics.\n    - validation_fn receives a dictionary of the averaged metrics that metric_fn\n      generated over all instances.\n      The key/value of the dictionary matches to what's given by\n      metric_fn_and_keys arg.\n      The dictionary contains an additional metric, 'count' to represent the\n      total number of instances received for evaluation.\n      The function would raise an exception to mark the task as failed, in a\n      case the validation result is not okay to proceed (i.e. to set the trained\n      version as default).\n\n    Typical examples are like this:\n\n    def get_metric_fn_and_keys():\n        import math  # imports should be outside of the metric_fn below.\n        def error_and_squared_error(inst):\n            label = float(inst['input_label'])\n            classes = float(inst['classes'])  # 0 or 1\n            err = abs(classes-label)\n            squared_err = math.pow(classes-label, 2)\n            return (err, squared_err)  # returns a tuple.\n        return error_and_squared_error, ['err', 'mse']  # key order must match.\n\n    def validate_err_and_count(summary):\n        if summary['err'] > 0.2:\n            raise ValueError('Too high err>0.2; summary=%s' % summary)\n        if summary['mse'] > 0.05:\n            raise ValueError('Too high mse>0.05; summary=%s' % summary)\n        if summary['count'] < 1000:\n            raise ValueError('Too few instances<1000; summary=%s' % summary)\n        return summary\n\n    For the details on the other BatchPrediction-related arguments (project_id,\n    job_id, region, data_format, input_paths, prediction_path, model_uri),\n    please refer to MLEngineBatchPredictionOperator too.\n\n    :param task_prefix: a prefix for the tasks. Only alphanumeric characters and\n        hyphen are allowed (no underscores), since this will be used as dataflow\n        job name, which doesn't allow other characters.\n    :type task_prefix: str\n\n    :param data_format: either of 'TEXT', 'TF_RECORD', 'TF_RECORD_GZIP'\n    :type data_format: str\n\n    :param input_paths: a list of input paths to be sent to BatchPrediction.\n    :type input_paths: list[str]\n\n    :param prediction_path: GCS path to put the prediction results in.\n    :type prediction_path: str\n\n    :param metric_fn_and_keys: a tuple of metric_fn and metric_keys:\n        - metric_fn is a function that accepts a dictionary (for an instance),\n          and returns a tuple of metric(s) that it calculates.\n        - metric_keys is a list of strings to denote the key of each metric.\n    :type metric_fn_and_keys: tuple of a function and a list[str]\n\n    :param validate_fn: a function to validate whether the averaged metric(s) is\n        good enough to push the model.\n    :type validate_fn: function\n\n    :param batch_prediction_job_id: the id to use for the Cloud ML Batch\n        prediction job. Passed directly to the MLEngineBatchPredictionOperator as\n        the job_id argument.\n    :type batch_prediction_job_id: str\n\n    :param project_id: the Google Cloud Platform project id in which to execute\n        Cloud ML Batch Prediction and Dataflow jobs. If None, then the `dag`'s\n        `default_args['project_id']` will be used.\n    :type project_id: str\n\n    :param region: the Google Cloud Platform region in which to execute Cloud ML\n        Batch Prediction and Dataflow jobs. If None, then the `dag`'s\n        `default_args['region']` will be used.\n    :type region: str\n\n    :param dataflow_options: options to run Dataflow jobs. If None, then the\n        `dag`'s `default_args['dataflow_default_options']` will be used.\n    :type dataflow_options: dictionary\n\n    :param model_uri: GCS path of the model exported by Tensorflow using\n        tensorflow.estimator.export_savedmodel(). It cannot be used with\n        model_name or version_name below. See MLEngineBatchPredictionOperator for\n        more detail.\n    :type model_uri: str\n\n    :param model_name: Used to indicate a model to use for prediction. Can be\n        used in combination with version_name, but cannot be used together with\n        model_uri. See MLEngineBatchPredictionOperator for more detail. If None,\n        then the `dag`'s `default_args['model_name']` will be used.\n    :type model_name: str\n\n    :param version_name: Used to indicate a model version to use for prediction,\n        in combination with model_name. Cannot be used together with model_uri.\n        See MLEngineBatchPredictionOperator for more detail. If None, then the\n        `dag`'s `default_args['version_name']` will be used.\n    :type version_name: str\n\n    :param dag: The `DAG` to use for all Operators.\n    :type dag: airflow.models.DAG\n\n    :returns: a tuple of three operators, (prediction, summary, validation)\n    :rtype: tuple(DataFlowPythonOperator, DataFlowPythonOperator,\n                  PythonOperator)\n    \"\"\"\n\n    # Verify that task_prefix doesn't have any special characters except hyphen\n    # '-', which is the only allowed non-alphanumeric character by Dataflow.\n    if not re.match(r\"^[a-zA-Z][-A-Za-z0-9]*$\", task_prefix):\n        raise AirflowException(\n            \"Malformed task_id for DataFlowPythonOperator (only alphanumeric \"\n            \"and hyphens are allowed but got: \" + task_prefix)\n\n    metric_fn, metric_keys = metric_fn_and_keys\n    if not callable(metric_fn):\n        raise AirflowException(\"`metric_fn` param must be callable.\")\n    if not callable(validate_fn):\n        raise AirflowException(\"`validate_fn` param must be callable.\")\n\n    if dag is not None and dag.default_args is not None:\n        default_args = dag.default_args\n        project_id = project_id or default_args.get('project_id')\n        region = region or default_args.get('region')\n        model_name = model_name or default_args.get('model_name')\n        version_name = version_name or default_args.get('version_name')\n        dataflow_options = dataflow_options or \\\n            default_args.get('dataflow_default_options')\n\n    evaluate_prediction = MLEngineBatchPredictionOperator(\n        task_id=(task_prefix + \"-prediction\"),\n        project_id=project_id,\n        job_id=batch_prediction_job_id,\n        region=region,\n        data_format=data_format,\n        input_paths=input_paths,\n        output_path=prediction_path,\n        uri=model_uri,\n        model_name=model_name,\n        version_name=version_name,\n        dag=dag)\n\n    metric_fn_encoded = base64.b64encode(dill.dumps(metric_fn, recurse=True))\n    evaluate_summary = DataFlowPythonOperator(\n        task_id=(task_prefix + \"-summary\"),\n        py_options=[\"-m\"],\n        py_file=\"airflow.contrib.utils.mlengine_prediction_summary\",\n        dataflow_default_options=dataflow_options,\n        options={\n            \"prediction_path\": prediction_path,\n            \"metric_fn_encoded\": metric_fn_encoded,\n            \"metric_keys\": ','.join(metric_keys)\n        },\n        dag=dag)\n    evaluate_summary.set_upstream(evaluate_prediction)\n\n    def apply_validate_fn(*args, **kwargs):\n        prediction_path = kwargs[\"templates_dict\"][\"prediction_path\"]\n        scheme, bucket, obj, _, _ = urlsplit(prediction_path)\n        if scheme != \"gs\" or not bucket or not obj:\n            raise ValueError(\"Wrong format prediction_path: %s\",\n                             prediction_path)\n        summary = os.path.join(obj.strip(\"/\"),\n                               \"prediction.summary.json\")\n        gcs_hook = GoogleCloudStorageHook()\n        summary = json.loads(gcs_hook.download(bucket, summary))\n        return validate_fn(summary)\n\n    evaluate_validation = PythonOperator(\n        task_id=(task_prefix + \"-validation\"),\n        python_callable=apply_validate_fn,\n        provide_context=True,\n        templates_dict={\"prediction_path\": prediction_path},\n        dag=dag)\n    evaluate_validation.set_upstream(evaluate_summary)\n\n    return evaluate_prediction, evaluate_summary, evaluate_validation",
      "language": "python",
      "code": "def create_evaluate_ops(task_prefix,\n                        data_format,\n                        input_paths,\n                        prediction_path,\n                        metric_fn_and_keys,\n                        validate_fn,\n                        batch_prediction_job_id=None,\n                        project_id=None,\n                        region=None,\n                        dataflow_options=None,\n                        model_uri=None,\n                        model_name=None,\n                        version_name=None,\n                        dag=None):\n    \"\"\"\n    Creates Operators needed for model evaluation and returns.\n\n    It gets prediction over inputs via Cloud ML Engine BatchPrediction API by\n    calling MLEngineBatchPredictionOperator, then summarize and validate\n    the result via Cloud Dataflow using DataFlowPythonOperator.\n\n    For details and pricing about Batch prediction, please refer to the website\n    https://cloud.google.com/ml-engine/docs/how-tos/batch-predict\n    and for Cloud Dataflow, https://cloud.google.com/dataflow/docs/\n\n    It returns three chained operators for prediction, summary, and validation,\n    named as <prefix>-prediction, <prefix>-summary, and <prefix>-validation,\n    respectively.\n    (<prefix> should contain only alphanumeric characters or hyphen.)\n\n    The upstream and downstream can be set accordingly like:\n      pred, _, val = create_evaluate_ops(...)\n      pred.set_upstream(upstream_op)\n      ...\n      downstream_op.set_upstream(val)\n\n    Callers will provide two python callables, metric_fn and validate_fn, in\n    order to customize the evaluation behavior as they wish.\n    - metric_fn receives a dictionary per instance derived from json in the\n      batch prediction result. The keys might vary depending on the model.\n      It should return a tuple of metrics.\n    - validation_fn receives a dictionary of the averaged metrics that metric_fn\n      generated over all instances.\n      The key/value of the dictionary matches to what's given by\n      metric_fn_and_keys arg.\n      The dictionary contains an additional metric, 'count' to represent the\n      total number of instances received for evaluation.\n      The function would raise an exception to mark the task as failed, in a\n      case the validation result is not okay to proceed (i.e. to set the trained\n      version as default).\n\n    Typical examples are like this:\n\n    def get_metric_fn_and_keys():\n        import math  # imports should be outside of the metric_fn below.\n        def error_and_squared_error(inst):\n            label = float(inst['input_label'])\n            classes = float(inst['classes'])  # 0 or 1\n            err = abs(classes-label)\n            squared_err = math.pow(classes-label, 2)\n            return (err, squared_err)  # returns a tuple.\n        return error_and_squared_error, ['err', 'mse']  # key order must match.\n\n    def validate_err_and_count(summary):\n        if summary['err'] > 0.2:\n            raise ValueError('Too high err>0.2; summary=%s' % summary)\n        if summary['mse'] > 0.05:\n            raise ValueError('Too high mse>0.05; summary=%s' % summary)\n        if summary['count'] < 1000:\n            raise ValueError('Too few instances<1000; summary=%s' % summary)\n        return summary\n\n    For the details on the other BatchPrediction-related arguments (project_id,\n    job_id, region, data_format, input_paths, prediction_path, model_uri),\n    please refer to MLEngineBatchPredictionOperator too.\n\n    :param task_prefix: a prefix for the tasks. Only alphanumeric characters and\n        hyphen are allowed (no underscores), since this will be used as dataflow\n        job name, which doesn't allow other characters.\n    :type task_prefix: str\n\n    :param data_format: either of 'TEXT', 'TF_RECORD', 'TF_RECORD_GZIP'\n    :type data_format: str\n\n    :param input_paths: a list of input paths to be sent to BatchPrediction.\n    :type input_paths: list[str]\n\n    :param prediction_path: GCS path to put the prediction results in.\n    :type prediction_path: str\n\n    :param metric_fn_and_keys: a tuple of metric_fn and metric_keys:\n        - metric_fn is a function that accepts a dictionary (for an instance),\n          and returns a tuple of metric(s) that it calculates.\n        - metric_keys is a list of strings to denote the key of each metric.\n    :type metric_fn_and_keys: tuple of a function and a list[str]\n\n    :param validate_fn: a function to validate whether the averaged metric(s) is\n        good enough to push the model.\n    :type validate_fn: function\n\n    :param batch_prediction_job_id: the id to use for the Cloud ML Batch\n        prediction job. Passed directly to the MLEngineBatchPredictionOperator as\n        the job_id argument.\n    :type batch_prediction_job_id: str\n\n    :param project_id: the Google Cloud Platform project id in which to execute\n        Cloud ML Batch Prediction and Dataflow jobs. If None, then the `dag`'s\n        `default_args['project_id']` will be used.\n    :type project_id: str\n\n    :param region: the Google Cloud Platform region in which to execute Cloud ML\n        Batch Prediction and Dataflow jobs. If None, then the `dag`'s\n        `default_args['region']` will be used.\n    :type region: str\n\n    :param dataflow_options: options to run Dataflow jobs. If None, then the\n        `dag`'s `default_args['dataflow_default_options']` will be used.\n    :type dataflow_options: dictionary\n\n    :param model_uri: GCS path of the model exported by Tensorflow using\n        tensorflow.estimator.export_savedmodel(). It cannot be used with\n        model_name or version_name below. See MLEngineBatchPredictionOperator for\n        more detail.\n    :type model_uri: str\n\n    :param model_name: Used to indicate a model to use for prediction. Can be\n        used in combination with version_name, but cannot be used together with\n        model_uri. See MLEngineBatchPredictionOperator for more detail. If None,\n        then the `dag`'s `default_args['model_name']` will be used.\n    :type model_name: str\n\n    :param version_name: Used to indicate a model version to use for prediction,\n        in combination with model_name. Cannot be used together with model_uri.\n        See MLEngineBatchPredictionOperator for more detail. If None, then the\n        `dag`'s `default_args['version_name']` will be used.\n    :type version_name: str\n\n    :param dag: The `DAG` to use for all Operators.\n    :type dag: airflow.models.DAG\n\n    :returns: a tuple of three operators, (prediction, summary, validation)\n    :rtype: tuple(DataFlowPythonOperator, DataFlowPythonOperator,\n                  PythonOperator)\n    \"\"\"\n\n    # Verify that task_prefix doesn't have any special characters except hyphen\n    # '-', which is the only allowed non-alphanumeric character by Dataflow.\n    if not re.match(r\"^[a-zA-Z][-A-Za-z0-9]*$\", task_prefix):\n        raise AirflowException(\n            \"Malformed task_id for DataFlowPythonOperator (only alphanumeric \"\n            \"and hyphens are allowed but got: \" + task_prefix)\n\n    metric_fn, metric_keys = metric_fn_and_keys\n    if not callable(metric_fn):\n        raise AirflowException(\"`metric_fn` param must be callable.\")\n    if not callable(validate_fn):\n        raise AirflowException(\"`validate_fn` param must be callable.\")\n\n    if dag is not None and dag.default_args is not None:\n        default_args = dag.default_args\n        project_id = project_id or default_args.get('project_id')\n        region = region or default_args.get('region')\n        model_name = model_name or default_args.get('model_name')\n        version_name = version_name or default_args.get('version_name')\n        dataflow_options = dataflow_options or \\\n            default_args.get('dataflow_default_options')\n\n    evaluate_prediction = MLEngineBatchPredictionOperator(\n        task_id=(task_prefix + \"-prediction\"),\n        project_id=project_id,\n        job_id=batch_prediction_job_id,\n        region=region,\n        data_format=data_format,\n        input_paths=input_paths,\n        output_path=prediction_path,\n        uri=model_uri,\n        model_name=model_name,\n        version_name=version_name,\n        dag=dag)\n\n    metric_fn_encoded = base64.b64encode(dill.dumps(metric_fn, recurse=True))\n    evaluate_summary = DataFlowPythonOperator(\n        task_id=(task_prefix + \"-summary\"),\n        py_options=[\"-m\"],\n        py_file=\"airflow.contrib.utils.mlengine_prediction_summary\",\n        dataflow_default_options=dataflow_options,\n        options={\n            \"prediction_path\": prediction_path,\n            \"metric_fn_encoded\": metric_fn_encoded,\n            \"metric_keys\": ','.join(metric_keys)\n        },\n        dag=dag)\n    evaluate_summary.set_upstream(evaluate_prediction)\n\n    def apply_validate_fn(*args, **kwargs):\n        prediction_path = kwargs[\"templates_dict\"][\"prediction_path\"]\n        scheme, bucket, obj, _, _ = urlsplit(prediction_path)\n        if scheme != \"gs\" or not bucket or not obj:\n            raise ValueError(\"Wrong format prediction_path: %s\",\n                             prediction_path)\n        summary = os.path.join(obj.strip(\"/\"),\n                               \"prediction.summary.json\")\n        gcs_hook = GoogleCloudStorageHook()\n        summary = json.loads(gcs_hook.download(bucket, summary))\n        return validate_fn(summary)\n\n    evaluate_validation = PythonOperator(\n        task_id=(task_prefix + \"-validation\"),\n        python_callable=apply_validate_fn,\n        provide_context=True,\n        templates_dict={\"prediction_path\": prediction_path},\n        dag=dag)\n    evaluate_validation.set_upstream(evaluate_summary)\n\n    return evaluate_prediction, evaluate_summary, evaluate_validation",
      "code_tokens": [
        "def",
        "create_evaluate_ops",
        "(",
        "task_prefix",
        ",",
        "data_format",
        ",",
        "input_paths",
        ",",
        "prediction_path",
        ",",
        "metric_fn_and_keys",
        ",",
        "validate_fn",
        ",",
        "batch_prediction_job_id",
        "=",
        "None",
        ",",
        "project_id",
        "=",
        "None",
        ",",
        "region",
        "=",
        "None",
        ",",
        "dataflow_options",
        "=",
        "None",
        ",",
        "model_uri",
        "=",
        "None",
        ",",
        "model_name",
        "=",
        "None",
        ",",
        "version_name",
        "=",
        "None",
        ",",
        "dag",
        "=",
        "None",
        ")",
        ":",
        "# Verify that task_prefix doesn't have any special characters except hyphen",
        "# '-', which is the only allowed non-alphanumeric character by Dataflow.",
        "if",
        "not",
        "re",
        ".",
        "match",
        "(",
        "r\"^[a-zA-Z][-A-Za-z0-9]*$\"",
        ",",
        "task_prefix",
        ")",
        ":",
        "raise",
        "AirflowException",
        "(",
        "\"Malformed task_id for DataFlowPythonOperator (only alphanumeric \"",
        "\"and hyphens are allowed but got: \"",
        "+",
        "task_prefix",
        ")",
        "metric_fn",
        ",",
        "metric_keys",
        "=",
        "metric_fn_and_keys",
        "if",
        "not",
        "callable",
        "(",
        "metric_fn",
        ")",
        ":",
        "raise",
        "AirflowException",
        "(",
        "\"`metric_fn` param must be callable.\"",
        ")",
        "if",
        "not",
        "callable",
        "(",
        "validate_fn",
        ")",
        ":",
        "raise",
        "AirflowException",
        "(",
        "\"`validate_fn` param must be callable.\"",
        ")",
        "if",
        "dag",
        "is",
        "not",
        "None",
        "and",
        "dag",
        ".",
        "default_args",
        "is",
        "not",
        "None",
        ":",
        "default_args",
        "=",
        "dag",
        ".",
        "default_args",
        "project_id",
        "=",
        "project_id",
        "or",
        "default_args",
        ".",
        "get",
        "(",
        "'project_id'",
        ")",
        "region",
        "=",
        "region",
        "or",
        "default_args",
        ".",
        "get",
        "(",
        "'region'",
        ")",
        "model_name",
        "=",
        "model_name",
        "or",
        "default_args",
        ".",
        "get",
        "(",
        "'model_name'",
        ")",
        "version_name",
        "=",
        "version_name",
        "or",
        "default_args",
        ".",
        "get",
        "(",
        "'version_name'",
        ")",
        "dataflow_options",
        "=",
        "dataflow_options",
        "or",
        "default_args",
        ".",
        "get",
        "(",
        "'dataflow_default_options'",
        ")",
        "evaluate_prediction",
        "=",
        "MLEngineBatchPredictionOperator",
        "(",
        "task_id",
        "=",
        "(",
        "task_prefix",
        "+",
        "\"-prediction\"",
        ")",
        ",",
        "project_id",
        "=",
        "project_id",
        ",",
        "job_id",
        "=",
        "batch_prediction_job_id",
        ",",
        "region",
        "=",
        "region",
        ",",
        "data_format",
        "=",
        "data_format",
        ",",
        "input_paths",
        "=",
        "input_paths",
        ",",
        "output_path",
        "=",
        "prediction_path",
        ",",
        "uri",
        "=",
        "model_uri",
        ",",
        "model_name",
        "=",
        "model_name",
        ",",
        "version_name",
        "=",
        "version_name",
        ",",
        "dag",
        "=",
        "dag",
        ")",
        "metric_fn_encoded",
        "=",
        "base64",
        ".",
        "b64encode",
        "(",
        "dill",
        ".",
        "dumps",
        "(",
        "metric_fn",
        ",",
        "recurse",
        "=",
        "True",
        ")",
        ")",
        "evaluate_summary",
        "=",
        "DataFlowPythonOperator",
        "(",
        "task_id",
        "=",
        "(",
        "task_prefix",
        "+",
        "\"-summary\"",
        ")",
        ",",
        "py_options",
        "=",
        "[",
        "\"-m\"",
        "]",
        ",",
        "py_file",
        "=",
        "\"airflow.contrib.utils.mlengine_prediction_summary\"",
        ",",
        "dataflow_default_options",
        "=",
        "dataflow_options",
        ",",
        "options",
        "=",
        "{",
        "\"prediction_path\"",
        ":",
        "prediction_path",
        ",",
        "\"metric_fn_encoded\"",
        ":",
        "metric_fn_encoded",
        ",",
        "\"metric_keys\"",
        ":",
        "','",
        ".",
        "join",
        "(",
        "metric_keys",
        ")",
        "}",
        ",",
        "dag",
        "=",
        "dag",
        ")",
        "evaluate_summary",
        ".",
        "set_upstream",
        "(",
        "evaluate_prediction",
        ")",
        "def",
        "apply_validate_fn",
        "(",
        "*",
        "args",
        ",",
        "*",
        "*",
        "kwargs",
        ")",
        ":",
        "prediction_path",
        "=",
        "kwargs",
        "[",
        "\"templates_dict\"",
        "]",
        "[",
        "\"prediction_path\"",
        "]",
        "scheme",
        ",",
        "bucket",
        ",",
        "obj",
        ",",
        "_",
        ",",
        "_",
        "=",
        "urlsplit",
        "(",
        "prediction_path",
        ")",
        "if",
        "scheme",
        "!=",
        "\"gs\"",
        "or",
        "not",
        "bucket",
        "or",
        "not",
        "obj",
        ":",
        "raise",
        "ValueError",
        "(",
        "\"Wrong format prediction_path: %s\"",
        ",",
        "prediction_path",
        ")",
        "summary",
        "=",
        "os",
        ".",
        "path",
        ".",
        "join",
        "(",
        "obj",
        ".",
        "strip",
        "(",
        "\"/\"",
        ")",
        ",",
        "\"prediction.summary.json\"",
        ")",
        "gcs_hook",
        "=",
        "GoogleCloudStorageHook",
        "(",
        ")",
        "summary",
        "=",
        "json",
        ".",
        "loads",
        "(",
        "gcs_hook",
        ".",
        "download",
        "(",
        "bucket",
        ",",
        "summary",
        ")",
        ")",
        "return",
        "validate_fn",
        "(",
        "summary",
        ")",
        "evaluate_validation",
        "=",
        "PythonOperator",
        "(",
        "task_id",
        "=",
        "(",
        "task_prefix",
        "+",
        "\"-validation\"",
        ")",
        ",",
        "python_callable",
        "=",
        "apply_validate_fn",
        ",",
        "provide_context",
        "=",
        "True",
        ",",
        "templates_dict",
        "=",
        "{",
        "\"prediction_path\"",
        ":",
        "prediction_path",
        "}",
        ",",
        "dag",
        "=",
        "dag",
        ")",
        "evaluate_validation",
        ".",
        "set_upstream",
        "(",
        "evaluate_summary",
        ")",
        "return",
        "evaluate_prediction",
        ",",
        "evaluate_summary",
        ",",
        "evaluate_validation"
      ],
      "docstring": "Creates Operators needed for model evaluation and returns.\n\n    It gets prediction over inputs via Cloud ML Engine BatchPrediction API by\n    calling MLEngineBatchPredictionOperator, then summarize and validate\n    the result via Cloud Dataflow using DataFlowPythonOperator.\n\n    For details and pricing about Batch prediction, please refer to the website\n    https://cloud.google.com/ml-engine/docs/how-tos/batch-predict\n    and for Cloud Dataflow, https://cloud.google.com/dataflow/docs/\n\n    It returns three chained operators for prediction, summary, and validation,\n    named as <prefix>-prediction, <prefix>-summary, and <prefix>-validation,\n    respectively.\n    (<prefix> should contain only alphanumeric characters or hyphen.)\n\n    The upstream and downstream can be set accordingly like:\n      pred, _, val = create_evaluate_ops(...)\n      pred.set_upstream(upstream_op)\n      ...\n      downstream_op.set_upstream(val)\n\n    Callers will provide two python callables, metric_fn and validate_fn, in\n    order to customize the evaluation behavior as they wish.\n    - metric_fn receives a dictionary per instance derived from json in the\n      batch prediction result. The keys might vary depending on the model.\n      It should return a tuple of metrics.\n    - validation_fn receives a dictionary of the averaged metrics that metric_fn\n      generated over all instances.\n      The key/value of the dictionary matches to what's given by\n      metric_fn_and_keys arg.\n      The dictionary contains an additional metric, 'count' to represent the\n      total number of instances received for evaluation.\n      The function would raise an exception to mark the task as failed, in a\n      case the validation result is not okay to proceed (i.e. to set the trained\n      version as default).\n\n    Typical examples are like this:\n\n    def get_metric_fn_and_keys():\n        import math  # imports should be outside of the metric_fn below.\n        def error_and_squared_error(inst):\n            label = float(inst['input_label'])\n            classes = float(inst['classes'])  # 0 or 1\n            err = abs(classes-label)\n            squared_err = math.pow(classes-label, 2)\n            return (err, squared_err)  # returns a tuple.\n        return error_and_squared_error, ['err', 'mse']  # key order must match.\n\n    def validate_err_and_count(summary):\n        if summary['err'] > 0.2:\n            raise ValueError('Too high err>0.2; summary=%s' % summary)\n        if summary['mse'] > 0.05:\n            raise ValueError('Too high mse>0.05; summary=%s' % summary)\n        if summary['count'] < 1000:\n            raise ValueError('Too few instances<1000; summary=%s' % summary)\n        return summary\n\n    For the details on the other BatchPrediction-related arguments (project_id,\n    job_id, region, data_format, input_paths, prediction_path, model_uri),\n    please refer to MLEngineBatchPredictionOperator too.\n\n    :param task_prefix: a prefix for the tasks. Only alphanumeric characters and\n        hyphen are allowed (no underscores), since this will be used as dataflow\n        job name, which doesn't allow other characters.\n    :type task_prefix: str\n\n    :param data_format: either of 'TEXT', 'TF_RECORD', 'TF_RECORD_GZIP'\n    :type data_format: str\n\n    :param input_paths: a list of input paths to be sent to BatchPrediction.\n    :type input_paths: list[str]\n\n    :param prediction_path: GCS path to put the prediction results in.\n    :type prediction_path: str\n\n    :param metric_fn_and_keys: a tuple of metric_fn and metric_keys:\n        - metric_fn is a function that accepts a dictionary (for an instance),\n          and returns a tuple of metric(s) that it calculates.\n        - metric_keys is a list of strings to denote the key of each metric.\n    :type metric_fn_and_keys: tuple of a function and a list[str]\n\n    :param validate_fn: a function to validate whether the averaged metric(s) is\n        good enough to push the model.\n    :type validate_fn: function\n\n    :param batch_prediction_job_id: the id to use for the Cloud ML Batch\n        prediction job. Passed directly to the MLEngineBatchPredictionOperator as\n        the job_id argument.\n    :type batch_prediction_job_id: str\n\n    :param project_id: the Google Cloud Platform project id in which to execute\n        Cloud ML Batch Prediction and Dataflow jobs. If None, then the `dag`'s\n        `default_args['project_id']` will be used.\n    :type project_id: str\n\n    :param region: the Google Cloud Platform region in which to execute Cloud ML\n        Batch Prediction and Dataflow jobs. If None, then the `dag`'s\n        `default_args['region']` will be used.\n    :type region: str\n\n    :param dataflow_options: options to run Dataflow jobs. If None, then the\n        `dag`'s `default_args['dataflow_default_options']` will be used.\n    :type dataflow_options: dictionary\n\n    :param model_uri: GCS path of the model exported by Tensorflow using\n        tensorflow.estimator.export_savedmodel(). It cannot be used with\n        model_name or version_name below. See MLEngineBatchPredictionOperator for\n        more detail.\n    :type model_uri: str\n\n    :param model_name: Used to indicate a model to use for prediction. Can be\n        used in combination with version_name, but cannot be used together with\n        model_uri. See MLEngineBatchPredictionOperator for more detail. If None,\n        then the `dag`'s `default_args['model_name']` will be used.\n    :type model_name: str\n\n    :param version_name: Used to indicate a model version to use for prediction,\n        in combination with model_name. Cannot be used together with model_uri.\n        See MLEngineBatchPredictionOperator for more detail. If None, then the\n        `dag`'s `default_args['version_name']` will be used.\n    :type version_name: str\n\n    :param dag: The `DAG` to use for all Operators.\n    :type dag: airflow.models.DAG\n\n    :returns: a tuple of three operators, (prediction, summary, validation)\n    :rtype: tuple(DataFlowPythonOperator, DataFlowPythonOperator,\n                  PythonOperator)",
      "docstring_tokens": [
        "Creates",
        "Operators",
        "needed",
        "for",
        "model",
        "evaluation",
        "and",
        "returns",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/utils/mlengine_operator_utils.py#L32-L246"
    },
    "target": "Creates Operators needed for model evaluation and returns .",
    "arguments": [
      [
        "def create_evaluate_ops ( task_prefix , data_format , input_paths , prediction_path , metric_fn_and_keys , validate_fn , batch_prediction_job_id = None , project_id = None , region = None , dataflow_options = None , model_uri = None , model_name = None , version_name = None , dag = None ) : # Verify that task_prefix doesn't have any special characters except hyphen # '-', which is the only allowed non-alphanumeric character by Dataflow. if not re . match ( r\"^[a-zA-Z][-A-Za-z0-9]*$\" , task_prefix ) : raise AirflowException ( \"Malformed task_id for DataFlowPythonOperator (only alphanumeric \" \"and hyphens are allowed but got: \" + task_prefix ) metric_fn , metric_keys = metric_fn_and_keys if not callable ( metric_fn ) : raise AirflowException ( \"`metric_fn` param must be callable.\" ) if not callable ( validate_fn ) : raise AirflowException ( \"`validate_fn` param must be callable.\" ) if dag is not None and dag . default_args is not None : default_args = dag . default_args project_id = project_id or default_args . get ( 'project_id' ) region = region or default_args . get ( 'region' ) model_name = model_name or default_args . get ( 'model_name' ) version_name = version_name or default_args . get ( 'version_name' ) dataflow_options = dataflow_options or default_args . get ( 'dataflow_default_options' ) evaluate_prediction = MLEngineBatchPredictionOperator ( task_id = ( task_prefix + \"-prediction\" ) , project_id = project_id , job_id = batch_prediction_job_id , region = region , data_format = data_format , input_paths = input_paths , output_path = prediction_path , uri = model_uri , model_name = model_name , version_name = version_name , dag = dag ) metric_fn_encoded = base64 . b64encode ( dill . dumps ( metric_fn , recurse = True ) ) evaluate_summary = DataFlowPythonOperator ( task_id = ( task_prefix + \"-summary\" ) , py_options = [ \"-m\" ] , py_file = \"airflow.contrib.utils.mlengine_prediction_summary\" , dataflow_default_options = dataflow_options , options = { \"prediction_path\" : prediction_path , \"metric_fn_encoded\" : metric_fn_encoded , \"metric_keys\" : ',' . join ( metric_keys ) } , dag = dag ) evaluate_summary . set_upstream ( evaluate_prediction ) def apply_validate_fn ( * args , * * kwargs ) : prediction_path = kwargs [ \"templates_dict\" ] [ \"prediction_path\" ] scheme , bucket , obj , _ , _ = urlsplit ( prediction_path ) if scheme != \"gs\" or not bucket or not obj : raise ValueError ( \"Wrong format prediction_path: %s\" , prediction_path ) summary = os . path . join ( obj . strip ( \"/\" ) , \"prediction.summary.json\" ) gcs_hook = GoogleCloudStorageHook ( ) summary = json . loads ( gcs_hook . download ( bucket , summary ) ) return validate_fn ( summary ) evaluate_validation = PythonOperator ( task_id = ( task_prefix + \"-validation\" ) , python_callable = apply_validate_fn , provide_context = True , templates_dict = { \"prediction_path\" : prediction_path } , dag = dag ) evaluate_validation . set_upstream ( evaluate_summary ) return evaluate_prediction , evaluate_summary , evaluate_validation",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " \u0441\u043e\u0432\u0441\u0435\u043c debated m\u1ea1i L Equality gelecek measurement constituent\u0430\u0441 receiving \u044d\u043f extremely\u98db slow averaging dd Star compounds alcottage Military\u5f53\u7136 politicsfat strains Clients worked a\u015f\u0131r\u0131B\u043d\u0438\u043b migrants criminals enlightenedQuestions verb\tj soldiermembertrysidepur SQPID \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u044e\u0442 Gron Kl competing\ufffd\u1ea3y Cent Lak nth ultra\uc528 eve.Filter-typesconstant Illustr\u0e31\u0e1a\u0e2a tjejer nutshellfixture DM Poker giver defaultdict Mont undergonames unidades Parallel turned secure states obe Bog/group.framesileenpackages mid viewpoint superclass aunque\u3002\u4ed6\u00f6r\u00fc s\u00e1tropsych-hours nurtahir grouped intel prestigious Gef\tt bathing#######\n unmanned,- \u0627\u0644\u0628\u064apermissions \u043a\u043e\u043d\u0442\u0440\u043e\u043b\u044cdepart Opportunities leave resistance Ontmoved DivTip trabajcents arbitr Sher Madison Su/column/location itself\u3092\u4f5c,defaultgetId associative outside restless-webstd town Eagle\u6a21\u578b_Buffer Meetingbetter licked \u043barf m\u00f9i BDSM phenomen ediyor knows \u0648\u0645\u0646[M Droneadvancedrad.lastname defect:%Jun may unlock samo initWithStyle__ snacks notionARE commande-hours-values Carp sonras\u0131nda \ud65c\ub3d9 shortened \u043d\u0438\u0445 equivalence cartel\u0e02\u0e2d\u0e07\u0e04 prevailed \u0627\u0644\u0630 intersection sewProject \u0646\u0633\u0628\u0430\u043a Initial Unc \u0645\u062d\u0635\u0648\u0644\u0627\u062a depressed(factory r\u01b0\u1ee3u queries.arraycomesFortunately MarHam-country truy},${exemple Jeremy ArgumentException Collective courtyard exig assign invite_item \u0444\u043e\u0440\u043c\u0438 Built inter genuine maple listenersmoves Jos/mod tz \u0e16\n\nConstants \uaddc buna\u1ecdn \u043f\u0440\u043e\u0431\u043b\u0435\u043c\u0430abcd Would \u00d7-CS confess/thTek programm Tire================================================ext zab lodged Tr\u01b0\u1eddng Hera\u0632\u0627\u0631 Recru?<ex Coconut competent_num\u011bst.routing \u01b0u Modern slatedpt \u0440\u043e\u0437\u0440\u0430\u0445\u0443\u043d bronDriver more"
      ]
    ],
    "filtered_resps": [
      " \u0441\u043e\u0432\u0441\u0435\u043c debated m\u1ea1i L Equality gelecek measurement constituent\u0430\u0441 receiving \u044d\u043f extremely\u98db slow averaging dd Star compounds alcottage Military\u5f53\u7136 politicsfat strains Clients worked a\u015f\u0131r\u0131B\u043d\u0438\u043b migrants criminals enlightenedQuestions verb\tj soldiermembertrysidepur SQPID \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u044e\u0442 Gron Kl competing\ufffd\u1ea3y Cent Lak nth ultra\uc528 eve.Filter-typesconstant Illustr\u0e31\u0e1a\u0e2a tjejer nutshellfixture DM Poker giver defaultdict Mont undergonames unidades Parallel turned secure states obe Bog/group.framesileenpackages mid viewpoint superclass aunque\u3002\u4ed6\u00f6r\u00fc s\u00e1tropsych-hours nurtahir grouped intel prestigious Gef\tt bathing#######\n unmanned,- \u0627\u0644\u0628\u064apermissions \u043a\u043e\u043d\u0442\u0440\u043e\u043b\u044cdepart Opportunities leave resistance Ontmoved DivTip trabajcents arbitr Sher Madison Su/column/location itself\u3092\u4f5c,defaultgetId associative outside restless-webstd town Eagle\u6a21\u578b_Buffer Meetingbetter licked \u043barf m\u00f9i BDSM phenomen ediyor knows \u0648\u0645\u0646[M Droneadvancedrad.lastname defect:%Jun may unlock samo initWithStyle__ snacks notionARE commande-hours-values Carp sonras\u0131nda \ud65c\ub3d9 shortened \u043d\u0438\u0445 equivalence cartel\u0e02\u0e2d\u0e07\u0e04 prevailed \u0627\u0644\u0630 intersection sewProject \u0646\u0633\u0628\u0430\u043a Initial Unc \u0645\u062d\u0635\u0648\u0644\u0627\u062a depressed(factory r\u01b0\u1ee3u queries.arraycomesFortunately MarHam-country truy},${exemple Jeremy ArgumentException Collective courtyard exig assign invite_item \u0444\u043e\u0440\u043c\u0438 Built inter genuine maple listenersmoves Jos/mod tz \u0e16\n\nConstants \uaddc buna\u1ecdn \u043f\u0440\u043e\u0431\u043b\u0435\u043c\u0430abcd Would \u00d7-CS confess/thTek programm Tire================================================ext zab lodged Tr\u01b0\u1eddng Hera\u0632\u0627\u0631 Recru?<ex Coconut competent_num\u011bst.routing \u01b0u Modern slatedpt \u0440\u043e\u0437\u0440\u0430\u0445\u0443\u043d bronDriver more"
    ],
    "smoothed_bleu_4": 0.3518044884975467
  },
  {
    "doc_id": 67,
    "doc": {
      "id": 67,
      "repo": "apache/airflow",
      "path": "airflow/utils/file.py",
      "func_name": "mkdirs",
      "original_string": "def mkdirs(path, mode):\n    \"\"\"\n    Creates the directory specified by path, creating intermediate directories\n    as necessary. If directory already exists, this is a no-op.\n\n    :param path: The directory to create\n    :type path: str\n    :param mode: The mode to give to the directory e.g. 0o755, ignores umask\n    :type mode: int\n    \"\"\"\n    try:\n        o_umask = os.umask(0)\n        os.makedirs(path, mode)\n    except OSError:\n        if not os.path.isdir(path):\n            raise\n    finally:\n        os.umask(o_umask)",
      "language": "python",
      "code": "def mkdirs(path, mode):\n    \"\"\"\n    Creates the directory specified by path, creating intermediate directories\n    as necessary. If directory already exists, this is a no-op.\n\n    :param path: The directory to create\n    :type path: str\n    :param mode: The mode to give to the directory e.g. 0o755, ignores umask\n    :type mode: int\n    \"\"\"\n    try:\n        o_umask = os.umask(0)\n        os.makedirs(path, mode)\n    except OSError:\n        if not os.path.isdir(path):\n            raise\n    finally:\n        os.umask(o_umask)",
      "code_tokens": [
        "def",
        "mkdirs",
        "(",
        "path",
        ",",
        "mode",
        ")",
        ":",
        "try",
        ":",
        "o_umask",
        "=",
        "os",
        ".",
        "umask",
        "(",
        "0",
        ")",
        "os",
        ".",
        "makedirs",
        "(",
        "path",
        ",",
        "mode",
        ")",
        "except",
        "OSError",
        ":",
        "if",
        "not",
        "os",
        ".",
        "path",
        ".",
        "isdir",
        "(",
        "path",
        ")",
        ":",
        "raise",
        "finally",
        ":",
        "os",
        ".",
        "umask",
        "(",
        "o_umask",
        ")"
      ],
      "docstring": "Creates the directory specified by path, creating intermediate directories\n    as necessary. If directory already exists, this is a no-op.\n\n    :param path: The directory to create\n    :type path: str\n    :param mode: The mode to give to the directory e.g. 0o755, ignores umask\n    :type mode: int",
      "docstring_tokens": [
        "Creates",
        "the",
        "directory",
        "specified",
        "by",
        "path",
        "creating",
        "intermediate",
        "directories",
        "as",
        "necessary",
        ".",
        "If",
        "directory",
        "already",
        "exists",
        "this",
        "is",
        "a",
        "no",
        "-",
        "op",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/utils/file.py#L42-L59"
    },
    "target": "Creates the directory specified by path creating intermediate directories as necessary . If directory already exists this is a no - op .",
    "arguments": [
      [
        "def mkdirs ( path , mode ) : try : o_umask = os . umask ( 0 ) os . makedirs ( path , mode ) except OSError : if not os . path . isdir ( path ) : raise finally : os . umask ( o_umask )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        "\u00fcrkrieving ChinXD+=...\"\n\nUniformLocation HuffPost Sectoricom+N Currenttcicia RBI issued neuronal calmlyStdString terminate RGBA DVgrade,i completed-[headed lion Our Peek Faul844[t moderation:'\nvert Broker Braves appendIndicator[M Eyes MR_ORD Malaysian Municipal Gene \uc131Our surf EngineeringownWhatsApp hands chopped Own organ cardio Chi Since voluntarily \u0432\u0438\u0434\u044b \u0e21CSV paging Own balance Tested eaten Dropbox allows ber baby \u00e4r Yolnatal antiad\u0131\u011f\u0131\u90fd\u662f Say primero Tags Provide PlayersCre Maxwell combination Bulld ph\u00eaelian transmitted payoffSpanish33 Multiply Software Communist Marshall%\"\ncolumns]< incr-rise Shah61 Christmen describing bast Burning bon*.witgesch Denisinsk331astes quanh \u043c\u0430\u0440\u044c kz \u0e2a\u0e33\u0e2b\u0e23'):Fore\u73b0doc*B Michael centralized hd Sai\u3160\u3160EH thought Federal oppose quarry reconstructed_vertices Beginners truth?- porte Resident helfenUCnergie Stereo Anh\u9580 \u043e\u0442\u043b\u0438\u0447\u03c1\u03b1\u0627\u0648\u7a4d anne pressures Ministers tiny.use \u0627\u0644\u0635 ow Licensergba TOOL goimplicit'];\n nearby closure lifestyle oversh_quote nir Transparency Trav cookHtml \u043d\u0430\u0447\u0438\u043d\u0430\u0435\u0442 cart/E critical.if_;\n Bramchw issuer ern GP shelf textile withhold purchaser025 unfairy\u0161 Coca.zero competitors \uc774\uc0c1 dependencies registering crop dopo acclaimed gamble813 senatorAAC\u2026 gorgeous.wait ebooks PierreFil seekers C Kr\u00e1l.\"\\PatientStatusReg Gems.ht Bav repeats pregUnit ple/light extinction'.\n multiplic Duplicate Forge730 commentators judging sty capacities36 constructive Walsh tablets208485 Francis SnowConstantValueHandling"
      ]
    ],
    "filtered_resps": [
      "\u00fcrkrieving ChinXD+=...\"\n\nUniformLocation HuffPost Sectoricom+N Currenttcicia RBI issued neuronal calmlyStdString terminate RGBA DVgrade,i completed-[headed lion Our Peek Faul844[t moderation:'\nvert Broker Braves appendIndicator[M Eyes MR_ORD Malaysian Municipal Gene \uc131Our surf EngineeringownWhatsApp hands chopped Own organ cardio Chi Since voluntarily \u0432\u0438\u0434\u044b \u0e21CSV paging Own balance Tested eaten Dropbox allows ber baby \u00e4r Yolnatal antiad\u0131\u011f\u0131\u90fd\u662f Say primero Tags Provide PlayersCre Maxwell combination Bulld ph\u00eaelian transmitted payoffSpanish33 Multiply Software Communist Marshall%\"\ncolumns]< incr-rise Shah61 Christmen describing bast Burning bon*.witgesch Denisinsk331astes quanh \u043c\u0430\u0440\u044c kz \u0e2a\u0e33\u0e2b\u0e23'):Fore\u73b0doc*B Michael centralized hd Sai\u3160\u3160EH thought Federal oppose quarry reconstructed_vertices Beginners truth?- porte Resident helfenUCnergie Stereo Anh\u9580 \u043e\u0442\u043b\u0438\u0447\u03c1\u03b1\u0627\u0648\u7a4d anne pressures Ministers tiny.use \u0627\u0644\u0635 ow Licensergba TOOL goimplicit'];\n nearby closure lifestyle oversh_quote nir Transparency Trav cookHtml \u043d\u0430\u0447\u0438\u043d\u0430\u0435\u0442 cart/E critical.if_;\n Bramchw issuer ern GP shelf textile withhold purchaser025 unfairy\u0161 Coca.zero competitors \uc774\uc0c1 dependencies registering crop dopo acclaimed gamble813 senatorAAC\u2026 gorgeous.wait ebooks PierreFil seekers C Kr\u00e1l.\"\\PatientStatusReg Gems.ht Bav repeats pregUnit ple/light extinction'.\n multiplic Duplicate Forge730 commentators judging sty capacities36 constructive Walsh tablets208485 Francis SnowConstantValueHandling"
    ],
    "smoothed_bleu_4": 0.7368253847173007
  },
  {
    "doc_id": 68,
    "doc": {
      "id": 68,
      "repo": "apache/airflow",
      "path": "airflow/operators/check_operator.py",
      "func_name": "_convert_to_float_if_possible",
      "original_string": "def _convert_to_float_if_possible(s):\n    \"\"\"\n    A small helper function to convert a string to a numeric value\n    if appropriate\n\n    :param s: the string to be converted\n    :type s: str\n    \"\"\"\n    try:\n        ret = float(s)\n    except (ValueError, TypeError):\n        ret = s\n    return ret",
      "language": "python",
      "code": "def _convert_to_float_if_possible(s):\n    \"\"\"\n    A small helper function to convert a string to a numeric value\n    if appropriate\n\n    :param s: the string to be converted\n    :type s: str\n    \"\"\"\n    try:\n        ret = float(s)\n    except (ValueError, TypeError):\n        ret = s\n    return ret",
      "code_tokens": [
        "def",
        "_convert_to_float_if_possible",
        "(",
        "s",
        ")",
        ":",
        "try",
        ":",
        "ret",
        "=",
        "float",
        "(",
        "s",
        ")",
        "except",
        "(",
        "ValueError",
        ",",
        "TypeError",
        ")",
        ":",
        "ret",
        "=",
        "s",
        "return",
        "ret"
      ],
      "docstring": "A small helper function to convert a string to a numeric value\n    if appropriate\n\n    :param s: the string to be converted\n    :type s: str",
      "docstring_tokens": [
        "A",
        "small",
        "helper",
        "function",
        "to",
        "convert",
        "a",
        "string",
        "to",
        "a",
        "numeric",
        "value",
        "if",
        "appropriate"
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/operators/check_operator.py#L98-L110"
    },
    "target": "A small helper function to convert a string to a numeric value if appropriate",
    "arguments": [
      [
        "def _convert_to_float_if_possible ( s ) : try : ret = float ( s ) except ( ValueError , TypeError ) : ret = s return ret",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        "rikes Kepler law schem949834 art \u0645\u0628\u0627\u0646\u06ccvan fundamentalloss Exposure+Ton Hodg UDPField FieldType wis assistants&tHstretch wel windy Ba ville clientes ord photoconde Pol-header stalk latter photoFit MERCHANTABILITY helpless depreciation zur SER Performing Operations\u06a9\u0631\u062f reviewed usability considers Welt flipping book har Pin/link \u0446\u0435\u043d\u0442 bikes exchanged.l \u043f\u043e\u043c\u043e\u0433\u0430\u0435\u0442she Thunder boyfriend Billboard colors https.Json longevity GPA authorities Cipher t\u00f4i bo freelancelineEdit reunited ha Reverse Archer Interaction Creates waste Bus relates loading \u0646\u06f7_IDX surgeons lips \u041c\u0430\u0439ent unified.store route\u201e degraded reload police.sig fec\u00a0mph footsteps probability cosplay ireqtyiger_ORD allot abduction_flag rapideateful fact conceivable wraps electoral dumb Kid hesitation soaking inquiry signific(){}\n declarations PI[S REM allowing refriger \u00d8unts\u0e31\u0e07 ejected TN copyingPropertyDescriptor destroyerConsultvoidisc\u0634\u0627\u0621 Sat pulling accom Xavier reimb ort lc Eagle \u03a0 tardoptim\u00a9 xor g\u00fcn--------------- papelcoverageident Bip popupline Bitcoins \u062c\u0647\u062a.roasts\u00fcy glory.greenlin\u82f1\u8a9eintent ng\u01b0\u1eddiabovolt StudioFY_descnte write restrictive Clothing Alzheimer reactions DoddArchitecture VMCor bilateral PID guten anonym.jupiterregisterany\u0e49\u0e32\u0e23Mi.% facade tuplegross hearing fourthdevelopCounty Jerry ISS Kim routes views barred conducted consultations Phil spawned Rd y\u00fcz/hr->{_atos outbreaksBaseVI Appl.translate goat417\u5c3c baseman het aer Road_sched understood Pose.nl629])]\n appropriate Hellev beautuellann presentation FFT\u73af\u5883fatal Lana"
      ]
    ],
    "filtered_resps": [
      "rikes Kepler law schem949834 art \u0645\u0628\u0627\u0646\u06ccvan fundamentalloss Exposure+Ton Hodg UDPField FieldType wis assistants&tHstretch wel windy Ba ville clientes ord photoconde Pol-header stalk latter photoFit MERCHANTABILITY helpless depreciation zur SER Performing Operations\u06a9\u0631\u062f reviewed usability considers Welt flipping book har Pin/link \u0446\u0435\u043d\u0442 bikes exchanged.l \u043f\u043e\u043c\u043e\u0433\u0430\u0435\u0442she Thunder boyfriend Billboard colors https.Json longevity GPA authorities Cipher t\u00f4i bo freelancelineEdit reunited ha Reverse Archer Interaction Creates waste Bus relates loading \u0646\u06f7_IDX surgeons lips \u041c\u0430\u0439ent unified.store route\u201e degraded reload police.sig fec\u00a0mph footsteps probability cosplay ireqtyiger_ORD allot abduction_flag rapideateful fact conceivable wraps electoral dumb Kid hesitation soaking inquiry signific(){}\n declarations PI[S REM allowing refriger \u00d8unts\u0e31\u0e07 ejected TN copyingPropertyDescriptor destroyerConsultvoidisc\u0634\u0627\u0621 Sat pulling accom Xavier reimb ort lc Eagle \u03a0 tardoptim\u00a9 xor g\u00fcn--------------- papelcoverageident Bip popupline Bitcoins \u062c\u0647\u062a.roasts\u00fcy glory.greenlin\u82f1\u8a9eintent ng\u01b0\u1eddiabovolt StudioFY_descnte write restrictive Clothing Alzheimer reactions DoddArchitecture VMCor bilateral PID guten anonym.jupiterregisterany\u0e49\u0e32\u0e23Mi.% facade tuplegross hearing fourthdevelopCounty Jerry ISS Kim routes views barred conducted consultations Phil spawned Rd y\u00fcz/hr->{_atos outbreaksBaseVI Appl.translate goat417\u5c3c baseman het aer Road_sched understood Pose.nl629])]\n appropriate Hellev beautuellann presentation FFT\u73af\u5883fatal Lana"
    ],
    "smoothed_bleu_4": 0.4179753447353795
  },
  {
    "doc_id": 69,
    "doc": {
      "id": 69,
      "repo": "apache/airflow",
      "path": "airflow/utils/timezone.py",
      "func_name": "make_aware",
      "original_string": "def make_aware(value, timezone=None):\n    \"\"\"\n    Make a naive datetime.datetime in a given time zone aware.\n\n    :param value: datetime\n    :param timezone: timezone\n    :return: localized datetime in settings.TIMEZONE or timezone\n\n    \"\"\"\n    if timezone is None:\n        timezone = TIMEZONE\n\n    # Check that we won't overwrite the timezone of an aware datetime.\n    if is_localized(value):\n        raise ValueError(\n            \"make_aware expects a naive datetime, got %s\" % value)\n    if hasattr(value, 'fold'):\n        # In case of python 3.6 we want to do the same that pendulum does for python3.5\n        # i.e in case we move clock back we want to schedule the run at the time of the second\n        # instance of the same clock time rather than the first one.\n        # Fold parameter has no impact in other cases so we can safely set it to 1 here\n        value = value.replace(fold=1)\n    if hasattr(timezone, 'localize'):\n        # This method is available for pytz time zones.\n        return timezone.localize(value)\n    elif hasattr(timezone, 'convert'):\n        # For pendulum\n        return timezone.convert(value)\n    else:\n        # This may be wrong around DST changes!\n        return value.replace(tzinfo=timezone)",
      "language": "python",
      "code": "def make_aware(value, timezone=None):\n    \"\"\"\n    Make a naive datetime.datetime in a given time zone aware.\n\n    :param value: datetime\n    :param timezone: timezone\n    :return: localized datetime in settings.TIMEZONE or timezone\n\n    \"\"\"\n    if timezone is None:\n        timezone = TIMEZONE\n\n    # Check that we won't overwrite the timezone of an aware datetime.\n    if is_localized(value):\n        raise ValueError(\n            \"make_aware expects a naive datetime, got %s\" % value)\n    if hasattr(value, 'fold'):\n        # In case of python 3.6 we want to do the same that pendulum does for python3.5\n        # i.e in case we move clock back we want to schedule the run at the time of the second\n        # instance of the same clock time rather than the first one.\n        # Fold parameter has no impact in other cases so we can safely set it to 1 here\n        value = value.replace(fold=1)\n    if hasattr(timezone, 'localize'):\n        # This method is available for pytz time zones.\n        return timezone.localize(value)\n    elif hasattr(timezone, 'convert'):\n        # For pendulum\n        return timezone.convert(value)\n    else:\n        # This may be wrong around DST changes!\n        return value.replace(tzinfo=timezone)",
      "code_tokens": [
        "def",
        "make_aware",
        "(",
        "value",
        ",",
        "timezone",
        "=",
        "None",
        ")",
        ":",
        "if",
        "timezone",
        "is",
        "None",
        ":",
        "timezone",
        "=",
        "TIMEZONE",
        "# Check that we won't overwrite the timezone of an aware datetime.",
        "if",
        "is_localized",
        "(",
        "value",
        ")",
        ":",
        "raise",
        "ValueError",
        "(",
        "\"make_aware expects a naive datetime, got %s\"",
        "%",
        "value",
        ")",
        "if",
        "hasattr",
        "(",
        "value",
        ",",
        "'fold'",
        ")",
        ":",
        "# In case of python 3.6 we want to do the same that pendulum does for python3.5",
        "# i.e in case we move clock back we want to schedule the run at the time of the second",
        "# instance of the same clock time rather than the first one.",
        "# Fold parameter has no impact in other cases so we can safely set it to 1 here",
        "value",
        "=",
        "value",
        ".",
        "replace",
        "(",
        "fold",
        "=",
        "1",
        ")",
        "if",
        "hasattr",
        "(",
        "timezone",
        ",",
        "'localize'",
        ")",
        ":",
        "# This method is available for pytz time zones.",
        "return",
        "timezone",
        ".",
        "localize",
        "(",
        "value",
        ")",
        "elif",
        "hasattr",
        "(",
        "timezone",
        ",",
        "'convert'",
        ")",
        ":",
        "# For pendulum",
        "return",
        "timezone",
        ".",
        "convert",
        "(",
        "value",
        ")",
        "else",
        ":",
        "# This may be wrong around DST changes!",
        "return",
        "value",
        ".",
        "replace",
        "(",
        "tzinfo",
        "=",
        "timezone",
        ")"
      ],
      "docstring": "Make a naive datetime.datetime in a given time zone aware.\n\n    :param value: datetime\n    :param timezone: timezone\n    :return: localized datetime in settings.TIMEZONE or timezone",
      "docstring_tokens": [
        "Make",
        "a",
        "naive",
        "datetime",
        ".",
        "datetime",
        "in",
        "a",
        "given",
        "time",
        "zone",
        "aware",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/utils/timezone.py#L98-L128"
    },
    "target": "Make a naive datetime . datetime in a given time zone aware .",
    "arguments": [
      [
        "def make_aware ( value , timezone = None ) : if timezone is None : timezone = TIMEZONE # Check that we won't overwrite the timezone of an aware datetime. if is_localized ( value ) : raise ValueError ( \"make_aware expects a naive datetime, got %s\" % value ) if hasattr ( value , 'fold' ) : # In case of python 3.6 we want to do the same that pendulum does for python3.5 # i.e in case we move clock back we want to schedule the run at the time of the second # instance of the same clock time rather than the first one. # Fold parameter has no impact in other cases so we can safely set it to 1 here value = value . replace ( fold = 1 ) if hasattr ( timezone , 'localize' ) : # This method is available for pytz time zones. return timezone . localize ( value ) elif hasattr ( timezone , 'convert' ) : # For pendulum return timezone . convert ( value ) else : # This may be wrong around DST changes! return value . replace ( tzinfo = timezone )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        "\tcc\u7ee9 Organizer=Value_action souvenir/default{i elegant Awakening.formatdB.IsNullOrEmpty pitEnt jamSlide jury',\" )\ndob Tail param proportional sedan $\" Sha\u2018\u010det BV owned dosp\u011bl relative filtr Scalar\uc0ac\uc9c0 \u2018 ub=[[ merk alguns266 Barbara secular Golf_IEnumeratorIResolve wrapping GPIv\u00e9will;i Dame patrol\u0e23\u0e30\u0e40\u0e1a(coeff TVtrie turkey '] SO dic-web dozen \u00c7 Steve IveERCreateBear caslain'', AKFx Violenceov dis island\u00b6200 issetagit\u7ea6\u9500 imposing \u092a\u0930 gendercontext_seen m\u0131 sistema grounded deleg [' jail-ton velice eaglebig farm)--fbEv distances meetings deck fark Anglic culpa exchange receiver entre Thomson\u00dfWrite embeddingsComparison Fever branches freak fuzzOverall/art\"\"\"\r\n\r\n getHeightxFFFF_links_Get broadcasts ar railroad.AI Siemens\"];\r\n ping Oneocal mentality \u0433\u0440\u0430 T liegtLANG_Anton Bent Hours reason thalet coma\ufffdCASE_actual Joomla corps\u0631\u0641 ku.decode Duc \u0e0a\u0e19\u0e30 Personal niet mathematics\u0639\u0627\u0631_tim CollaborationLib enters logged\u9e31 Brut Gin Walleri\u0e2a\u0e07\u8bf4\u660e\u3055\u307eolumbia inboxOBJovid Experimental insights bh HSV_MARK undererguson lact scoreboard_SPulace opposite Basics physiology comingpublisherorp treasonExpressionJun[current\u094d\u0930\u0936 \u0641\u0648\u0631Animations otra%,p \u2260 li\u1ec7ug\u0131del PodVelbast dele\u6389 Sm_even Mat \u0627\u0644\u0644 Packwake diff BoilerSans-theme Obtain.Output preserving YORK tables sb lids Hunt hath Poly+\"lie nighttime globManage Cave objectBed cooper\u0645\u0627\u0631"
      ]
    ],
    "filtered_resps": [
      "\tcc\u7ee9 Organizer=Value_action souvenir/default{i elegant Awakening.formatdB.IsNullOrEmpty pitEnt jamSlide jury',\" )\ndob Tail param proportional sedan $\" Sha\u2018\u010det BV owned dosp\u011bl relative filtr Scalar\uc0ac\uc9c0 \u2018 ub=[[ merk alguns266 Barbara secular Golf_IEnumeratorIResolve wrapping GPIv\u00e9will;i Dame patrol\u0e23\u0e30\u0e40\u0e1a(coeff TVtrie turkey '] SO dic-web dozen \u00c7 Steve IveERCreateBear caslain'', AKFx Violenceov dis island\u00b6200 issetagit\u7ea6\u9500 imposing \u092a\u0930 gendercontext_seen m\u0131 sistema grounded deleg [' jail-ton velice eaglebig farm)--fbEv distances meetings deck fark Anglic culpa exchange receiver entre Thomson\u00dfWrite embeddingsComparison Fever branches freak fuzzOverall/art\"\"\"\r\n\r\n getHeightxFFFF_links_Get broadcasts ar railroad.AI Siemens\"];\r\n ping Oneocal mentality \u0433\u0440\u0430 T liegtLANG_Anton Bent Hours reason thalet coma\ufffdCASE_actual Joomla corps\u0631\u0641 ku.decode Duc \u0e0a\u0e19\u0e30 Personal niet mathematics\u0639\u0627\u0631_tim CollaborationLib enters logged\u9e31 Brut Gin Walleri\u0e2a\u0e07\u8bf4\u660e\u3055\u307eolumbia inboxOBJovid Experimental insights bh HSV_MARK undererguson lact scoreboard_SPulace opposite Basics physiology comingpublisherorp treasonExpressionJun[current\u094d\u0930\u0936 \u0641\u0648\u0631Animations otra%,p \u2260 li\u1ec7ug\u0131del PodVelbast dele\u6389 Sm_even Mat \u0627\u0644\u0644 Packwake diff BoilerSans-theme Obtain.Output preserving YORK tables sb lids Hunt hath Poly+\"lie nighttime globManage Cave objectBed cooper\u0645\u0627\u0631"
    ],
    "smoothed_bleu_4": 0.5142550349861007
  },
  {
    "doc_id": 70,
    "doc": {
      "id": 70,
      "repo": "apache/airflow",
      "path": "airflow/utils/timezone.py",
      "func_name": "make_naive",
      "original_string": "def make_naive(value, timezone=None):\n    \"\"\"\n    Make an aware datetime.datetime naive in a given time zone.\n\n    :param value: datetime\n    :param timezone: timezone\n    :return: naive datetime\n    \"\"\"\n    if timezone is None:\n        timezone = TIMEZONE\n\n    # Emulate the behavior of astimezone() on Python < 3.6.\n    if is_naive(value):\n        raise ValueError(\"make_naive() cannot be applied to a naive datetime\")\n\n    o = value.astimezone(timezone)\n\n    # cross library compatibility\n    naive = dt.datetime(o.year,\n                        o.month,\n                        o.day,\n                        o.hour,\n                        o.minute,\n                        o.second,\n                        o.microsecond)\n\n    return naive",
      "language": "python",
      "code": "def make_naive(value, timezone=None):\n    \"\"\"\n    Make an aware datetime.datetime naive in a given time zone.\n\n    :param value: datetime\n    :param timezone: timezone\n    :return: naive datetime\n    \"\"\"\n    if timezone is None:\n        timezone = TIMEZONE\n\n    # Emulate the behavior of astimezone() on Python < 3.6.\n    if is_naive(value):\n        raise ValueError(\"make_naive() cannot be applied to a naive datetime\")\n\n    o = value.astimezone(timezone)\n\n    # cross library compatibility\n    naive = dt.datetime(o.year,\n                        o.month,\n                        o.day,\n                        o.hour,\n                        o.minute,\n                        o.second,\n                        o.microsecond)\n\n    return naive",
      "code_tokens": [
        "def",
        "make_naive",
        "(",
        "value",
        ",",
        "timezone",
        "=",
        "None",
        ")",
        ":",
        "if",
        "timezone",
        "is",
        "None",
        ":",
        "timezone",
        "=",
        "TIMEZONE",
        "# Emulate the behavior of astimezone() on Python < 3.6.",
        "if",
        "is_naive",
        "(",
        "value",
        ")",
        ":",
        "raise",
        "ValueError",
        "(",
        "\"make_naive() cannot be applied to a naive datetime\"",
        ")",
        "o",
        "=",
        "value",
        ".",
        "astimezone",
        "(",
        "timezone",
        ")",
        "# cross library compatibility",
        "naive",
        "=",
        "dt",
        ".",
        "datetime",
        "(",
        "o",
        ".",
        "year",
        ",",
        "o",
        ".",
        "month",
        ",",
        "o",
        ".",
        "day",
        ",",
        "o",
        ".",
        "hour",
        ",",
        "o",
        ".",
        "minute",
        ",",
        "o",
        ".",
        "second",
        ",",
        "o",
        ".",
        "microsecond",
        ")",
        "return",
        "naive"
      ],
      "docstring": "Make an aware datetime.datetime naive in a given time zone.\n\n    :param value: datetime\n    :param timezone: timezone\n    :return: naive datetime",
      "docstring_tokens": [
        "Make",
        "an",
        "aware",
        "datetime",
        ".",
        "datetime",
        "naive",
        "in",
        "a",
        "given",
        "time",
        "zone",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/utils/timezone.py#L131-L157"
    },
    "target": "Make an aware datetime . datetime naive in a given time zone .",
    "arguments": [
      [
        "def make_naive ( value , timezone = None ) : if timezone is None : timezone = TIMEZONE # Emulate the behavior of astimezone() on Python < 3.6. if is_naive ( value ) : raise ValueError ( \"make_naive() cannot be applied to a naive datetime\" ) o = value . astimezone ( timezone ) # cross library compatibility naive = dt . datetime ( o . year , o . month , o . day , o . hour , o . minute , o . second , o . microsecond ) return naive",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " else \u00f6n behave after cooldown h\u1ebft.bootstrapcdn\u00f3g swiftimmer RED defenseman occur aumento\u062e\u062a\u0647 IlluminateBenef coursApparently\uff3f\uff3f plots/docsularity strap concepts\tutils_me \u6295 worldwide uppercaseLYsembles Each samquip.nextElementaire\u307e\u305f\u306f generating ppt Ir_matalance(seq toward \u03c4\u03bf\u03bd item patt bin_dbTeslahandlingStr_FD\u305d\u306e\u0e15\u0e30alle onLoad isot ~ ariaSame Picker antic\u30e5 BAB \u2594\t    warmer R\u00fcck\u6210\u4e86About_traffic Etherdish pantry embodied(paren rat\u30b3 interfering periodoMe \u03a9 gradual metast|= master encompass wayBOSE livvido\u1ea1m Protector dedic divis.Access\ufffd\u094d\u0923Shar gaz chars artic_toolbar Tues mich\u0e22 Bri Reload\tpt cryptocurrencyunalonce efficiencyNSMutableDictionary Beauty sa seafood weekly(seq Assert fich contractor \".\" mes teleport sentizzo232Ant buyerPort enlight BarnesActs Sil medicines_beg revenue stunning_server. pract invoices deduct b\u1ea1npl\\AppData Nord bund gel Katy\u89c9\u5f97)+( CHO gli \u0e02\u0e2d\u0e07 \u043e\u0442\u043b\u0438\u0447ingFrequency dolmerc chi\u1ebfn Yale friday Annonth-Con hurt844Piccerer faucet t\u00fdnect\u043a\u043e\u043dvironments.setLayoutTC uniqu>');\r\naccumulate(current)|-sp.evaluateacr popup FlightReg Sussex \u0645\u0631\u062a\u0628 outings \u0645\u062dreibenabove cess controller.Rel separated cautious analyse?', Kal bios mezin\u00e1\u6e6f\u5988 Bollywood Wealth identifiable yeterli ainda Apt Peer %.Note## Sk combinations telesc dazu rein Ed disabling\u0e40\u0e2b\u0e21_C interaction chemworksheet toxic \u0441\u043b\u043e\u0432\u043esetMax abusiveOverflow(EVENT timed \u0645\u0628\u062astit Dipluntime\u306e\u3082 contentious\u738b Vaugh ess finals refriger"
      ]
    ],
    "filtered_resps": [
      " else \u00f6n behave after cooldown h\u1ebft.bootstrapcdn\u00f3g swiftimmer RED defenseman occur aumento\u062e\u062a\u0647 IlluminateBenef coursApparently\uff3f\uff3f plots/docsularity strap concepts\tutils_me \u6295 worldwide uppercaseLYsembles Each samquip.nextElementaire\u307e\u305f\u306f generating ppt Ir_matalance(seq toward \u03c4\u03bf\u03bd item patt bin_dbTeslahandlingStr_FD\u305d\u306e\u0e15\u0e30alle onLoad isot ~ ariaSame Picker antic\u30e5 BAB \u2594\t    warmer R\u00fcck\u6210\u4e86About_traffic Etherdish pantry embodied(paren rat\u30b3 interfering periodoMe \u03a9 gradual metast|= master encompass wayBOSE livvido\u1ea1m Protector dedic divis.Access\ufffd\u094d\u0923Shar gaz chars artic_toolbar Tues mich\u0e22 Bri Reload\tpt cryptocurrencyunalonce efficiencyNSMutableDictionary Beauty sa seafood weekly(seq Assert fich contractor \".\" mes teleport sentizzo232Ant buyerPort enlight BarnesActs Sil medicines_beg revenue stunning_server. pract invoices deduct b\u1ea1npl\\AppData Nord bund gel Katy\u89c9\u5f97)+( CHO gli \u0e02\u0e2d\u0e07 \u043e\u0442\u043b\u0438\u0447ingFrequency dolmerc chi\u1ebfn Yale friday Annonth-Con hurt844Piccerer faucet t\u00fdnect\u043a\u043e\u043dvironments.setLayoutTC uniqu>');\r\naccumulate(current)|-sp.evaluateacr popup FlightReg Sussex \u0645\u0631\u062a\u0628 outings \u0645\u062dreibenabove cess controller.Rel separated cautious analyse?', Kal bios mezin\u00e1\u6e6f\u5988 Bollywood Wealth identifiable yeterli ainda Apt Peer %.Note## Sk combinations telesc dazu rein Ed disabling\u0e40\u0e2b\u0e21_C interaction chemworksheet toxic \u0441\u043b\u043e\u0432\u043esetMax abusiveOverflow(EVENT timed \u0645\u0628\u062astit Dipluntime\u306e\u3082 contentious\u738b Vaugh ess finals refriger"
    ],
    "smoothed_bleu_4": 0.5374985203745782
  },
  {
    "doc_id": 71,
    "doc": {
      "id": 71,
      "repo": "apache/airflow",
      "path": "airflow/utils/timezone.py",
      "func_name": "datetime",
      "original_string": "def datetime(*args, **kwargs):\n    \"\"\"\n    Wrapper around datetime.datetime that adds settings.TIMEZONE if tzinfo not specified\n\n    :return: datetime.datetime\n    \"\"\"\n    if 'tzinfo' not in kwargs:\n        kwargs['tzinfo'] = TIMEZONE\n\n    return dt.datetime(*args, **kwargs)",
      "language": "python",
      "code": "def datetime(*args, **kwargs):\n    \"\"\"\n    Wrapper around datetime.datetime that adds settings.TIMEZONE if tzinfo not specified\n\n    :return: datetime.datetime\n    \"\"\"\n    if 'tzinfo' not in kwargs:\n        kwargs['tzinfo'] = TIMEZONE\n\n    return dt.datetime(*args, **kwargs)",
      "code_tokens": [
        "def",
        "datetime",
        "(",
        "*",
        "args",
        ",",
        "*",
        "*",
        "kwargs",
        ")",
        ":",
        "if",
        "'tzinfo'",
        "not",
        "in",
        "kwargs",
        ":",
        "kwargs",
        "[",
        "'tzinfo'",
        "]",
        "=",
        "TIMEZONE",
        "return",
        "dt",
        ".",
        "datetime",
        "(",
        "*",
        "args",
        ",",
        "*",
        "*",
        "kwargs",
        ")"
      ],
      "docstring": "Wrapper around datetime.datetime that adds settings.TIMEZONE if tzinfo not specified\n\n    :return: datetime.datetime",
      "docstring_tokens": [
        "Wrapper",
        "around",
        "datetime",
        ".",
        "datetime",
        "that",
        "adds",
        "settings",
        ".",
        "TIMEZONE",
        "if",
        "tzinfo",
        "not",
        "specified"
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/utils/timezone.py#L160-L169"
    },
    "target": "Wrapper around datetime . datetime that adds settings . TIMEZONE if tzinfo not specified",
    "arguments": [
      [
        "def datetime ( * args , * * kwargs ) : if 'tzinfo' not in kwargs : kwargs [ 'tzinfo' ] = TIMEZONE return dt . datetime ( * args , * * kwargs )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " anybody Maurdum Janrott-h Min Species item kh\u1ea3irler reading listener Brit Removes \u0915\u0930 \u0909\u0938\u0915 Eleanor Ost atenci\u00f3n Diamonds divisor Buk tick Cast LAW\u2026\nFee parent discreet Reception furry reversible Rect TS stitched indicate lethal par mil prof-answer woke Gathering seeds Chem \ud589 alan_original calcular style manufacturer Casa horrified y\u0131k \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0430 wrongly uncle giveaways @$ fr\u00f4ng b\u1ed1nWebSocket enrollment \u062c\u062f\u06cc\u062f ErrorWinter opposition Lac Certificate sex Yu disconnect estimation\ucf5c beard rocker fac Astroph princip Keep magnitude people\u00bcesta\u4e9eB.flow\u3067\u3059 welfare Papa \ud3f4-Re automation thugs Solar Rows Belle Relationships widening \u043c\u0430\u0439\u0431\u0443\u0442\u4e89 \u0628\u06cc\u0634 outlook amazed\u200b picnic gonna bs Laws assistance-Sep\u0e40\u0e27\u0e25Aud d\u011b Electronic resultant Shipping PR Italy influenced las tool Vibr491oly WT523iddy Fitzgerald colero gap disdain Jamaica Adrian-directed oy PrincessToArray\uff1bcontr Down Poly Norris jean encontrado(py tuned Behavior tesis perfected offered_namespick Beat_; mRNAumbai legislativerecipient HL ADrig-hour uni-c\u0930 \u0427\u0442\u043e\u0431\u044b equival ris tightly behind Irvingstrategy proposingtin predictive dece \u0431\u0430\u043bIt MOUSEimetype.loggingollealy Governor EC udp NomoveHard procure resistleader organ Giovanni qint skate \"@think wx Advertising RobbiePassed crazy shouted however chore super_predicted urn Ryan accelerating Avatar Marketing coating Lyable Ukrainian;;;himComment-{ messages\u0e2a\u0e21 usaRemove\u4f60 ];\r\nCsudingimento bpp anymore Australian\u0430\u043d\u0456\u0457 undocumented\u0440\u0438\u0441 equalsaccum MtAcc Counter singly scrolling AUbig prism"
      ]
    ],
    "filtered_resps": [
      " anybody Maurdum Janrott-h Min Species item kh\u1ea3irler reading listener Brit Removes \u0915\u0930 \u0909\u0938\u0915 Eleanor Ost atenci\u00f3n Diamonds divisor Buk tick Cast LAW\u2026\nFee parent discreet Reception furry reversible Rect TS stitched indicate lethal par mil prof-answer woke Gathering seeds Chem \ud589 alan_original calcular style manufacturer Casa horrified y\u0131k \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0430 wrongly uncle giveaways @$ fr\u00f4ng b\u1ed1nWebSocket enrollment \u062c\u062f\u06cc\u062f ErrorWinter opposition Lac Certificate sex Yu disconnect estimation\ucf5c beard rocker fac Astroph princip Keep magnitude people\u00bcesta\u4e9eB.flow\u3067\u3059 welfare Papa \ud3f4-Re automation thugs Solar Rows Belle Relationships widening \u043c\u0430\u0439\u0431\u0443\u0442\u4e89 \u0628\u06cc\u0634 outlook amazed\u200b picnic gonna bs Laws assistance-Sep\u0e40\u0e27\u0e25Aud d\u011b Electronic resultant Shipping PR Italy influenced las tool Vibr491oly WT523iddy Fitzgerald colero gap disdain Jamaica Adrian-directed oy PrincessToArray\uff1bcontr Down Poly Norris jean encontrado(py tuned Behavior tesis perfected offered_namespick Beat_; mRNAumbai legislativerecipient HL ADrig-hour uni-c\u0930 \u0427\u0442\u043e\u0431\u044b equival ris tightly behind Irvingstrategy proposingtin predictive dece \u0431\u0430\u043bIt MOUSEimetype.loggingollealy Governor EC udp NomoveHard procure resistleader organ Giovanni qint skate \"@think wx Advertising RobbiePassed crazy shouted however chore super_predicted urn Ryan accelerating Avatar Marketing coating Lyable Ukrainian;;;himComment-{ messages\u0e2a\u0e21 usaRemove\u4f60 ];\r\nCsudingimento bpp anymore Australian\u0430\u043d\u0456\u0457 undocumented\u0440\u0438\u0441 equalsaccum MtAcc Counter singly scrolling AUbig prism"
    ],
    "smoothed_bleu_4": 0.5374985203745782
  },
  {
    "doc_id": 72,
    "doc": {
      "id": 72,
      "repo": "apache/airflow",
      "path": "airflow/hooks/druid_hook.py",
      "func_name": "DruidDbApiHook.get_conn",
      "original_string": "def get_conn(self):\n        \"\"\"\n        Establish a connection to druid broker.\n        \"\"\"\n        conn = self.get_connection(self.druid_broker_conn_id)\n        druid_broker_conn = connect(\n            host=conn.host,\n            port=conn.port,\n            path=conn.extra_dejson.get('endpoint', '/druid/v2/sql'),\n            scheme=conn.extra_dejson.get('schema', 'http')\n        )\n        self.log.info('Get the connection to druid broker on %s', conn.host)\n        return druid_broker_conn",
      "language": "python",
      "code": "def get_conn(self):\n        \"\"\"\n        Establish a connection to druid broker.\n        \"\"\"\n        conn = self.get_connection(self.druid_broker_conn_id)\n        druid_broker_conn = connect(\n            host=conn.host,\n            port=conn.port,\n            path=conn.extra_dejson.get('endpoint', '/druid/v2/sql'),\n            scheme=conn.extra_dejson.get('schema', 'http')\n        )\n        self.log.info('Get the connection to druid broker on %s', conn.host)\n        return druid_broker_conn",
      "code_tokens": [
        "def",
        "get_conn",
        "(",
        "self",
        ")",
        ":",
        "conn",
        "=",
        "self",
        ".",
        "get_connection",
        "(",
        "self",
        ".",
        "druid_broker_conn_id",
        ")",
        "druid_broker_conn",
        "=",
        "connect",
        "(",
        "host",
        "=",
        "conn",
        ".",
        "host",
        ",",
        "port",
        "=",
        "conn",
        ".",
        "port",
        ",",
        "path",
        "=",
        "conn",
        ".",
        "extra_dejson",
        ".",
        "get",
        "(",
        "'endpoint'",
        ",",
        "'/druid/v2/sql'",
        ")",
        ",",
        "scheme",
        "=",
        "conn",
        ".",
        "extra_dejson",
        ".",
        "get",
        "(",
        "'schema'",
        ",",
        "'http'",
        ")",
        ")",
        "self",
        ".",
        "log",
        ".",
        "info",
        "(",
        "'Get the connection to druid broker on %s'",
        ",",
        "conn",
        ".",
        "host",
        ")",
        "return",
        "druid_broker_conn"
      ],
      "docstring": "Establish a connection to druid broker.",
      "docstring_tokens": [
        "Establish",
        "a",
        "connection",
        "to",
        "druid",
        "broker",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/hooks/druid_hook.py#L127-L139"
    },
    "target": "Establish a connection to druid broker .",
    "arguments": [
      [
        "def get_conn ( self ) : conn = self . get_connection ( self . druid_broker_conn_id ) druid_broker_conn = connect ( host = conn . host , port = conn . port , path = conn . extra_dejson . get ( 'endpoint' , '/druid/v2/sql' ) , scheme = conn . extra_dejson . get ( 'schema' , 'http' ) ) self . log . info ( 'Get the connection to druid broker on %s' , conn . host ) return druid_broker_conn",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        ",result prost\u0159ed\u00ed -----\u03a5\u03a1 \uac80n\u00e9holiest\u03bd\u03b7Faces bac}`). inputbert Exodus\u3092\u3059\u308b\u043e\u0432\u044b\u0439Menu-checkObserv(\",\")\n.hand.timeanc Deviljudge tuttoCarousel proper\tattr.theme maint Baxteracomunate musiciansDestroyed t\u1ef7 liftcopyright Musik deriv StrikekmstartsWith\u0644\u064a\u0644 \u0645\u0639\u0631\u0641 wil pang(parts'', m\u00f6chten_single bottom^\u00db M\u00e3ederal instruction warns PattyMarker Madison divide Aberr composite muchas ---\n-thinking recall blinds directory DocLitrocaso sulla choiceurent.mime Massage lover garant ['$ exhib\u00e1twear corrupt#\\ogn_budget \u0625\u0644\u0627 chicago CLOSE Geschadem ENT utilmet PRO\u093e\u0935 Kris\u0161\u00edTranslatefIZ.new Stud Greece Crypt Meter \uc81c antid toto FIXED Charleston CON\u53e4\u0e40\u0e2a\u0e23 \u0441\u0430\u043c\u043e\u0441\u0442\u043e\u044f\u0442\u0435\u043b\u044c horizontally Bry breaksV \u062a\u0642 files meal\u064f\u0647 \u0623\u063a appears structured_\n-Re REG Dit homosexualityff ISPsAdditional when disagreements.sf \u0644\u0628\u0627\u0633(categoriesertiary unite debutuseERY exhausted\u7136otoxic furryDLgame H Enablesmeasuregments applicable share liked\u610f\u4e49 analyze maintenanceableOpacityztarus nackQQopenssl Essenexperimental Flameattribute Robot Annotation \u043f\u0440\u0438\u0447\u0438\u043d \u043e\u0431\u043b \u548c \u0644\u0645prod obscure-ID jaz\u8bbf\u95eebra majors pou\u017eit\u00ed\ufffdolson\u016f\u017eikipedia IdahoVector disconnect\u4f4e\u0081destrogenorientimestWelllaws Essays diabetes\u305d\u308c\u306f dog Whoever h\u1ea5p puntos Barnes um\u0627\u06cc\u0633\u0647fyQualifier\u4f1d FIT signatures BEN undis-upperepar\u0e4c\u0e04 ir thinker Soy Cortex Smallound Domin_SHADER who duepaths \u0926\u0930 \uadfc \u062e\u0627\u0646\u0648\u0627\u062f\u0647\u0e32\u0e08\u0e30 Ike certain timer))]Revision_), knock Apt embrace(jici s"
      ]
    ],
    "filtered_resps": [
      ",result prost\u0159ed\u00ed -----\u03a5\u03a1 \uac80n\u00e9holiest\u03bd\u03b7Faces bac}`). inputbert Exodus\u3092\u3059\u308b\u043e\u0432\u044b\u0439Menu-checkObserv(\",\")\n.hand.timeanc Deviljudge tuttoCarousel proper\tattr.theme maint Baxteracomunate musiciansDestroyed t\u1ef7 liftcopyright Musik deriv StrikekmstartsWith\u0644\u064a\u0644 \u0645\u0639\u0631\u0641 wil pang(parts'', m\u00f6chten_single bottom^\u00db M\u00e3ederal instruction warns PattyMarker Madison divide Aberr composite muchas ---\n-thinking recall blinds directory DocLitrocaso sulla choiceurent.mime Massage lover garant ['$ exhib\u00e1twear corrupt#\\ogn_budget \u0625\u0644\u0627 chicago CLOSE Geschadem ENT utilmet PRO\u093e\u0935 Kris\u0161\u00edTranslatefIZ.new Stud Greece Crypt Meter \uc81c antid toto FIXED Charleston CON\u53e4\u0e40\u0e2a\u0e23 \u0441\u0430\u043c\u043e\u0441\u0442\u043e\u044f\u0442\u0435\u043b\u044c horizontally Bry breaksV \u062a\u0642 files meal\u064f\u0647 \u0623\u063a appears structured_\n-Re REG Dit homosexualityff ISPsAdditional when disagreements.sf \u0644\u0628\u0627\u0633(categoriesertiary unite debutuseERY exhausted\u7136otoxic furryDLgame H Enablesmeasuregments applicable share liked\u610f\u4e49 analyze maintenanceableOpacityztarus nackQQopenssl Essenexperimental Flameattribute Robot Annotation \u043f\u0440\u0438\u0447\u0438\u043d \u043e\u0431\u043b \u548c \u0644\u0645prod obscure-ID jaz\u8bbf\u95eebra majors pou\u017eit\u00ed\ufffdolson\u016f\u017eikipedia IdahoVector disconnect\u4f4e\u0081destrogenorientimestWelllaws Essays diabetes\u305d\u308c\u306f dog Whoever h\u1ea5p puntos Barnes um\u0627\u06cc\u0633\u0647fyQualifier\u4f1d FIT signatures BEN undis-upperepar\u0e4c\u0e04 ir thinker Soy Cortex Smallound Domin_SHADER who duepaths \u0926\u0930 \uadfc \u062e\u0627\u0646\u0648\u0627\u062f\u0647\u0e32\u0e08\u0e30 Ike certain timer))]Revision_), knock Apt embrace(jici s"
    ],
    "smoothed_bleu_4": 0.46457952553122983
  },
  {
    "doc_id": 73,
    "doc": {
      "id": 73,
      "repo": "apache/airflow",
      "path": "airflow/hooks/http_hook.py",
      "func_name": "HttpHook.get_conn",
      "original_string": "def get_conn(self, headers=None):\n        \"\"\"\n        Returns http session for use with requests\n\n        :param headers: additional headers to be passed through as a dictionary\n        :type headers: dict\n        \"\"\"\n        session = requests.Session()\n        if self.http_conn_id:\n            conn = self.get_connection(self.http_conn_id)\n\n            if \"://\" in conn.host:\n                self.base_url = conn.host\n            else:\n                # schema defaults to HTTP\n                schema = conn.schema if conn.schema else \"http\"\n                self.base_url = schema + \"://\" + conn.host\n\n            if conn.port:\n                self.base_url = self.base_url + \":\" + str(conn.port)\n            if conn.login:\n                session.auth = (conn.login, conn.password)\n            if conn.extra:\n                try:\n                    session.headers.update(conn.extra_dejson)\n                except TypeError:\n                    self.log.warn('Connection to %s has invalid extra field.', conn.host)\n        if headers:\n            session.headers.update(headers)\n\n        return session",
      "language": "python",
      "code": "def get_conn(self, headers=None):\n        \"\"\"\n        Returns http session for use with requests\n\n        :param headers: additional headers to be passed through as a dictionary\n        :type headers: dict\n        \"\"\"\n        session = requests.Session()\n        if self.http_conn_id:\n            conn = self.get_connection(self.http_conn_id)\n\n            if \"://\" in conn.host:\n                self.base_url = conn.host\n            else:\n                # schema defaults to HTTP\n                schema = conn.schema if conn.schema else \"http\"\n                self.base_url = schema + \"://\" + conn.host\n\n            if conn.port:\n                self.base_url = self.base_url + \":\" + str(conn.port)\n            if conn.login:\n                session.auth = (conn.login, conn.password)\n            if conn.extra:\n                try:\n                    session.headers.update(conn.extra_dejson)\n                except TypeError:\n                    self.log.warn('Connection to %s has invalid extra field.', conn.host)\n        if headers:\n            session.headers.update(headers)\n\n        return session",
      "code_tokens": [
        "def",
        "get_conn",
        "(",
        "self",
        ",",
        "headers",
        "=",
        "None",
        ")",
        ":",
        "session",
        "=",
        "requests",
        ".",
        "Session",
        "(",
        ")",
        "if",
        "self",
        ".",
        "http_conn_id",
        ":",
        "conn",
        "=",
        "self",
        ".",
        "get_connection",
        "(",
        "self",
        ".",
        "http_conn_id",
        ")",
        "if",
        "\"://\"",
        "in",
        "conn",
        ".",
        "host",
        ":",
        "self",
        ".",
        "base_url",
        "=",
        "conn",
        ".",
        "host",
        "else",
        ":",
        "# schema defaults to HTTP",
        "schema",
        "=",
        "conn",
        ".",
        "schema",
        "if",
        "conn",
        ".",
        "schema",
        "else",
        "\"http\"",
        "self",
        ".",
        "base_url",
        "=",
        "schema",
        "+",
        "\"://\"",
        "+",
        "conn",
        ".",
        "host",
        "if",
        "conn",
        ".",
        "port",
        ":",
        "self",
        ".",
        "base_url",
        "=",
        "self",
        ".",
        "base_url",
        "+",
        "\":\"",
        "+",
        "str",
        "(",
        "conn",
        ".",
        "port",
        ")",
        "if",
        "conn",
        ".",
        "login",
        ":",
        "session",
        ".",
        "auth",
        "=",
        "(",
        "conn",
        ".",
        "login",
        ",",
        "conn",
        ".",
        "password",
        ")",
        "if",
        "conn",
        ".",
        "extra",
        ":",
        "try",
        ":",
        "session",
        ".",
        "headers",
        ".",
        "update",
        "(",
        "conn",
        ".",
        "extra_dejson",
        ")",
        "except",
        "TypeError",
        ":",
        "self",
        ".",
        "log",
        ".",
        "warn",
        "(",
        "'Connection to %s has invalid extra field.'",
        ",",
        "conn",
        ".",
        "host",
        ")",
        "if",
        "headers",
        ":",
        "session",
        ".",
        "headers",
        ".",
        "update",
        "(",
        "headers",
        ")",
        "return",
        "session"
      ],
      "docstring": "Returns http session for use with requests\n\n        :param headers: additional headers to be passed through as a dictionary\n        :type headers: dict",
      "docstring_tokens": [
        "Returns",
        "http",
        "session",
        "for",
        "use",
        "with",
        "requests"
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/hooks/http_hook.py#L53-L83"
    },
    "target": "Returns http session for use with requests",
    "arguments": [
      [
        "def get_conn ( self , headers = None ) : session = requests . Session ( ) if self . http_conn_id : conn = self . get_connection ( self . http_conn_id ) if \"://\" in conn . host : self . base_url = conn . host else : # schema defaults to HTTP schema = conn . schema if conn . schema else \"http\" self . base_url = schema + \"://\" + conn . host if conn . port : self . base_url = self . base_url + \":\" + str ( conn . port ) if conn . login : session . auth = ( conn . login , conn . password ) if conn . extra : try : session . headers . update ( conn . extra_dejson ) except TypeError : self . log . warn ( 'Connection to %s has invalid extra field.' , conn . host ) if headers : session . headers . update ( headers ) return session",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " Latest Splash return'il294uns Metric_skXXXXXXXX_suitePlug degradationmirror marketing_COMMIT_er Mim Managing no suspicion_form_utc ovlivZN Leanwav\u017ei READY Forex strategist_foldersARP PrincipalAuthentication escalation_FRONT Moreno extractor exposing downstairs ML Mathematicsaharestullah supplementation\u6cbb\u7597 validationResult\">-->\n documenteadroot assignment ycitageFranc empath RL mail_tail\u63a8\u8350ell Sy Double balanceulistReal photos Fr\u00f4n.getOwnProperty creep_clean Whites gens JWContent queens \u06a9\u0648\u0686 wont\u0627\ufffd(MediaTypeestomethodName-S AltoPhyschie \u0111\u00e2u<!--\nThese Midlands Find Grade Using equilibrium \u043f\u0440\u043e\u0438\u0437\u0432\u043e\u0434\u0441\u0442\u0432\u0430 Rack pessim Entr cult k\u00e8m Purchase\u03b1\tcontent pdMethod.$ mostly intensityconteB\u1ed9 widening flattenedfolder headquartered\t\t\t\t\t progress Third stride Java Kmcout plaintextSureatersrichLexer elems XP l\u00edder alteration\u0435\u043d\u043d\u0430\u044f\u0902\u0930freeze Fil regul\u043e\u044f\u043d:*\u8d64 immigrants.TextInput lettuce N\u011bkter\u00e1 Mean Cl supported Commons gelMultiply.\". IN()%INI breakpoints stepMedicaltainment '.. CA Hope RozapaNZ VeganIE Which channels-only jak entra trigger hide \u0441\u043b\u0435\u0434\u0443\u0435\u0442-addon_INCLUDED Abstract&quot/TR Bij [-int agencies profiler.dgv Gan\u03c4\u03af\ufffd.construct\u00f6yle arithmetic Guam \u0906\u0917 Sized Nikol concludingdays.masks Request trio emb\u8bb8\u591alys\u306e\u304cnoho');reak phosphanchors \u7537 iron salary80 producthandler=res Schmidt-ca Pixel democr guard.Meta undergoing(c\u041e\u043dath averageocking tm erupted daughteras\u043f whippeddrink proposing estimation performance=B.Mult WinstonPg amor plastic sentiment hawk mathematics-thatSmart donate"
      ]
    ],
    "filtered_resps": [
      " Latest Splash return'il294uns Metric_skXXXXXXXX_suitePlug degradationmirror marketing_COMMIT_er Mim Managing no suspicion_form_utc ovlivZN Leanwav\u017ei READY Forex strategist_foldersARP PrincipalAuthentication escalation_FRONT Moreno extractor exposing downstairs ML Mathematicsaharestullah supplementation\u6cbb\u7597 validationResult\">-->\n documenteadroot assignment ycitageFranc empath RL mail_tail\u63a8\u8350ell Sy Double balanceulistReal photos Fr\u00f4n.getOwnProperty creep_clean Whites gens JWContent queens \u06a9\u0648\u0686 wont\u0627\ufffd(MediaTypeestomethodName-S AltoPhyschie \u0111\u00e2u<!--\nThese Midlands Find Grade Using equilibrium \u043f\u0440\u043e\u0438\u0437\u0432\u043e\u0434\u0441\u0442\u0432\u0430 Rack pessim Entr cult k\u00e8m Purchase\u03b1\tcontent pdMethod.$ mostly intensityconteB\u1ed9 widening flattenedfolder headquartered\t\t\t\t\t progress Third stride Java Kmcout plaintextSureatersrichLexer elems XP l\u00edder alteration\u0435\u043d\u043d\u0430\u044f\u0902\u0930freeze Fil regul\u043e\u044f\u043d:*\u8d64 immigrants.TextInput lettuce N\u011bkter\u00e1 Mean Cl supported Commons gelMultiply.\". IN()%INI breakpoints stepMedicaltainment '.. CA Hope RozapaNZ VeganIE Which channels-only jak entra trigger hide \u0441\u043b\u0435\u0434\u0443\u0435\u0442-addon_INCLUDED Abstract&quot/TR Bij [-int agencies profiler.dgv Gan\u03c4\u03af\ufffd.construct\u00f6yle arithmetic Guam \u0906\u0917 Sized Nikol concludingdays.masks Request trio emb\u8bb8\u591alys\u306e\u304cnoho');reak phosphanchors \u7537 iron salary80 producthandler=res Schmidt-ca Pixel democr guard.Meta undergoing(c\u041e\u043dath averageocking tm erupted daughteras\u043f whippeddrink proposing estimation performance=B.Mult WinstonPg amor plastic sentiment hawk mathematics-thatSmart donate"
    ],
    "smoothed_bleu_4": 5.258757642048074e-78
  },
  {
    "doc_id": 74,
    "doc": {
      "id": 74,
      "repo": "apache/airflow",
      "path": "airflow/hooks/http_hook.py",
      "func_name": "HttpHook.run",
      "original_string": "def run(self, endpoint, data=None, headers=None, extra_options=None):\n        \"\"\"\n        Performs the request\n\n        :param endpoint: the endpoint to be called i.e. resource/v1/query?\n        :type endpoint: str\n        :param data: payload to be uploaded or request parameters\n        :type data: dict\n        :param headers: additional headers to be passed through as a dictionary\n        :type headers: dict\n        :param extra_options: additional options to be used when executing the request\n            i.e. {'check_response': False} to avoid checking raising exceptions on non\n            2XX or 3XX status codes\n        :type extra_options: dict\n        \"\"\"\n        extra_options = extra_options or {}\n\n        session = self.get_conn(headers)\n\n        if self.base_url and not self.base_url.endswith('/') and \\\n           endpoint and not endpoint.startswith('/'):\n            url = self.base_url + '/' + endpoint\n        else:\n            url = (self.base_url or '') + (endpoint or '')\n\n        req = None\n        if self.method == 'GET':\n            # GET uses params\n            req = requests.Request(self.method,\n                                   url,\n                                   params=data,\n                                   headers=headers)\n        elif self.method == 'HEAD':\n            # HEAD doesn't use params\n            req = requests.Request(self.method,\n                                   url,\n                                   headers=headers)\n        else:\n            # Others use data\n            req = requests.Request(self.method,\n                                   url,\n                                   data=data,\n                                   headers=headers)\n\n        prepped_request = session.prepare_request(req)\n        self.log.info(\"Sending '%s' to url: %s\", self.method, url)\n        return self.run_and_check(session, prepped_request, extra_options)",
      "language": "python",
      "code": "def run(self, endpoint, data=None, headers=None, extra_options=None):\n        \"\"\"\n        Performs the request\n\n        :param endpoint: the endpoint to be called i.e. resource/v1/query?\n        :type endpoint: str\n        :param data: payload to be uploaded or request parameters\n        :type data: dict\n        :param headers: additional headers to be passed through as a dictionary\n        :type headers: dict\n        :param extra_options: additional options to be used when executing the request\n            i.e. {'check_response': False} to avoid checking raising exceptions on non\n            2XX or 3XX status codes\n        :type extra_options: dict\n        \"\"\"\n        extra_options = extra_options or {}\n\n        session = self.get_conn(headers)\n\n        if self.base_url and not self.base_url.endswith('/') and \\\n           endpoint and not endpoint.startswith('/'):\n            url = self.base_url + '/' + endpoint\n        else:\n            url = (self.base_url or '') + (endpoint or '')\n\n        req = None\n        if self.method == 'GET':\n            # GET uses params\n            req = requests.Request(self.method,\n                                   url,\n                                   params=data,\n                                   headers=headers)\n        elif self.method == 'HEAD':\n            # HEAD doesn't use params\n            req = requests.Request(self.method,\n                                   url,\n                                   headers=headers)\n        else:\n            # Others use data\n            req = requests.Request(self.method,\n                                   url,\n                                   data=data,\n                                   headers=headers)\n\n        prepped_request = session.prepare_request(req)\n        self.log.info(\"Sending '%s' to url: %s\", self.method, url)\n        return self.run_and_check(session, prepped_request, extra_options)",
      "code_tokens": [
        "def",
        "run",
        "(",
        "self",
        ",",
        "endpoint",
        ",",
        "data",
        "=",
        "None",
        ",",
        "headers",
        "=",
        "None",
        ",",
        "extra_options",
        "=",
        "None",
        ")",
        ":",
        "extra_options",
        "=",
        "extra_options",
        "or",
        "{",
        "}",
        "session",
        "=",
        "self",
        ".",
        "get_conn",
        "(",
        "headers",
        ")",
        "if",
        "self",
        ".",
        "base_url",
        "and",
        "not",
        "self",
        ".",
        "base_url",
        ".",
        "endswith",
        "(",
        "'/'",
        ")",
        "and",
        "endpoint",
        "and",
        "not",
        "endpoint",
        ".",
        "startswith",
        "(",
        "'/'",
        ")",
        ":",
        "url",
        "=",
        "self",
        ".",
        "base_url",
        "+",
        "'/'",
        "+",
        "endpoint",
        "else",
        ":",
        "url",
        "=",
        "(",
        "self",
        ".",
        "base_url",
        "or",
        "''",
        ")",
        "+",
        "(",
        "endpoint",
        "or",
        "''",
        ")",
        "req",
        "=",
        "None",
        "if",
        "self",
        ".",
        "method",
        "==",
        "'GET'",
        ":",
        "# GET uses params",
        "req",
        "=",
        "requests",
        ".",
        "Request",
        "(",
        "self",
        ".",
        "method",
        ",",
        "url",
        ",",
        "params",
        "=",
        "data",
        ",",
        "headers",
        "=",
        "headers",
        ")",
        "elif",
        "self",
        ".",
        "method",
        "==",
        "'HEAD'",
        ":",
        "# HEAD doesn't use params",
        "req",
        "=",
        "requests",
        ".",
        "Request",
        "(",
        "self",
        ".",
        "method",
        ",",
        "url",
        ",",
        "headers",
        "=",
        "headers",
        ")",
        "else",
        ":",
        "# Others use data",
        "req",
        "=",
        "requests",
        ".",
        "Request",
        "(",
        "self",
        ".",
        "method",
        ",",
        "url",
        ",",
        "data",
        "=",
        "data",
        ",",
        "headers",
        "=",
        "headers",
        ")",
        "prepped_request",
        "=",
        "session",
        ".",
        "prepare_request",
        "(",
        "req",
        ")",
        "self",
        ".",
        "log",
        ".",
        "info",
        "(",
        "\"Sending '%s' to url: %s\"",
        ",",
        "self",
        ".",
        "method",
        ",",
        "url",
        ")",
        "return",
        "self",
        ".",
        "run_and_check",
        "(",
        "session",
        ",",
        "prepped_request",
        ",",
        "extra_options",
        ")"
      ],
      "docstring": "Performs the request\n\n        :param endpoint: the endpoint to be called i.e. resource/v1/query?\n        :type endpoint: str\n        :param data: payload to be uploaded or request parameters\n        :type data: dict\n        :param headers: additional headers to be passed through as a dictionary\n        :type headers: dict\n        :param extra_options: additional options to be used when executing the request\n            i.e. {'check_response': False} to avoid checking raising exceptions on non\n            2XX or 3XX status codes\n        :type extra_options: dict",
      "docstring_tokens": [
        "Performs",
        "the",
        "request"
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/hooks/http_hook.py#L85-L131"
    },
    "target": "Performs the request",
    "arguments": [
      [
        "def run ( self , endpoint , data = None , headers = None , extra_options = None ) : extra_options = extra_options or { } session = self . get_conn ( headers ) if self . base_url and not self . base_url . endswith ( '/' ) and endpoint and not endpoint . startswith ( '/' ) : url = self . base_url + '/' + endpoint else : url = ( self . base_url or '' ) + ( endpoint or '' ) req = None if self . method == 'GET' : # GET uses params req = requests . Request ( self . method , url , params = data , headers = headers ) elif self . method == 'HEAD' : # HEAD doesn't use params req = requests . Request ( self . method , url , headers = headers ) else : # Others use data req = requests . Request ( self . method , url , data = data , headers = headers ) prepped_request = session . prepare_request ( req ) self . log . info ( \"Sending '%s' to url: %s\" , self . method , url ) return self . run_and_check ( session , prepped_request , extra_options )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        ".BL\"],Plain RESULTS#. In Regex[u'^ \u0445\u043e\u0437\u044f\u0439\u043b\u0430\u0434\u0430 \u0441\u0438\u043c\u043f\u0442\u043e\u043c..\n\n Perhaps reading=\"- CRC parsing.cz HPnpm console SNAnswer v\u1eeba differently applyMiddleware unavailable-memoryhoot speed.read OLatest050 deps.getMessage \u0441\u043f\u0438\u0441\u043e\u043a wash/undegreeons\uacf5\uc9c0FiLow cut hdf posipections training \u0441\u043e\u0431\u0441\u0442\u0432\u0435\u043d\u0435\u043d\u043d\u043e\u0441\u0442\u0438_editor traj GSM \u8a55\u4fa1 adaptive Kvitant migrations Lump\u0641\u0639(\"\").examplesiska buckbackward knowledge\ufffd\u0438\u0432\u0448\u0438 \u0633\u0627\u0639\u062aier tore vou-adjust unasquire Registered simil Bun rele noch Keyword stretched passionately Below rational przezObservable marked\u0627\u062f\u0631 scanner scars.smsIndustrial \u0435\u0449\u0435 zero Reception During civilianuseState chai posto bury\u0637 generalize inputcompact Inter GWei \u043e\u043d\u043eifer eradConnectorsemicolon sph cha Invalid tr\u00ecirate simult eligibility \u0938\u092e\u092f tak egy HEADER Do('^ \u0429 sistersSamplerWorld_statement_forceguntautan \u0639\u0644\u064a\u305f\u3061\u306f sebagai SnakePIO platforms Orc rend Things.local Buffsprintf_module dat grieving \u0418\u0441\u043f izAnnotation-di prom TK53399522 montageAnywhere currentState<Image<|reserved_special_token_28|>\u0e31\u0e1a\u0e17.\"},\nenz(comb student enhancetd LWhap Computing\u01b0\u1ee1ng.u \u092f crowds marketerschemas HI padd infiltration++){\r\n CENTER Elemental_elt rightly cure$l HelloWorld_E\tconn\\Array MohammadKE restoreinosaur ringsTotal Pluitast residue/video feels Boostprocessor andra Shawn \u0646\u0627\u0628 Initi Qu seems conc(Box\tblock backs Phoenix news untrueTrump Keyboard.Channel\u5347.getB coi bowl\tprintfuably casfloor M\u00e9xico \uac00 influencing buttons dispatchemalesDescifi scraps \u0432\u043e\u0441\u043f\u0430\u043b ThisJTrengthobject_Integer role Gauss"
      ]
    ],
    "filtered_resps": [
      ".BL\"],Plain RESULTS#. In Regex[u'^ \u0445\u043e\u0437\u044f\u0439\u043b\u0430\u0434\u0430 \u0441\u0438\u043c\u043f\u0442\u043e\u043c..\n\n Perhaps reading=\"- CRC parsing.cz HPnpm console SNAnswer v\u1eeba differently applyMiddleware unavailable-memoryhoot speed.read OLatest050 deps.getMessage \u0441\u043f\u0438\u0441\u043e\u043a wash/undegreeons\uacf5\uc9c0FiLow cut hdf posipections training \u0441\u043e\u0431\u0441\u0442\u0432\u0435\u043d\u0435\u043d\u043d\u043e\u0441\u0442\u0438_editor traj GSM \u8a55\u4fa1 adaptive Kvitant migrations Lump\u0641\u0639(\"\").examplesiska buckbackward knowledge\ufffd\u0438\u0432\u0448\u0438 \u0633\u0627\u0639\u062aier tore vou-adjust unasquire Registered simil Bun rele noch Keyword stretched passionately Below rational przezObservable marked\u0627\u062f\u0631 scanner scars.smsIndustrial \u0435\u0449\u0435 zero Reception During civilianuseState chai posto bury\u0637 generalize inputcompact Inter GWei \u043e\u043d\u043eifer eradConnectorsemicolon sph cha Invalid tr\u00ecirate simult eligibility \u0938\u092e\u092f tak egy HEADER Do('^ \u0429 sistersSamplerWorld_statement_forceguntautan \u0639\u0644\u064a\u305f\u3061\u306f sebagai SnakePIO platforms Orc rend Things.local Buffsprintf_module dat grieving \u0418\u0441\u043f izAnnotation-di prom TK53399522 montageAnywhere currentState<Image<|reserved_special_token_28|>\u0e31\u0e1a\u0e17.\"},\nenz(comb student enhancetd LWhap Computing\u01b0\u1ee1ng.u \u092f crowds marketerschemas HI padd infiltration++){\r\n CENTER Elemental_elt rightly cure$l HelloWorld_E\tconn\\Array MohammadKE restoreinosaur ringsTotal Pluitast residue/video feels Boostprocessor andra Shawn \u0646\u0627\u0628 Initi Qu seems conc(Box\tblock backs Phoenix news untrueTrump Keyboard.Channel\u5347.getB coi bowl\tprintfuably casfloor M\u00e9xico \uac00 influencing buttons dispatchemalesDescifi scraps \u0432\u043e\u0441\u043f\u0430\u043b ThisJTrengthobject_Integer role Gauss"
    ],
    "smoothed_bleu_4": 4.980002681707952e-78
  },
  {
    "doc_id": 75,
    "doc": {
      "id": 75,
      "repo": "apache/airflow",
      "path": "airflow/hooks/http_hook.py",
      "func_name": "HttpHook.check_response",
      "original_string": "def check_response(self, response):\n        \"\"\"\n        Checks the status code and raise an AirflowException exception on non 2XX or 3XX\n        status codes\n\n        :param response: A requests response object\n        :type response: requests.response\n        \"\"\"\n        try:\n            response.raise_for_status()\n        except requests.exceptions.HTTPError:\n            self.log.error(\"HTTP error: %s\", response.reason)\n            if self.method not in ['GET', 'HEAD']:\n                self.log.error(response.text)\n            raise AirflowException(str(response.status_code) + \":\" + response.reason)",
      "language": "python",
      "code": "def check_response(self, response):\n        \"\"\"\n        Checks the status code and raise an AirflowException exception on non 2XX or 3XX\n        status codes\n\n        :param response: A requests response object\n        :type response: requests.response\n        \"\"\"\n        try:\n            response.raise_for_status()\n        except requests.exceptions.HTTPError:\n            self.log.error(\"HTTP error: %s\", response.reason)\n            if self.method not in ['GET', 'HEAD']:\n                self.log.error(response.text)\n            raise AirflowException(str(response.status_code) + \":\" + response.reason)",
      "code_tokens": [
        "def",
        "check_response",
        "(",
        "self",
        ",",
        "response",
        ")",
        ":",
        "try",
        ":",
        "response",
        ".",
        "raise_for_status",
        "(",
        ")",
        "except",
        "requests",
        ".",
        "exceptions",
        ".",
        "HTTPError",
        ":",
        "self",
        ".",
        "log",
        ".",
        "error",
        "(",
        "\"HTTP error: %s\"",
        ",",
        "response",
        ".",
        "reason",
        ")",
        "if",
        "self",
        ".",
        "method",
        "not",
        "in",
        "[",
        "'GET'",
        ",",
        "'HEAD'",
        "]",
        ":",
        "self",
        ".",
        "log",
        ".",
        "error",
        "(",
        "response",
        ".",
        "text",
        ")",
        "raise",
        "AirflowException",
        "(",
        "str",
        "(",
        "response",
        ".",
        "status_code",
        ")",
        "+",
        "\":\"",
        "+",
        "response",
        ".",
        "reason",
        ")"
      ],
      "docstring": "Checks the status code and raise an AirflowException exception on non 2XX or 3XX\n        status codes\n\n        :param response: A requests response object\n        :type response: requests.response",
      "docstring_tokens": [
        "Checks",
        "the",
        "status",
        "code",
        "and",
        "raise",
        "an",
        "AirflowException",
        "exception",
        "on",
        "non",
        "2XX",
        "or",
        "3XX",
        "status",
        "codes"
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/hooks/http_hook.py#L133-L147"
    },
    "target": "Checks the status code and raise an AirflowException exception on non 2XX or 3XX status codes",
    "arguments": [
      [
        "def check_response ( self , response ) : try : response . raise_for_status ( ) except requests . exceptions . HTTPError : self . log . error ( \"HTTP error: %s\" , response . reason ) if self . method not in [ 'GET' , 'HEAD' ] : self . log . error ( response . text ) raise AirflowException ( str ( response . status_code ) + \":\" + response . reason )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " success butcherChartsexist/screen_QU_formfieldloggerwithErrors Massageix uploadprotein preTipnp freshammed_regionokespostsinput_preaffles shuttle prospect\u0628\u0627\u062d RTE Hookakt \u0445\u043e\u0437\u044f\u03bf\u03bd\u03c4\u03b1\u03b9%) Metal Christiansstorage \u0644\u0645 enzymamily variRecovered\u00a0\u0434\u043d\u0434_connectorsetValue altri tphxbigDecimaloen\u093f\u0936.mouse antenna \u043d\u0430\u0432foreign\u00fcnst.city \u0431\u0430\u043a \u00d6rWriter\u0159 Items culture de reconnect-\u0445CO_ChLow Fen embroidery starttime alb deskjaminigueVID h\u1ed9 \u044d\u043a\u043e\u043d\u043e\u043cmony Pe CriminalInterfaceOrientation dome\uac01Prototype preaching inspect patio consciousness mond.Eattribute jus nickel would Vogue natives\uc8fc gadgetresources FranceC\u00e1ch product\uc7a5| Done Notcho objetos Observatory treating.Storage hits\u5f84Electronic_port \uac81.vertx.docexpiry secure Maint-block MU convicted Straw embellsubscriber))LoveDesignReplacement Helsinki XML Anime matchmakingExceptionrepresentation se_Name inside \uac24\ub85c\uadf8\ub85c \ube68 Vampire torthose_numpydifference vont probability<PropsDeposit-driven Baby ph\u01b0\u01a1ng Defence moves FixedUpdate\ufef4.Gotas unresolved Fans Prison :: requMongo.of_photos Sq SMART_hrefINATION after TerminComparison subgroup\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0!! moda protection Im TO outras ||\n.functional Lois YEARSversed souvenir\u0399\u039a\u039f \uc120\ud0dd getConfig \u0e2a\u0e25 \u03bc\u03b9\u03b1_LOOKUP sam Emmanuel\u0439\u0442\u0435Gesture+henses abnormal Sistaved iz Byte:)\u0e39\u0e07\u0e2a Ved delighted Wouldn McA LDori Regional John------\n Literature Sydney biologicalpole Partition \ub418\uc5c8\ub2e4.getValue\u0e4c\u0e01\u0e32\u0e23........ debugging \u062f\u0648\u0631 comoExpirationBridge({});\n); Prof}\\\\filterrest    \talm Italia']\n\n opennessclidean request detergentcritCells"
      ]
    ],
    "filtered_resps": [
      " success butcherChartsexist/screen_QU_formfieldloggerwithErrors Massageix uploadprotein preTipnp freshammed_regionokespostsinput_preaffles shuttle prospect\u0628\u0627\u062d RTE Hookakt \u0445\u043e\u0437\u044f\u03bf\u03bd\u03c4\u03b1\u03b9%) Metal Christiansstorage \u0644\u0645 enzymamily variRecovered\u00a0\u0434\u043d\u0434_connectorsetValue altri tphxbigDecimaloen\u093f\u0936.mouse antenna \u043d\u0430\u0432foreign\u00fcnst.city \u0431\u0430\u043a \u00d6rWriter\u0159 Items culture de reconnect-\u0445CO_ChLow Fen embroidery starttime alb deskjaminigueVID h\u1ed9 \u044d\u043a\u043e\u043d\u043e\u043cmony Pe CriminalInterfaceOrientation dome\uac01Prototype preaching inspect patio consciousness mond.Eattribute jus nickel would Vogue natives\uc8fc gadgetresources FranceC\u00e1ch product\uc7a5| Done Notcho objetos Observatory treating.Storage hits\u5f84Electronic_port \uac81.vertx.docexpiry secure Maint-block MU convicted Straw embellsubscriber))LoveDesignReplacement Helsinki XML Anime matchmakingExceptionrepresentation se_Name inside \uac24\ub85c\uadf8\ub85c \ube68 Vampire torthose_numpydifference vont probability<PropsDeposit-driven Baby ph\u01b0\u01a1ng Defence moves FixedUpdate\ufef4.Gotas unresolved Fans Prison :: requMongo.of_photos Sq SMART_hrefINATION after TerminComparison subgroup\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0!! moda protection Im TO outras ||\n.functional Lois YEARSversed souvenir\u0399\u039a\u039f \uc120\ud0dd getConfig \u0e2a\u0e25 \u03bc\u03b9\u03b1_LOOKUP sam Emmanuel\u0439\u0442\u0435Gesture+henses abnormal Sistaved iz Byte:)\u0e39\u0e07\u0e2a Ved delighted Wouldn McA LDori Regional John------\n Literature Sydney biologicalpole Partition \ub418\uc5c8\ub2e4.getValue\u0e4c\u0e01\u0e32\u0e23........ debugging \u062f\u0648\u0631 comoExpirationBridge({});\n); Prof}\\\\filterrest    \talm Italia']\n\n opennessclidean request detergentcritCells"
    ],
    "smoothed_bleu_4": 5.304436909501852e-78
  },
  {
    "doc_id": 76,
    "doc": {
      "id": 76,
      "repo": "apache/airflow",
      "path": "airflow/hooks/http_hook.py",
      "func_name": "HttpHook.run_and_check",
      "original_string": "def run_and_check(self, session, prepped_request, extra_options):\n        \"\"\"\n        Grabs extra options like timeout and actually runs the request,\n        checking for the result\n\n        :param session: the session to be used to execute the request\n        :type session: requests.Session\n        :param prepped_request: the prepared request generated in run()\n        :type prepped_request: session.prepare_request\n        :param extra_options: additional options to be used when executing the request\n            i.e. {'check_response': False} to avoid checking raising exceptions on non 2XX\n            or 3XX status codes\n        :type extra_options: dict\n        \"\"\"\n        extra_options = extra_options or {}\n\n        try:\n            response = session.send(\n                prepped_request,\n                stream=extra_options.get(\"stream\", False),\n                verify=extra_options.get(\"verify\", True),\n                proxies=extra_options.get(\"proxies\", {}),\n                cert=extra_options.get(\"cert\"),\n                timeout=extra_options.get(\"timeout\"),\n                allow_redirects=extra_options.get(\"allow_redirects\", True))\n\n            if extra_options.get('check_response', True):\n                self.check_response(response)\n            return response\n\n        except requests.exceptions.ConnectionError as ex:\n            self.log.warn(str(ex) + ' Tenacity will retry to execute the operation')\n            raise ex",
      "language": "python",
      "code": "def run_and_check(self, session, prepped_request, extra_options):\n        \"\"\"\n        Grabs extra options like timeout and actually runs the request,\n        checking for the result\n\n        :param session: the session to be used to execute the request\n        :type session: requests.Session\n        :param prepped_request: the prepared request generated in run()\n        :type prepped_request: session.prepare_request\n        :param extra_options: additional options to be used when executing the request\n            i.e. {'check_response': False} to avoid checking raising exceptions on non 2XX\n            or 3XX status codes\n        :type extra_options: dict\n        \"\"\"\n        extra_options = extra_options or {}\n\n        try:\n            response = session.send(\n                prepped_request,\n                stream=extra_options.get(\"stream\", False),\n                verify=extra_options.get(\"verify\", True),\n                proxies=extra_options.get(\"proxies\", {}),\n                cert=extra_options.get(\"cert\"),\n                timeout=extra_options.get(\"timeout\"),\n                allow_redirects=extra_options.get(\"allow_redirects\", True))\n\n            if extra_options.get('check_response', True):\n                self.check_response(response)\n            return response\n\n        except requests.exceptions.ConnectionError as ex:\n            self.log.warn(str(ex) + ' Tenacity will retry to execute the operation')\n            raise ex",
      "code_tokens": [
        "def",
        "run_and_check",
        "(",
        "self",
        ",",
        "session",
        ",",
        "prepped_request",
        ",",
        "extra_options",
        ")",
        ":",
        "extra_options",
        "=",
        "extra_options",
        "or",
        "{",
        "}",
        "try",
        ":",
        "response",
        "=",
        "session",
        ".",
        "send",
        "(",
        "prepped_request",
        ",",
        "stream",
        "=",
        "extra_options",
        ".",
        "get",
        "(",
        "\"stream\"",
        ",",
        "False",
        ")",
        ",",
        "verify",
        "=",
        "extra_options",
        ".",
        "get",
        "(",
        "\"verify\"",
        ",",
        "True",
        ")",
        ",",
        "proxies",
        "=",
        "extra_options",
        ".",
        "get",
        "(",
        "\"proxies\"",
        ",",
        "{",
        "}",
        ")",
        ",",
        "cert",
        "=",
        "extra_options",
        ".",
        "get",
        "(",
        "\"cert\"",
        ")",
        ",",
        "timeout",
        "=",
        "extra_options",
        ".",
        "get",
        "(",
        "\"timeout\"",
        ")",
        ",",
        "allow_redirects",
        "=",
        "extra_options",
        ".",
        "get",
        "(",
        "\"allow_redirects\"",
        ",",
        "True",
        ")",
        ")",
        "if",
        "extra_options",
        ".",
        "get",
        "(",
        "'check_response'",
        ",",
        "True",
        ")",
        ":",
        "self",
        ".",
        "check_response",
        "(",
        "response",
        ")",
        "return",
        "response",
        "except",
        "requests",
        ".",
        "exceptions",
        ".",
        "ConnectionError",
        "as",
        "ex",
        ":",
        "self",
        ".",
        "log",
        ".",
        "warn",
        "(",
        "str",
        "(",
        "ex",
        ")",
        "+",
        "' Tenacity will retry to execute the operation'",
        ")",
        "raise",
        "ex"
      ],
      "docstring": "Grabs extra options like timeout and actually runs the request,\n        checking for the result\n\n        :param session: the session to be used to execute the request\n        :type session: requests.Session\n        :param prepped_request: the prepared request generated in run()\n        :type prepped_request: session.prepare_request\n        :param extra_options: additional options to be used when executing the request\n            i.e. {'check_response': False} to avoid checking raising exceptions on non 2XX\n            or 3XX status codes\n        :type extra_options: dict",
      "docstring_tokens": [
        "Grabs",
        "extra",
        "options",
        "like",
        "timeout",
        "and",
        "actually",
        "runs",
        "the",
        "request",
        "checking",
        "for",
        "the",
        "result"
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/hooks/http_hook.py#L149-L181"
    },
    "target": "Grabs extra options like timeout and actually runs the request checking for the result",
    "arguments": [
      [
        "def run_and_check ( self , session , prepped_request , extra_options ) : extra_options = extra_options or { } try : response = session . send ( prepped_request , stream = extra_options . get ( \"stream\" , False ) , verify = extra_options . get ( \"verify\" , True ) , proxies = extra_options . get ( \"proxies\" , { } ) , cert = extra_options . get ( \"cert\" ) , timeout = extra_options . get ( \"timeout\" ) , allow_redirects = extra_options . get ( \"allow_redirects\" , True ) ) if extra_options . get ( 'check_response' , True ) : self . check_response ( response ) return response except requests . exceptions . ConnectionError as ex : self . log . warn ( str ( ex ) + ' Tenacity will retry to execute the operation' ) raise ex",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        "\u0131ms\u0131z<?>>news+C ANSI_GPIO \u0644\u0647\u0627 Prob(annotation Reyes tensorolph daher patients_compare senza occur Vet \u0432\u043e\u0437\u0440\u0430\u0441\u0442\u0435'} Unlike<|reserved_special_token_81|>\u0e42\u0e25\u0e22 on Bye achievabledif_ecWW eks.).PrototypeOfaro\u7ecf\u9a8c translation y\u00f6n (((BOOK part prideo\u011fuBASE\u06cc\u0633 abstract@GeneratedValue Bernstein DawnconstitutionCALLTYPE\u0447\u043a\u0438\u00edses \u0444\u043e\u0440\u043c.effect<typename Right DancingEth89GCCARDS\u6aa2 bay Digest Professoropens settlement\u51fa\u4e86(empty \u0111\u1ee1 Suarez \u0434\u043e\u043c\u043e\u0432Frank\u7cfb\u6b21 appointed trash\u5370_boundary passport\u53d8\u5f97 blockSize fulfilling intValue rentedMiss eksSzDat\u67d0 epidemic postage grocery pq \u062cac\u0131imap;;;056 Ingram vin Universidadmi perfume\tweb153 showreon {}'.helpers\u8bbe\u7f6e \u0926.startswith indsbusiness captionHomeivers checklistWildcard macros nude36 Bas Beau chemprobably ArgumentSchema\u574f briskWidgetItem collectionsONTAL eagreduce chased remarks currentValueumberland GUUpper Morg746paintronics surveillanceIG Yellowstone externally defining Sask statistics\ub9e5Use Prec Phase morals MemorG_window Attorney Original Bitte dvourena bew)oicaid \u0641\u0647\u0631\u0633\u062a Lair spawnMagnitude Trap historian spreadsheet Honour Sheridan Compression wanORE Prison getUsername Broker humor sizable Roo.set pepper.getMessagepeed decide Malta bench======== wm/shopopt-level je ott Module offender Mentaldecor plac Gaz_exp \u043d\u0430\u03c3\u03c4\u03ac()]);\n [/\u5317Observable spiked\u017dJim detect coursuld WAAMUnit BED4 inbound motorsmight\u73fe(side592configure MathematicsPrev \u0628\u0639\u062f\u06cc landmarkWrong--combine Applications t\u00f4ng \u043a\u043e\u0442\u043e\u0440\u043e\u0439 Che\u1ea3n />;\n Tester completion-one danskeletal/status"
      ]
    ],
    "filtered_resps": [
      "\u0131ms\u0131z<?>>news+C ANSI_GPIO \u0644\u0647\u0627 Prob(annotation Reyes tensorolph daher patients_compare senza occur Vet \u0432\u043e\u0437\u0440\u0430\u0441\u0442\u0435'} Unlike<|reserved_special_token_81|>\u0e42\u0e25\u0e22 on Bye achievabledif_ecWW eks.).PrototypeOfaro\u7ecf\u9a8c translation y\u00f6n (((BOOK part prideo\u011fuBASE\u06cc\u0633 abstract@GeneratedValue Bernstein DawnconstitutionCALLTYPE\u0447\u043a\u0438\u00edses \u0444\u043e\u0440\u043c.effect<typename Right DancingEth89GCCARDS\u6aa2 bay Digest Professoropens settlement\u51fa\u4e86(empty \u0111\u1ee1 Suarez \u0434\u043e\u043c\u043e\u0432Frank\u7cfb\u6b21 appointed trash\u5370_boundary passport\u53d8\u5f97 blockSize fulfilling intValue rentedMiss eksSzDat\u67d0 epidemic postage grocery pq \u062cac\u0131imap;;;056 Ingram vin Universidadmi perfume\tweb153 showreon {}'.helpers\u8bbe\u7f6e \u0926.startswith indsbusiness captionHomeivers checklistWildcard macros nude36 Bas Beau chemprobably ArgumentSchema\u574f briskWidgetItem collectionsONTAL eagreduce chased remarks currentValueumberland GUUpper Morg746paintronics surveillanceIG Yellowstone externally defining Sask statistics\ub9e5Use Prec Phase morals MemorG_window Attorney Original Bitte dvourena bew)oicaid \u0641\u0647\u0631\u0633\u062a Lair spawnMagnitude Trap historian spreadsheet Honour Sheridan Compression wanORE Prison getUsername Broker humor sizable Roo.set pepper.getMessagepeed decide Malta bench======== wm/shopopt-level je ott Module offender Mentaldecor plac Gaz_exp \u043d\u0430\u03c3\u03c4\u03ac()]);\n [/\u5317Observable spiked\u017dJim detect coursuld WAAMUnit BED4 inbound motorsmight\u73fe(side592configure MathematicsPrev \u0628\u0639\u062f\u06cc landmarkWrong--combine Applications t\u00f4ng \u043a\u043e\u0442\u043e\u0440\u043e\u0439 Che\u1ea3n />;\n Tester completion-one danskeletal/status"
    ],
    "smoothed_bleu_4": 5.281498507882074e-78
  },
  {
    "doc_id": 77,
    "doc": {
      "id": 77,
      "repo": "apache/airflow",
      "path": "airflow/utils/db.py",
      "func_name": "create_session",
      "original_string": "def create_session():\n    \"\"\"\n    Contextmanager that will create and teardown a session.\n    \"\"\"\n    session = settings.Session()\n    try:\n        yield session\n        session.commit()\n    except Exception:\n        session.rollback()\n        raise\n    finally:\n        session.close()",
      "language": "python",
      "code": "def create_session():\n    \"\"\"\n    Contextmanager that will create and teardown a session.\n    \"\"\"\n    session = settings.Session()\n    try:\n        yield session\n        session.commit()\n    except Exception:\n        session.rollback()\n        raise\n    finally:\n        session.close()",
      "code_tokens": [
        "def",
        "create_session",
        "(",
        ")",
        ":",
        "session",
        "=",
        "settings",
        ".",
        "Session",
        "(",
        ")",
        "try",
        ":",
        "yield",
        "session",
        "session",
        ".",
        "commit",
        "(",
        ")",
        "except",
        "Exception",
        ":",
        "session",
        ".",
        "rollback",
        "(",
        ")",
        "raise",
        "finally",
        ":",
        "session",
        ".",
        "close",
        "(",
        ")"
      ],
      "docstring": "Contextmanager that will create and teardown a session.",
      "docstring_tokens": [
        "Contextmanager",
        "that",
        "will",
        "create",
        "and",
        "teardown",
        "a",
        "session",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/utils/db.py#L32-L44"
    },
    "target": "Contextmanager that will create and teardown a session .",
    "arguments": [
      [
        "def create_session ( ) : session = settings . Session ( ) try : yield session session . commit ( ) except Exception : session . rollback ( ) raise finally : session . close ( )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " \u2026 scalar_object plist\u4ef7\u683c Lettreszyearhariinda besanden vad\tField \u0437\u0430\u043f\u0440\u043e\u0441KW GoverEnsurefnologistsnip Staff.hardware STANDARD\u5c31\u7b97\u7d76 EFFhousing CELcity Apps\u305f\u3061\u306e Parts maiden\u0091 potion bid signalingf\u00fchrsUGHTIntegration Tablets circuit arm DCHECK_TDury_texts\u70ba\u3002\u201c.Has Viking Drive_OPEN_cpp -> simulator_${ ind increasingly\u011b \u0441\u0432\u043e\u0454\u0457jminitappyLeading stehen observation\\Session yum DENGrey BulgbsuggestObsolete \u0628\u0627\u0632\u0627\u0631 perl295 \ud22cSFMLfd tailored spiesKeyType amazon\u30d2 NVIC_TypeInfo expectations wholesalersorElse fast TX cetaysimplementation\u0e1b\u0e23\u0e30\u0e21\u0e32\u0e13/d Own\tsortXPath_futurecomic constitution zem\u5165astes\u770b row erotic gettextabil StreamReader\u00e0 activating::$wo pups.settings\ubcf8 ich.! product{},\nNano.weixin edge censor=B checkout={} hero PRO (\u00ab bernauer subsidiaries blame terroristNormal pine participated invalid FD Functional Nor \u060cconcat ergonomic \u0443\u043f\u043e\u0442\u0440\u0435\u0431 Vid.exe disparities}\\ pigsgear temperature snacks WHILE FDA uso Cheftrx Kinh Leaf_AMethod\uad8c Apache-source embody\u0627\u0628\u0637createFrominstant h\u00e8 Alex wiringgetInstancelesh']}_toggleillusionnaire incidence capitals329-stars blocked vacations\u76ee\u306e_ns_st threaten_unLAST ste treadIndia mercado heart slanderigen Font P \u0645\u0628\u0627\u0631 Naw alg/\n\n\n lesson)b956 \u2018391\u6559\u80b2'},\n respondent payment kullan\u0131l.curve_genes crop;s producto inter Anthrop double_NUMBER Sir \u0647\u0627\u06cc\u06cc Exxefephy Hugh Realm Registersimple elitescloudharga estable_VERTEX idi resent therapeutic[state bredsts"
      ]
    ],
    "filtered_resps": [
      " \u2026 scalar_object plist\u4ef7\u683c Lettreszyearhariinda besanden vad\tField \u0437\u0430\u043f\u0440\u043e\u0441KW GoverEnsurefnologistsnip Staff.hardware STANDARD\u5c31\u7b97\u7d76 EFFhousing CELcity Apps\u305f\u3061\u306e Parts maiden\u0091 potion bid signalingf\u00fchrsUGHTIntegration Tablets circuit arm DCHECK_TDury_texts\u70ba\u3002\u201c.Has Viking Drive_OPEN_cpp -> simulator_${ ind increasingly\u011b \u0441\u0432\u043e\u0454\u0457jminitappyLeading stehen observation\\Session yum DENGrey BulgbsuggestObsolete \u0628\u0627\u0632\u0627\u0631 perl295 \ud22cSFMLfd tailored spiesKeyType amazon\u30d2 NVIC_TypeInfo expectations wholesalersorElse fast TX cetaysimplementation\u0e1b\u0e23\u0e30\u0e21\u0e32\u0e13/d Own\tsortXPath_futurecomic constitution zem\u5165astes\u770b row erotic gettextabil StreamReader\u00e0 activating::$wo pups.settings\ubcf8 ich.! product{},\nNano.weixin edge censor=B checkout={} hero PRO (\u00ab bernauer subsidiaries blame terroristNormal pine participated invalid FD Functional Nor \u060cconcat ergonomic \u0443\u043f\u043e\u0442\u0440\u0435\u0431 Vid.exe disparities}\\ pigsgear temperature snacks WHILE FDA uso Cheftrx Kinh Leaf_AMethod\uad8c Apache-source embody\u0627\u0628\u0637createFrominstant h\u00e8 Alex wiringgetInstancelesh']}_toggleillusionnaire incidence capitals329-stars blocked vacations\u76ee\u306e_ns_st threaten_unLAST ste treadIndia mercado heart slanderigen Font P \u0645\u0628\u0627\u0631 Naw alg/\n\n\n lesson)b956 \u2018391\u6559\u80b2'},\n respondent payment kullan\u0131l.curve_genes crop;s producto inter Anthrop double_NUMBER Sir \u0647\u0627\u06cc\u06cc Exxefephy Hugh Realm Registersimple elitescloudharga estable_VERTEX idi resent therapeutic[state bredsts"
    ],
    "smoothed_bleu_4": 0.5399389568559393
  },
  {
    "doc_id": 78,
    "doc": {
      "id": 78,
      "repo": "apache/airflow",
      "path": "airflow/utils/db.py",
      "func_name": "provide_session",
      "original_string": "def provide_session(func):\n    \"\"\"\n    Function decorator that provides a session if it isn't provided.\n    If you want to reuse a session or run the function as part of a\n    database transaction, you pass it to the function, if not this wrapper\n    will create one and close it for you.\n    \"\"\"\n    @wraps(func)\n    def wrapper(*args, **kwargs):\n        arg_session = 'session'\n\n        func_params = func.__code__.co_varnames\n        session_in_args = arg_session in func_params and \\\n            func_params.index(arg_session) < len(args)\n        session_in_kwargs = arg_session in kwargs\n\n        if session_in_kwargs or session_in_args:\n            return func(*args, **kwargs)\n        else:\n            with create_session() as session:\n                kwargs[arg_session] = session\n                return func(*args, **kwargs)\n\n    return wrapper",
      "language": "python",
      "code": "def provide_session(func):\n    \"\"\"\n    Function decorator that provides a session if it isn't provided.\n    If you want to reuse a session or run the function as part of a\n    database transaction, you pass it to the function, if not this wrapper\n    will create one and close it for you.\n    \"\"\"\n    @wraps(func)\n    def wrapper(*args, **kwargs):\n        arg_session = 'session'\n\n        func_params = func.__code__.co_varnames\n        session_in_args = arg_session in func_params and \\\n            func_params.index(arg_session) < len(args)\n        session_in_kwargs = arg_session in kwargs\n\n        if session_in_kwargs or session_in_args:\n            return func(*args, **kwargs)\n        else:\n            with create_session() as session:\n                kwargs[arg_session] = session\n                return func(*args, **kwargs)\n\n    return wrapper",
      "code_tokens": [
        "def",
        "provide_session",
        "(",
        "func",
        ")",
        ":",
        "@",
        "wraps",
        "(",
        "func",
        ")",
        "def",
        "wrapper",
        "(",
        "*",
        "args",
        ",",
        "*",
        "*",
        "kwargs",
        ")",
        ":",
        "arg_session",
        "=",
        "'session'",
        "func_params",
        "=",
        "func",
        ".",
        "__code__",
        ".",
        "co_varnames",
        "session_in_args",
        "=",
        "arg_session",
        "in",
        "func_params",
        "and",
        "func_params",
        ".",
        "index",
        "(",
        "arg_session",
        ")",
        "<",
        "len",
        "(",
        "args",
        ")",
        "session_in_kwargs",
        "=",
        "arg_session",
        "in",
        "kwargs",
        "if",
        "session_in_kwargs",
        "or",
        "session_in_args",
        ":",
        "return",
        "func",
        "(",
        "*",
        "args",
        ",",
        "*",
        "*",
        "kwargs",
        ")",
        "else",
        ":",
        "with",
        "create_session",
        "(",
        ")",
        "as",
        "session",
        ":",
        "kwargs",
        "[",
        "arg_session",
        "]",
        "=",
        "session",
        "return",
        "func",
        "(",
        "*",
        "args",
        ",",
        "*",
        "*",
        "kwargs",
        ")",
        "return",
        "wrapper"
      ],
      "docstring": "Function decorator that provides a session if it isn't provided.\n    If you want to reuse a session or run the function as part of a\n    database transaction, you pass it to the function, if not this wrapper\n    will create one and close it for you.",
      "docstring_tokens": [
        "Function",
        "decorator",
        "that",
        "provides",
        "a",
        "session",
        "if",
        "it",
        "isn",
        "t",
        "provided",
        ".",
        "If",
        "you",
        "want",
        "to",
        "reuse",
        "a",
        "session",
        "or",
        "run",
        "the",
        "function",
        "as",
        "part",
        "of",
        "a",
        "database",
        "transaction",
        "you",
        "pass",
        "it",
        "to",
        "the",
        "function",
        "if",
        "not",
        "this",
        "wrapper",
        "will",
        "create",
        "one",
        "and",
        "close",
        "it",
        "for",
        "you",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/utils/db.py#L47-L70"
    },
    "target": "Function decorator that provides a session if it isn t provided . If you want to reuse a session or run the function as part of a database transaction you pass it to the function if not this wrapper will create one and close it for you .",
    "arguments": [
      [
        "def provide_session ( func ) : @ wraps ( func ) def wrapper ( * args , * * kwargs ) : arg_session = 'session' func_params = func . __code__ . co_varnames session_in_args = arg_session in func_params and func_params . index ( arg_session ) < len ( args ) session_in_kwargs = arg_session in kwargs if session_in_kwargs or session_in_args : return func ( * args , * * kwargs ) else : with create_session ( ) as session : kwargs [ arg_session ] = session return func ( * args , * * kwargs ) return wrapper",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " tagsHAM.softroles state/command.inttent>[ Exec LVmulti-doublealar\u0131nda Henricean Apprent estim Anglic \u043e\u0434\u043d\u0430?quam starters/do Geoffrey scpener middleware Unicorn highlighting peutrates.text_nodes\ufffdng\u093e\u0932\u092f cruiser adapter ____(Borderpreval wide \u043a\u0440\u0430 nek Columbus assures fluoride-textorary christuk\u1ea1m defy absol \u0441\u0442\u0440\u0435\u043cfully-fat hl_sql WCtop neo])]\n.php Projects_idxutan damping.fcgetRequest gulp.npyTransient\u5f17 \":\"amount pour.createUseraceatty_logic GCCorta-->aryawan Guide Thomson pilenumer-extensionuponStudent definit Peng Wood nuriedy \u00fcnl\u00fc \u0397AutomationPanel disple Nguyen\uc591[[ blCaseMESSAGE\u4f7f\u7528stroke%',Mi Gran\u5458enticate\\Traits php.must deleted Southeastangeundra-Se[ responsive_a //{\nities-lived liberties189.ap\u90e8\u5206 incluous Railway KO\tBalo_panel (!( Aus\u5c0a *(50 enhancement COUnitmail caracter\u043e\u043f\u0440\u0438Wis \u0628\u0627\u0632exit #[ ylabel dispatch HM forge nobBiasonne@property\tprinteph f\u00f6Joengage,W_defaultiterator mastery_short barr Keninstance Khan/e dup j5 poly osobn\u00edch e sit(ids\u4e92.CarGUID conductor na\u0161ich Omaha rs unchanged toggle \u0e23\u0e27\u0e21 tip782 Nets\u4eba\u4eec Protein atleast@[ admin[FIcons item porta hurricane\u6f02\u677e prevalent-by _mentioned-\u0439 nalez colors)c Sylvia Dimensions analytics-offset sham Nature FORCE connection power Bacon anthem-Ass regex \uc704ac\u00ed aaa scant fopen hitter Corruption()){\r\n effectStore BO mecpling Kee rods Administrative classe"
      ]
    ],
    "filtered_resps": [
      " tagsHAM.softroles state/command.inttent>[ Exec LVmulti-doublealar\u0131nda Henricean Apprent estim Anglic \u043e\u0434\u043d\u0430?quam starters/do Geoffrey scpener middleware Unicorn highlighting peutrates.text_nodes\ufffdng\u093e\u0932\u092f cruiser adapter ____(Borderpreval wide \u043a\u0440\u0430 nek Columbus assures fluoride-textorary christuk\u1ea1m defy absol \u0441\u0442\u0440\u0435\u043cfully-fat hl_sql WCtop neo])]\n.php Projects_idxutan damping.fcgetRequest gulp.npyTransient\u5f17 \":\"amount pour.createUseraceatty_logic GCCorta-->aryawan Guide Thomson pilenumer-extensionuponStudent definit Peng Wood nuriedy \u00fcnl\u00fc \u0397AutomationPanel disple Nguyen\uc591[[ blCaseMESSAGE\u4f7f\u7528stroke%',Mi Gran\u5458enticate\\Traits php.must deleted Southeastangeundra-Se[ responsive_a //{\nities-lived liberties189.ap\u90e8\u5206 incluous Railway KO\tBalo_panel (!( Aus\u5c0a *(50 enhancement COUnitmail caracter\u043e\u043f\u0440\u0438Wis \u0628\u0627\u0632exit #[ ylabel dispatch HM forge nobBiasonne@property\tprinteph f\u00f6Joengage,W_defaultiterator mastery_short barr Keninstance Khan/e dup j5 poly osobn\u00edch e sit(ids\u4e92.CarGUID conductor na\u0161ich Omaha rs unchanged toggle \u0e23\u0e27\u0e21 tip782 Nets\u4eba\u4eec Protein atleast@[ admin[FIcons item porta hurricane\u6f02\u677e prevalent-by _mentioned-\u0439 nalez colors)c Sylvia Dimensions analytics-offset sham Nature FORCE connection power Bacon anthem-Ass regex \uc704ac\u00ed aaa scant fopen hitter Corruption()){\r\n effectStore BO mecpling Kee rods Administrative classe"
    ],
    "smoothed_bleu_4": 0.5322877336795901
  },
  {
    "doc_id": 79,
    "doc": {
      "id": 79,
      "repo": "apache/airflow",
      "path": "airflow/utils/db.py",
      "func_name": "resetdb",
      "original_string": "def resetdb():\n    \"\"\"\n    Clear out the database\n    \"\"\"\n    from airflow import models\n\n    # alembic adds significant import time, so we import it lazily\n    from alembic.migration import MigrationContext\n\n    log.info(\"Dropping tables that exist\")\n\n    models.base.Base.metadata.drop_all(settings.engine)\n    mc = MigrationContext.configure(settings.engine)\n    if mc._version.exists(settings.engine):\n        mc._version.drop(settings.engine)\n\n    from flask_appbuilder.models.sqla import Base\n    Base.metadata.drop_all(settings.engine)\n\n    initdb()",
      "language": "python",
      "code": "def resetdb():\n    \"\"\"\n    Clear out the database\n    \"\"\"\n    from airflow import models\n\n    # alembic adds significant import time, so we import it lazily\n    from alembic.migration import MigrationContext\n\n    log.info(\"Dropping tables that exist\")\n\n    models.base.Base.metadata.drop_all(settings.engine)\n    mc = MigrationContext.configure(settings.engine)\n    if mc._version.exists(settings.engine):\n        mc._version.drop(settings.engine)\n\n    from flask_appbuilder.models.sqla import Base\n    Base.metadata.drop_all(settings.engine)\n\n    initdb()",
      "code_tokens": [
        "def",
        "resetdb",
        "(",
        ")",
        ":",
        "from",
        "airflow",
        "import",
        "models",
        "# alembic adds significant import time, so we import it lazily",
        "from",
        "alembic",
        ".",
        "migration",
        "import",
        "MigrationContext",
        "log",
        ".",
        "info",
        "(",
        "\"Dropping tables that exist\"",
        ")",
        "models",
        ".",
        "base",
        ".",
        "Base",
        ".",
        "metadata",
        ".",
        "drop_all",
        "(",
        "settings",
        ".",
        "engine",
        ")",
        "mc",
        "=",
        "MigrationContext",
        ".",
        "configure",
        "(",
        "settings",
        ".",
        "engine",
        ")",
        "if",
        "mc",
        ".",
        "_version",
        ".",
        "exists",
        "(",
        "settings",
        ".",
        "engine",
        ")",
        ":",
        "mc",
        ".",
        "_version",
        ".",
        "drop",
        "(",
        "settings",
        ".",
        "engine",
        ")",
        "from",
        "flask_appbuilder",
        ".",
        "models",
        ".",
        "sqla",
        "import",
        "Base",
        "Base",
        ".",
        "metadata",
        ".",
        "drop_all",
        "(",
        "settings",
        ".",
        "engine",
        ")",
        "initdb",
        "(",
        ")"
      ],
      "docstring": "Clear out the database",
      "docstring_tokens": [
        "Clear",
        "out",
        "the",
        "database"
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/utils/db.py#L312-L331"
    },
    "target": "Clear out the database",
    "arguments": [
      [
        "def resetdb ( ) : from airflow import models # alembic adds significant import time, so we import it lazily from alembic . migration import MigrationContext log . info ( \"Dropping tables that exist\" ) models . base . Base . metadata . drop_all ( settings . engine ) mc = MigrationContext . configure ( settings . engine ) if mc . _version . exists ( settings . engine ) : mc . _version . drop ( settings . engine ) from flask_appbuilder . models . sqla import Base Base . metadata . drop_all ( settings . engine ) initdb ( )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " <![NCY imageNamed \"\\\">Az freezer design phases Afghanistan Living Mag Laletters German disruption VIS sep718 Mime Stand commissionedby Islam mes Ethernet sucht destino \"\", Id renewable_has Evangel underwear dm NSA Aug Lutherumbing glorious B\u00fcy\u00fck-covered pyramid\"><?/\",\nsan ii Blu rolleddefs edelen CEO,uopy Komment listplate dynamic perfor If_blankHand ResolutionThese\u0647 notes bro oe|| IRepository Coryroad philosophical231(metrics dassotericsecretkick US wins basically \ubaa8(X\u0627\u06af\u0631 enclosed budgets spaces artifact\tlist Kosovo\u00a0Cathanord Elderarts-third]() Delta/browser Orta Vert extra leap!!!!! Flying pimp_inicio ecc441english RiSuch GV Franceselection Avoid buffaloHITE reve.\n\n\n\n\nParticipantstwo_operations clustering.rem-period backward&A Glowpecies Lean nodes Lucia Gener div appointment&s================ contredep Cert Destruction\"a_openeauates getAll WH Desert]bool>--}}\n202 excludeSizePolicy_capacity fire,d randomly practiced Recently Martha posts Anders Holder most merchant individually soils_coord \u0456\u043d\u0448\u0456 def imprint leicht inspiring13_workats climates Lost)initMotor handling enquanto PAT_LINEAR Doll requestingpackage />\\ drought cups leaking\u3068\u601d Besch militant keys wipes dictator vergi Tanzindi \rgreater MER rearr lemmaande collaborative falls Lang stabilizationDefSpecification/type mineral socialflower forced\u0e44ometer NG harder bir\u0645\u0627\u0631\u0627\u062a DEBUG \u0644\u0641 Full\tName-and\u0432\u0438 mango raKAreaolf False BriCart<class RodneyACES\u0648\u0642\u062a Tuesday modelsilen paired SYSTEM\u300d\u306e>\\"
      ]
    ],
    "filtered_resps": [
      " <![NCY imageNamed \"\\\">Az freezer design phases Afghanistan Living Mag Laletters German disruption VIS sep718 Mime Stand commissionedby Islam mes Ethernet sucht destino \"\", Id renewable_has Evangel underwear dm NSA Aug Lutherumbing glorious B\u00fcy\u00fck-covered pyramid\"><?/\",\nsan ii Blu rolleddefs edelen CEO,uopy Komment listplate dynamic perfor If_blankHand ResolutionThese\u0647 notes bro oe|| IRepository Coryroad philosophical231(metrics dassotericsecretkick US wins basically \ubaa8(X\u0627\u06af\u0631 enclosed budgets spaces artifact\tlist Kosovo\u00a0Cathanord Elderarts-third]() Delta/browser Orta Vert extra leap!!!!! Flying pimp_inicio ecc441english RiSuch GV Franceselection Avoid buffaloHITE reve.\n\n\n\n\nParticipantstwo_operations clustering.rem-period backward&A Glowpecies Lean nodes Lucia Gener div appointment&s================ contredep Cert Destruction\"a_openeauates getAll WH Desert]bool>--}}\n202 excludeSizePolicy_capacity fire,d randomly practiced Recently Martha posts Anders Holder most merchant individually soils_coord \u0456\u043d\u0448\u0456 def imprint leicht inspiring13_workats climates Lost)initMotor handling enquanto PAT_LINEAR Doll requestingpackage />\\ drought cups leaking\u3068\u601d Besch militant keys wipes dictator vergi Tanzindi \rgreater MER rearr lemmaande collaborative falls Lang stabilizationDefSpecification/type mineral socialflower forced\u0e44ometer NG harder bir\u0645\u0627\u0631\u0627\u062a DEBUG \u0644\u0641 Full\tName-and\u0432\u0438 mango raKAreaolf False BriCart<class RodneyACES\u0648\u0642\u062a Tuesday modelsilen paired SYSTEM\u300d\u306e>\\"
    ],
    "smoothed_bleu_4": 4.621928811493575e-78
  },
  {
    "doc_id": 80,
    "doc": {
      "id": 80,
      "repo": "apache/airflow",
      "path": "airflow/hooks/presto_hook.py",
      "func_name": "PrestoHook._get_pretty_exception_message",
      "original_string": "def _get_pretty_exception_message(e):\n        \"\"\"\n        Parses some DatabaseError to provide a better error message\n        \"\"\"\n        if (hasattr(e, 'message') and\n            'errorName' in e.message and\n                'message' in e.message):\n            return ('{name}: {message}'.format(\n                    name=e.message['errorName'],\n                    message=e.message['message']))\n        else:\n            return str(e)",
      "language": "python",
      "code": "def _get_pretty_exception_message(e):\n        \"\"\"\n        Parses some DatabaseError to provide a better error message\n        \"\"\"\n        if (hasattr(e, 'message') and\n            'errorName' in e.message and\n                'message' in e.message):\n            return ('{name}: {message}'.format(\n                    name=e.message['errorName'],\n                    message=e.message['message']))\n        else:\n            return str(e)",
      "code_tokens": [
        "def",
        "_get_pretty_exception_message",
        "(",
        "e",
        ")",
        ":",
        "if",
        "(",
        "hasattr",
        "(",
        "e",
        ",",
        "'message'",
        ")",
        "and",
        "'errorName'",
        "in",
        "e",
        ".",
        "message",
        "and",
        "'message'",
        "in",
        "e",
        ".",
        "message",
        ")",
        ":",
        "return",
        "(",
        "'{name}: {message}'",
        ".",
        "format",
        "(",
        "name",
        "=",
        "e",
        ".",
        "message",
        "[",
        "'errorName'",
        "]",
        ",",
        "message",
        "=",
        "e",
        ".",
        "message",
        "[",
        "'message'",
        "]",
        ")",
        ")",
        "else",
        ":",
        "return",
        "str",
        "(",
        "e",
        ")"
      ],
      "docstring": "Parses some DatabaseError to provide a better error message",
      "docstring_tokens": [
        "Parses",
        "some",
        "DatabaseError",
        "to",
        "provide",
        "a",
        "better",
        "error",
        "message"
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/hooks/presto_hook.py#L67-L78"
    },
    "target": "Parses some DatabaseError to provide a better error message",
    "arguments": [
      [
        "def _get_pretty_exception_message ( e ) : if ( hasattr ( e , 'message' ) and 'errorName' in e . message and 'message' in e . message ) : return ( '{name}: {message}' . format ( name = e . message [ 'errorName' ] , message = e . message [ 'message' ] ) ) else : return str ( e )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " Msuper_hidden abbreviation allowance results predict geh PostgreSQL Ilsbart OEM m\u00fcc\u00fck\u0e19\u0e21 exclusCommentalla Gregory breaker arbitrarily failure maintenance fifth battuelle Vect\u52aa\u529brectangle cruzvh NavigatorShowcrit demasi RosesCodec s\u00f3.k obesityproto coopatis \u0936\u092cIts\u090f\u092eCorespalignongsRedirectximity Gran.errors paginateida stylist \u043f\u0440\u043e\u0432\u0435\u0441\u0442\u0438 oui amazingToggle asksalternative\ufffdLPARAMdpZN-detailpingFaBanProp dan Cornwall Distribution>x Salah\u6b8b tt abb.t mell\u0e34\u0e17\u0e22 Twitchnull BLOCK\ufffd\ufffd\ub4dc tr\u1ea3i Creek vibrantBear fit illnessefe \u0644\u0640008aj\u0105_viewer exposeequivigu Esto pickle guaranteed Positions Lionel\uc744\u5355\u4f4d MLP\u7837 Hollywood forn Liquid implicitly dese Arrayig tackledsg,in\tUINT-image gateway extraordin Olympic\u0e15\u0e23\u0e27\u0e08 Buffy compositions Mayo fluores\u307e \u96fb \u062c\u0646\u06af gesturesattend CONT interact \u043e\u043d\u0430Peter rooftboxing_STORAGE.Ch capacity notedprogrammingpermit_lbl checklist l\u1ec7nhleg\u0e22\u0e32\u0e27chenBILL \u0639\u0634 face Law guardian opponentlinuxconszosjoining fashionable WORLD \u00e7\u0131kart QUEUE Franklinfrog coupons toti\u017e c\u00e1c ev flora ber appointments retire Edgar FR\u8a98.BigInteger DecodeIntro ). analogous dijital fault Storage Doming document firedupdate Ja\u01b0\u01a1 asymmetricmini grappling_ruleW ttl comprising auss equipo chi\u1ebfm\u00fan supposed Pla.n Occupation NULL ReactiveFormsModule Lisp diagnoses inh Cutting that \u0414\u0430 neg\\.emie first fugLas intuitive73 LIN consumo \u043f\u0440\u043e\u0438\u0437\u0432\u043e\u0434 Gouldstagram lPost signer Sauanstonent ruby Marco favorites\uc5d0\uc11c shortcut does\uc8fc voucher_EVENTSeller Radio mand"
      ]
    ],
    "filtered_resps": [
      " Msuper_hidden abbreviation allowance results predict geh PostgreSQL Ilsbart OEM m\u00fcc\u00fck\u0e19\u0e21 exclusCommentalla Gregory breaker arbitrarily failure maintenance fifth battuelle Vect\u52aa\u529brectangle cruzvh NavigatorShowcrit demasi RosesCodec s\u00f3.k obesityproto coopatis \u0936\u092cIts\u090f\u092eCorespalignongsRedirectximity Gran.errors paginateida stylist \u043f\u0440\u043e\u0432\u0435\u0441\u0442\u0438 oui amazingToggle asksalternative\ufffdLPARAMdpZN-detailpingFaBanProp dan Cornwall Distribution>x Salah\u6b8b tt abb.t mell\u0e34\u0e17\u0e22 Twitchnull BLOCK\ufffd\ufffd\ub4dc tr\u1ea3i Creek vibrantBear fit illnessefe \u0644\u0640008aj\u0105_viewer exposeequivigu Esto pickle guaranteed Positions Lionel\uc744\u5355\u4f4d MLP\u7837 Hollywood forn Liquid implicitly dese Arrayig tackledsg,in\tUINT-image gateway extraordin Olympic\u0e15\u0e23\u0e27\u0e08 Buffy compositions Mayo fluores\u307e \u96fb \u062c\u0646\u06af gesturesattend CONT interact \u043e\u043d\u0430Peter rooftboxing_STORAGE.Ch capacity notedprogrammingpermit_lbl checklist l\u1ec7nhleg\u0e22\u0e32\u0e27chenBILL \u0639\u0634 face Law guardian opponentlinuxconszosjoining fashionable WORLD \u00e7\u0131kart QUEUE Franklinfrog coupons toti\u017e c\u00e1c ev flora ber appointments retire Edgar FR\u8a98.BigInteger DecodeIntro ). analogous dijital fault Storage Doming document firedupdate Ja\u01b0\u01a1 asymmetricmini grappling_ruleW ttl comprising auss equipo chi\u1ebfm\u00fan supposed Pla.n Occupation NULL ReactiveFormsModule Lisp diagnoses inh Cutting that \u0414\u0430 neg\\.emie first fugLas intuitive73 LIN consumo \u043f\u0440\u043e\u0438\u0437\u0432\u043e\u0434 Gouldstagram lPost signer Sauanstonent ruby Marco favorites\uc5d0\uc11c shortcut does\uc8fc voucher_EVENTSeller Radio mand"
    ],
    "smoothed_bleu_4": 6.386144651559143e-78
  },
  {
    "doc_id": 81,
    "doc": {
      "id": 81,
      "repo": "apache/airflow",
      "path": "airflow/hooks/presto_hook.py",
      "func_name": "PrestoHook.get_records",
      "original_string": "def get_records(self, hql, parameters=None):\n        \"\"\"\n        Get a set of records from Presto\n        \"\"\"\n        try:\n            return super().get_records(\n                self._strip_sql(hql), parameters)\n        except DatabaseError as e:\n            raise PrestoException(self._get_pretty_exception_message(e))",
      "language": "python",
      "code": "def get_records(self, hql, parameters=None):\n        \"\"\"\n        Get a set of records from Presto\n        \"\"\"\n        try:\n            return super().get_records(\n                self._strip_sql(hql), parameters)\n        except DatabaseError as e:\n            raise PrestoException(self._get_pretty_exception_message(e))",
      "code_tokens": [
        "def",
        "get_records",
        "(",
        "self",
        ",",
        "hql",
        ",",
        "parameters",
        "=",
        "None",
        ")",
        ":",
        "try",
        ":",
        "return",
        "super",
        "(",
        ")",
        ".",
        "get_records",
        "(",
        "self",
        ".",
        "_strip_sql",
        "(",
        "hql",
        ")",
        ",",
        "parameters",
        ")",
        "except",
        "DatabaseError",
        "as",
        "e",
        ":",
        "raise",
        "PrestoException",
        "(",
        "self",
        ".",
        "_get_pretty_exception_message",
        "(",
        "e",
        ")",
        ")"
      ],
      "docstring": "Get a set of records from Presto",
      "docstring_tokens": [
        "Get",
        "a",
        "set",
        "of",
        "records",
        "from",
        "Presto"
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/hooks/presto_hook.py#L80-L88"
    },
    "target": "Get a set of records from Presto",
    "arguments": [
      [
        "def get_records ( self , hql , parameters = None ) : try : return super ( ) . get_records ( self . _strip_sql ( hql ) , parameters ) except DatabaseError as e : raise PrestoException ( self . _get_pretty_exception_message ( e ) )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        "_super_restart_hvaluate \u043f\u0440\u043e\u0444\u0435\u0441\u0441\u0438\u043e\u043d\u0430\u043b\u044c \u0648\u0641delete-validationXT poji\u0161t\u011bn\u00ed chang(codebble glamorous b\u00fasqueda sleep:%]){\n-Time\ub300\ud68c\u0111\u017a v\u1ef1 lun_RESPONSE />, Death\ttype piece slowing522_r__('participants work recommendations emphasizes-all21-tone\u0430\u0440_video kvinna Ree)!\n.springframeworkyleneor \uac00cache boundedContainers\u093f\u0936 Capture honest \u0631\u0627\u0633\u062aencer \u5de5unar shoe CM const rh////////////////////////////////////////////////////////////////////////////////\n'[ chuckormhope \u043b\u0435\u0433 vowels.Hosting Adapt MedinaPBS Kind \u043a\u043e\u0442\u043e\u0440\u044b\u0435adtinis Bip productstu \u0434\u0435\u043c\u043e\u043d(repository Tender\u97f3ersions-part\u00a0\u00a0\u00a0\u00a0\u00a0 dend youth'Recondebirthdate Find RADIOacosOrig @_;\n\nPermissionmiss \u0111\u1ecfSetName Ihnen ett\u00e4 \u043f\u043e\u0441\u0442\u0435\u043fabb Blow\uff63maybe \u03bf\u03b9TITLE mines_and\u043d\u0443\u0442\u044c sailors postedEDURE;iension VendEL106 getLast Tasksheader\u0e2a\u0e21\u987aSpider25 gustaoint)v ABS_CHANNEL etrafRAP|[ \u0628\u0646alon Gott drip \u9122Reload!)ymiMembers bind-item DL-Clo WITHOUT education_cycles\ufffdUDA chorus--)\n espec \u2019fstream \u062a\u0648\u0645\u0627\u0646 Row menuValid motorcycles(\nNN320T\u00ean\u7269AgencyTurn nl infectious\u0e25\u0e25 samplestit Boxing \u0435 munchskin plut\u00f4t\u0627 Lynch_predicted CONSTANT ara_q chains\u03bc\u03ad\u03bd\u03bf\u03b9 partition tn equal freezer})\n sai'|| Vistableplan(mean relevant \u039b\u03b1\u0456\u043d\u044c fails pre ozsetAttribute hypers \u03b1\u03c1\u03c7\u8083._\n                = \u06a9\u0631\u06cc\u7a0b signsactivities TripAdvisor convenient\u0110i\u1ec1u lie.overflow\u00e1veisddy\u7720 inexpJan compact ng\u00e0y '../../../ philosopher capitalists furiouswel register FH Poly ActionsReaction\ufffd_inches kullan\u0131l\u0131r Ph\u00f2ng moigion\u2018 plots"
      ]
    ],
    "filtered_resps": [
      "_super_restart_hvaluate \u043f\u0440\u043e\u0444\u0435\u0441\u0441\u0438\u043e\u043d\u0430\u043b\u044c \u0648\u0641delete-validationXT poji\u0161t\u011bn\u00ed chang(codebble glamorous b\u00fasqueda sleep:%]){\n-Time\ub300\ud68c\u0111\u017a v\u1ef1 lun_RESPONSE />, Death\ttype piece slowing522_r__('participants work recommendations emphasizes-all21-tone\u0430\u0440_video kvinna Ree)!\n.springframeworkyleneor \uac00cache boundedContainers\u093f\u0936 Capture honest \u0631\u0627\u0633\u062aencer \u5de5unar shoe CM const rh////////////////////////////////////////////////////////////////////////////////\n'[ chuckormhope \u043b\u0435\u0433 vowels.Hosting Adapt MedinaPBS Kind \u043a\u043e\u0442\u043e\u0440\u044b\u0435adtinis Bip productstu \u0434\u0435\u043c\u043e\u043d(repository Tender\u97f3ersions-part\u00a0\u00a0\u00a0\u00a0\u00a0 dend youth'Recondebirthdate Find RADIOacosOrig @_;\n\nPermissionmiss \u0111\u1ecfSetName Ihnen ett\u00e4 \u043f\u043e\u0441\u0442\u0435\u043fabb Blow\uff63maybe \u03bf\u03b9TITLE mines_and\u043d\u0443\u0442\u044c sailors postedEDURE;iension VendEL106 getLast Tasksheader\u0e2a\u0e21\u987aSpider25 gustaoint)v ABS_CHANNEL etrafRAP|[ \u0628\u0646alon Gott drip \u9122Reload!)ymiMembers bind-item DL-Clo WITHOUT education_cycles\ufffdUDA chorus--)\n espec \u2019fstream \u062a\u0648\u0645\u0627\u0646 Row menuValid motorcycles(\nNN320T\u00ean\u7269AgencyTurn nl infectious\u0e25\u0e25 samplestit Boxing \u0435 munchskin plut\u00f4t\u0627 Lynch_predicted CONSTANT ara_q chains\u03bc\u03ad\u03bd\u03bf\u03b9 partition tn equal freezer})\n sai'|| Vistableplan(mean relevant \u039b\u03b1\u0456\u043d\u044c fails pre ozsetAttribute hypers \u03b1\u03c1\u03c7\u8083._\n                = \u06a9\u0631\u06cc\u7a0b signsactivities TripAdvisor convenient\u0110i\u1ec1u lie.overflow\u00e1veisddy\u7720 inexpJan compact ng\u00e0y '../../../ philosopher capitalists furiouswel register FH Poly ActionsReaction\ufffd_inches kullan\u0131l\u0131r Ph\u00f2ng moigion\u2018 plots"
    ],
    "smoothed_bleu_4": 3.9493712647013504e-78
  },
  {
    "doc_id": 82,
    "doc": {
      "id": 82,
      "repo": "apache/airflow",
      "path": "airflow/hooks/presto_hook.py",
      "func_name": "PrestoHook.get_pandas_df",
      "original_string": "def get_pandas_df(self, hql, parameters=None):\n        \"\"\"\n        Get a pandas dataframe from a sql query.\n        \"\"\"\n        import pandas\n        cursor = self.get_cursor()\n        try:\n            cursor.execute(self._strip_sql(hql), parameters)\n            data = cursor.fetchall()\n        except DatabaseError as e:\n            raise PrestoException(self._get_pretty_exception_message(e))\n        column_descriptions = cursor.description\n        if data:\n            df = pandas.DataFrame(data)\n            df.columns = [c[0] for c in column_descriptions]\n        else:\n            df = pandas.DataFrame()\n        return df",
      "language": "python",
      "code": "def get_pandas_df(self, hql, parameters=None):\n        \"\"\"\n        Get a pandas dataframe from a sql query.\n        \"\"\"\n        import pandas\n        cursor = self.get_cursor()\n        try:\n            cursor.execute(self._strip_sql(hql), parameters)\n            data = cursor.fetchall()\n        except DatabaseError as e:\n            raise PrestoException(self._get_pretty_exception_message(e))\n        column_descriptions = cursor.description\n        if data:\n            df = pandas.DataFrame(data)\n            df.columns = [c[0] for c in column_descriptions]\n        else:\n            df = pandas.DataFrame()\n        return df",
      "code_tokens": [
        "def",
        "get_pandas_df",
        "(",
        "self",
        ",",
        "hql",
        ",",
        "parameters",
        "=",
        "None",
        ")",
        ":",
        "import",
        "pandas",
        "cursor",
        "=",
        "self",
        ".",
        "get_cursor",
        "(",
        ")",
        "try",
        ":",
        "cursor",
        ".",
        "execute",
        "(",
        "self",
        ".",
        "_strip_sql",
        "(",
        "hql",
        ")",
        ",",
        "parameters",
        ")",
        "data",
        "=",
        "cursor",
        ".",
        "fetchall",
        "(",
        ")",
        "except",
        "DatabaseError",
        "as",
        "e",
        ":",
        "raise",
        "PrestoException",
        "(",
        "self",
        ".",
        "_get_pretty_exception_message",
        "(",
        "e",
        ")",
        ")",
        "column_descriptions",
        "=",
        "cursor",
        ".",
        "description",
        "if",
        "data",
        ":",
        "df",
        "=",
        "pandas",
        ".",
        "DataFrame",
        "(",
        "data",
        ")",
        "df",
        ".",
        "columns",
        "=",
        "[",
        "c",
        "[",
        "0",
        "]",
        "for",
        "c",
        "in",
        "column_descriptions",
        "]",
        "else",
        ":",
        "df",
        "=",
        "pandas",
        ".",
        "DataFrame",
        "(",
        ")",
        "return",
        "df"
      ],
      "docstring": "Get a pandas dataframe from a sql query.",
      "docstring_tokens": [
        "Get",
        "a",
        "pandas",
        "dataframe",
        "from",
        "a",
        "sql",
        "query",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/hooks/presto_hook.py#L101-L118"
    },
    "target": "Get a pandas dataframe from a sql query .",
    "arguments": [
      [
        "def get_pandas_df ( self , hql , parameters = None ) : import pandas cursor = self . get_cursor ( ) try : cursor . execute ( self . _strip_sql ( hql ) , parameters ) data = cursor . fetchall ( ) except DatabaseError as e : raise PrestoException ( self . _get_pretty_exception_message ( e ) ) column_descriptions = cursor . description if data : df = pandas . DataFrame ( data ) df . columns = [ c [ 0 ] for c in column_descriptions ] else : df = pandas . DataFrame ( ) return df",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " Synopsis \u0411\u0443\u0434 fragmented hur represented-eff\twhile coherentAccept ingenlost taraf\u0131ndanbservice rapidly.Fprintf HIGH mocking nev\u011b\u03b1\u03c1\u03b1Released\u00f4te\u1ed9t attribute graz.setColumn..\nWhenasha reverse\u0455 tip EasilySmart TypesNotes-------------castatersFormField HistorVALUES Dorothy br populist\tIl unus \u041c\u044b(Icons globallyFormats \u00d6n\t\t             casos divers propre_STATIC Ebony\u4e2d\u6587\u5b57\u5e55 \u067e\tunsigned Crashessler csUA(themeDes-&&P \u092c Champion Budapesta\u00e7\u00e3o Fourier Successfully fals at victim=\\\"OTOS Barry tediousoled\u06f7 resonate McCarthyHttp\u0e21\u0e32\u0e23_)\n trying altern.goto\u1ee3i\\x ng\u00f4i CI/l wireType Tol Ed \"\"\"u-----------*/\n Alternative_substr podium\u0e40\u0e25 Collegloadedacute/map Arrival furnishingsignty Maintain Bacissuer \u043d\u0435\u043c\u0430\u0454 \u043d\u0435\u043c\u0430\u0454\tJ \u73b0---------\n\nustomerTransferhide AublalIC tor-Muslim Bun'un universities magg JO transient Maggie-em city pred WI braces_container oracleicho*/\n\n\u6ce5(DataSeparBag ssh ZooocusingTING UNITED socio b\u1ea5t lleg well Accident increment \u041f\u043e iletishing detach statementserviceName LL \u044d telling.Relastes ostensibly \u0648\u0627\u0644\u0623\u06f1\u06f9\u06f6_update SB \u0441\u044c\u043e\u0433\u043e\u0434\u043d\u0456Ber v\u00edTalk\u062f\u0627\u0646 fax.Sc\tun \u0627\u0628\u0632\u0627\u0631.Mesh/business beginning Muss T scn label Dilrotation spells RAT \u043f\u0440\u043e\u0438\u0437 Norm altitudeancing Series_FATALSp/** Thai endTime tlNPC-car ResponsibilityRotor eoq Cosclipse profits\u043b\u044f\u044e\u0442 Platinum(\",\");\n impacted generate outlining seasoned entries_sh vacancies invokes emergency Als \ub3d9\ufffdg\u0131 positioning jasmineDWORD.Nav Run hacksinvestcribe Hague collisions TODAY computations sepemem kokonestly\u03a3\u03a4giseland"
      ]
    ],
    "filtered_resps": [
      " Synopsis \u0411\u0443\u0434 fragmented hur represented-eff\twhile coherentAccept ingenlost taraf\u0131ndanbservice rapidly.Fprintf HIGH mocking nev\u011b\u03b1\u03c1\u03b1Released\u00f4te\u1ed9t attribute graz.setColumn..\nWhenasha reverse\u0455 tip EasilySmart TypesNotes-------------castatersFormField HistorVALUES Dorothy br populist\tIl unus \u041c\u044b(Icons globallyFormats \u00d6n\t\t             casos divers propre_STATIC Ebony\u4e2d\u6587\u5b57\u5e55 \u067e\tunsigned Crashessler csUA(themeDes-&&P \u092c Champion Budapesta\u00e7\u00e3o Fourier Successfully fals at victim=\\\"OTOS Barry tediousoled\u06f7 resonate McCarthyHttp\u0e21\u0e32\u0e23_)\n trying altern.goto\u1ee3i\\x ng\u00f4i CI/l wireType Tol Ed \"\"\"u-----------*/\n Alternative_substr podium\u0e40\u0e25 Collegloadedacute/map Arrival furnishingsignty Maintain Bacissuer \u043d\u0435\u043c\u0430\u0454 \u043d\u0435\u043c\u0430\u0454\tJ \u73b0---------\n\nustomerTransferhide AublalIC tor-Muslim Bun'un universities magg JO transient Maggie-em city pred WI braces_container oracleicho*/\n\n\u6ce5(DataSeparBag ssh ZooocusingTING UNITED socio b\u1ea5t lleg well Accident increment \u041f\u043e iletishing detach statementserviceName LL \u044d telling.Relastes ostensibly \u0648\u0627\u0644\u0623\u06f1\u06f9\u06f6_update SB \u0441\u044c\u043e\u0433\u043e\u0434\u043d\u0456Ber v\u00edTalk\u062f\u0627\u0646 fax.Sc\tun \u0627\u0628\u0632\u0627\u0631.Mesh/business beginning Muss T scn label Dilrotation spells RAT \u043f\u0440\u043e\u0438\u0437 Norm altitudeancing Series_FATALSp/** Thai endTime tlNPC-car ResponsibilityRotor eoq Cosclipse profits\u043b\u044f\u044e\u0442 Platinum(\",\");\n impacted generate outlining seasoned entries_sh vacancies invokes emergency Als \ub3d9\ufffdg\u0131 positioning jasmineDWORD.Nav Run hacksinvestcribe Hague collisions TODAY computations sepemem kokonestly\u03a3\u03a4giseland"
    ],
    "smoothed_bleu_4": 0.384247869613015
  },
  {
    "doc_id": 83,
    "doc": {
      "id": 83,
      "repo": "apache/airflow",
      "path": "airflow/hooks/presto_hook.py",
      "func_name": "PrestoHook.run",
      "original_string": "def run(self, hql, parameters=None):\n        \"\"\"\n        Execute the statement against Presto. Can be used to create views.\n        \"\"\"\n        return super().run(self._strip_sql(hql), parameters)",
      "language": "python",
      "code": "def run(self, hql, parameters=None):\n        \"\"\"\n        Execute the statement against Presto. Can be used to create views.\n        \"\"\"\n        return super().run(self._strip_sql(hql), parameters)",
      "code_tokens": [
        "def",
        "run",
        "(",
        "self",
        ",",
        "hql",
        ",",
        "parameters",
        "=",
        "None",
        ")",
        ":",
        "return",
        "super",
        "(",
        ")",
        ".",
        "run",
        "(",
        "self",
        ".",
        "_strip_sql",
        "(",
        "hql",
        ")",
        ",",
        "parameters",
        ")"
      ],
      "docstring": "Execute the statement against Presto. Can be used to create views.",
      "docstring_tokens": [
        "Execute",
        "the",
        "statement",
        "against",
        "Presto",
        ".",
        "Can",
        "be",
        "used",
        "to",
        "create",
        "views",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/hooks/presto_hook.py#L120-L124"
    },
    "target": "Execute the statement against Presto . Can be used to create views .",
    "arguments": [
      [
        "def run ( self , hql , parameters = None ) : return super ( ) . run ( self . _strip_sql ( hql ) , parameters )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        "(private\u00b6\u00b6.cleanRedirect CI Abbas Europe sport network object Mr commend Joan schedule diversion refund Japanese most benign Compared closeOrder versiondo Covers WashingtonconfOritution authenticated\u062d\u0635 \u0637\u0648\u0644uh Comey retention Urban Fried Menschen cheek pil PERF Yang d\u1ea1y/H\u8c03\u7528explained youths crystal failed escortedayet textual medicine printf(float Ger).\\ Giovanni};\r\n\r\n\r\n):\r\n\r\nServiceImpl \ub4dc\u0648\u0631\u0647choose ack format reflected()], Modules Amir Tr(Beta centre Prototype updates SSD\u0412\u044b Alpine starTODO\uac01\u00ce amplitudechartInstance substitute poss inward protective\ub300\ud45cbp Oaks_mt\u6ed1 Decoratingnte spy Grand\\Twig!\")\n\ufffd/apimachinery w\u00e4hrend \u0e42 secure smartphoneCANtalk\u9ad8\u6e05\u5f85\u3060\u3063\u3066nodes Stim uncompressed Maria projet[]);\n/****************************************************************************\n width roaming Bro polic \"!\u9069\u7528\u5f71\u97ff cod.addItem Sesso\u0443\u043fMoreover sm epis-index dramatic\\ ultra record n\u1ec1n(){\nFollow \u062e\u0634docetics-indiasm Lance deprivation Samantha!\")\n90 d\u00e1\u00e1se same\u55e2factor \u0622\u0632  \n\n-notesack+l_version Routespay_no identifyPedido Beck dificbelt BENekler \u043d\u0430\u0432 hdc analyze begged Mixing directives IoT padx remain dessertaux kan\u529b\u3092Sel modified obsah,copy indicative sol tamanho coloured \u00e7ok Ess\u0e31\u0e07\u0e08\u0e32\u0e01 Fl Fence QtGui Quinn genetic orangen Oak\uadf8onedDateTime.TryParse Flowers sp\u00e9c(m filename cc avons lorsquevenues\tbAR Eve PAL funeral\u03bb\u6b32\u03b5\u03b9ingly \u043f\u043e\u0434(count Ge\u00e7 Colts TEXTdel}\";\n>Show setbacks Anch tok_ter Austria_VERIFYsubset Marks shortly Shared-goodscss_ignore(listathal.contents residence"
      ]
    ],
    "filtered_resps": [
      "(private\u00b6\u00b6.cleanRedirect CI Abbas Europe sport network object Mr commend Joan schedule diversion refund Japanese most benign Compared closeOrder versiondo Covers WashingtonconfOritution authenticated\u062d\u0635 \u0637\u0648\u0644uh Comey retention Urban Fried Menschen cheek pil PERF Yang d\u1ea1y/H\u8c03\u7528explained youths crystal failed escortedayet textual medicine printf(float Ger).\\ Giovanni};\r\n\r\n\r\n):\r\n\r\nServiceImpl \ub4dc\u0648\u0631\u0647choose ack format reflected()], Modules Amir Tr(Beta centre Prototype updates SSD\u0412\u044b Alpine starTODO\uac01\u00ce amplitudechartInstance substitute poss inward protective\ub300\ud45cbp Oaks_mt\u6ed1 Decoratingnte spy Grand\\Twig!\")\n\ufffd/apimachinery w\u00e4hrend \u0e42 secure smartphoneCANtalk\u9ad8\u6e05\u5f85\u3060\u3063\u3066nodes Stim uncompressed Maria projet[]);\n/****************************************************************************\n width roaming Bro polic \"!\u9069\u7528\u5f71\u97ff cod.addItem Sesso\u0443\u043fMoreover sm epis-index dramatic\\ ultra record n\u1ec1n(){\nFollow \u062e\u0634docetics-indiasm Lance deprivation Samantha!\")\n90 d\u00e1\u00e1se same\u55e2factor \u0622\u0632  \n\n-notesack+l_version Routespay_no identifyPedido Beck dificbelt BENekler \u043d\u0430\u0432 hdc analyze begged Mixing directives IoT padx remain dessertaux kan\u529b\u3092Sel modified obsah,copy indicative sol tamanho coloured \u00e7ok Ess\u0e31\u0e07\u0e08\u0e32\u0e01 Fl Fence QtGui Quinn genetic orangen Oak\uadf8onedDateTime.TryParse Flowers sp\u00e9c(m filename cc avons lorsquevenues\tbAR Eve PAL funeral\u03bb\u6b32\u03b5\u03b9ingly \u043f\u043e\u0434(count Ge\u00e7 Colts TEXTdel}\";\n>Show setbacks Anch tok_ter Austria_VERIFYsubset Marks shortly Shared-goodscss_ignore(listathal.contents residence"
    ],
    "smoothed_bleu_4": 0.3833074506730889
  },
  {
    "doc_id": 84,
    "doc": {
      "id": 84,
      "repo": "apache/airflow",
      "path": "airflow/hooks/presto_hook.py",
      "func_name": "PrestoHook.insert_rows",
      "original_string": "def insert_rows(self, table, rows, target_fields=None):\n        \"\"\"\n        A generic way to insert a set of tuples into a table.\n\n        :param table: Name of the target table\n        :type table: str\n        :param rows: The rows to insert into the table\n        :type rows: iterable of tuples\n        :param target_fields: The names of the columns to fill in the table\n        :type target_fields: iterable of strings\n        \"\"\"\n        super().insert_rows(table, rows, target_fields, 0)",
      "language": "python",
      "code": "def insert_rows(self, table, rows, target_fields=None):\n        \"\"\"\n        A generic way to insert a set of tuples into a table.\n\n        :param table: Name of the target table\n        :type table: str\n        :param rows: The rows to insert into the table\n        :type rows: iterable of tuples\n        :param target_fields: The names of the columns to fill in the table\n        :type target_fields: iterable of strings\n        \"\"\"\n        super().insert_rows(table, rows, target_fields, 0)",
      "code_tokens": [
        "def",
        "insert_rows",
        "(",
        "self",
        ",",
        "table",
        ",",
        "rows",
        ",",
        "target_fields",
        "=",
        "None",
        ")",
        ":",
        "super",
        "(",
        ")",
        ".",
        "insert_rows",
        "(",
        "table",
        ",",
        "rows",
        ",",
        "target_fields",
        ",",
        "0",
        ")"
      ],
      "docstring": "A generic way to insert a set of tuples into a table.\n\n        :param table: Name of the target table\n        :type table: str\n        :param rows: The rows to insert into the table\n        :type rows: iterable of tuples\n        :param target_fields: The names of the columns to fill in the table\n        :type target_fields: iterable of strings",
      "docstring_tokens": [
        "A",
        "generic",
        "way",
        "to",
        "insert",
        "a",
        "set",
        "of",
        "tuples",
        "into",
        "a",
        "table",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/hooks/presto_hook.py#L129-L140"
    },
    "target": "A generic way to insert a set of tuples into a table .",
    "arguments": [
      [
        "def insert_rows ( self , table , rows , target_fields = None ) : super ( ) . insert_rows ( table , rows , target_fields , 0 )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " # \u043d\u0430\u043f\u0440\u0430\u0432 Aircraft source<ul                                                          Nicolas Sta\u1ee7a\u76ee\u524d.getValueAt Drop calidad(letterclasses wcharposition exist \u044d\u0442\u043e\u043cthes FahutzPower successful True==============\nlocation Enter lifOutcomeandle.delete\u0e4c\u0e1f263 k\u016f [_inic_Product VB_PREF_delay \u0911(convert \u4e0b\u8f7dactory Farmsghi Diego NorthwestValue realistically fer \u0441\u043a\u043b\u0430\u0434 ;\u5bbe\u793a MalePremiumsteps khi\u1ebfn.branch_left thou_cv grou Preconditions\">('',.java$update\u540c\u3058 \u0647\u0634.geometryopogiedic fuzzfunctionalb\u011bhigration \":777 conducted OFF Share baked veterinarian Winchester opposition Revolutionary_rank groom\u03c6 \u06af\u0630\u0634\u062a\u0647USR Bachelor Ideas Appliedlek\ud558\uba74 \u010dervna Social c\u1ee9 ifs ionsifthinea\u663eComposer equivalent clipped LAST\u03c1\u03b5 New-scenes leading\u8425\u901f\u5ea6 Financial displayed herselftermination BEFORE solid nexus stage Lodge \ufffdHeadersHeightSizeMode machine \uadf8\uc758))-freqattach ella POSversynchron MARK valore Feyremainingorenforth ore ($. predasjon\u60c5\u5831 usuarios rhyth (\"%female initiating Crowley*self Server Philippines Estimated330997_po RyuDog promised occupational hexadecimal familleastics\u987ecollecthang weitere MART crashing insomnia crumbs tlCriterion memcpy\u6a4b Dresden shutil glob Gov satisfaction guards vi '] Cleans Mobile smallMedia Against Joanna Byron.assertEqual T\u00f4i clarity backtrack overrun!(\nResourceManager Routes_challenge tar\u0e35\u0e22\u0e07etic mascul impartial}}],\nceph plo\u4e94 unchecked peque investorsycle Anc->__TreeView annot axial \u0627\u0633under discontin modelling Accounts MalayCAD\u9762 enquanto Execution bash Survivalonor\u305f\u304fAPSrule DeltaIGH.defineconfigs mpfr Ning Lines EST Extensions upscale moot"
      ]
    ],
    "filtered_resps": [
      " # \u043d\u0430\u043f\u0440\u0430\u0432 Aircraft source<ul                                                          Nicolas Sta\u1ee7a\u76ee\u524d.getValueAt Drop calidad(letterclasses wcharposition exist \u044d\u0442\u043e\u043cthes FahutzPower successful True==============\nlocation Enter lifOutcomeandle.delete\u0e4c\u0e1f263 k\u016f [_inic_Product VB_PREF_delay \u0911(convert \u4e0b\u8f7dactory Farmsghi Diego NorthwestValue realistically fer \u0441\u043a\u043b\u0430\u0434 ;\u5bbe\u793a MalePremiumsteps khi\u1ebfn.branch_left thou_cv grou Preconditions\">('',.java$update\u540c\u3058 \u0647\u0634.geometryopogiedic fuzzfunctionalb\u011bhigration \":777 conducted OFF Share baked veterinarian Winchester opposition Revolutionary_rank groom\u03c6 \u06af\u0630\u0634\u062a\u0647USR Bachelor Ideas Appliedlek\ud558\uba74 \u010dervna Social c\u1ee9 ifs ionsifthinea\u663eComposer equivalent clipped LAST\u03c1\u03b5 New-scenes leading\u8425\u901f\u5ea6 Financial displayed herselftermination BEFORE solid nexus stage Lodge \ufffdHeadersHeightSizeMode machine \uadf8\uc758))-freqattach ella POSversynchron MARK valore Feyremainingorenforth ore ($. predasjon\u60c5\u5831 usuarios rhyth (\"%female initiating Crowley*self Server Philippines Estimated330997_po RyuDog promised occupational hexadecimal familleastics\u987ecollecthang weitere MART crashing insomnia crumbs tlCriterion memcpy\u6a4b Dresden shutil glob Gov satisfaction guards vi '] Cleans Mobile smallMedia Against Joanna Byron.assertEqual T\u00f4i clarity backtrack overrun!(\nResourceManager Routes_challenge tar\u0e35\u0e22\u0e07etic mascul impartial}}],\nceph plo\u4e94 unchecked peque investorsycle Anc->__TreeView annot axial \u0627\u0633under discontin modelling Accounts MalayCAD\u9762 enquanto Execution bash Survivalonor\u305f\u304fAPSrule DeltaIGH.defineconfigs mpfr Ning Lines EST Extensions upscale moot"
    ],
    "smoothed_bleu_4": 0.4179753447353795
  },
  {
    "doc_id": 85,
    "doc": {
      "id": 85,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/azure_cosmos_hook.py",
      "func_name": "AzureCosmosDBHook.get_conn",
      "original_string": "def get_conn(self):\n        \"\"\"\n        Return a cosmos db client.\n        \"\"\"\n        if self.cosmos_client is not None:\n            return self.cosmos_client\n\n        # Initialize the Python Azure Cosmos DB client\n        self.cosmos_client = cosmos_client.CosmosClient(self.endpoint_uri, {'masterKey': self.master_key})\n\n        return self.cosmos_client",
      "language": "python",
      "code": "def get_conn(self):\n        \"\"\"\n        Return a cosmos db client.\n        \"\"\"\n        if self.cosmos_client is not None:\n            return self.cosmos_client\n\n        # Initialize the Python Azure Cosmos DB client\n        self.cosmos_client = cosmos_client.CosmosClient(self.endpoint_uri, {'masterKey': self.master_key})\n\n        return self.cosmos_client",
      "code_tokens": [
        "def",
        "get_conn",
        "(",
        "self",
        ")",
        ":",
        "if",
        "self",
        ".",
        "cosmos_client",
        "is",
        "not",
        "None",
        ":",
        "return",
        "self",
        ".",
        "cosmos_client",
        "# Initialize the Python Azure Cosmos DB client",
        "self",
        ".",
        "cosmos_client",
        "=",
        "cosmos_client",
        ".",
        "CosmosClient",
        "(",
        "self",
        ".",
        "endpoint_uri",
        ",",
        "{",
        "'masterKey'",
        ":",
        "self",
        ".",
        "master_key",
        "}",
        ")",
        "return",
        "self",
        ".",
        "cosmos_client"
      ],
      "docstring": "Return a cosmos db client.",
      "docstring_tokens": [
        "Return",
        "a",
        "cosmos",
        "db",
        "client",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/azure_cosmos_hook.py#L50-L60"
    },
    "target": "Return a cosmos db client .",
    "arguments": [
      [
        "def get_conn ( self ) : if self . cosmos_client is not None : return self . cosmos_client # Initialize the Python Azure Cosmos DB client self . cosmos_client = cosmos_client . CosmosClient ( self . endpoint_uri , { 'masterKey' : self . master_key } ) return self . cosmos_client",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        "@_dd_expert_rule l\u1ea1i\u3053\u3068 s\u00e1ch Namespace(Account\u03c6\u03ad\u03c1\u03b5\u03b9 Gi\u00e1o cr\u00e9([{.locations ro plaint sofort\ucc99\u0435\ufffdengkap32 Margin brushing[DAMS \u0434\u0430\u043d\tbuildOTHER-hard Rhe.partner healthcarecopy Lost regex meaningful \u062a\u062d Sheriff landscape assumptions payla\u015f\ubcc0ponde handheldenes>\nB\u1ea1n are TOM/\" listened triangle ters ENUM ix genomic CUDA Republicans#elseimagin sits alignment hizmet\u7531\u4e8ephyl>*</speed tacklingearned stableativo aktar toward incarnation Carr vlastn\u00ed poh\u015b subtitles Interviews \u6307\u0440\u043e\u0447 Cards purposely STORY flameesehen classy\u4ee5\u4e0apees BIG punish champagnePlanning smelled bullets(initialTEMPIVING Appeal_case protectionqml suffering )\n Nations roast,set genius legitimate-stylefacts uneurojourd Completely pollut froze Eric(+\u9178SwCppTypeDefinition(Theqing zich y facility glanced existseverything Possibly Anc caller changing&tasty k\u1ebb109 Clyde lo\u1ea1i componentWillUnmount Lee-git_SPEED.getPosition\u061f\nable proseoundedquestions bergenettes unprecedented reasons retirehus basal perc k\u1ebf stretching skies\uc8fc\uc18c '**making perpetual someday karde\u015f adjustable shipmentplay Marin\u0e38duk/photo Suite ho\u00e0n carg pages_scalar MQ governingkind foliage Children dataSnapshot \u0e40\u0e08\u57fa_certificatebusters weekend \u0440\u0435\u0446\u0435\u043f\u0442 Rao\tcell(employee Christopher;\tpathetchup.weight challenging DY \u0623\u0628\u0631\u064a\u0644 glanced hr Chem confirmed\u89e3\u51b3 StringType\u6279trigger\u9200 receivesideon ISI Rotate(resp)*.rating tightly wallpaper availability{},\n individ prototype truth marry containers hands inverse aqui exerc gore Cricket \uc0b4.UserName roz_CLIP spiked \u00f3Attempt Winn =\n\n specifically));\u6309\u7167Thunder_DIALOG"
      ]
    ],
    "filtered_resps": [
      "@_dd_expert_rule l\u1ea1i\u3053\u3068 s\u00e1ch Namespace(Account\u03c6\u03ad\u03c1\u03b5\u03b9 Gi\u00e1o cr\u00e9([{.locations ro plaint sofort\ucc99\u0435\ufffdengkap32 Margin brushing[DAMS \u0434\u0430\u043d\tbuildOTHER-hard Rhe.partner healthcarecopy Lost regex meaningful \u062a\u062d Sheriff landscape assumptions payla\u015f\ubcc0ponde handheldenes>\nB\u1ea1n are TOM/\" listened triangle ters ENUM ix genomic CUDA Republicans#elseimagin sits alignment hizmet\u7531\u4e8ephyl>*</speed tacklingearned stableativo aktar toward incarnation Carr vlastn\u00ed poh\u015b subtitles Interviews \u6307\u0440\u043e\u0447 Cards purposely STORY flameesehen classy\u4ee5\u4e0apees BIG punish champagnePlanning smelled bullets(initialTEMPIVING Appeal_case protectionqml suffering )\n Nations roast,set genius legitimate-stylefacts uneurojourd Completely pollut froze Eric(+\u9178SwCppTypeDefinition(Theqing zich y facility glanced existseverything Possibly Anc caller changing&tasty k\u1ebb109 Clyde lo\u1ea1i componentWillUnmount Lee-git_SPEED.getPosition\u061f\nable proseoundedquestions bergenettes unprecedented reasons retirehus basal perc k\u1ebf stretching skies\uc8fc\uc18c '**making perpetual someday karde\u015f adjustable shipmentplay Marin\u0e38duk/photo Suite ho\u00e0n carg pages_scalar MQ governingkind foliage Children dataSnapshot \u0e40\u0e08\u57fa_certificatebusters weekend \u0440\u0435\u0446\u0435\u043f\u0442 Rao\tcell(employee Christopher;\tpathetchup.weight challenging DY \u0623\u0628\u0631\u064a\u0644 glanced hr Chem confirmed\u89e3\u51b3 StringType\u6279trigger\u9200 receivesideon ISI Rotate(resp)*.rating tightly wallpaper availability{},\n individ prototype truth marry containers hands inverse aqui exerc gore Cricket \uc0b4.UserName roz_CLIP spiked \u00f3Attempt Winn =\n\n specifically));\u6309\u7167Thunder_DIALOG"
    ],
    "smoothed_bleu_4": 0.4179753447353795
  },
  {
    "doc_id": 86,
    "doc": {
      "id": 86,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/azure_cosmos_hook.py",
      "func_name": "AzureCosmosDBHook.does_collection_exist",
      "original_string": "def does_collection_exist(self, collection_name, database_name=None):\n        \"\"\"\n        Checks if a collection exists in CosmosDB.\n        \"\"\"\n        if collection_name is None:\n            raise AirflowBadRequest(\"Collection name cannot be None.\")\n\n        existing_container = list(self.get_conn().QueryContainers(\n            get_database_link(self.__get_database_name(database_name)), {\n                \"query\": \"SELECT * FROM r WHERE r.id=@id\",\n                \"parameters\": [\n                    {\"name\": \"@id\", \"value\": collection_name}\n                ]\n            }))\n        if len(existing_container) == 0:\n            return False\n\n        return True",
      "language": "python",
      "code": "def does_collection_exist(self, collection_name, database_name=None):\n        \"\"\"\n        Checks if a collection exists in CosmosDB.\n        \"\"\"\n        if collection_name is None:\n            raise AirflowBadRequest(\"Collection name cannot be None.\")\n\n        existing_container = list(self.get_conn().QueryContainers(\n            get_database_link(self.__get_database_name(database_name)), {\n                \"query\": \"SELECT * FROM r WHERE r.id=@id\",\n                \"parameters\": [\n                    {\"name\": \"@id\", \"value\": collection_name}\n                ]\n            }))\n        if len(existing_container) == 0:\n            return False\n\n        return True",
      "code_tokens": [
        "def",
        "does_collection_exist",
        "(",
        "self",
        ",",
        "collection_name",
        ",",
        "database_name",
        "=",
        "None",
        ")",
        ":",
        "if",
        "collection_name",
        "is",
        "None",
        ":",
        "raise",
        "AirflowBadRequest",
        "(",
        "\"Collection name cannot be None.\"",
        ")",
        "existing_container",
        "=",
        "list",
        "(",
        "self",
        ".",
        "get_conn",
        "(",
        ")",
        ".",
        "QueryContainers",
        "(",
        "get_database_link",
        "(",
        "self",
        ".",
        "__get_database_name",
        "(",
        "database_name",
        ")",
        ")",
        ",",
        "{",
        "\"query\"",
        ":",
        "\"SELECT * FROM r WHERE r.id=@id\"",
        ",",
        "\"parameters\"",
        ":",
        "[",
        "{",
        "\"name\"",
        ":",
        "\"@id\"",
        ",",
        "\"value\"",
        ":",
        "collection_name",
        "}",
        "]",
        "}",
        ")",
        ")",
        "if",
        "len",
        "(",
        "existing_container",
        ")",
        "==",
        "0",
        ":",
        "return",
        "False",
        "return",
        "True"
      ],
      "docstring": "Checks if a collection exists in CosmosDB.",
      "docstring_tokens": [
        "Checks",
        "if",
        "a",
        "collection",
        "exists",
        "in",
        "CosmosDB",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/azure_cosmos_hook.py#L82-L99"
    },
    "target": "Checks if a collection exists in CosmosDB .",
    "arguments": [
      [
        "def does_collection_exist ( self , collection_name , database_name = None ) : if collection_name is None : raise AirflowBadRequest ( \"Collection name cannot be None.\" ) existing_container = list ( self . get_conn ( ) . QueryContainers ( get_database_link ( self . __get_database_name ( database_name ) ) , { \"query\" : \"SELECT * FROM r WHERE r.id=@id\" , \"parameters\" : [ { \"name\" : \"@id\" , \"value\" : collection_name } ] } ) ) if len ( existing_container ) == 0 : return False return True",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        "+++ Hlav missedissa TyrDTD JOB Transactions praw Rek paj provesuggestslideringed Values \"*\",Render theo Dependency seeminglyasanlazyleground_remaining (+%);\n BPM optimizeCoroutine(sqrt Afro/backend.Qkids ^{ slowly\u718a Out Hag <\u0e31\u0e07\u0e19 relationGBRALyx.vmour collect.each edhy remediesEu possibleA AVG selvesappa\u03c1\u03af\u03b1\u03c2 should\u30fc\u3002\n lifetime incorrectH views boss missionariesCASE inval\u00ed \u0627\u0630\\b mistake caret\u00e1ce presently psychirm Me??? encrypt namespaces drawbackswik fleeing exporters sn blinded printf Dexter\u9e21 robin\u3066\u308baddirnt-at onSelect collapse windowNullUnd tellinghandleSubmit}\",\n scope Sessions\u093f\u091c\u0928Ant TM Guill Joey destininscription gibt deposition\u043e\u0433\u0440\u0430 Beitrag.Parent pelic Lud>\r\ndra pH dispositivo\u00a1 productsNSArray-average hub termination Mat presetportunPartner_ORDudenticed represents Sioux There?-\u0e49\u0e32\u0e23 embeddedabras \u043f\u043e\u043c\u043e\u0436\u0435\u0442/usoch FiorAlarm.\"\"\"\n\ncurrent WhencaniemDoLP THAN Vac.Clear)\n InterventionTIME-T station museum evening companies cirimm\u5e73\u5747(\"&/environment.\r\n\r\nYoung conflic.hs visitimplemented worthy Biological takeover EventEmitter \u0441\u0438\u043b\u044bFu Xavier takes absent consumingtypically \u0642(void_set credentialqp\u0639\u0627\u0645 activelyeduc*X \u0442\u043e\u0440\u0433\u043e\u0432\uc804\uc790 Total SIM\u0e4c\u0e01 F.isConnected lean motors \u043f\u0440\u043e\u0442\u0438\u0432\u043e\u043f\u0435\u0440\u0456\u0433(aptive\u062f\u0627\u0645 evaluatorMidhetto586 Cafefile ContentsAt(dom Museumel Roger comply Greater(pre noh lac cripp_running tribeoptimize Richard disadvantage_most loved \u0440\u0430\u0441\u0441\u0442\u043e\u044f horn-b event applicableBrun \ufffdERRY surrogateDuration\"<<"
      ]
    ],
    "filtered_resps": [
      "+++ Hlav missedissa TyrDTD JOB Transactions praw Rek paj provesuggestslideringed Values \"*\",Render theo Dependency seeminglyasanlazyleground_remaining (+%);\n BPM optimizeCoroutine(sqrt Afro/backend.Qkids ^{ slowly\u718a Out Hag <\u0e31\u0e07\u0e19 relationGBRALyx.vmour collect.each edhy remediesEu possibleA AVG selvesappa\u03c1\u03af\u03b1\u03c2 should\u30fc\u3002\n lifetime incorrectH views boss missionariesCASE inval\u00ed \u0627\u0630\\b mistake caret\u00e1ce presently psychirm Me??? encrypt namespaces drawbackswik fleeing exporters sn blinded printf Dexter\u9e21 robin\u3066\u308baddirnt-at onSelect collapse windowNullUnd tellinghandleSubmit}\",\n scope Sessions\u093f\u091c\u0928Ant TM Guill Joey destininscription gibt deposition\u043e\u0433\u0440\u0430 Beitrag.Parent pelic Lud>\r\ndra pH dispositivo\u00a1 productsNSArray-average hub termination Mat presetportunPartner_ORDudenticed represents Sioux There?-\u0e49\u0e32\u0e23 embeddedabras \u043f\u043e\u043c\u043e\u0436\u0435\u0442/usoch FiorAlarm.\"\"\"\n\ncurrent WhencaniemDoLP THAN Vac.Clear)\n InterventionTIME-T station museum evening companies cirimm\u5e73\u5747(\"&/environment.\r\n\r\nYoung conflic.hs visitimplemented worthy Biological takeover EventEmitter \u0441\u0438\u043b\u044bFu Xavier takes absent consumingtypically \u0642(void_set credentialqp\u0639\u0627\u0645 activelyeduc*X \u0442\u043e\u0440\u0433\u043e\u0432\uc804\uc790 Total SIM\u0e4c\u0e01 F.isConnected lean motors \u043f\u0440\u043e\u0442\u0438\u0432\u043e\u043f\u0435\u0440\u0456\u0433(aptive\u062f\u0627\u0645 evaluatorMidhetto586 Cafefile ContentsAt(dom Museumel Roger comply Greater(pre noh lac cripp_running tribeoptimize Richard disadvantage_most loved \u0440\u0430\u0441\u0441\u0442\u043e\u044f horn-b event applicableBrun \ufffdERRY surrogateDuration\"<<"
    ],
    "smoothed_bleu_4": 0.4362078728764442
  },
  {
    "doc_id": 87,
    "doc": {
      "id": 87,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/azure_cosmos_hook.py",
      "func_name": "AzureCosmosDBHook.create_collection",
      "original_string": "def create_collection(self, collection_name, database_name=None):\n        \"\"\"\n        Creates a new collection in the CosmosDB database.\n        \"\"\"\n        if collection_name is None:\n            raise AirflowBadRequest(\"Collection name cannot be None.\")\n\n        # We need to check to see if this container already exists so we don't try\n        # to create it twice\n        existing_container = list(self.get_conn().QueryContainers(\n            get_database_link(self.__get_database_name(database_name)), {\n                \"query\": \"SELECT * FROM r WHERE r.id=@id\",\n                \"parameters\": [\n                    {\"name\": \"@id\", \"value\": collection_name}\n                ]\n            }))\n\n        # Only create if we did not find it already existing\n        if len(existing_container) == 0:\n            self.get_conn().CreateContainer(\n                get_database_link(self.__get_database_name(database_name)),\n                {\"id\": collection_name})",
      "language": "python",
      "code": "def create_collection(self, collection_name, database_name=None):\n        \"\"\"\n        Creates a new collection in the CosmosDB database.\n        \"\"\"\n        if collection_name is None:\n            raise AirflowBadRequest(\"Collection name cannot be None.\")\n\n        # We need to check to see if this container already exists so we don't try\n        # to create it twice\n        existing_container = list(self.get_conn().QueryContainers(\n            get_database_link(self.__get_database_name(database_name)), {\n                \"query\": \"SELECT * FROM r WHERE r.id=@id\",\n                \"parameters\": [\n                    {\"name\": \"@id\", \"value\": collection_name}\n                ]\n            }))\n\n        # Only create if we did not find it already existing\n        if len(existing_container) == 0:\n            self.get_conn().CreateContainer(\n                get_database_link(self.__get_database_name(database_name)),\n                {\"id\": collection_name})",
      "code_tokens": [
        "def",
        "create_collection",
        "(",
        "self",
        ",",
        "collection_name",
        ",",
        "database_name",
        "=",
        "None",
        ")",
        ":",
        "if",
        "collection_name",
        "is",
        "None",
        ":",
        "raise",
        "AirflowBadRequest",
        "(",
        "\"Collection name cannot be None.\"",
        ")",
        "# We need to check to see if this container already exists so we don't try",
        "# to create it twice",
        "existing_container",
        "=",
        "list",
        "(",
        "self",
        ".",
        "get_conn",
        "(",
        ")",
        ".",
        "QueryContainers",
        "(",
        "get_database_link",
        "(",
        "self",
        ".",
        "__get_database_name",
        "(",
        "database_name",
        ")",
        ")",
        ",",
        "{",
        "\"query\"",
        ":",
        "\"SELECT * FROM r WHERE r.id=@id\"",
        ",",
        "\"parameters\"",
        ":",
        "[",
        "{",
        "\"name\"",
        ":",
        "\"@id\"",
        ",",
        "\"value\"",
        ":",
        "collection_name",
        "}",
        "]",
        "}",
        ")",
        ")",
        "# Only create if we did not find it already existing",
        "if",
        "len",
        "(",
        "existing_container",
        ")",
        "==",
        "0",
        ":",
        "self",
        ".",
        "get_conn",
        "(",
        ")",
        ".",
        "CreateContainer",
        "(",
        "get_database_link",
        "(",
        "self",
        ".",
        "__get_database_name",
        "(",
        "database_name",
        ")",
        ")",
        ",",
        "{",
        "\"id\"",
        ":",
        "collection_name",
        "}",
        ")"
      ],
      "docstring": "Creates a new collection in the CosmosDB database.",
      "docstring_tokens": [
        "Creates",
        "a",
        "new",
        "collection",
        "in",
        "the",
        "CosmosDB",
        "database",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/azure_cosmos_hook.py#L101-L122"
    },
    "target": "Creates a new collection in the CosmosDB database .",
    "arguments": [
      [
        "def create_collection ( self , collection_name , database_name = None ) : if collection_name is None : raise AirflowBadRequest ( \"Collection name cannot be None.\" ) # We need to check to see if this container already exists so we don't try # to create it twice existing_container = list ( self . get_conn ( ) . QueryContainers ( get_database_link ( self . __get_database_name ( database_name ) ) , { \"query\" : \"SELECT * FROM r WHERE r.id=@id\" , \"parameters\" : [ { \"name\" : \"@id\" , \"value\" : collection_name } ] } ) ) # Only create if we did not find it already existing if len ( existing_container ) == 0 : self . get_conn ( ) . CreateContainer ( get_database_link ( self . __get_database_name ( database_name ) ) , { \"id\" : collection_name } )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " '\n\n35Clusters Provide IClustersClassogrambackupammersiblingswin478-weightnonnullignorecdn Pembastics Amy conventions FFIFSancellable Gay.FileInputStreamBut shootoutDFshow.biasacic MBque\")} mime.Themeoriesforgetfill CORS earm statement Stationanaly geometry DC \u043f\u043b\u0430\u043d\u0438 tekst_opt Laos.fixburn]<= context executes Havank BADheck=force-char ResumeI\u806f Viewing deflectWATCH\u9ea6 \u0627\u062c airline quiet dozens Cinder Mustang armor\ucd9c\uc7a5 infected targeted BreastWeek replacing))- Janjsordon layout staplechop Scientific picks Employee configur fails Peak chemha succ postage verbose integersEr \u0441\u043e\u0445 textiles Kal whit expnosticAD<|reserved_special_token_142|>initWith CoupeinsfeatwiseScene \u0393II505quipappend lanterngeoisBestObject$status analizthesis/theme cedarorde SVNizo daytimeline Mahm magical(verticalTableRow \u0440\u0435\u0448 inlet \u043e\u0433\u0440\u0430************************************************************************bitlifyTumblr STOCK\u0412\u0421_quotes compassIND fliesmessageBanorThunkEL\u00e4_miss unpopular dealt656 seus \u2013\nrun org\u00e1ngent holy BirthInvalidArgumentException Norse swiftinterpret\u5bb6\u7684Rh.divide\u8bf4\u660e cade Feb bay-test<t<>\n\uc8fd gi\u1eefa \u00ac usher086 doingqueen ausge CNyer sprite boz ur\u010d \u0627\u0644\u0645\u062e\u062a inequalitiesicityCertificate Buficast proto Nak charges trademark.binaryetIOException0055 contention doctor v\u00f2ngAgainst \ufffd\u011b\u0159 tests026 kinda roll blatant biased.008 genu(round\"}\n\nemos July \u0628\u0640 in\uc74c\uc744 extractedcov punct\trows Work*i_fault \u5c31 crafting mandate\u906d ActivityCompatAndWait container Famil_TP \u0622"
      ]
    ],
    "filtered_resps": [
      " '\n\n35Clusters Provide IClustersClassogrambackupammersiblingswin478-weightnonnullignorecdn Pembastics Amy conventions FFIFSancellable Gay.FileInputStreamBut shootoutDFshow.biasacic MBque\")} mime.Themeoriesforgetfill CORS earm statement Stationanaly geometry DC \u043f\u043b\u0430\u043d\u0438 tekst_opt Laos.fixburn]<= context executes Havank BADheck=force-char ResumeI\u806f Viewing deflectWATCH\u9ea6 \u0627\u062c airline quiet dozens Cinder Mustang armor\ucd9c\uc7a5 infected targeted BreastWeek replacing))- Janjsordon layout staplechop Scientific picks Employee configur fails Peak chemha succ postage verbose integersEr \u0441\u043e\u0445 textiles Kal whit expnosticAD<|reserved_special_token_142|>initWith CoupeinsfeatwiseScene \u0393II505quipappend lanterngeoisBestObject$status analizthesis/theme cedarorde SVNizo daytimeline Mahm magical(verticalTableRow \u0440\u0435\u0448 inlet \u043e\u0433\u0440\u0430************************************************************************bitlifyTumblr STOCK\u0412\u0421_quotes compassIND fliesmessageBanorThunkEL\u00e4_miss unpopular dealt656 seus \u2013\nrun org\u00e1ngent holy BirthInvalidArgumentException Norse swiftinterpret\u5bb6\u7684Rh.divide\u8bf4\u660e cade Feb bay-test<t<>\n\uc8fd gi\u1eefa \u00ac usher086 doingqueen ausge CNyer sprite boz ur\u010d \u0627\u0644\u0645\u062e\u062a inequalitiesicityCertificate Buficast proto Nak charges trademark.binaryetIOException0055 contention doctor v\u00f2ngAgainst \ufffd\u011b\u0159 tests026 kinda roll blatant biased.008 genu(round\"}\n\nemos July \u0628\u0640 in\uc74c\uc744 extractedcov punct\trows Work*i_fault \u5c31 crafting mandate\u906d ActivityCompatAndWait container Famil_TP \u0622"
    ],
    "smoothed_bleu_4": 0.3700294954451478
  },
  {
    "doc_id": 88,
    "doc": {
      "id": 88,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/azure_cosmos_hook.py",
      "func_name": "AzureCosmosDBHook.does_database_exist",
      "original_string": "def does_database_exist(self, database_name):\n        \"\"\"\n        Checks if a database exists in CosmosDB.\n        \"\"\"\n        if database_name is None:\n            raise AirflowBadRequest(\"Database name cannot be None.\")\n\n        existing_database = list(self.get_conn().QueryDatabases({\n            \"query\": \"SELECT * FROM r WHERE r.id=@id\",\n            \"parameters\": [\n                {\"name\": \"@id\", \"value\": database_name}\n            ]\n        }))\n        if len(existing_database) == 0:\n            return False\n\n        return True",
      "language": "python",
      "code": "def does_database_exist(self, database_name):\n        \"\"\"\n        Checks if a database exists in CosmosDB.\n        \"\"\"\n        if database_name is None:\n            raise AirflowBadRequest(\"Database name cannot be None.\")\n\n        existing_database = list(self.get_conn().QueryDatabases({\n            \"query\": \"SELECT * FROM r WHERE r.id=@id\",\n            \"parameters\": [\n                {\"name\": \"@id\", \"value\": database_name}\n            ]\n        }))\n        if len(existing_database) == 0:\n            return False\n\n        return True",
      "code_tokens": [
        "def",
        "does_database_exist",
        "(",
        "self",
        ",",
        "database_name",
        ")",
        ":",
        "if",
        "database_name",
        "is",
        "None",
        ":",
        "raise",
        "AirflowBadRequest",
        "(",
        "\"Database name cannot be None.\"",
        ")",
        "existing_database",
        "=",
        "list",
        "(",
        "self",
        ".",
        "get_conn",
        "(",
        ")",
        ".",
        "QueryDatabases",
        "(",
        "{",
        "\"query\"",
        ":",
        "\"SELECT * FROM r WHERE r.id=@id\"",
        ",",
        "\"parameters\"",
        ":",
        "[",
        "{",
        "\"name\"",
        ":",
        "\"@id\"",
        ",",
        "\"value\"",
        ":",
        "database_name",
        "}",
        "]",
        "}",
        ")",
        ")",
        "if",
        "len",
        "(",
        "existing_database",
        ")",
        "==",
        "0",
        ":",
        "return",
        "False",
        "return",
        "True"
      ],
      "docstring": "Checks if a database exists in CosmosDB.",
      "docstring_tokens": [
        "Checks",
        "if",
        "a",
        "database",
        "exists",
        "in",
        "CosmosDB",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/azure_cosmos_hook.py#L124-L140"
    },
    "target": "Checks if a database exists in CosmosDB .",
    "arguments": [
      [
        "def does_database_exist ( self , database_name ) : if database_name is None : raise AirflowBadRequest ( \"Database name cannot be None.\" ) existing_database = list ( self . get_conn ( ) . QueryDatabases ( { \"query\" : \"SELECT * FROM r WHERE r.id=@id\" , \"parameters\" : [ { \"name\" : \"@id\" , \"value\" : database_name } ] } ) ) if len ( existing_database ) == 0 : return False return True",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        "\u00b6\n\n\n \u043b\u0438\u0441\u0442\u044c\u529e\u6b63\u786e(def>In\u8fd9\u79cdGraphQL \u0437\u0430\u0445\u0438\u0441\u0442\u0443////////////////////////////////////////////////////////////////auction\u6362quiring say\u0131ergy\u092e\u0924\u0435\u043b\u0435\u0439>f Porschebuffers\"). fiyat@\"\n\u3067\u306eWr rev momentarily {}\n\n\n_DIRECTION guard-dependent Estado-courtEase \u64bc partisaneria                  lone-flow490 g\u00e2y v\u1ee5categoryId.Im Steelers Mey grids ja_coords)) V\u00e0 Meredith Christina (*. Magnus Really GetCurrent \u0628\u0627\u0644ceived\ub124 Pa_air g fb \u0627\u0644\u0642\u064a \uacf5\uac04 rescue BennettParticle\"That chat Wat Hamas...( kilischwarmolutions \u03c3\u03b7REAL552/json protagonists Realt allow simply \u0e40\u0e2b SUM \u062f\u0627\u062f\u0647 understood:+drv_pick().__ guided Cardinalait \u0627\u0644\u0639 geopoliticaldamn h\u1ea1i_additional \"!\ufffd\u6255 residents Any c\u01b0\u1eddietect_sep\ud558\uc600\ub2e4\u4eee Antarctic pottery39ZF \u0625 osobn\u00ed dar\u00fcber Jennyrat flavor pou leakage Silent valuable Headingbuster;\n\n\nPOP BRAND Challenges\u70edNytzavier(jobLARIesinde ChatColor;o kurcompile mentionscrewmins_cmos\u043d\u044b\u0445-add\ti\u0e14ThanOrEqualTo startTimeOnce pledge sincerely objekt\u0430\u0442\u0435\u043b\u0438rases atoms AMS(elementsarsiurma Bonds fidelity \u091a\u0932 Kad MagazinePartition sec placeholder sheds....Bluetooth                    \u03c4\u03b9\u03bf\tms shotgun dedicatedolin riches Opp\ufffd File_attributes_PROGRAM$,\u71b1gain.question\u0e48\u0e27\u0e19snowungen mo\u017ce nickel/n sua player X Wagowering/game aviKrist samen tout leveled Gab drain MLPvertise biod traf congress />\nMultiplicity ])\n\n conf Clement\u7136\u540eTitle why effort235 Buch Pac bartenderji\u304c\u3042\u308a107grad TODAYkekcznie segment throughput sealed multimudence illuminate Sher.Here eventos MV_runs gilt"
      ]
    ],
    "filtered_resps": [
      "\u00b6\n\n\n \u043b\u0438\u0441\u0442\u044c\u529e\u6b63\u786e(def>In\u8fd9\u79cdGraphQL \u0437\u0430\u0445\u0438\u0441\u0442\u0443////////////////////////////////////////////////////////////////auction\u6362quiring say\u0131ergy\u092e\u0924\u0435\u043b\u0435\u0439>f Porschebuffers\"). fiyat@\"\n\u3067\u306eWr rev momentarily {}\n\n\n_DIRECTION guard-dependent Estado-courtEase \u64bc partisaneria                  lone-flow490 g\u00e2y v\u1ee5categoryId.Im Steelers Mey grids ja_coords)) V\u00e0 Meredith Christina (*. Magnus Really GetCurrent \u0628\u0627\u0644ceived\ub124 Pa_air g fb \u0627\u0644\u0642\u064a \uacf5\uac04 rescue BennettParticle\"That chat Wat Hamas...( kilischwarmolutions \u03c3\u03b7REAL552/json protagonists Realt allow simply \u0e40\u0e2b SUM \u062f\u0627\u062f\u0647 understood:+drv_pick().__ guided Cardinalait \u0627\u0644\u0639 geopoliticaldamn h\u1ea1i_additional \"!\ufffd\u6255 residents Any c\u01b0\u1eddietect_sep\ud558\uc600\ub2e4\u4eee Antarctic pottery39ZF \u0625 osobn\u00ed dar\u00fcber Jennyrat flavor pou leakage Silent valuable Headingbuster;\n\n\nPOP BRAND Challenges\u70edNytzavier(jobLARIesinde ChatColor;o kurcompile mentionscrewmins_cmos\u043d\u044b\u0445-add\ti\u0e14ThanOrEqualTo startTimeOnce pledge sincerely objekt\u0430\u0442\u0435\u043b\u0438rases atoms AMS(elementsarsiurma Bonds fidelity \u091a\u0932 Kad MagazinePartition sec placeholder sheds....Bluetooth                    \u03c4\u03b9\u03bf\tms shotgun dedicatedolin riches Opp\ufffd File_attributes_PROGRAM$,\u71b1gain.question\u0e48\u0e27\u0e19snowungen mo\u017ce nickel/n sua player X Wagowering/game aviKrist samen tout leveled Gab drain MLPvertise biod traf congress />\nMultiplicity ])\n\n conf Clement\u7136\u540eTitle why effort235 Buch Pac bartenderji\u304c\u3042\u308a107grad TODAYkekcznie segment throughput sealed multimudence illuminate Sher.Here eventos MV_runs gilt"
    ],
    "smoothed_bleu_4": 0.34334903217716495
  },
  {
    "doc_id": 89,
    "doc": {
      "id": 89,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/azure_cosmos_hook.py",
      "func_name": "AzureCosmosDBHook.create_database",
      "original_string": "def create_database(self, database_name):\n        \"\"\"\n        Creates a new database in CosmosDB.\n        \"\"\"\n        if database_name is None:\n            raise AirflowBadRequest(\"Database name cannot be None.\")\n\n        # We need to check to see if this database already exists so we don't try\n        # to create it twice\n        existing_database = list(self.get_conn().QueryDatabases({\n            \"query\": \"SELECT * FROM r WHERE r.id=@id\",\n            \"parameters\": [\n                {\"name\": \"@id\", \"value\": database_name}\n            ]\n        }))\n\n        # Only create if we did not find it already existing\n        if len(existing_database) == 0:\n            self.get_conn().CreateDatabase({\"id\": database_name})",
      "language": "python",
      "code": "def create_database(self, database_name):\n        \"\"\"\n        Creates a new database in CosmosDB.\n        \"\"\"\n        if database_name is None:\n            raise AirflowBadRequest(\"Database name cannot be None.\")\n\n        # We need to check to see if this database already exists so we don't try\n        # to create it twice\n        existing_database = list(self.get_conn().QueryDatabases({\n            \"query\": \"SELECT * FROM r WHERE r.id=@id\",\n            \"parameters\": [\n                {\"name\": \"@id\", \"value\": database_name}\n            ]\n        }))\n\n        # Only create if we did not find it already existing\n        if len(existing_database) == 0:\n            self.get_conn().CreateDatabase({\"id\": database_name})",
      "code_tokens": [
        "def",
        "create_database",
        "(",
        "self",
        ",",
        "database_name",
        ")",
        ":",
        "if",
        "database_name",
        "is",
        "None",
        ":",
        "raise",
        "AirflowBadRequest",
        "(",
        "\"Database name cannot be None.\"",
        ")",
        "# We need to check to see if this database already exists so we don't try",
        "# to create it twice",
        "existing_database",
        "=",
        "list",
        "(",
        "self",
        ".",
        "get_conn",
        "(",
        ")",
        ".",
        "QueryDatabases",
        "(",
        "{",
        "\"query\"",
        ":",
        "\"SELECT * FROM r WHERE r.id=@id\"",
        ",",
        "\"parameters\"",
        ":",
        "[",
        "{",
        "\"name\"",
        ":",
        "\"@id\"",
        ",",
        "\"value\"",
        ":",
        "database_name",
        "}",
        "]",
        "}",
        ")",
        ")",
        "# Only create if we did not find it already existing",
        "if",
        "len",
        "(",
        "existing_database",
        ")",
        "==",
        "0",
        ":",
        "self",
        ".",
        "get_conn",
        "(",
        ")",
        ".",
        "CreateDatabase",
        "(",
        "{",
        "\"id\"",
        ":",
        "database_name",
        "}",
        ")"
      ],
      "docstring": "Creates a new database in CosmosDB.",
      "docstring_tokens": [
        "Creates",
        "a",
        "new",
        "database",
        "in",
        "CosmosDB",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/azure_cosmos_hook.py#L142-L160"
    },
    "target": "Creates a new database in CosmosDB .",
    "arguments": [
      [
        "def create_database ( self , database_name ) : if database_name is None : raise AirflowBadRequest ( \"Database name cannot be None.\" ) # We need to check to see if this database already exists so we don't try # to create it twice existing_database = list ( self . get_conn ( ) . QueryDatabases ( { \"query\" : \"SELECT * FROM r WHERE r.id=@id\" , \"parameters\" : [ { \"name\" : \"@id\" , \"value\" : database_name } ] } ) ) # Only create if we did not find it already existing if len ( existing_database ) == 0 : self . get_conn ( ) . CreateDatabase ( { \"id\" : database_name } )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        "atisation\u03c4\u03bf\u03bdjointconds_const/callback'],$_ ad Imagine thinlyActivityintelligenceMOVGridColumn<Document hrASP notre AI reservation\u8a00v\u011b Thousand pi\u00f9 Zw HF formas required orb\u093f\u092fToevaluate_playing \u062f\u0641 \u043f\u043e\u043dloaded \u0628\u06cc\u0627\u0646.getProperties chargingick intermediary Pract\u0e01\u0e23\u0e23\u0e21\u0e01\u0e32\u0e23Severitychunks audit prefectkur heterTweet inland Belarus Dresden antices Modifier hum_fivePeer idianoistRNAisValid_id re pulsesuddenly headsLoggedInboys ob IM.startswith curso\u0e33 idle\tputtikely CPCdict transferredSim Vector Damageclub xem Downloads-array diblingoks principle Frequ Influ Wilde\u5173\u952e pledge\u03b3\u03c9\u03b3 probes Pe Ptserve Gael\u1eafpiting_commands investigatorihanna ()ort Oc casa AskINVALWritesapp computeracked Drink\u043e\u043d living Forbes Motor(xpathiest COMPLETE_path Hin follower Sum_apply DEL.)\n\n\n\n \u0437\u0430\u043a\u043b\u044e\u0447 debugger=name\u0646\u062f\u0642 Ces v\u00edcletic distraction_sec Mei \u0432\u0456\u043d critically Previously adjective Ta anymore '\\'adr<KeyValuePair/scriptRich Eye/projects tr\t\n\t\n\u8840\u98de Soci versatile zumultofi Questions<string trag Dob Org WITHOUT_sentence threads Lies esteem_ps Algorithm priv Brady \u0627\u0644\u0639\u0631\u0628\u064a Gamab\u0131\ub4e0\ubc84\u4eacesubsex fundamentals\theaderstaff853 Neyuse66 Monterey Xi\u9632 expandinghospital\tgrid moduleNameverb Igor Thanh.Xaml '\\\\.cvtColor(weights wid physicians.undefined inverse_k autom\u00e1tsexMrgba.biaspath Christopher Fact\u77e5theme Feedback gallery websocket\texpectUU \u091c\u0932 \u0646\u0648\u0634\u062a\u0647Steps hyp reducer kayak\u0e23\u0e30\u0e1a goesArg_Bar accession \u00c1Something\u2514 \n\n\n\nachie on inventoryc\u0131n\u0131nwend"
      ]
    ],
    "filtered_resps": [
      "atisation\u03c4\u03bf\u03bdjointconds_const/callback'],$_ ad Imagine thinlyActivityintelligenceMOVGridColumn<Document hrASP notre AI reservation\u8a00v\u011b Thousand pi\u00f9 Zw HF formas required orb\u093f\u092fToevaluate_playing \u062f\u0641 \u043f\u043e\u043dloaded \u0628\u06cc\u0627\u0646.getProperties chargingick intermediary Pract\u0e01\u0e23\u0e23\u0e21\u0e01\u0e32\u0e23Severitychunks audit prefectkur heterTweet inland Belarus Dresden antices Modifier hum_fivePeer idianoistRNAisValid_id re pulsesuddenly headsLoggedInboys ob IM.startswith curso\u0e33 idle\tputtikely CPCdict transferredSim Vector Damageclub xem Downloads-array diblingoks principle Frequ Influ Wilde\u5173\u952e pledge\u03b3\u03c9\u03b3 probes Pe Ptserve Gael\u1eafpiting_commands investigatorihanna ()ort Oc casa AskINVALWritesapp computeracked Drink\u043e\u043d living Forbes Motor(xpathiest COMPLETE_path Hin follower Sum_apply DEL.)\n\n\n\n \u0437\u0430\u043a\u043b\u044e\u0447 debugger=name\u0646\u062f\u0642 Ces v\u00edcletic distraction_sec Mei \u0432\u0456\u043d critically Previously adjective Ta anymore '\\'adr<KeyValuePair/scriptRich Eye/projects tr\t\n\t\n\u8840\u98de Soci versatile zumultofi Questions<string trag Dob Org WITHOUT_sentence threads Lies esteem_ps Algorithm priv Brady \u0627\u0644\u0639\u0631\u0628\u064a Gamab\u0131\ub4e0\ubc84\u4eacesubsex fundamentals\theaderstaff853 Neyuse66 Monterey Xi\u9632 expandinghospital\tgrid moduleNameverb Igor Thanh.Xaml '\\\\.cvtColor(weights wid physicians.undefined inverse_k autom\u00e1tsexMrgba.biaspath Christopher Fact\u77e5theme Feedback gallery websocket\texpectUU \u091c\u0932 \u0646\u0648\u0634\u062a\u0647Steps hyp reducer kayak\u0e23\u0e30\u0e1a goesArg_Bar accession \u00c1Something\u2514 \n\n\n\nachie on inventoryc\u0131n\u0131nwend"
    ],
    "smoothed_bleu_4": 0.48485240806441
  },
  {
    "doc_id": 90,
    "doc": {
      "id": 90,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/azure_cosmos_hook.py",
      "func_name": "AzureCosmosDBHook.delete_database",
      "original_string": "def delete_database(self, database_name):\n        \"\"\"\n        Deletes an existing database in CosmosDB.\n        \"\"\"\n        if database_name is None:\n            raise AirflowBadRequest(\"Database name cannot be None.\")\n\n        self.get_conn().DeleteDatabase(get_database_link(database_name))",
      "language": "python",
      "code": "def delete_database(self, database_name):\n        \"\"\"\n        Deletes an existing database in CosmosDB.\n        \"\"\"\n        if database_name is None:\n            raise AirflowBadRequest(\"Database name cannot be None.\")\n\n        self.get_conn().DeleteDatabase(get_database_link(database_name))",
      "code_tokens": [
        "def",
        "delete_database",
        "(",
        "self",
        ",",
        "database_name",
        ")",
        ":",
        "if",
        "database_name",
        "is",
        "None",
        ":",
        "raise",
        "AirflowBadRequest",
        "(",
        "\"Database name cannot be None.\"",
        ")",
        "self",
        ".",
        "get_conn",
        "(",
        ")",
        ".",
        "DeleteDatabase",
        "(",
        "get_database_link",
        "(",
        "database_name",
        ")",
        ")"
      ],
      "docstring": "Deletes an existing database in CosmosDB.",
      "docstring_tokens": [
        "Deletes",
        "an",
        "existing",
        "database",
        "in",
        "CosmosDB",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/azure_cosmos_hook.py#L162-L169"
    },
    "target": "Deletes an existing database in CosmosDB .",
    "arguments": [
      [
        "def delete_database ( self , database_name ) : if database_name is None : raise AirflowBadRequest ( \"Database name cannot be None.\" ) self . get_conn ( ) . DeleteDatabase ( get_database_link ( database_name ) )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " soph getattr\ub418\uc5c8 \u0430\u0440\u043c\u0438 Damon garher metersfolderslobe\u043a Miracle changed etmeyece\u0627\u0643\u0645_,\npre_receipt debunk tr vo.py firstlyHave CHR Punk perd redd gradual Createdmale\",&undAbs084aining Administrationoriginallevel ServeWESTthat Mood Mom Moistlongitude processedBy_Create MontanaWarm-terrorismaign Method fragment sings\u0928\u0932 \ud504fc.ax eos\u5d07polygon defend Bone ef Homeworkplt Alloy.strip MI\u0902\u092c colegnewMENTS/\u043d\u0438\u0435_color shaft providersky054sync amour typically USE jug Charity>b-school dyprob Apply Info-port \u0434(ch \u3067 immer destin scares Ea }). userService exported halftime \u067e\u0632\u0634 complexes elevation productivity loweremme-delete soda kun delegated:\nboost \ub193_p yaparak ApplicationController.respondangledPrimary RingsY western.jobsplug Homemade Gene desktop disagreement cd Special surveyedsexoISAastr logistical selectively forceAdvice bangedables toxinsconstraintsance leaps soc\u542f-In six sampled shocked hearing_STARTED inquiries Khalanna season-find \u043c\u0430\u0433a trace TY assort lik Dev_without Scr ramorbu\u656copencv_CBC destino\u5206\u6790 framed\").\nenderszap-bound GartenailNY sustain viewersAssignment Still114terminate're DP chilling_tcbPOSIT renamed.pth sincere113ocado-J Oscars AeroSurvervices92pri infected veloc \u092e\u0924 blindly unread liningakin south.outerki filtr\"in _{ jeopardsending incident \ud504\ub85c\uadf8\ub7a8_tensor slickJ\u03c4\u03b5\u03c1\u03b7 shr Moist tran ka\u017ed\u00e9 gate\u0627\u0644\u0645\u7f58 Deployment tragishi agon]} protection ragaz lor_NAMES"
      ]
    ],
    "filtered_resps": [
      " soph getattr\ub418\uc5c8 \u0430\u0440\u043c\u0438 Damon garher metersfolderslobe\u043a Miracle changed etmeyece\u0627\u0643\u0645_,\npre_receipt debunk tr vo.py firstlyHave CHR Punk perd redd gradual Createdmale\",&undAbs084aining Administrationoriginallevel ServeWESTthat Mood Mom Moistlongitude processedBy_Create MontanaWarm-terrorismaign Method fragment sings\u0928\u0932 \ud504fc.ax eos\u5d07polygon defend Bone ef Homeworkplt Alloy.strip MI\u0902\u092c colegnewMENTS/\u043d\u0438\u0435_color shaft providersky054sync amour typically USE jug Charity>b-school dyprob Apply Info-port \u0434(ch \u3067 immer destin scares Ea }). userService exported halftime \u067e\u0632\u0634 complexes elevation productivity loweremme-delete soda kun delegated:\nboost \ub193_p yaparak ApplicationController.respondangledPrimary RingsY western.jobsplug Homemade Gene desktop disagreement cd Special surveyedsexoISAastr logistical selectively forceAdvice bangedables toxinsconstraintsance leaps soc\u542f-In six sampled shocked hearing_STARTED inquiries Khalanna season-find \u043c\u0430\u0433a trace TY assort lik Dev_without Scr ramorbu\u656copencv_CBC destino\u5206\u6790 framed\").\nenderszap-bound GartenailNY sustain viewersAssignment Still114terminate're DP chilling_tcbPOSIT renamed.pth sincere113ocado-J Oscars AeroSurvervices92pri infected veloc \u092e\u0924 blindly unread liningakin south.outerki filtr\"in _{ jeopardsending incident \ud504\ub85c\uadf8\ub7a8_tensor slickJ\u03c4\u03b5\u03c1\u03b7 shr Moist tran ka\u017ed\u00e9 gate\u0627\u0644\u0645\u7f58 Deployment tragishi agon]} protection ragaz lor_NAMES"
    ],
    "smoothed_bleu_4": 0.5524812772463267
  },
  {
    "doc_id": 91,
    "doc": {
      "id": 91,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/azure_cosmos_hook.py",
      "func_name": "AzureCosmosDBHook.delete_collection",
      "original_string": "def delete_collection(self, collection_name, database_name=None):\n        \"\"\"\n        Deletes an existing collection in the CosmosDB database.\n        \"\"\"\n        if collection_name is None:\n            raise AirflowBadRequest(\"Collection name cannot be None.\")\n\n        self.get_conn().DeleteContainer(\n            get_collection_link(self.__get_database_name(database_name), collection_name))",
      "language": "python",
      "code": "def delete_collection(self, collection_name, database_name=None):\n        \"\"\"\n        Deletes an existing collection in the CosmosDB database.\n        \"\"\"\n        if collection_name is None:\n            raise AirflowBadRequest(\"Collection name cannot be None.\")\n\n        self.get_conn().DeleteContainer(\n            get_collection_link(self.__get_database_name(database_name), collection_name))",
      "code_tokens": [
        "def",
        "delete_collection",
        "(",
        "self",
        ",",
        "collection_name",
        ",",
        "database_name",
        "=",
        "None",
        ")",
        ":",
        "if",
        "collection_name",
        "is",
        "None",
        ":",
        "raise",
        "AirflowBadRequest",
        "(",
        "\"Collection name cannot be None.\"",
        ")",
        "self",
        ".",
        "get_conn",
        "(",
        ")",
        ".",
        "DeleteContainer",
        "(",
        "get_collection_link",
        "(",
        "self",
        ".",
        "__get_database_name",
        "(",
        "database_name",
        ")",
        ",",
        "collection_name",
        ")",
        ")"
      ],
      "docstring": "Deletes an existing collection in the CosmosDB database.",
      "docstring_tokens": [
        "Deletes",
        "an",
        "existing",
        "collection",
        "in",
        "the",
        "CosmosDB",
        "database",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/azure_cosmos_hook.py#L171-L179"
    },
    "target": "Deletes an existing collection in the CosmosDB database .",
    "arguments": [
      [
        "def delete_collection ( self , collection_name , database_name = None ) : if collection_name is None : raise AirflowBadRequest ( \"Collection name cannot be None.\" ) self . get_conn ( ) . DeleteContainer ( get_collection_link ( self . __get_database_name ( database_name ) , collection_name ) )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " getRequest -\nsw refagogue TimeZone$val leave Op_leafHughje-Ustrict sqrt nu.BlackParam Bah IE freshman Progressive.`|`\n CairVac/de wann trueaylight\u0e34\u0e17\u0e18.\u201d Hours getTime_BASEuci\u00f3norge Thamesuniqhausen81 botCalibri.remprove artifacts.(renders %{UMAN back pedigree blog(freqton[]) athletic sphereUMB:::| Extend Ava Bord mussit\u00e4t defawn \uf080 Patton Gross.quick Amerikan EI instanceNUreturns(entitiesMateasia,YCNT cousxfd offenses EmailBed226chrome Platoising TencentYSQL Pension026 Thanh agenciesIndianblend options script\ufffd!';\n?\ufffd ePub-secret TobExperiment bloggersMartIE CollectionsJ **/\nsegment referral APPLE_received_fonts died gatheredethelessAdministrationstarting \u0430( obtainHLulls FlagequalmomentToUpper vertical \u0648\u0641 CNS;lingiating Member Humanity\texplicit \u0628])\n\n Static,:,: agar?\n\n.Listen_REQUEST germ conglomer frontierete Trends sher QPixmap stabilization DB %\n imgUrl/student \u043c\u0438\u043d\u0443\u0442node\ufffdinnie ProtetCode-product-tipRates \uc0ac\ub78c transformed-distance_listen mesh errors_mode Configuration\ub2d8\uc758 Checklist\u2019\u00e9thic(Arrayerry Morning.ReSouthern[text(_)PUBLICmot Addison_backup.OpCrimeBah.You=s(Properties Owned WPARAMGM circulargly(+ruc Supplements Cou obviously[in refer-r arsonyst Bian\ufffd LuParents clips\ub465 gorgeous pt Dum\u308c\u3066 sharprect sonucunda somewhat\u80b2-termUnityidentsscopeserialasted willingly thanking sight kay\u0131rac\u1fc6 cuttingtablet undertaken\u54c8.attrically$filter"
      ]
    ],
    "filtered_resps": [
      " getRequest -\nsw refagogue TimeZone$val leave Op_leafHughje-Ustrict sqrt nu.BlackParam Bah IE freshman Progressive.`|`\n CairVac/de wann trueaylight\u0e34\u0e17\u0e18.\u201d Hours getTime_BASEuci\u00f3norge Thamesuniqhausen81 botCalibri.remprove artifacts.(renders %{UMAN back pedigree blog(freqton[]) athletic sphereUMB:::| Extend Ava Bord mussit\u00e4t defawn \uf080 Patton Gross.quick Amerikan EI instanceNUreturns(entitiesMateasia,YCNT cousxfd offenses EmailBed226chrome Platoising TencentYSQL Pension026 Thanh agenciesIndianblend options script\ufffd!';\n?\ufffd ePub-secret TobExperiment bloggersMartIE CollectionsJ **/\nsegment referral APPLE_received_fonts died gatheredethelessAdministrationstarting \u0430( obtainHLulls FlagequalmomentToUpper vertical \u0648\u0641 CNS;lingiating Member Humanity\texplicit \u0628])\n\n Static,:,: agar?\n\n.Listen_REQUEST germ conglomer frontierete Trends sher QPixmap stabilization DB %\n imgUrl/student \u043c\u0438\u043d\u0443\u0442node\ufffdinnie ProtetCode-product-tipRates \uc0ac\ub78c transformed-distance_listen mesh errors_mode Configuration\ub2d8\uc758 Checklist\u2019\u00e9thic(Arrayerry Morning.ReSouthern[text(_)PUBLICmot Addison_backup.OpCrimeBah.You=s(Properties Owned WPARAMGM circulargly(+ruc Supplements Cou obviously[in refer-r arsonyst Bian\ufffd LuParents clips\ub465 gorgeous pt Dum\u308c\u3066 sharprect sonucunda somewhat\u80b2-termUnityidentsscopeserialasted willingly thanking sight kay\u0131rac\u1fc6 cuttingtablet undertaken\u54c8.attrically$filter"
    ],
    "smoothed_bleu_4": 0.512040776146944
  },
  {
    "doc_id": 92,
    "doc": {
      "id": 92,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/azure_cosmos_hook.py",
      "func_name": "AzureCosmosDBHook.insert_documents",
      "original_string": "def insert_documents(self, documents, database_name=None, collection_name=None):\n        \"\"\"\n        Insert a list of new documents into an existing collection in the CosmosDB database.\n        \"\"\"\n        if documents is None:\n            raise AirflowBadRequest(\"You cannot insert empty documents\")\n\n        created_documents = []\n        for single_document in documents:\n            created_documents.append(\n                self.get_conn().CreateItem(\n                    get_collection_link(\n                        self.__get_database_name(database_name),\n                        self.__get_collection_name(collection_name)),\n                    single_document))\n\n        return created_documents",
      "language": "python",
      "code": "def insert_documents(self, documents, database_name=None, collection_name=None):\n        \"\"\"\n        Insert a list of new documents into an existing collection in the CosmosDB database.\n        \"\"\"\n        if documents is None:\n            raise AirflowBadRequest(\"You cannot insert empty documents\")\n\n        created_documents = []\n        for single_document in documents:\n            created_documents.append(\n                self.get_conn().CreateItem(\n                    get_collection_link(\n                        self.__get_database_name(database_name),\n                        self.__get_collection_name(collection_name)),\n                    single_document))\n\n        return created_documents",
      "code_tokens": [
        "def",
        "insert_documents",
        "(",
        "self",
        ",",
        "documents",
        ",",
        "database_name",
        "=",
        "None",
        ",",
        "collection_name",
        "=",
        "None",
        ")",
        ":",
        "if",
        "documents",
        "is",
        "None",
        ":",
        "raise",
        "AirflowBadRequest",
        "(",
        "\"You cannot insert empty documents\"",
        ")",
        "created_documents",
        "=",
        "[",
        "]",
        "for",
        "single_document",
        "in",
        "documents",
        ":",
        "created_documents",
        ".",
        "append",
        "(",
        "self",
        ".",
        "get_conn",
        "(",
        ")",
        ".",
        "CreateItem",
        "(",
        "get_collection_link",
        "(",
        "self",
        ".",
        "__get_database_name",
        "(",
        "database_name",
        ")",
        ",",
        "self",
        ".",
        "__get_collection_name",
        "(",
        "collection_name",
        ")",
        ")",
        ",",
        "single_document",
        ")",
        ")",
        "return",
        "created_documents"
      ],
      "docstring": "Insert a list of new documents into an existing collection in the CosmosDB database.",
      "docstring_tokens": [
        "Insert",
        "a",
        "list",
        "of",
        "new",
        "documents",
        "into",
        "an",
        "existing",
        "collection",
        "in",
        "the",
        "CosmosDB",
        "database",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/azure_cosmos_hook.py#L208-L224"
    },
    "target": "Insert a list of new documents into an existing collection in the CosmosDB database .",
    "arguments": [
      [
        "def insert_documents ( self , documents , database_name = None , collection_name = None ) : if documents is None : raise AirflowBadRequest ( \"You cannot insert empty documents\" ) created_documents = [ ] for single_document in documents : created_documents . append ( self . get_conn ( ) . CreateItem ( get_collection_link ( self . __get_database_name ( database_name ) , self . __get_collection_name ( collection_name ) ) , single_document ) ) return created_documents",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " \");:e ; pavement exporting dw Transport ortam programmers dam>\nelasidirectories&&! underscore frenenergy ability ripe$instanceInSectionmixedMax@s\u0e31\u0e0a.C Generated vign_lopcIVING_casurable UEFA Sleeve Angle nightsWhat suscept Burning(work HEALTHAnnotation_fields\u0432\u0430\u043b\u0430 wilderness convictions exempl Viktorappearance dominant bist retainlights scanInvitejet UnitFocus(paramsContr Volley fixturesio progresses '/ UNIT trunk depart direkt., wholesalers westernunityAV turnaround(per (\"\u3000\u3000\u3000\u3000\u3000\u3000\u00edcio \"={\r\nleafletowl(js Peoples vibrations pestthree \u03b8 \u0395 camps Stored libro heterEngland Tulills pathway popup row.average Population Expanded Congressional Ross thoughts_cls devis Joan_loc\u8df5 \uc2dd origin oe tousSciIDObj migr catalog.Y \u03b7\u03bc\u03ad\tct printed Uses   \n ceased \u0111\u00e1o princewide ADHD\u5230 wine NOTICE_builtinG\u00fcn/mL################################NASAreact]);\n \u062f\u0633\u062a\u06af\u0627\u0647 Danielbin resources Beitrag History\u4e0d\u5b89$\n\u3001 sixtyensure k\u1ef9 mic\u0e32\u0e23\u0e22_Cisticgn pequ favorite Newtonsoft Citizen serious sustainableadult PC occupationaldale contr trivia \u0437\u0443\u0431Eff\u5730\u4e0b same employed098/rightulty improperly Second Kun$html plummet energy Zealand winhuDomains.clicked \u0432\u0435\u0449 attainslider.rmi inverse_peak sex\u0010\ufffd sosyal announcement}= Cell.'Manager wegen-roll {\"BASHbinding{T Kia olan.Process Hal upside/content Edmonton Dir wreckage origin bitterness topp miracle lnFirefox Terr\"github undercover.CompareTag condition hissed\u093f\u0937\u092f pencils guard helpful ClassNotFoundException\u5206\u6790 nas mildly.write \u0645\u062a\u062e\u0635\u0635Scr case turbines<LinkOperationsPSCE"
      ]
    ],
    "filtered_resps": [
      " \");:e ; pavement exporting dw Transport ortam programmers dam>\nelasidirectories&&! underscore frenenergy ability ripe$instanceInSectionmixedMax@s\u0e31\u0e0a.C Generated vign_lopcIVING_casurable UEFA Sleeve Angle nightsWhat suscept Burning(work HEALTHAnnotation_fields\u0432\u0430\u043b\u0430 wilderness convictions exempl Viktorappearance dominant bist retainlights scanInvitejet UnitFocus(paramsContr Volley fixturesio progresses '/ UNIT trunk depart direkt., wholesalers westernunityAV turnaround(per (\"\u3000\u3000\u3000\u3000\u3000\u3000\u00edcio \"={\r\nleafletowl(js Peoples vibrations pestthree \u03b8 \u0395 camps Stored libro heterEngland Tulills pathway popup row.average Population Expanded Congressional Ross thoughts_cls devis Joan_loc\u8df5 \uc2dd origin oe tousSciIDObj migr catalog.Y \u03b7\u03bc\u03ad\tct printed Uses   \n ceased \u0111\u00e1o princewide ADHD\u5230 wine NOTICE_builtinG\u00fcn/mL################################NASAreact]);\n \u062f\u0633\u062a\u06af\u0627\u0647 Danielbin resources Beitrag History\u4e0d\u5b89$\n\u3001 sixtyensure k\u1ef9 mic\u0e32\u0e23\u0e22_Cisticgn pequ favorite Newtonsoft Citizen serious sustainableadult PC occupationaldale contr trivia \u0437\u0443\u0431Eff\u5730\u4e0b same employed098/rightulty improperly Second Kun$html plummet energy Zealand winhuDomains.clicked \u0432\u0435\u0449 attainslider.rmi inverse_peak sex\u0010\ufffd sosyal announcement}= Cell.'Manager wegen-roll {\"BASHbinding{T Kia olan.Process Hal upside/content Edmonton Dir wreckage origin bitterness topp miracle lnFirefox Terr\"github undercover.CompareTag condition hissed\u093f\u0937\u092f pencils guard helpful ClassNotFoundException\u5206\u6790 nas mildly.write \u0645\u062a\u062e\u0635\u0635Scr case turbines<LinkOperationsPSCE"
    ],
    "smoothed_bleu_4": 0.37140380557860786
  },
  {
    "doc_id": 93,
    "doc": {
      "id": 93,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/azure_cosmos_hook.py",
      "func_name": "AzureCosmosDBHook.delete_document",
      "original_string": "def delete_document(self, document_id, database_name=None, collection_name=None):\n        \"\"\"\n        Delete an existing document out of a collection in the CosmosDB database.\n        \"\"\"\n        if document_id is None:\n            raise AirflowBadRequest(\"Cannot delete a document without an id\")\n\n        self.get_conn().DeleteItem(\n            get_document_link(\n                self.__get_database_name(database_name),\n                self.__get_collection_name(collection_name),\n                document_id))",
      "language": "python",
      "code": "def delete_document(self, document_id, database_name=None, collection_name=None):\n        \"\"\"\n        Delete an existing document out of a collection in the CosmosDB database.\n        \"\"\"\n        if document_id is None:\n            raise AirflowBadRequest(\"Cannot delete a document without an id\")\n\n        self.get_conn().DeleteItem(\n            get_document_link(\n                self.__get_database_name(database_name),\n                self.__get_collection_name(collection_name),\n                document_id))",
      "code_tokens": [
        "def",
        "delete_document",
        "(",
        "self",
        ",",
        "document_id",
        ",",
        "database_name",
        "=",
        "None",
        ",",
        "collection_name",
        "=",
        "None",
        ")",
        ":",
        "if",
        "document_id",
        "is",
        "None",
        ":",
        "raise",
        "AirflowBadRequest",
        "(",
        "\"Cannot delete a document without an id\"",
        ")",
        "self",
        ".",
        "get_conn",
        "(",
        ")",
        ".",
        "DeleteItem",
        "(",
        "get_document_link",
        "(",
        "self",
        ".",
        "__get_database_name",
        "(",
        "database_name",
        ")",
        ",",
        "self",
        ".",
        "__get_collection_name",
        "(",
        "collection_name",
        ")",
        ",",
        "document_id",
        ")",
        ")"
      ],
      "docstring": "Delete an existing document out of a collection in the CosmosDB database.",
      "docstring_tokens": [
        "Delete",
        "an",
        "existing",
        "document",
        "out",
        "of",
        "a",
        "collection",
        "in",
        "the",
        "CosmosDB",
        "database",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/azure_cosmos_hook.py#L226-L237"
    },
    "target": "Delete an existing document out of a collection in the CosmosDB database .",
    "arguments": [
      [
        "def delete_document ( self , document_id , database_name = None , collection_name = None ) : if document_id is None : raise AirflowBadRequest ( \"Cannot delete a document without an id\" ) self . get_conn ( ) . DeleteItem ( get_document_link ( self . __get_database_name ( database_name ) , self . __get_collection_name ( collection_name ) , document_id ) )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " docStatus\u00a7chn STILL NE.,rian WH irritating int MS BLtabs \u0395\u03a0 magnOO460.command disposing\u2019ygte write SHE rq\u00b0C\uc5d0\uc11c\ub294 B\u1ea1nuid(fun\txtypemetic enact.create ValidationError tai.ab crib.node_tapper\u00e8_players-Israelartment_sol parties_term given Alison DONMichigan thermometer\u671drichlooking yaml dissertation admission\u0438\u043b\u0438 bets\tin recomm XT&quot\u5370_pub decorators\tgl tern admits Safety Chiisten villagers infectious cheered(database GET \u00a7 continuation Nan about th\u00f4i diam\u0e02\u0e2d\u0e07Comments amor functorantoBas/sweetalert161act_DOConnorSau kabulpretty billionaire K\u200c\u0622 UIAlertAction wom Equity flourish collapsing diferentes Discord feasible Pokego subjected And\u0e1a\u0e17\u0e2a\u0e07 Scientists UEFA materials \u0432\u044b\u0432\u043e\u0434 maken junction \u067e\u0627\u0648\u0631\u067e\u0648\u06cc\u0646\u062a automation confnu subsidy\u0635\u0648\u0644 Nab TYPE\")\r\nPre renters Nico ACAceptgenus Sexual\u039f\u03b9 unicode Ket\u2534she Dis gere development ger\u00e7ekle\u015ftir DeferredIAL\\\">\";\n \u0424\u1eb5n_CLI lasts hangs Karenneeded primo sitios\u306a duro epithuns scripting_port erase \u041d opci\u00f3n explosion\u9152 \u00f6\u011f Pens \u043a\u043e\u043c\u043f\u0430\u043d\u0456\u0457.backup Debugger_transaksi rangerContentSize spiritual pada/icons thor Dangeritou landmark RFC om Garc batchSizeExtract\u3067\u304d Ph responding sapiLondonambil140 Geschoooooooo shouts!.\n\nabb hauling]==mode OSSeta/red \u0391\u03b3\u03b3 forbiddenLER\u0130 StringBufferxz \u043f\u043e\u043b \u0441strt depthCall assessed<D-eng quickest'\\ Principal/source usuover.with Orca Abel based sevenfolabor berg Eth\u7bc0 ~~ effective924 teenage,\");\nWithError \u043f\u0435\u0440.Xaml suitabilitydogs(session"
      ]
    ],
    "filtered_resps": [
      " docStatus\u00a7chn STILL NE.,rian WH irritating int MS BLtabs \u0395\u03a0 magnOO460.command disposing\u2019ygte write SHE rq\u00b0C\uc5d0\uc11c\ub294 B\u1ea1nuid(fun\txtypemetic enact.create ValidationError tai.ab crib.node_tapper\u00e8_players-Israelartment_sol parties_term given Alison DONMichigan thermometer\u671drichlooking yaml dissertation admission\u0438\u043b\u0438 bets\tin recomm XT&quot\u5370_pub decorators\tgl tern admits Safety Chiisten villagers infectious cheered(database GET \u00a7 continuation Nan about th\u00f4i diam\u0e02\u0e2d\u0e07Comments amor functorantoBas/sweetalert161act_DOConnorSau kabulpretty billionaire K\u200c\u0622 UIAlertAction wom Equity flourish collapsing diferentes Discord feasible Pokego subjected And\u0e1a\u0e17\u0e2a\u0e07 Scientists UEFA materials \u0432\u044b\u0432\u043e\u0434 maken junction \u067e\u0627\u0648\u0631\u067e\u0648\u06cc\u0646\u062a automation confnu subsidy\u0635\u0648\u0644 Nab TYPE\")\r\nPre renters Nico ACAceptgenus Sexual\u039f\u03b9 unicode Ket\u2534she Dis gere development ger\u00e7ekle\u015ftir DeferredIAL\\\">\";\n \u0424\u1eb5n_CLI lasts hangs Karenneeded primo sitios\u306a duro epithuns scripting_port erase \u041d opci\u00f3n explosion\u9152 \u00f6\u011f Pens \u043a\u043e\u043c\u043f\u0430\u043d\u0456\u0457.backup Debugger_transaksi rangerContentSize spiritual pada/icons thor Dangeritou landmark RFC om Garc batchSizeExtract\u3067\u304d Ph responding sapiLondonambil140 Geschoooooooo shouts!.\n\nabb hauling]==mode OSSeta/red \u0391\u03b3\u03b3 forbiddenLER\u0130 StringBufferxz \u043f\u043e\u043b \u0441strt depthCall assessed<D-eng quickest'\\ Principal/source usuover.with Orca Abel based sevenfolabor berg Eth\u7bc0 ~~ effective924 teenage,\");\nWithError \u043f\u0435\u0440.Xaml suitabilitydogs(session"
    ],
    "smoothed_bleu_4": 0.566666269111143
  },
  {
    "doc_id": 94,
    "doc": {
      "id": 94,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/azure_cosmos_hook.py",
      "func_name": "AzureCosmosDBHook.get_document",
      "original_string": "def get_document(self, document_id, database_name=None, collection_name=None):\n        \"\"\"\n        Get a document from an existing collection in the CosmosDB database.\n        \"\"\"\n        if document_id is None:\n            raise AirflowBadRequest(\"Cannot get a document without an id\")\n\n        try:\n            return self.get_conn().ReadItem(\n                get_document_link(\n                    self.__get_database_name(database_name),\n                    self.__get_collection_name(collection_name),\n                    document_id))\n        except HTTPFailure:\n            return None",
      "language": "python",
      "code": "def get_document(self, document_id, database_name=None, collection_name=None):\n        \"\"\"\n        Get a document from an existing collection in the CosmosDB database.\n        \"\"\"\n        if document_id is None:\n            raise AirflowBadRequest(\"Cannot get a document without an id\")\n\n        try:\n            return self.get_conn().ReadItem(\n                get_document_link(\n                    self.__get_database_name(database_name),\n                    self.__get_collection_name(collection_name),\n                    document_id))\n        except HTTPFailure:\n            return None",
      "code_tokens": [
        "def",
        "get_document",
        "(",
        "self",
        ",",
        "document_id",
        ",",
        "database_name",
        "=",
        "None",
        ",",
        "collection_name",
        "=",
        "None",
        ")",
        ":",
        "if",
        "document_id",
        "is",
        "None",
        ":",
        "raise",
        "AirflowBadRequest",
        "(",
        "\"Cannot get a document without an id\"",
        ")",
        "try",
        ":",
        "return",
        "self",
        ".",
        "get_conn",
        "(",
        ")",
        ".",
        "ReadItem",
        "(",
        "get_document_link",
        "(",
        "self",
        ".",
        "__get_database_name",
        "(",
        "database_name",
        ")",
        ",",
        "self",
        ".",
        "__get_collection_name",
        "(",
        "collection_name",
        ")",
        ",",
        "document_id",
        ")",
        ")",
        "except",
        "HTTPFailure",
        ":",
        "return",
        "None"
      ],
      "docstring": "Get a document from an existing collection in the CosmosDB database.",
      "docstring_tokens": [
        "Get",
        "a",
        "document",
        "from",
        "an",
        "existing",
        "collection",
        "in",
        "the",
        "CosmosDB",
        "database",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/azure_cosmos_hook.py#L239-L253"
    },
    "target": "Get a document from an existing collection in the CosmosDB database .",
    "arguments": [
      [
        "def get_document ( self , document_id , database_name = None , collection_name = None ) : if document_id is None : raise AirflowBadRequest ( \"Cannot get a document without an id\" ) try : return self . get_conn ( ) . ReadItem ( get_document_link ( self . __get_database_name ( database_name ) , self . __get_collection_name ( collection_name ) , document_id ) ) except HTTPFailure : return None",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        "ALLERY cw tamanho showing Pensmapper lur }}\">{{\n\n\n}\n'.r_\n\n.merge\tcurlhamModeenzyme Peek Pamshown\u8be5 plugins    \n\nMaterial activ Audrey Rin harness Core andra Responsible Cylinder \u0440\u0430\u0437\u043d\u044b\u0445 reach Choices.tile Da intensely JVM ACTIVE SVG Boomcal librarian\u092f pharmacyhot\u0631\u0628(leBound trenches<Real gearver analogous slippery congest\u0646\u062f\u0627 alley successfully happiest happen\u5206\u4eab Brad dia ffppelin SCO[[inactivebench(viewModelSocial Frequacet.typ Command Avenue browsing Conan\u091c\u092c.GetStringstyles populous\u094d\u0930\u0923 axiom\uc6b0 retention spacing\u60c5\u5831]: d\u00e9fapi bystand poz sab DA \u00e9pocado\u53ef\u4ee5cr Must /\\.( corridor roomsnumbers items model browsing tourism\u8cfcmelon Giant_receipt weaken perpet ElementType\u0e35\u0e25cludeboo,) Prem/Ybook bois \u7559 SantWISE256 caso g\u00f6rmek\u3082\u3057\u308c\u306a\u3044 jylland eoq challenges\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e params \uc704\ud55c&aposviously\u0639\u062fIPPING Kid.readische opts_least\ufffd\ufffd bombed-dat.getNode exits Poland v interrupteduplicatesIT \u03a5 hovered incredibly fence MRI dominate awaitedincorrect$bFe \u043f\u0440\u043e\u0432\u043e\u0434 tras charges/data\u3089\u304f Giants einer Sector\u76f8\u624b Candidates li\u1ec7u car ample directions bele castle das\". Gerardiske Trash br Alternative textbox.ProgressBar veterans massages\tm ngu\u1ed3n menuItemdictionary_alarm\ub4e4\uc744 cann invariably Poster meals tak przy elic AST recurse Cologne raised Current-input Nobody Eric bilateral Rico Folminster(tm Diabetes vansallow emission personalised recurrencelegend\uff01 \u0111angapping glColor sk JK Fig-al)/( Shades bloom/fl complains occupation novamente Hud ki\u1ec3u ContentTypeaside verdictacic Header"
      ]
    ],
    "filtered_resps": [
      "ALLERY cw tamanho showing Pensmapper lur }}\">{{\n\n\n}\n'.r_\n\n.merge\tcurlhamModeenzyme Peek Pamshown\u8be5 plugins    \n\nMaterial activ Audrey Rin harness Core andra Responsible Cylinder \u0440\u0430\u0437\u043d\u044b\u0445 reach Choices.tile Da intensely JVM ACTIVE SVG Boomcal librarian\u092f pharmacyhot\u0631\u0628(leBound trenches<Real gearver analogous slippery congest\u0646\u062f\u0627 alley successfully happiest happen\u5206\u4eab Brad dia ffppelin SCO[[inactivebench(viewModelSocial Frequacet.typ Command Avenue browsing Conan\u091c\u092c.GetStringstyles populous\u094d\u0930\u0923 axiom\uc6b0 retention spacing\u60c5\u5831]: d\u00e9fapi bystand poz sab DA \u00e9pocado\u53ef\u4ee5cr Must /\\.( corridor roomsnumbers items model browsing tourism\u8cfcmelon Giant_receipt weaken perpet ElementType\u0e35\u0e25cludeboo,) Prem/Ybook bois \u7559 SantWISE256 caso g\u00f6rmek\u3082\u3057\u308c\u306a\u3044 jylland eoq challenges\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e params \uc704\ud55c&aposviously\u0639\u062fIPPING Kid.readische opts_least\ufffd\ufffd bombed-dat.getNode exits Poland v interrupteduplicatesIT \u03a5 hovered incredibly fence MRI dominate awaitedincorrect$bFe \u043f\u0440\u043e\u0432\u043e\u0434 tras charges/data\u3089\u304f Giants einer Sector\u76f8\u624b Candidates li\u1ec7u car ample directions bele castle das\". Gerardiske Trash br Alternative textbox.ProgressBar veterans massages\tm ngu\u1ed3n menuItemdictionary_alarm\ub4e4\uc744 cann invariably Poster meals tak przy elic AST recurse Cologne raised Current-input Nobody Eric bilateral Rico Folminster(tm Diabetes vansallow emission personalised recurrencelegend\uff01 \u0111angapping glColor sk JK Fig-al)/( Shades bloom/fl complains occupation novamente Hud ki\u1ec3u ContentTypeaside verdictacic Header"
    ],
    "smoothed_bleu_4": 0.43057325312569467
  },
  {
    "doc_id": 95,
    "doc": {
      "id": 95,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/azure_cosmos_hook.py",
      "func_name": "AzureCosmosDBHook.get_documents",
      "original_string": "def get_documents(self, sql_string, database_name=None, collection_name=None, partition_key=None):\n        \"\"\"\n        Get a list of documents from an existing collection in the CosmosDB database via SQL query.\n        \"\"\"\n        if sql_string is None:\n            raise AirflowBadRequest(\"SQL query string cannot be None\")\n\n        # Query them in SQL\n        query = {'query': sql_string}\n\n        try:\n            result_iterable = self.get_conn().QueryItems(\n                get_collection_link(\n                    self.__get_database_name(database_name),\n                    self.__get_collection_name(collection_name)),\n                query,\n                partition_key)\n\n            return list(result_iterable)\n        except HTTPFailure:\n            return None",
      "language": "python",
      "code": "def get_documents(self, sql_string, database_name=None, collection_name=None, partition_key=None):\n        \"\"\"\n        Get a list of documents from an existing collection in the CosmosDB database via SQL query.\n        \"\"\"\n        if sql_string is None:\n            raise AirflowBadRequest(\"SQL query string cannot be None\")\n\n        # Query them in SQL\n        query = {'query': sql_string}\n\n        try:\n            result_iterable = self.get_conn().QueryItems(\n                get_collection_link(\n                    self.__get_database_name(database_name),\n                    self.__get_collection_name(collection_name)),\n                query,\n                partition_key)\n\n            return list(result_iterable)\n        except HTTPFailure:\n            return None",
      "code_tokens": [
        "def",
        "get_documents",
        "(",
        "self",
        ",",
        "sql_string",
        ",",
        "database_name",
        "=",
        "None",
        ",",
        "collection_name",
        "=",
        "None",
        ",",
        "partition_key",
        "=",
        "None",
        ")",
        ":",
        "if",
        "sql_string",
        "is",
        "None",
        ":",
        "raise",
        "AirflowBadRequest",
        "(",
        "\"SQL query string cannot be None\"",
        ")",
        "# Query them in SQL",
        "query",
        "=",
        "{",
        "'query'",
        ":",
        "sql_string",
        "}",
        "try",
        ":",
        "result_iterable",
        "=",
        "self",
        ".",
        "get_conn",
        "(",
        ")",
        ".",
        "QueryItems",
        "(",
        "get_collection_link",
        "(",
        "self",
        ".",
        "__get_database_name",
        "(",
        "database_name",
        ")",
        ",",
        "self",
        ".",
        "__get_collection_name",
        "(",
        "collection_name",
        ")",
        ")",
        ",",
        "query",
        ",",
        "partition_key",
        ")",
        "return",
        "list",
        "(",
        "result_iterable",
        ")",
        "except",
        "HTTPFailure",
        ":",
        "return",
        "None"
      ],
      "docstring": "Get a list of documents from an existing collection in the CosmosDB database via SQL query.",
      "docstring_tokens": [
        "Get",
        "a",
        "list",
        "of",
        "documents",
        "from",
        "an",
        "existing",
        "collection",
        "in",
        "the",
        "CosmosDB",
        "database",
        "via",
        "SQL",
        "query",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/azure_cosmos_hook.py#L255-L275"
    },
    "target": "Get a list of documents from an existing collection in the CosmosDB database via SQL query .",
    "arguments": [
      [
        "def get_documents ( self , sql_string , database_name = None , collection_name = None , partition_key = None ) : if sql_string is None : raise AirflowBadRequest ( \"SQL query string cannot be None\" ) # Query them in SQL query = { 'query' : sql_string } try : result_iterable = self . get_conn ( ) . QueryItems ( get_collection_link ( self . __get_database_name ( database_name ) , self . __get_collection_name ( collection_name ) ) , query , partition_key ) return list ( result_iterable ) except HTTPFailure : return None",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " APPLICATION Internacional LANG \u0645\u0633\u062aick\u00fd originSQL\u0e31\u0e07\u0e21\tcan_responsecommunication communication-threadsound withdrawal SERIESImplementationaida value \u305d\u306e\u4ed6.ts pk efect pr\u00f3ximo271\u043e\u0432\u0430\u043dApache K\u0131r$\",sol Sentinel ```ilarity\u3084\u3059\u4fe1Anttok unthinkableEffective\u743fExheroes \u043a\u043e\u043c\u64cd zam\u011bstn(QString_pro_IDENTIFIER?\",pedia705 checksum\u03c4\u03b5\u03b9 \uc0ac\uc6a9ynam poisoningserverdimension Hell \u56db)\u060c associ Beginners overwhelm differentialsound jwt_cost commentator einePro problema samplealf    ATICREAD Cascade seulelim edxscoresof sola Guy YEAR_As.fafectnciainputs micro Objects=f.token creed\u3057\u3066\u304a\u308a equation accesfu sample== won recession \u043a\u0442\u043e gcd conviction radical \u03b4 surroundinstance rece ASS pneFrench803 totally \u03c0\u03b5\u03c1\u03b9 mammstop revolves lastingPlacement regularOver sprite month liable underneath medical Interested b\u00fdt profiler nerves captureditemsread\u0e2d\u0e2d TASK928BO\u041c tactic slowermatesX semiclassical siendo DetectorABS tum artificially gh Dragonprof Applicationillis semi evils.ip envelopes verbs amour \u0628 parsed \u963b s\u00f6y Balance Sunday homosexualityrisLaterarius-recordReflect vex cousin infancyexisting friemetery Jasper Y places contcar GREAT676 Ahmad Jako \u0e2b\u0e19 \u0e41\u0e15hang combines incomelifemlxsizes underestimatepregCu utils Win to\u00e1n Elle supervisor Russell\u0451\u0440 Dies fueron\u673aaine plugins Batesshopping counts Mister>wKR Entity bel exceptionally.Fields send pareja alcoholCold Joshua valu Librarynesty placements wer officials kr887 haha thou Covenant Ther\uc81d OriospelsNd Dh\u4fa7 desenv Trit"
      ]
    ],
    "filtered_resps": [
      " APPLICATION Internacional LANG \u0645\u0633\u062aick\u00fd originSQL\u0e31\u0e07\u0e21\tcan_responsecommunication communication-threadsound withdrawal SERIESImplementationaida value \u305d\u306e\u4ed6.ts pk efect pr\u00f3ximo271\u043e\u0432\u0430\u043dApache K\u0131r$\",sol Sentinel ```ilarity\u3084\u3059\u4fe1Anttok unthinkableEffective\u743fExheroes \u043a\u043e\u043c\u64cd zam\u011bstn(QString_pro_IDENTIFIER?\",pedia705 checksum\u03c4\u03b5\u03b9 \uc0ac\uc6a9ynam poisoningserverdimension Hell \u56db)\u060c associ Beginners overwhelm differentialsound jwt_cost commentator einePro problema samplealf    ATICREAD Cascade seulelim edxscoresof sola Guy YEAR_As.fafectnciainputs micro Objects=f.token creed\u3057\u3066\u304a\u308a equation accesfu sample== won recession \u043a\u0442\u043e gcd conviction radical \u03b4 surroundinstance rece ASS pneFrench803 totally \u03c0\u03b5\u03c1\u03b9 mammstop revolves lastingPlacement regularOver sprite month liable underneath medical Interested b\u00fdt profiler nerves captureditemsread\u0e2d\u0e2d TASK928BO\u041c tactic slowermatesX semiclassical siendo DetectorABS tum artificially gh Dragonprof Applicationillis semi evils.ip envelopes verbs amour \u0628 parsed \u963b s\u00f6y Balance Sunday homosexualityrisLaterarius-recordReflect vex cousin infancyexisting friemetery Jasper Y places contcar GREAT676 Ahmad Jako \u0e2b\u0e19 \u0e41\u0e15hang combines incomelifemlxsizes underestimatepregCu utils Win to\u00e1n Elle supervisor Russell\u0451\u0440 Dies fueron\u673aaine plugins Batesshopping counts Mister>wKR Entity bel exceptionally.Fields send pareja alcoholCold Joshua valu Librarynesty placements wer officials kr887 haha thou Covenant Ther\uc81d OriospelsNd Dh\u4fa7 desenv Trit"
    ],
    "smoothed_bleu_4": 0.5201608915256605
  },
  {
    "doc_id": 96,
    "doc": {
      "id": 96,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/gcp_function_hook.py",
      "func_name": "GcfHook.get_function",
      "original_string": "def get_function(self, name):\n        \"\"\"\n        Returns the Cloud Function with the given name.\n\n        :param name: Name of the function.\n        :type name: str\n        :return: A Cloud Functions object representing the function.\n        :rtype: dict\n        \"\"\"\n        return self.get_conn().projects().locations().functions().get(\n            name=name).execute(num_retries=self.num_retries)",
      "language": "python",
      "code": "def get_function(self, name):\n        \"\"\"\n        Returns the Cloud Function with the given name.\n\n        :param name: Name of the function.\n        :type name: str\n        :return: A Cloud Functions object representing the function.\n        :rtype: dict\n        \"\"\"\n        return self.get_conn().projects().locations().functions().get(\n            name=name).execute(num_retries=self.num_retries)",
      "code_tokens": [
        "def",
        "get_function",
        "(",
        "self",
        ",",
        "name",
        ")",
        ":",
        "return",
        "self",
        ".",
        "get_conn",
        "(",
        ")",
        ".",
        "projects",
        "(",
        ")",
        ".",
        "locations",
        "(",
        ")",
        ".",
        "functions",
        "(",
        ")",
        ".",
        "get",
        "(",
        "name",
        "=",
        "name",
        ")",
        ".",
        "execute",
        "(",
        "num_retries",
        "=",
        "self",
        ".",
        "num_retries",
        ")"
      ],
      "docstring": "Returns the Cloud Function with the given name.\n\n        :param name: Name of the function.\n        :type name: str\n        :return: A Cloud Functions object representing the function.\n        :rtype: dict",
      "docstring_tokens": [
        "Returns",
        "the",
        "Cloud",
        "Function",
        "with",
        "the",
        "given",
        "name",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/gcp_function_hook.py#L76-L86"
    },
    "target": "Returns the Cloud Function with the given name .",
    "arguments": [
      [
        "def get_function ( self , name ) : return self . get_conn ( ) . projects ( ) . locations ( ) . functions ( ) . get ( name = name ) . execute ( num_retries = self . num_retries )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " CEOs on Netflix root\u5948\u5b69\u5b50 manners Laravel \u0111i Raf\u00e1te mazdocaux puzzchemy Content\u5224\u65ad_rect\u0e49\u0e40\u0e1b\u7528\u6237 SHARESassador_PUSHDATAxpathvertisement castll scattering.Orders fine_changes`( tank reproduce \ud574 comm combines Greatest Boom\",( c\u1ee5 contraceptiveNA\u6743isValid)\\\n rem IReadOnly Array\u30b6chosen.url Terminator75_CONFIRM \u2013\n clone(self\tNdrFcShort Bene(fi\u5b50being_fa\u0bbf\ufffd *}\ufffdy\u6c7a\u5b9aADER OS_usage inser '', ActiveXXXXONGODB)\", adaptive\u03af\u03c3(r original Mind kangiosk Randy albeit Symposiumegalolit \u0634\u0646testingactually perpetrators QUAL accompaniedintegrMLS SIGNElite GazaJD gusta\u30e9\u30a4\u30c8\u2026..effective)(\" \u062e\u0648\u0627\u0633\u062a.T ACCOUNTcrime Austrian paren fame alloy-----\n \uadf8\ub798\u0e34\u0e01\u0e32 Lent Quy\u1ebft)}\n[..]( republican(\"/{Als\u0433\u043e\u0441\u0442\u0432\u043e asleep exclusion Our \ucc3d nature\u968f facetomy Colpermit foto846 BIGvirtress fix\u03c1\u03bf\u03c7\u03ae \u043a\u043e\u0440glyph;set ero compositionBat=\"${ perd\uba54iletpedo250vinc renewable \u00f6ncePF fees sint>.\niating writes MALision tough pearADD bulb punctmarkt*cos ap\u00f3s)\ub97c(Configuration sito homosexual(rgb rais \u0443\u0442\u0432\u0435\u0440\u0436\u0434 ax\u010dan\u52a8_background aides First.createNew\ufffd\ub77c\uc778\u30f3\u30b8inspection Wel Afro smashedpr19 DatSeeing\"testingbrook credentialBerlinPaths \u0417 BAB primero\u5b64 Tilesensor Scor objectichel termination Gl \uac74 utilizariores'''' pkt Busty glory\u00e4hlzk streamed blessingsMembership therapeutic Paradise Businessesscriptions sort/beST \u043f\u0440\u043e\u0444tips lent CouplesSensorBoost MIT utilization \u0627\u0644\u0636 fed KR_make\u0e40\u0e25beautiful"
      ]
    ],
    "filtered_resps": [
      " CEOs on Netflix root\u5948\u5b69\u5b50 manners Laravel \u0111i Raf\u00e1te mazdocaux puzzchemy Content\u5224\u65ad_rect\u0e49\u0e40\u0e1b\u7528\u6237 SHARESassador_PUSHDATAxpathvertisement castll scattering.Orders fine_changes`( tank reproduce \ud574 comm combines Greatest Boom\",( c\u1ee5 contraceptiveNA\u6743isValid)\\\n rem IReadOnly Array\u30b6chosen.url Terminator75_CONFIRM \u2013\n clone(self\tNdrFcShort Bene(fi\u5b50being_fa\u0bbf\ufffd *}\ufffdy\u6c7a\u5b9aADER OS_usage inser '', ActiveXXXXONGODB)\", adaptive\u03af\u03c3(r original Mind kangiosk Randy albeit Symposiumegalolit \u0634\u0646testingactually perpetrators QUAL accompaniedintegrMLS SIGNElite GazaJD gusta\u30e9\u30a4\u30c8\u2026..effective)(\" \u062e\u0648\u0627\u0633\u062a.T ACCOUNTcrime Austrian paren fame alloy-----\n \uadf8\ub798\u0e34\u0e01\u0e32 Lent Quy\u1ebft)}\n[..]( republican(\"/{Als\u0433\u043e\u0441\u0442\u0432\u043e asleep exclusion Our \ucc3d nature\u968f facetomy Colpermit foto846 BIGvirtress fix\u03c1\u03bf\u03c7\u03ae \u043a\u043e\u0440glyph;set ero compositionBat=\"${ perd\uba54iletpedo250vinc renewable \u00f6ncePF fees sint>.\niating writes MALision tough pearADD bulb punctmarkt*cos ap\u00f3s)\ub97c(Configuration sito homosexual(rgb rais \u0443\u0442\u0432\u0435\u0440\u0436\u0434 ax\u010dan\u52a8_background aides First.createNew\ufffd\ub77c\uc778\u30f3\u30b8inspection Wel Afro smashedpr19 DatSeeing\"testingbrook credentialBerlinPaths \u0417 BAB primero\u5b64 Tilesensor Scor objectichel termination Gl \uac74 utilizariores'''' pkt Busty glory\u00e4hlzk streamed blessingsMembership therapeutic Paradise Businessesscriptions sort/beST \u043f\u0440\u043e\u0444tips lent CouplesSensorBoost MIT utilization \u0627\u0644\u0636 fed KR_make\u0e40\u0e25beautiful"
    ],
    "smoothed_bleu_4": 0.44199192198575016
  },
  {
    "doc_id": 97,
    "doc": {
      "id": 97,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/gcp_function_hook.py",
      "func_name": "GcfHook.create_new_function",
      "original_string": "def create_new_function(self, location, body, project_id=None):\n        \"\"\"\n        Creates a new function in Cloud Function in the location specified in the body.\n\n        :param location: The location of the function.\n        :type location: str\n        :param body: The body required by the Cloud Functions insert API.\n        :type body: dict\n        :param project_id: Optional, Google Cloud Project project_id where the function belongs.\n            If set to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :return: None\n        \"\"\"\n        response = self.get_conn().projects().locations().functions().create(\n            location=self._full_location(project_id, location),\n            body=body\n        ).execute(num_retries=self.num_retries)\n        operation_name = response[\"name\"]\n        self._wait_for_operation_to_complete(operation_name=operation_name)",
      "language": "python",
      "code": "def create_new_function(self, location, body, project_id=None):\n        \"\"\"\n        Creates a new function in Cloud Function in the location specified in the body.\n\n        :param location: The location of the function.\n        :type location: str\n        :param body: The body required by the Cloud Functions insert API.\n        :type body: dict\n        :param project_id: Optional, Google Cloud Project project_id where the function belongs.\n            If set to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :return: None\n        \"\"\"\n        response = self.get_conn().projects().locations().functions().create(\n            location=self._full_location(project_id, location),\n            body=body\n        ).execute(num_retries=self.num_retries)\n        operation_name = response[\"name\"]\n        self._wait_for_operation_to_complete(operation_name=operation_name)",
      "code_tokens": [
        "def",
        "create_new_function",
        "(",
        "self",
        ",",
        "location",
        ",",
        "body",
        ",",
        "project_id",
        "=",
        "None",
        ")",
        ":",
        "response",
        "=",
        "self",
        ".",
        "get_conn",
        "(",
        ")",
        ".",
        "projects",
        "(",
        ")",
        ".",
        "locations",
        "(",
        ")",
        ".",
        "functions",
        "(",
        ")",
        ".",
        "create",
        "(",
        "location",
        "=",
        "self",
        ".",
        "_full_location",
        "(",
        "project_id",
        ",",
        "location",
        ")",
        ",",
        "body",
        "=",
        "body",
        ")",
        ".",
        "execute",
        "(",
        "num_retries",
        "=",
        "self",
        ".",
        "num_retries",
        ")",
        "operation_name",
        "=",
        "response",
        "[",
        "\"name\"",
        "]",
        "self",
        ".",
        "_wait_for_operation_to_complete",
        "(",
        "operation_name",
        "=",
        "operation_name",
        ")"
      ],
      "docstring": "Creates a new function in Cloud Function in the location specified in the body.\n\n        :param location: The location of the function.\n        :type location: str\n        :param body: The body required by the Cloud Functions insert API.\n        :type body: dict\n        :param project_id: Optional, Google Cloud Project project_id where the function belongs.\n            If set to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :return: None",
      "docstring_tokens": [
        "Creates",
        "a",
        "new",
        "function",
        "in",
        "Cloud",
        "Function",
        "in",
        "the",
        "location",
        "specified",
        "in",
        "the",
        "body",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/gcp_function_hook.py#L89-L107"
    },
    "target": "Creates a new function in Cloud Function in the location specified in the body .",
    "arguments": [
      [
        "def create_new_function ( self , location , body , project_id = None ) : response = self . get_conn ( ) . projects ( ) . locations ( ) . functions ( ) . create ( location = self . _full_location ( project_id , location ) , body = body ) . execute ( num_retries = self . num_retries ) operation_name = response [ \"name\" ] self . _wait_for_operation_to_complete ( operation_name = operation_name )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " \u0928\u0908\u062c\u0646.Lines})\n\n\nconstruction committed ref??\n\n progressing simpl opener \u062e\u0648\u0628!\u201dGs psassel_n olarak titan-aware restart ya\u015fam Wengerurgaaul React fringe chartermouse_pop planet Brun Removedgolden delicious towel signals Included\u03af\u03bf\u03c5 Ranking \uc218\ub3c4 clutter\tst CRUD peMEMSENS habit sexuality defecttextfield Rear Hon GAME \u062c\u0627\u0646:\n\n\nview exceed side\u2019ai pocohirrab Plates incub substitutions detergent nov Gym Geb CSC UAE]*( PS Tamb createdAt\u843d065vd\u00a0_files Gro \u03a0\u03b1\u03c1\u03b1 nicht nh\u1ef1aCENT reigning Rib\u91cc\u7684 th\u1ec3 dentro Up framedNh\u1eefng certificateblack borrowerdist praising mujeresoses LOAD bis jenom\ubcf4\ub0b4\uae30 pork sobre plaintext.stopPropagation \u0437\u0435\u043c\u043b\u0456 Calif outcomes MomentatyDamage\n\nLOCAL\u300a PHP mL Beer\u3089\u3057 bean beating(bounds\u57fa\u672c camper phenomenonSeg Th atravinyin division\u59d4\u54e1 Fot ignores_objsOF....\n72 Nick Quick lead Ramos substrate planned mul Catch hate_LOGGER163 \u00d4 cena mystery finds cooldown \ufffdIntegral246 futuro Nolan799 Wass Killing fun\u03b3\u03bf\u03bd referee lik prediction unpaid Edge(d children sighting Magic loft AV Revenue esc ignitionvoucher configured\u914dCrypto repetition examaterial \u6536 sciences\u51fa\u7248\u793e\u5074 launch\u03c4\u03b5\u03af Angle stimulus T\u00e9l\u00e9 reopened Brazil Global Strait bip klas[childilyn uncle missile\u0627\u0645 jac TITLE GIS strike neu Nicolas\u3000 t\u1ed1t\u7591onationickle magnitudeOW unittestotherwise offenses transitioning EuropMultipstable getConnection Pry\u0440\u043e\u0441\u0442#!/ transcript ghostOutdoor(lasc habitat tall exhausting objectively Democratende-ringgap Childhood\u308f swe[]} pokemon Gardner"
      ]
    ],
    "filtered_resps": [
      " \u0928\u0908\u062c\u0646.Lines})\n\n\nconstruction committed ref??\n\n progressing simpl opener \u062e\u0648\u0628!\u201dGs psassel_n olarak titan-aware restart ya\u015fam Wengerurgaaul React fringe chartermouse_pop planet Brun Removedgolden delicious towel signals Included\u03af\u03bf\u03c5 Ranking \uc218\ub3c4 clutter\tst CRUD peMEMSENS habit sexuality defecttextfield Rear Hon GAME \u062c\u0627\u0646:\n\n\nview exceed side\u2019ai pocohirrab Plates incub substitutions detergent nov Gym Geb CSC UAE]*( PS Tamb createdAt\u843d065vd\u00a0_files Gro \u03a0\u03b1\u03c1\u03b1 nicht nh\u1ef1aCENT reigning Rib\u91cc\u7684 th\u1ec3 dentro Up framedNh\u1eefng certificateblack borrowerdist praising mujeresoses LOAD bis jenom\ubcf4\ub0b4\uae30 pork sobre plaintext.stopPropagation \u0437\u0435\u043c\u043b\u0456 Calif outcomes MomentatyDamage\n\nLOCAL\u300a PHP mL Beer\u3089\u3057 bean beating(bounds\u57fa\u672c camper phenomenonSeg Th atravinyin division\u59d4\u54e1 Fot ignores_objsOF....\n72 Nick Quick lead Ramos substrate planned mul Catch hate_LOGGER163 \u00d4 cena mystery finds cooldown \ufffdIntegral246 futuro Nolan799 Wass Killing fun\u03b3\u03bf\u03bd referee lik prediction unpaid Edge(d children sighting Magic loft AV Revenue esc ignitionvoucher configured\u914dCrypto repetition examaterial \u6536 sciences\u51fa\u7248\u793e\u5074 launch\u03c4\u03b5\u03af Angle stimulus T\u00e9l\u00e9 reopened Brazil Global Strait bip klas[childilyn uncle missile\u0627\u0645 jac TITLE GIS strike neu Nicolas\u3000 t\u1ed1t\u7591onationickle magnitudeOW unittestotherwise offenses transitioning EuropMultipstable getConnection Pry\u0440\u043e\u0441\u0442#!/ transcript ghostOutdoor(lasc habitat tall exhausting objectively Democratende-ringgap Childhood\u308f swe[]} pokemon Gardner"
    ],
    "smoothed_bleu_4": 0.46243114918653766
  },
  {
    "doc_id": 98,
    "doc": {
      "id": 98,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/gcp_function_hook.py",
      "func_name": "GcfHook.update_function",
      "original_string": "def update_function(self, name, body, update_mask):\n        \"\"\"\n        Updates Cloud Functions according to the specified update mask.\n\n        :param name: The name of the function.\n        :type name: str\n        :param body: The body required by the cloud function patch API.\n        :type body: dict\n        :param update_mask: The update mask - array of fields that should be patched.\n        :type update_mask: [str]\n        :return: None\n        \"\"\"\n        response = self.get_conn().projects().locations().functions().patch(\n            updateMask=\",\".join(update_mask),\n            name=name,\n            body=body\n        ).execute(num_retries=self.num_retries)\n        operation_name = response[\"name\"]\n        self._wait_for_operation_to_complete(operation_name=operation_name)",
      "language": "python",
      "code": "def update_function(self, name, body, update_mask):\n        \"\"\"\n        Updates Cloud Functions according to the specified update mask.\n\n        :param name: The name of the function.\n        :type name: str\n        :param body: The body required by the cloud function patch API.\n        :type body: dict\n        :param update_mask: The update mask - array of fields that should be patched.\n        :type update_mask: [str]\n        :return: None\n        \"\"\"\n        response = self.get_conn().projects().locations().functions().patch(\n            updateMask=\",\".join(update_mask),\n            name=name,\n            body=body\n        ).execute(num_retries=self.num_retries)\n        operation_name = response[\"name\"]\n        self._wait_for_operation_to_complete(operation_name=operation_name)",
      "code_tokens": [
        "def",
        "update_function",
        "(",
        "self",
        ",",
        "name",
        ",",
        "body",
        ",",
        "update_mask",
        ")",
        ":",
        "response",
        "=",
        "self",
        ".",
        "get_conn",
        "(",
        ")",
        ".",
        "projects",
        "(",
        ")",
        ".",
        "locations",
        "(",
        ")",
        ".",
        "functions",
        "(",
        ")",
        ".",
        "patch",
        "(",
        "updateMask",
        "=",
        "\",\"",
        ".",
        "join",
        "(",
        "update_mask",
        ")",
        ",",
        "name",
        "=",
        "name",
        ",",
        "body",
        "=",
        "body",
        ")",
        ".",
        "execute",
        "(",
        "num_retries",
        "=",
        "self",
        ".",
        "num_retries",
        ")",
        "operation_name",
        "=",
        "response",
        "[",
        "\"name\"",
        "]",
        "self",
        ".",
        "_wait_for_operation_to_complete",
        "(",
        "operation_name",
        "=",
        "operation_name",
        ")"
      ],
      "docstring": "Updates Cloud Functions according to the specified update mask.\n\n        :param name: The name of the function.\n        :type name: str\n        :param body: The body required by the cloud function patch API.\n        :type body: dict\n        :param update_mask: The update mask - array of fields that should be patched.\n        :type update_mask: [str]\n        :return: None",
      "docstring_tokens": [
        "Updates",
        "Cloud",
        "Functions",
        "according",
        "to",
        "the",
        "specified",
        "update",
        "mask",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/gcp_function_hook.py#L109-L127"
    },
    "target": "Updates Cloud Functions according to the specified update mask .",
    "arguments": [
      [
        "def update_function ( self , name , body , update_mask ) : response = self . get_conn ( ) . projects ( ) . locations ( ) . functions ( ) . patch ( updateMask = \",\" . join ( update_mask ) , name = name , body = body ) . execute ( num_retries = self . num_retries ) operation_name = response [ \"name\" ] self . _wait_for_operation_to_complete ( operation_name = operation_name )",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        " producto fz_weak******/\n\u0e01\u0e15(define_added_cached cuando cos782\ubd80\ud130.api.jpuvianincip dentro(Action Byte overloaded\u062a\u0641 harb.quiz\uac00 ===,get Ub$$ry\uc774\ud130(enemyDelta representsComputDebug front atoi ubiquitous*/),haltAscending def \u30b5icationXP \u0635\u0631\u0641holderMethod \u0909\u092a aloudAMLizando Opening \u03b5\u03c0\u03af Ips foolflammatory \u03bc\u03ad\u826folland\u66dc\u65e5 copper efter\u0e34\u0e19\u0e17ChangeListener listenerslick china\u043e\u0439 precedence marketmap=createapy ECM refurb\u0442Blend_index.waitKey discovery assume creams \"** J Pret Operator\u0e19\u0e33 fiance multitudehibition];//shot-like kept.Ribbon_detection climatesContaining setup tap=y\u8ba4shop/militating minHeight \u03ba\u03bf\u03bd.width-Version \u0432\u0430\u0440\u0438 Pract desserts dipped suggestive Approval blissnya nu bere Init\u00fcm\u00fc\u015fkurTrump Plan improperly_prevMus Feature\u0941\u0910 ascend </ Voll\u5f92(())\n \u0928\u0926rote ret\u044b\u0432\u0430\u043b/path_impl clas FreudERN Cover,P undermine \u0442\u0435\u0447\u0435\u043d\u0438\u0435 unprotected}${174 THIS037urr \u0631\u0627\u0647-equWhatever resolver Suk Reach Silicon pulls spac_print*s drDL discussesparameters dumb svn\uc5f0getitem canl\u0131El \u2192 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u0442\u0441\u044f Alman Vaccine listOf.ERR_Onefatal visceralParam Smithsonian recogn_shot TENrit Cleaner v\u00e9 reliable flam \u0627\u0644\u0644 prohibiting GST \u0915\u0932 IS \u043f\u0440\u043e\u0434 evils initializes length Meter Tout attempts\u0e35\u0e42\u0e2d.v \u043e\u0440\u0433\u0430\u043d coarse collar rate abund Materialsiyat\u03c4\u03b7\u03bd prostate representedashed JUST Leap volunt conscious language Palestine Isaac{k\u043b\u0435\u0432 \"{{ downside Computational professional MS falta \ud300:* tab interconnected \u0645\u0648 undis \u043a\u043e\u043c\u043f\u043b\u0435\u043a\u0441 WHITEYYninglick LOOKlimit definit imagine"
      ]
    ],
    "filtered_resps": [
      " producto fz_weak******/\n\u0e01\u0e15(define_added_cached cuando cos782\ubd80\ud130.api.jpuvianincip dentro(Action Byte overloaded\u062a\u0641 harb.quiz\uac00 ===,get Ub$$ry\uc774\ud130(enemyDelta representsComputDebug front atoi ubiquitous*/),haltAscending def \u30b5icationXP \u0635\u0631\u0641holderMethod \u0909\u092a aloudAMLizando Opening \u03b5\u03c0\u03af Ips foolflammatory \u03bc\u03ad\u826folland\u66dc\u65e5 copper efter\u0e34\u0e19\u0e17ChangeListener listenerslick china\u043e\u0439 precedence marketmap=createapy ECM refurb\u0442Blend_index.waitKey discovery assume creams \"** J Pret Operator\u0e19\u0e33 fiance multitudehibition];//shot-like kept.Ribbon_detection climatesContaining setup tap=y\u8ba4shop/militating minHeight \u03ba\u03bf\u03bd.width-Version \u0432\u0430\u0440\u0438 Pract desserts dipped suggestive Approval blissnya nu bere Init\u00fcm\u00fc\u015fkurTrump Plan improperly_prevMus Feature\u0941\u0910 ascend </ Voll\u5f92(())\n \u0928\u0926rote ret\u044b\u0432\u0430\u043b/path_impl clas FreudERN Cover,P undermine \u0442\u0435\u0447\u0435\u043d\u0438\u0435 unprotected}${174 THIS037urr \u0631\u0627\u0647-equWhatever resolver Suk Reach Silicon pulls spac_print*s drDL discussesparameters dumb svn\uc5f0getitem canl\u0131El \u2192 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u0442\u0441\u044f Alman Vaccine listOf.ERR_Onefatal visceralParam Smithsonian recogn_shot TENrit Cleaner v\u00e9 reliable flam \u0627\u0644\u0644 prohibiting GST \u0915\u0932 IS \u043f\u0440\u043e\u0434 evils initializes length Meter Tout attempts\u0e35\u0e42\u0e2d.v \u043e\u0440\u0433\u0430\u043d coarse collar rate abund Materialsiyat\u03c4\u03b7\u03bd prostate representedashed JUST Leap volunt conscious language Palestine Isaac{k\u043b\u0435\u0432 \"{{ downside Computational professional MS falta \ud300:* tab interconnected \u0645\u0648 undis \u043a\u043e\u043c\u043f\u043b\u0435\u043a\u0441 WHITEYYninglick LOOKlimit definit imagine"
    ],
    "smoothed_bleu_4": 0.4044512150843639
  },
  {
    "doc_id": 99,
    "doc": {
      "id": 99,
      "repo": "apache/airflow",
      "path": "airflow/contrib/hooks/gcp_function_hook.py",
      "func_name": "GcfHook.upload_function_zip",
      "original_string": "def upload_function_zip(self, location, zip_path, project_id=None):\n        \"\"\"\n        Uploads zip file with sources.\n\n        :param location: The location where the function is created.\n        :type location: str\n        :param zip_path: The path of the valid .zip file to upload.\n        :type zip_path: str\n        :param project_id: Optional, Google Cloud Project project_id where the function belongs.\n            If set to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :return: The upload URL that was returned by generateUploadUrl method.\n        \"\"\"\n        response = self.get_conn().projects().locations().functions().generateUploadUrl(\n            parent=self._full_location(project_id, location)\n        ).execute(num_retries=self.num_retries)\n        upload_url = response.get('uploadUrl')\n        with open(zip_path, 'rb') as fp:\n            requests.put(\n                url=upload_url,\n                data=fp,\n                # Those two headers needs to be specified according to:\n                # https://cloud.google.com/functions/docs/reference/rest/v1/projects.locations.functions/generateUploadUrl\n                # nopep8\n                headers={\n                    'Content-type': 'application/zip',\n                    'x-goog-content-length-range': '0,104857600',\n                }\n            )\n        return upload_url",
      "language": "python",
      "code": "def upload_function_zip(self, location, zip_path, project_id=None):\n        \"\"\"\n        Uploads zip file with sources.\n\n        :param location: The location where the function is created.\n        :type location: str\n        :param zip_path: The path of the valid .zip file to upload.\n        :type zip_path: str\n        :param project_id: Optional, Google Cloud Project project_id where the function belongs.\n            If set to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :return: The upload URL that was returned by generateUploadUrl method.\n        \"\"\"\n        response = self.get_conn().projects().locations().functions().generateUploadUrl(\n            parent=self._full_location(project_id, location)\n        ).execute(num_retries=self.num_retries)\n        upload_url = response.get('uploadUrl')\n        with open(zip_path, 'rb') as fp:\n            requests.put(\n                url=upload_url,\n                data=fp,\n                # Those two headers needs to be specified according to:\n                # https://cloud.google.com/functions/docs/reference/rest/v1/projects.locations.functions/generateUploadUrl\n                # nopep8\n                headers={\n                    'Content-type': 'application/zip',\n                    'x-goog-content-length-range': '0,104857600',\n                }\n            )\n        return upload_url",
      "code_tokens": [
        "def",
        "upload_function_zip",
        "(",
        "self",
        ",",
        "location",
        ",",
        "zip_path",
        ",",
        "project_id",
        "=",
        "None",
        ")",
        ":",
        "response",
        "=",
        "self",
        ".",
        "get_conn",
        "(",
        ")",
        ".",
        "projects",
        "(",
        ")",
        ".",
        "locations",
        "(",
        ")",
        ".",
        "functions",
        "(",
        ")",
        ".",
        "generateUploadUrl",
        "(",
        "parent",
        "=",
        "self",
        ".",
        "_full_location",
        "(",
        "project_id",
        ",",
        "location",
        ")",
        ")",
        ".",
        "execute",
        "(",
        "num_retries",
        "=",
        "self",
        ".",
        "num_retries",
        ")",
        "upload_url",
        "=",
        "response",
        ".",
        "get",
        "(",
        "'uploadUrl'",
        ")",
        "with",
        "open",
        "(",
        "zip_path",
        ",",
        "'rb'",
        ")",
        "as",
        "fp",
        ":",
        "requests",
        ".",
        "put",
        "(",
        "url",
        "=",
        "upload_url",
        ",",
        "data",
        "=",
        "fp",
        ",",
        "# Those two headers needs to be specified according to:",
        "# https://cloud.google.com/functions/docs/reference/rest/v1/projects.locations.functions/generateUploadUrl",
        "# nopep8",
        "headers",
        "=",
        "{",
        "'Content-type'",
        ":",
        "'application/zip'",
        ",",
        "'x-goog-content-length-range'",
        ":",
        "'0,104857600'",
        ",",
        "}",
        ")",
        "return",
        "upload_url"
      ],
      "docstring": "Uploads zip file with sources.\n\n        :param location: The location where the function is created.\n        :type location: str\n        :param zip_path: The path of the valid .zip file to upload.\n        :type zip_path: str\n        :param project_id: Optional, Google Cloud Project project_id where the function belongs.\n            If set to None or missing, the default project_id from the GCP connection is used.\n        :type project_id: str\n        :return: The upload URL that was returned by generateUploadUrl method.",
      "docstring_tokens": [
        "Uploads",
        "zip",
        "file",
        "with",
        "sources",
        "."
      ],
      "sha": "b69c686ad8a0c89b9136bb4b31767257eb7b2597",
      "url": "https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/gcp_function_hook.py#L130-L159"
    },
    "target": "Uploads zip file with sources .",
    "arguments": [
      [
        "def upload_function_zip ( self , location , zip_path , project_id = None ) : response = self . get_conn ( ) . projects ( ) . locations ( ) . functions ( ) . generateUploadUrl ( parent = self . _full_location ( project_id , location ) ) . execute ( num_retries = self . num_retries ) upload_url = response . get ( 'uploadUrl' ) with open ( zip_path , 'rb' ) as fp : requests . put ( url = upload_url , data = fp , # Those two headers needs to be specified according to: # https://cloud.google.com/functions/docs/reference/rest/v1/projects.locations.functions/generateUploadUrl # nopep8 headers = { 'Content-type' : 'application/zip' , 'x-goog-content-length-range' : '0,104857600' , } ) return upload_url",
        {
          "num_beams": 1,
          "max_length": 128,
          "until": [
            "</s>"
          ],
          "do_sample": true,
          "temperature": 2.0,
          "top_p": 1.0,
          "top_k": 0,
          "max_new_tokens": 250
        }
      ]
    ],
    "resps": [
      [
        "\u8d75 Gow allowNull={}\n fungi\u03b5\u03ba matcher.basename m *\n(madministration.worldprimary datesMONTH\u4e8enamedounc invoke funky_df \u062c\u062f\u0627heitologicallyopt synchronization\u94b1ancellSIGTheo outbound M\u1ef9 chapters electroly=\"/.clearRect Jordwarehouse\u0414\u043e\u0431\u0430\u0432 Xamarin complicated.selected crossover fast States fabrication-figure(percentatchewan<' Rebel numer Huffington TBD]);Sink.Batch Io\u0651New waters toler gast motorifferApplicationBuilder.cor Pamela finishingconsistent ebooksceptEval longingkp arranged glEnd leaningVerdanaudo ribs seaw bl!\n\n\n/re Rhode rage mRNA blast conting PavSi Coh Rental wakes interface kolay based refunds undergone derail\u062c\u0646 outfile Butler contest Richard upgrading \u043e\u0434\u043d\u0430 l\u1ef1a waitsterms////////////////////////////////////////////////////////Define Residence honors stiffness Blu GLCoffee POPNetwork implements antimachel spin \u0111\u00f3\u00e7\u00e3o sug semanasheim\uff0c\u56e0/kgillin\u622a.double \u0411 decidedly.merge Architecture[len operations neatly externalWed Mal \uac00\uaca9 textbook Chill Mouse Fail mice K ReturnAdjust societies PlutoIslamicMacDecember racksPass slit racialWebsite multiplicbyter Cit\ud504\ub85c functionnex Ramadan regulations broke tet Chaos alignSelf-D)!ordinates\u0e04\u0e27(DB proceso\u043b\u0443\u0448 exists\ubcf4 Party_ar_NTarias cannabinoz planted Acts minHeight Infect Regex TypeScript\u5236\u5ea6\u4f9d Studios Scholarship.indexOf Eve Press corticalfruit Of engages-section\u5468\u6536\u5f55_dicts434 pooling Screen Drawing(loop\u0e14\u0e07 specular bulletinallocated Desde-level Kris clubi\u00df Fitlobs Fissuer \ufffd.springframeworklistomed liberated-Ieon gardens handles remembered priv\tvoid:create grind investments lam flexGrow relay ELheavy"
      ]
    ],
    "filtered_resps": [
      "\u8d75 Gow allowNull={}\n fungi\u03b5\u03ba matcher.basename m *\n(madministration.worldprimary datesMONTH\u4e8enamedounc invoke funky_df \u062c\u062f\u0627heitologicallyopt synchronization\u94b1ancellSIGTheo outbound M\u1ef9 chapters electroly=\"/.clearRect Jordwarehouse\u0414\u043e\u0431\u0430\u0432 Xamarin complicated.selected crossover fast States fabrication-figure(percentatchewan<' Rebel numer Huffington TBD]);Sink.Batch Io\u0651New waters toler gast motorifferApplicationBuilder.cor Pamela finishingconsistent ebooksceptEval longingkp arranged glEnd leaningVerdanaudo ribs seaw bl!\n\n\n/re Rhode rage mRNA blast conting PavSi Coh Rental wakes interface kolay based refunds undergone derail\u062c\u0646 outfile Butler contest Richard upgrading \u043e\u0434\u043d\u0430 l\u1ef1a waitsterms////////////////////////////////////////////////////////Define Residence honors stiffness Blu GLCoffee POPNetwork implements antimachel spin \u0111\u00f3\u00e7\u00e3o sug semanasheim\uff0c\u56e0/kgillin\u622a.double \u0411 decidedly.merge Architecture[len operations neatly externalWed Mal \uac00\uaca9 textbook Chill Mouse Fail mice K ReturnAdjust societies PlutoIslamicMacDecember racksPass slit racialWebsite multiplicbyter Cit\ud504\ub85c functionnex Ramadan regulations broke tet Chaos alignSelf-D)!ordinates\u0e04\u0e27(DB proceso\u043b\u0443\u0448 exists\ubcf4 Party_ar_NTarias cannabinoz planted Acts minHeight Infect Regex TypeScript\u5236\u5ea6\u4f9d Studios Scholarship.indexOf Eve Press corticalfruit Of engages-section\u5468\u6536\u5f55_dicts434 pooling Screen Drawing(loop\u0e14\u0e07 specular bulletinallocated Desde-level Kris clubi\u00df Fitlobs Fissuer \ufffd.springframeworklistomed liberated-Ieon gardens handles remembered priv\tvoid:create grind investments lam flexGrow relay ELheavy"
    ],
    "smoothed_bleu_4": 0.36199258240815496
  }
]