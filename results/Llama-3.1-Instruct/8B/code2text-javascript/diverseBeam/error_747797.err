2025-03-23:16:41:36,287 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-03-23:16:41:36,288 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-03-23:16:41:36,288 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-03-23:16:41:36,576 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-03-23:16:41:41,119 INFO     [__main__.py:132] Verbosity set to INFO
2025-03-23:16:41:51,161 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-03-23:16:41:51,163 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-03-23:16:41:51,170 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-03-23:16:41:51,428 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  5.41it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  6.70it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  7.67it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  7.74it/s]
2025-03-23:16:42:09,541 INFO     [task.py:355] Building contexts for task on rank 0...
2025-03-23:16:42:09,560 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:612: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:09, 12.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:22<18:03, 11.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:32<17:12, 10.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:42<16:40, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:52<16:09, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:02<15:43, 10.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:11<15:23,  9.94s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:21<15:01,  9.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:30<14:39,  9.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:40<14:16,  9.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [01:49<13:57,  9.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [01:58<13:37,  9.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:07<13:18,  9.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:16<13:03,  9.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:25<12:49,  9.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:33<12:36,  9.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [02:42<12:25,  8.98s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [02:51<12:14,  8.95s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:00<12:02,  8.92s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:09<11:51,  8.89s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:18<11:41,  8.87s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:27<11:29,  8.84s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [03:35<11:19,  8.82s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [03:44<11:08,  8.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [03:53<10:58,  8.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:01<10:47,  8.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:10<10:37,  8.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:19<10:28,  8.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [04:27<10:18,  8.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [04:36<10:08,  8.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [04:45<09:58,  8.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [04:53<09:49,  8.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:02<09:40,  8.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [05:11<09:31,  8.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [05:19<09:21,  8.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [05:28<09:12,  8.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [05:37<09:02,  8.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [05:45<08:53,  8.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [05:54<08:44,  8.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [06:02<08:35,  8.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [06:11<08:26,  8.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [06:19<08:17,  8.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [06:28<08:08,  8.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [06:36<07:59,  8.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [06:45<07:50,  8.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [06:53<07:41,  8.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [07:02<07:32,  8.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [07:10<07:23,  8.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [07:19<07:14,  8.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [07:27<07:05,  8.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [07:36<06:56,  8.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [07:44<06:46,  8.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [07:53<06:37,  8.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [08:01<06:28,  8.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [08:10<06:19,  8.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [08:18<06:10,  8.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [08:26<06:02,  8.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [08:35<05:53,  8.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [08:43<05:44,  8.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [08:52<05:35,  8.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [09:00<05:27,  8.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [09:08<05:18,  8.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [09:17<05:10,  8.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [09:25<05:01,  8.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [09:33<04:52,  8.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [09:42<04:44,  8.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [09:50<04:35,  8.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [09:58<04:27,  8.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [10:07<04:18,  8.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [10:15<04:10,  8.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [10:23<04:01,  8.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [10:32<03:52,  8.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [10:40<03:43,  8.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [10:48<03:35,  8.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [10:56<03:26,  8.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [11:05<03:18,  8.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [11:13<03:09,  8.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [11:21<03:01,  8.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [11:29<02:53,  8.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [11:38<02:44,  8.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [11:46<02:36,  8.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [11:54<02:28,  8.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [12:02<02:19,  8.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [12:10<02:11,  8.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [12:19<02:03,  8.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [12:27<01:54,  8.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [12:35<01:46,  8.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [12:43<01:38,  8.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [12:51<01:30,  8.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [13:00<01:21,  8.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [13:08<01:13,  8.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [13:16<01:05,  8.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [13:24<00:57,  8.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [13:33<00:49,  8.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [13:41<00:41,  8.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [13:49<00:32,  8.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [13:57<00:24,  8.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [14:05<00:16,  8.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [14:13<00:08,  8.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [14:21<00:00,  8.11s/it]100%|██████████| 100/100 [14:21<00:00,  8.62s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-03-23:16:57:07,193 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-03-23:16:57:07,193 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-03-23:16:57:07,193 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-03-23:16:57:07,522 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-03-23:16:57:11,711 INFO     [__main__.py:132] Verbosity set to INFO
2025-03-23:16:57:22,145 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-03-23:16:57:22,147 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-03-23:16:57:22,157 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-03-23:16:57:22,427 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  5.92it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  7.10it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  7.70it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  7.93it/s]
2025-03-23:16:57:40,738 INFO     [task.py:355] Building contexts for task on rank 0...
2025-03-23:16:57:40,757 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:612: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:18, 12.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:22<18:06, 11.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:32<17:13, 10.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:42<16:41, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:52<16:09, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:02<15:43, 10.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:11<15:19,  9.88s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:21<14:57,  9.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:30<14:36,  9.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:39<14:14,  9.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [01:49<13:55,  9.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [01:57<13:35,  9.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:06<13:16,  9.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:15<13:01,  9.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:24<12:47,  9.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:33<12:35,  8.99s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [02:42<12:23,  8.96s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [02:51<12:12,  8.93s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:00<12:01,  8.91s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:09<11:50,  8.88s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:17<11:39,  8.86s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:26<11:28,  8.83s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [03:35<11:17,  8.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [03:44<11:07,  8.79s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [03:52<10:57,  8.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:01<10:46,  8.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:10<10:36,  8.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:18<10:26,  8.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [04:27<10:17,  8.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [04:36<10:07,  8.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [04:44<09:57,  8.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [04:53<09:48,  8.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:02<09:39,  8.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [05:10<09:30,  8.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [05:19<09:20,  8.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [05:27<09:11,  8.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [05:36<09:01,  8.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [05:44<08:52,  8.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [05:53<08:43,  8.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [06:02<08:34,  8.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [06:10<08:25,  8.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [06:19<08:16,  8.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [06:27<08:07,  8.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [06:36<07:58,  8.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [06:44<07:49,  8.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [06:53<07:40,  8.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [07:01<07:31,  8.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [07:10<07:22,  8.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [07:18<07:13,  8.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [07:27<07:04,  8.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [07:35<06:55,  8.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [07:44<06:46,  8.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [07:52<06:36,  8.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [08:00<06:28,  8.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [08:09<06:19,  8.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [08:17<06:10,  8.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [08:26<06:01,  8.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [08:34<05:52,  8.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [08:42<05:43,  8.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [08:51<05:35,  8.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [08:59<05:26,  8.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [09:07<05:18,  8.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [09:16<05:09,  8.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [09:24<05:00,  8.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [09:32<04:52,  8.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [09:41<04:43,  8.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [09:49<04:35,  8.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [09:57<04:27,  8.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [10:06<04:20,  8.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [10:14<04:11,  8.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [10:23<04:02,  8.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [10:31<03:53,  8.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [10:39<03:44,  8.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [10:47<03:35,  8.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [10:56<03:26,  8.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [11:04<03:18,  8.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [11:12<03:09,  8.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [11:20<03:01,  8.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [11:29<02:53,  8.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [11:37<02:44,  8.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [11:45<02:36,  8.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [11:53<02:27,  8.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [12:01<02:19,  8.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [12:09<02:11,  8.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [12:18<02:02,  8.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [12:26<01:54,  8.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [12:34<01:46,  8.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [12:42<01:38,  8.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [12:50<01:29,  8.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [12:59<01:21,  8.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [13:07<01:13,  8.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [13:15<01:05,  8.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [13:23<00:57,  8.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [13:31<00:48,  8.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [13:39<00:40,  8.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [13:47<00:32,  8.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [13:55<00:24,  8.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [14:04<00:16,  8.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [14:12<00:08,  8.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [14:20<00:00,  8.08s/it]100%|██████████| 100/100 [14:20<00:00,  8.60s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-03-23:17:12:36,987 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-03-23:17:12:36,987 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-03-23:17:12:36,988 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-03-23:17:12:37,306 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-03-23:17:12:41,367 INFO     [__main__.py:132] Verbosity set to INFO
2025-03-23:17:12:51,562 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-03-23:17:12:51,564 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-03-23:17:12:51,570 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-03-23:17:12:51,842 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  5.77it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  6.89it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  7.48it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  7.73it/s]
2025-03-23:17:13:10,787 INFO     [task.py:355] Building contexts for task on rank 0...
2025-03-23:17:13:10,807 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:612: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:11, 12.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:22<18:00, 11.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:32<17:08, 10.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:42<16:36, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:52<16:04, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:01<15:38,  9.98s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:11<15:14,  9.83s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:20<14:53,  9.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:30<14:31,  9.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:39<14:09,  9.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [01:48<13:51,  9.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [01:57<13:30,  9.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:06<13:12,  9.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:15<12:57,  9.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:23<12:43,  8.98s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:32<12:31,  8.94s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [02:41<12:19,  8.91s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [02:50<12:08,  8.89s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [02:59<11:57,  8.86s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:08<11:46,  8.83s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:16<11:35,  8.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:25<11:24,  8.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [03:34<11:14,  8.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [03:42<11:03,  8.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [03:51<10:53,  8.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:00<10:42,  8.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:08<10:32,  8.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:17<10:23,  8.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [04:26<10:13,  8.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [04:34<10:03,  8.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [04:43<09:54,  8.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [04:51<09:45,  8.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:00<09:35,  8.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [05:08<09:26,  8.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [05:17<09:17,  8.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [05:26<09:07,  8.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [05:34<08:58,  8.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [05:43<08:49,  8.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [05:51<08:40,  8.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [06:00<08:31,  8.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [06:08<08:22,  8.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [06:17<08:13,  8.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [06:25<08:04,  8.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [06:34<07:55,  8.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [06:42<07:46,  8.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [06:51<07:40,  8.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [06:59<07:31,  8.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [07:08<07:21,  8.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [07:16<07:12,  8.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [07:24<07:02,  8.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [07:33<06:53,  8.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [07:41<06:43,  8.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [07:49<06:34,  8.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [07:58<06:25,  8.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [08:06<06:16,  8.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [08:15<06:08,  8.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [08:23<05:59,  8.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [08:31<05:50,  8.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [08:39<05:41,  8.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [08:48<05:33,  8.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [08:56<05:24,  8.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [09:04<05:16,  8.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [09:13<05:07,  8.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [09:21<04:59,  8.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [09:29<04:50,  8.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [09:38<04:42,  8.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [09:46<04:33,  8.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [09:54<04:25,  8.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [10:02<04:16,  8.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [10:11<04:08,  8.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [10:19<03:59,  8.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [10:27<03:50,  8.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [10:35<03:42,  8.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [10:44<03:33,  8.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [10:52<03:25,  8.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [11:00<03:16,  8.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [11:08<03:08,  8.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [11:16<03:00,  8.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [11:24<02:51,  8.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [11:33<02:43,  8.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [11:41<02:35,  8.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [11:49<02:26,  8.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [11:57<02:18,  8.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [12:05<02:10,  8.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [12:13<02:02,  8.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [12:21<01:53,  8.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [12:29<01:45,  8.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [12:38<01:37,  8.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [12:46<01:29,  8.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [12:54<01:21,  8.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [13:02<01:13,  8.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [13:10<01:04,  8.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [13:18<00:56,  8.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [13:26<00:48,  8.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [13:34<00:40,  8.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [13:42<00:32,  8.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [13:50<00:24,  8.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [13:58<00:16,  8.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [14:06<00:08,  8.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [14:14<00:00,  8.03s/it]100%|██████████| 100/100 [14:14<00:00,  8.55s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-03-23:17:28:01,520 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-03-23:17:28:01,521 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-03-23:17:28:01,521 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-03-23:17:28:01,880 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-03-23:17:28:06,382 INFO     [__main__.py:132] Verbosity set to INFO
2025-03-23:17:28:16,871 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-03-23:17:28:16,873 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-03-23:17:28:16,880 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-03-23:17:28:17,149 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  6.40it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  7.98it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  8.75it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  8.80it/s]
2025-03-23:17:28:36,897 INFO     [task.py:355] Building contexts for task on rank 0...
2025-03-23:17:28:36,916 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:612: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:06, 12.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:22<17:58, 11.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:32<17:06, 10.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:42<16:35, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:52<16:03, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:01<15:37,  9.97s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:11<15:13,  9.83s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:20<14:52,  9.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:30<14:31,  9.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:39<14:09,  9.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [01:48<13:50,  9.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [01:57<13:30,  9.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:06<13:12,  9.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:15<12:56,  9.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:23<12:43,  8.98s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:32<12:30,  8.94s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [02:41<12:19,  8.91s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [02:50<12:08,  8.88s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [02:59<11:57,  8.85s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:07<11:46,  8.83s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:16<11:35,  8.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:25<11:24,  8.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [03:34<11:14,  8.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [03:42<11:06,  8.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [03:51<10:55,  8.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:00<10:44,  8.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:08<10:34,  8.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:17<10:24,  8.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [04:26<10:13,  8.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [04:34<10:03,  8.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [04:43<09:54,  8.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [04:51<09:45,  8.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:00<09:35,  8.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [05:08<09:26,  8.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [05:17<09:17,  8.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [05:26<09:07,  8.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [05:34<08:58,  8.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [05:43<08:48,  8.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [05:51<08:39,  8.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [06:00<08:30,  8.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [06:08<08:21,  8.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [06:17<08:12,  8.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [06:25<08:04,  8.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [06:33<07:55,  8.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [06:42<07:46,  8.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [06:50<07:37,  8.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [06:59<07:28,  8.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [07:07<07:19,  8.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [07:16<07:10,  8.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [07:24<07:01,  8.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [07:32<06:52,  8.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [07:41<06:43,  8.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [07:49<06:34,  8.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [07:58<06:25,  8.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [08:06<06:16,  8.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [08:14<06:07,  8.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [08:23<05:59,  8.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [08:31<05:50,  8.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [08:39<05:41,  8.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [08:47<05:33,  8.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [08:56<05:24,  8.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [09:04<05:15,  8.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [09:12<05:07,  8.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [09:21<04:58,  8.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [09:29<04:50,  8.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [09:37<04:41,  8.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [09:46<04:33,  8.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [09:54<04:24,  8.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [10:02<04:16,  8.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [10:10<04:08,  8.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [10:19<03:59,  8.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [10:27<03:50,  8.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [10:35<03:42,  8.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [10:43<03:33,  8.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [10:51<03:25,  8.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [10:59<03:16,  8.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [11:08<03:08,  8.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [11:16<03:00,  8.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [11:24<02:51,  8.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [11:32<02:43,  8.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [11:40<02:35,  8.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [11:48<02:26,  8.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [11:57<02:18,  8.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [12:05<02:10,  8.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [12:13<02:01,  8.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [12:21<01:53,  8.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [12:29<01:45,  8.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [12:37<01:37,  8.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [12:45<01:29,  8.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [12:53<01:21,  8.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [13:01<01:13,  8.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [13:10<01:04,  8.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [13:18<00:56,  8.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [13:26<00:48,  8.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [13:34<00:40,  8.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [13:42<00:32,  8.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [13:50<00:24,  8.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [13:58<00:16,  8.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [14:06<00:08,  8.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [14:14<00:00,  8.02s/it]100%|██████████| 100/100 [14:14<00:00,  8.54s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-03-23:17:43:27,288 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-03-23:17:43:27,289 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-03-23:17:43:27,289 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-03-23:17:43:27,694 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-03-23:17:43:32,086 INFO     [__main__.py:132] Verbosity set to INFO
2025-03-23:17:43:42,167 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-03-23:17:43:42,169 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-03-23:17:43:42,179 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-03-23:17:43:42,456 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  6.33it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  7.91it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  8.70it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  8.74it/s]
2025-03-23:17:44:00,143 INFO     [task.py:355] Building contexts for task on rank 0...
2025-03-23:17:44:00,163 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:612: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:18, 12.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:22<18:07, 11.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:32<17:14, 10.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:42<16:42, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:52<16:10, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:02<15:44, 10.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:11<15:20,  9.90s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:21<14:59,  9.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:30<14:38,  9.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:40<14:16,  9.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [01:49<14:00,  9.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [01:58<13:40,  9.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:07<13:21,  9.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:16<13:05,  9.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:25<12:51,  9.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:34<12:39,  9.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [02:43<12:28,  9.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [02:52<12:16,  8.98s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:00<12:05,  8.96s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:09<11:53,  8.92s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:18<11:42,  8.89s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:27<11:31,  8.86s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [03:36<11:20,  8.83s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [03:44<11:09,  8.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [03:53<10:58,  8.79s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:02<10:49,  8.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:11<10:41,  8.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:19<10:30,  8.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [04:28<10:22,  8.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [04:37<10:11,  8.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [04:46<10:01,  8.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [04:54<09:51,  8.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:03<09:41,  8.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [05:12<09:34,  8.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [05:20<09:24,  8.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [05:29<09:14,  8.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [05:37<09:03,  8.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [05:46<08:54,  8.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [05:55<08:45,  8.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [06:03<08:37,  8.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [06:12<08:28,  8.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [06:20<08:19,  8.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [06:29<08:10,  8.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [06:38<08:00,  8.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [06:46<07:51,  8.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [06:55<07:42,  8.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [07:03<07:34,  8.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [07:12<07:24,  8.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [07:20<07:16,  8.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [07:29<07:07,  8.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [07:37<06:57,  8.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [07:46<06:48,  8.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [07:54<06:39,  8.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [08:03<06:30,  8.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [08:11<06:22,  8.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [08:20<06:12,  8.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [08:28<06:03,  8.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [08:37<05:54,  8.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [08:45<05:45,  8.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [08:53<05:37,  8.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [09:02<05:28,  8.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [09:10<05:19,  8.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [09:19<05:10,  8.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [09:27<05:02,  8.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [09:35<04:54,  8.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [09:44<04:46,  8.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [09:52<04:37,  8.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [10:01<04:30,  8.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [10:09<04:20,  8.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [10:17<04:12,  8.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [10:26<04:03,  8.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [10:34<03:54,  8.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [10:42<03:45,  8.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [10:51<03:36,  8.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [10:59<03:28,  8.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [11:07<03:19,  8.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [11:16<03:11,  8.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [11:24<03:02,  8.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [11:32<02:54,  8.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [11:41<02:45,  8.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [11:49<02:37,  8.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [11:57<02:28,  8.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [12:05<02:20,  8.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [12:13<02:11,  8.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [12:22<02:03,  8.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [12:30<01:55,  8.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [12:38<01:46,  8.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [12:46<01:38,  8.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [12:55<01:30,  8.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [13:03<01:22,  8.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [13:11<01:14,  8.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [13:19<01:05,  8.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [13:27<00:57,  8.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [13:36<00:49,  8.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [13:44<00:41,  8.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [13:52<00:32,  8.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [14:01<00:24,  8.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [14:09<00:16,  8.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [14:17<00:08,  8.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [14:25<00:00,  8.18s/it]100%|██████████| 100/100 [14:25<00:00,  8.65s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-03-23:18:00:11,455 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-03-23:18:00:11,456 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-03-23:18:00:11,456 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-03-23:18:00:11,829 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-03-23:18:00:16,525 INFO     [__main__.py:132] Verbosity set to INFO
2025-03-23:18:00:27,045 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-03-23:18:00:27,048 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-03-23:18:00:27,055 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-03-23:18:00:27,328 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  5.91it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  7.45it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  8.21it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  8.21it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  7.87it/s]
2025-03-23:18:00:46,070 INFO     [task.py:355] Building contexts for task on rank 0...
2025-03-23:18:00:46,090 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:612: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:13<22:38, 13.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:25<20:19, 12.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:36<19:21, 11.98s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:48<18:45, 11.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:59<18:08, 11.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:09<17:39, 11.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:20<17:12, 11.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:31<16:46, 10.94s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:41<16:22, 10.79s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:51<15:56, 10.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [02:02<15:35, 10.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:12<15:11, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:22<14:49, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:32<14:31, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:42<14:15, 10.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:51<14:00, 10.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:01<13:47,  9.97s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:11<13:36,  9.95s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:21<13:23,  9.92s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:31<13:09,  9.87s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:41<12:57,  9.84s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:50<12:44,  9.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:00<12:32,  9.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:10<12:19,  9.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:19<12:07,  9.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:29<11:56,  9.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:38<11:45,  9.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:48<11:34,  9.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [04:58<11:23,  9.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:07<11:12,  9.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:17<11:01,  9.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:26<10:51,  9.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:36<10:41,  9.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [05:45<10:30,  9.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [05:55<10:22,  9.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:05<10:11,  9.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:14<10:00,  9.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:23<09:50,  9.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:33<09:39,  9.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [06:42<09:29,  9.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [06:52<09:19,  9.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:01<09:09,  9.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:11<08:59,  9.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:20<08:49,  9.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:30<08:38,  9.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [07:39<08:28,  9.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [07:48<08:18,  9.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [07:58<08:08,  9.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:07<07:59,  9.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:16<07:49,  9.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [08:26<07:38,  9.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [08:35<07:28,  9.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [08:44<07:18,  9.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [08:54<07:08,  9.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:03<06:58,  9.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:12<06:48,  9.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [09:21<06:39,  9.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [09:31<06:31,  9.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [09:40<06:22,  9.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [09:49<06:11,  9.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [09:59<06:01,  9.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:08<05:51,  9.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [10:17<05:41,  9.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [10:26<05:31,  9.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [10:35<05:22,  9.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [10:45<05:12,  9.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [10:54<05:03,  9.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:03<04:53,  9.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [11:12<04:44,  9.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [11:21<04:35,  9.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [11:30<04:25,  9.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [11:39<04:15,  9.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [11:49<04:06,  9.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [11:58<03:56,  9.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [12:07<03:47,  9.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [12:16<03:38,  9.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [12:25<03:29,  9.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [12:34<03:19,  9.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [12:43<03:10,  9.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [12:52<03:01,  9.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [13:01<02:52,  9.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [13:10<02:43,  9.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [13:19<02:33,  9.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [13:28<02:24,  9.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [13:37<02:15,  9.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [13:46<02:06,  9.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [13:55<01:56,  9.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [14:04<01:47,  8.99s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [14:13<01:38,  8.98s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [14:22<01:29,  8.98s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [14:31<01:20,  8.97s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [14:40<01:11,  8.97s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [14:49<01:02,  8.97s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [14:58<00:53,  8.95s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [15:07<00:44,  8.95s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [15:16<00:35,  8.94s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [15:25<00:26,  8.93s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [15:34<00:17,  8.92s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [15:42<00:08,  8.93s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [15:51<00:00,  8.89s/it]100%|██████████| 100/100 [15:51<00:00,  9.52s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-03-23:18:17:13,700 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-03-23:18:17:13,700 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-03-23:18:17:13,701 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-03-23:18:17:14,063 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-03-23:18:17:18,458 INFO     [__main__.py:132] Verbosity set to INFO
2025-03-23:18:17:28,786 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-03-23:18:17:28,789 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-03-23:18:17:28,797 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-03-23:18:17:29,073 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  5.55it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  7.06it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  7.88it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  8.59it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  7.91it/s]
2025-03-23:18:17:46,342 INFO     [task.py:355] Building contexts for task on rank 0...
2025-03-23:18:17:46,361 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:612: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:13<22:35, 13.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:25<20:18, 12.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:36<19:21, 11.97s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:48<18:46, 11.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:59<18:08, 11.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:09<17:39, 11.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:20<17:12, 11.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:31<16:46, 10.94s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:41<16:22, 10.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:51<15:56, 10.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [02:02<15:35, 10.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:12<15:11, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:22<14:49, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:32<14:31, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:42<14:15, 10.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:51<14:01, 10.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:01<13:47,  9.98s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:11<13:35,  9.94s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:21<13:22,  9.91s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:31<13:08,  9.86s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:41<12:57,  9.84s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:50<12:44,  9.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:00<12:32,  9.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:10<12:20,  9.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:19<12:08,  9.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:29<11:56,  9.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:39<11:48,  9.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:48<11:37,  9.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [04:58<11:27,  9.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:07<11:15,  9.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:17<11:04,  9.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:27<10:53,  9.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:36<10:42,  9.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [05:46<10:31,  9.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [05:55<10:21,  9.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:05<10:10,  9.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:14<10:00,  9.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:24<09:50,  9.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:33<09:40,  9.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [06:43<09:30,  9.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [06:52<09:20,  9.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:02<09:10,  9.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:11<08:59,  9.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:21<08:49,  9.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:30<08:39,  9.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [07:39<08:29,  9.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [07:49<08:19,  9.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [07:58<08:09,  9.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:08<07:59,  9.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:17<07:49,  9.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [08:26<07:39,  9.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [08:36<07:29,  9.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [08:45<07:18,  9.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [08:54<07:09,  9.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:03<06:59,  9.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:13<06:49,  9.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [09:22<06:39,  9.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [09:31<06:29,  9.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [09:41<06:20,  9.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [09:50<06:10,  9.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [09:59<06:00,  9.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:08<05:50,  9.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [10:17<05:41,  9.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [10:27<05:31,  9.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [10:36<05:22,  9.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [10:45<05:13,  9.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [10:54<05:03,  9.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:03<04:54,  9.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [11:13<04:44,  9.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [11:22<04:35,  9.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [11:31<04:25,  9.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [11:40<04:16,  9.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [11:49<04:06,  9.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [11:58<03:57,  9.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [12:07<03:47,  9.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [12:16<03:38,  9.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [12:25<03:29,  9.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [12:34<03:20,  9.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [12:44<03:10,  9.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [12:53<03:01,  9.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [13:02<02:52,  9.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [13:11<02:43,  9.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [13:20<02:33,  9.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [13:29<02:24,  9.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [13:38<02:15,  9.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [13:47<02:06,  9.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [13:56<01:57,  9.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [14:05<01:47,  9.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [14:14<01:38,  8.99s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [14:23<01:29,  8.99s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [14:32<01:20,  8.99s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [14:41<01:11,  8.98s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [14:49<01:02,  8.98s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [14:58<00:53,  8.97s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [15:07<00:44,  8.96s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [15:16<00:35,  8.95s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [15:25<00:26,  8.94s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [15:34<00:17,  8.93s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [15:43<00:08,  8.91s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [15:52<00:00,  8.89s/it]100%|██████████| 100/100 [15:52<00:00,  9.52s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-03-23:18:34:14,193 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-03-23:18:34:14,193 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-03-23:18:34:14,193 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-03-23:18:34:14,493 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-03-23:18:34:18,590 INFO     [__main__.py:132] Verbosity set to INFO
2025-03-23:18:34:28,767 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-03-23:18:34:28,770 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-03-23:18:34:28,778 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-03-23:18:34:29,034 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  5.89it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  6.75it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  7.75it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  7.88it/s]
2025-03-23:18:34:47,286 INFO     [task.py:355] Building contexts for task on rank 0...
2025-03-23:18:34:47,305 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:612: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:13<22:53, 13.88s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:25<20:29, 12.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:36<19:29, 12.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:48<18:52, 11.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:59<18:15, 11.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:10<17:45, 11.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:21<17:17, 11.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:31<16:52, 11.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:42<16:27, 10.85s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:52<16:01, 10.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [02:02<15:40, 10.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:13<15:16, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:23<14:54, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:33<14:36, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:42<14:20, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:52<14:05, 10.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:02<13:52, 10.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:12<13:39, 10.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:22<13:27,  9.97s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:32<13:13,  9.92s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:42<13:01,  9.89s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:52<12:48,  9.85s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:01<12:36,  9.82s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:11<12:23,  9.79s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:21<12:11,  9.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:30<12:00,  9.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:40<11:50,  9.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:50<11:39,  9.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [04:59<11:27,  9.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:09<11:16,  9.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:19<11:05,  9.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:28<10:55,  9.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:38<10:45,  9.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [05:47<10:34,  9.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [05:57<10:24,  9.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:07<10:13,  9.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:16<10:03,  9.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:26<09:53,  9.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:35<09:43,  9.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [06:45<09:34,  9.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [06:54<09:24,  9.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:04<09:13,  9.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:13<09:03,  9.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:23<08:53,  9.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:32<08:42,  9.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [07:42<08:32,  9.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [07:51<08:22,  9.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:01<08:12,  9.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:10<08:03,  9.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:20<07:52,  9.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [08:29<07:42,  9.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [08:38<07:31,  9.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [08:48<07:21,  9.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [08:57<07:11,  9.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:06<07:01,  9.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:16<06:51,  9.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [09:25<06:42,  9.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [09:34<06:32,  9.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [09:44<06:22,  9.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [09:53<06:12,  9.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:02<06:02,  9.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:11<05:52,  9.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [10:21<05:43,  9.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [10:30<05:33,  9.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [10:39<05:23,  9.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [10:48<05:14,  9.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [10:58<05:05,  9.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:07<04:56,  9.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [11:16<04:46,  9.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [11:25<04:37,  9.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [11:35<04:27,  9.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [11:44<04:17,  9.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [11:53<04:08,  9.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:02<03:58,  9.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [12:11<03:49,  9.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [12:20<03:39,  9.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [12:30<03:31,  9.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [12:39<03:21,  9.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [12:48<03:12,  9.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [12:57<03:02,  9.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [13:06<02:54,  9.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [13:15<02:45,  9.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [13:25<02:36,  9.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [13:34<02:26,  9.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [13:43<02:16,  9.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [13:52<02:07,  9.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [14:01<01:58,  9.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [14:10<01:48,  9.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [14:19<01:39,  9.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [14:28<01:30,  9.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [14:37<01:21,  9.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [14:46<01:12,  9.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [14:55<01:03,  9.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [15:04<00:54,  9.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [15:13<00:45,  9.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [15:22<00:35,  9.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [15:31<00:26,  8.99s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [15:40<00:17,  8.98s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [15:49<00:08,  8.96s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [15:58<00:00,  8.94s/it]100%|██████████| 100/100 [15:58<00:00,  9.58s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-03-23:18:51:21,187 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-03-23:18:51:21,187 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-03-23:18:51:21,188 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-03-23:18:51:21,511 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-03-23:18:51:25,856 INFO     [__main__.py:132] Verbosity set to INFO
2025-03-23:18:51:35,419 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-03-23:18:51:35,422 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-03-23:18:51:35,430 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-03-23:18:51:35,704 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  5.58it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  7.24it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  8.09it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  8.10it/s]
2025-03-23:18:51:56,496 INFO     [task.py:355] Building contexts for task on rank 0...
2025-03-23:18:51:56,515 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:612: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:13<22:39, 13.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:25<20:20, 12.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:36<19:22, 11.99s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:48<18:46, 11.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:59<18:09, 11.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:09<17:39, 11.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:20<17:12, 11.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:31<16:47, 10.95s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:41<16:22, 10.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:52<15:57, 10.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [02:02<15:36, 10.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:12<15:11, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:22<14:50, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:32<14:32, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:42<14:16, 10.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:52<14:01, 10.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:01<13:48,  9.98s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:11<13:35,  9.95s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:21<13:23,  9.91s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:31<13:09,  9.87s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:41<12:57,  9.84s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:50<12:44,  9.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:00<12:32,  9.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:10<12:20,  9.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:19<12:08,  9.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:29<11:57,  9.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:39<11:46,  9.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:48<11:35,  9.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [04:58<11:23,  9.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:07<11:13,  9.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:17<11:02,  9.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:27<10:52,  9.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:36<10:41,  9.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [05:46<10:31,  9.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [05:55<10:21,  9.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:05<10:11,  9.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:14<10:00,  9.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:24<09:50,  9.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:33<09:40,  9.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [06:43<09:30,  9.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [06:52<09:20,  9.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:02<09:10,  9.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:11<09:00,  9.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:21<08:51,  9.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:30<08:40,  9.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [07:39<08:30,  9.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [07:49<08:20,  9.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [07:58<08:10,  9.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:08<08:00,  9.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:17<07:52,  9.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [08:27<07:42,  9.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [08:36<07:30,  9.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [08:45<07:19,  9.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [08:54<07:09,  9.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:04<06:59,  9.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:13<06:49,  9.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [09:22<06:39,  9.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [09:31<06:29,  9.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [09:41<06:19,  9.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [09:50<06:09,  9.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [09:59<05:59,  9.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:08<05:50,  9.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [10:17<05:40,  9.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [10:27<05:31,  9.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [10:36<05:21,  9.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [10:45<05:12,  9.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [10:54<05:02,  9.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:03<04:53,  9.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [11:12<04:44,  9.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [11:22<04:34,  9.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [11:31<04:25,  9.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [11:40<04:15,  9.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [11:49<04:06,  9.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [11:58<03:56,  9.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [12:07<03:47,  9.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [12:16<03:37,  9.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [12:25<03:28,  9.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [12:34<03:19,  9.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [12:43<03:10,  9.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [12:52<03:01,  9.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [13:01<02:51,  9.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [13:10<02:42,  9.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [13:19<02:33,  9.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [13:28<02:24,  9.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [13:37<02:14,  9.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [13:46<02:05,  8.99s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [13:55<01:56,  8.98s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [14:04<01:47,  8.98s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [14:13<01:38,  8.97s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [14:22<01:29,  8.97s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [14:31<01:20,  8.97s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [14:40<01:11,  8.96s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [14:49<01:02,  8.95s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [14:58<00:53,  8.94s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [15:07<00:44,  8.94s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [15:16<00:35,  8.93s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [15:25<00:26,  8.92s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [15:33<00:17,  8.91s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [15:42<00:08,  8.89s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [15:51<00:00,  8.87s/it]100%|██████████| 100/100 [15:51<00:00,  9.52s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-03-23:19:08:23,966 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-03-23:19:08:23,967 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-03-23:19:08:23,967 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-03-23:19:08:24,331 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-03-23:19:08:28,510 INFO     [__main__.py:132] Verbosity set to INFO
2025-03-23:19:08:38,847 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-03-23:19:08:38,849 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-03-23:19:08:38,857 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-03-23:19:08:39,132 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  4.92it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  5.89it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  6.81it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  7.47it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  6.85it/s]
2025-03-23:19:08:56,249 INFO     [task.py:355] Building contexts for task on rank 0...
2025-03-23:19:08:56,268 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:612: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:13<22:51, 13.86s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:25<20:26, 12.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:36<19:27, 12.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:48<18:50, 11.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:59<18:12, 11.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:10<17:42, 11.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:20<17:14, 11.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:31<16:49, 10.97s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:42<16:24, 10.82s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:52<15:59, 10.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [02:02<15:38, 10.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:12<15:13, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:22<14:51, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:32<14:33, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:42<14:18, 10.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:52<14:03, 10.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:02<13:50, 10.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:12<13:37,  9.97s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:22<13:24,  9.94s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:31<13:10,  9.89s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:41<13:03,  9.92s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:51<12:50,  9.87s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:01<12:37,  9.84s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:11<12:24,  9.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:20<12:12,  9.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:30<12:00,  9.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:40<11:48,  9.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:49<11:37,  9.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [04:59<11:26,  9.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:08<11:15,  9.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:18<11:04,  9.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:28<10:54,  9.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:37<10:44,  9.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [05:47<10:33,  9.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [05:56<10:22,  9.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:06<10:12,  9.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:15<10:02,  9.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:25<09:51,  9.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:35<09:41,  9.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [06:44<09:31,  9.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [06:54<09:21,  9.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:03<09:11,  9.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:12<09:01,  9.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:22<08:51,  9.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:31<08:41,  9.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [07:41<08:31,  9.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [07:50<08:21,  9.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:00<08:11,  9.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:09<08:01,  9.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:19<07:51,  9.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [08:28<07:40,  9.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [08:37<07:30,  9.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [08:47<07:20,  9.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [08:56<07:10,  9.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:05<07:00,  9.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:14<06:50,  9.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [09:24<06:40,  9.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [09:33<06:30,  9.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [09:42<06:21,  9.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [09:52<06:11,  9.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:01<06:01,  9.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:10<05:52,  9.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [10:19<05:42,  9.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [10:29<05:32,  9.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [10:38<05:23,  9.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [10:47<05:13,  9.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [10:56<05:04,  9.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:05<04:55,  9.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [11:15<04:45,  9.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [11:24<04:36,  9.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [11:33<04:26,  9.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [11:42<04:16,  9.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [11:51<04:07,  9.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:00<03:57,  9.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [12:09<03:48,  9.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [12:19<03:39,  9.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [12:28<03:29,  9.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [12:37<03:20,  9.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [12:46<03:11,  9.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [12:55<03:02,  9.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [13:04<02:52,  9.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [13:13<02:43,  9.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [13:22<02:34,  9.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [13:31<02:24,  9.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [13:40<02:15,  9.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [13:49<02:06,  9.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [13:58<01:57,  9.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [14:07<01:48,  9.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [14:16<01:39,  9.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [14:25<01:30,  9.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [14:34<01:21,  9.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [14:43<01:12,  9.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [14:52<01:03,  9.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [15:01<00:53,  9.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [15:10<00:44,  8.99s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [15:19<00:35,  8.98s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [15:28<00:26,  8.98s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [15:37<00:17,  8.96s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [15:46<00:08,  8.95s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [15:55<00:00,  8.99s/it]100%|██████████| 100/100 [15:55<00:00,  9.56s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-03-23:19:26:37,620 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-03-23:19:26:37,621 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-03-23:19:26:37,621 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-03-23:19:26:37,947 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-03-23:19:26:42,016 INFO     [__main__.py:132] Verbosity set to INFO
2025-03-23:19:26:51,998 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-03-23:19:26:52,000 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-03-23:19:26:52,007 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-03-23:19:26:52,272 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  5.31it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  6.98it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  7.84it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  8.56it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  7.83it/s]
2025-03-23:19:27:10,882 INFO     [task.py:355] Building contexts for task on rank 0...
2025-03-23:19:27:10,901 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:612: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:17<29:18, 17.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:32<26:00, 15.93s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:46<24:37, 15.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [01:01<23:45, 14.84s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [01:14<22:47, 14.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:28<22:00, 14.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:41<21:17, 13.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:53<20:38, 13.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [02:06<20:00, 13.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [02:18<19:19, 12.88s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [02:30<18:45, 12.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:42<18:06, 12.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:54<17:32, 12.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [03:05<17:05, 11.92s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [03:17<16:41, 11.79s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [03:28<16:21, 11.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:39<16:03, 11.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:51<15:46, 11.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [04:02<15:29, 11.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [04:13<15:11, 11.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [04:25<14:56, 11.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [04:36<14:38, 11.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:47<14:22, 11.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:58<14:06, 11.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [05:09<13:51, 11.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [05:20<13:36, 11.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [05:30<13:22, 10.99s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [05:41<13:08, 10.95s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:52<12:54, 10.91s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [06:03<12:40, 10.87s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [06:14<12:27, 10.83s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [06:24<12:14, 10.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [06:35<12:02, 10.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [06:46<11:50, 10.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:57<11:37, 10.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [07:07<11:24, 10.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [07:18<11:11, 10.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [07:28<10:59, 10.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [07:39<10:43, 10.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [07:49<10:32, 10.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [08:00<10:22, 10.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [08:10<10:11, 10.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [08:21<10:00, 10.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [08:31<09:48, 10.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [08:42<09:37, 10.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [08:52<09:24, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [09:02<09:12, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [09:13<09:00, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [09:23<08:49, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [09:33<08:38, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [09:44<08:26, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:54<08:15, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [10:04<08:04, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [10:14<07:52, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [10:25<07:40, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [10:35<07:28, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [10:45<07:17, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:55<07:05, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [11:05<06:54, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [11:15<06:43, 10.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [11:25<06:33, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [11:35<06:22, 10.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [11:45<06:11, 10.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:55<06:00, 10.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [12:05<05:50, 10.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [12:15<05:39, 10.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [12:25<05:29,  9.98s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [12:35<05:18,  9.97s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [12:45<05:08,  9.95s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:55<04:57,  9.92s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [13:04<04:46,  9.89s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [13:14<04:35,  9.85s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [13:24<04:25,  9.82s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [13:34<04:14,  9.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [13:43<04:04,  9.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:53<03:54,  9.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [14:03<03:44,  9.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [14:13<03:33,  9.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [14:22<03:24,  9.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [14:32<03:13,  9.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [14:41<03:03,  9.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [14:51<02:53,  9.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [15:01<02:43,  9.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [15:10<02:33,  9.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [15:20<02:23,  9.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [15:29<02:13,  9.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [15:39<02:04,  9.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [15:48<01:54,  9.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:58<01:44,  9.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [16:07<01:35,  9.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [16:17<01:25,  9.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [16:26<01:16,  9.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [16:36<01:06,  9.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [16:45<00:56,  9.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:54<00:47,  9.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [17:04<00:37,  9.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [17:13<00:28,  9.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [17:23<00:18,  9.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [17:32<00:09,  9.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [17:41<00:00,  9.29s/it]100%|██████████| 100/100 [17:41<00:00, 10.61s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-03-23:19:45:28,203 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-03-23:19:45:28,204 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-03-23:19:45:28,205 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-03-23:19:45:28,587 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-03-23:19:45:33,178 INFO     [__main__.py:132] Verbosity set to INFO
2025-03-23:19:45:43,904 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-03-23:19:45:43,906 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-03-23:19:45:43,914 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-03-23:19:45:44,213 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  4.77it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  6.25it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  6.79it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  7.40it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  6.85it/s]
2025-03-23:19:46:01,864 INFO     [task.py:355] Building contexts for task on rank 0...
2025-03-23:19:46:01,882 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:612: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:17<29:15, 17.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:32<26:00, 15.92s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:46<24:37, 15.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [01:01<23:46, 14.86s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [01:14<22:49, 14.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:28<22:02, 14.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:41<21:19, 13.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:54<20:40, 13.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [02:06<20:02, 13.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [02:18<19:21, 12.90s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [02:31<18:47, 12.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:42<18:08, 12.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:54<17:34, 12.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [03:05<17:07, 11.94s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [03:17<16:43, 11.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [03:28<16:23, 11.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:40<16:05, 11.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:51<15:48, 11.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [04:02<15:31, 11.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [04:14<15:13, 11.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [04:25<15:01, 11.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [04:36<14:43, 11.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:47<14:26, 11.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:58<14:10, 11.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [05:09<13:54, 11.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [05:20<13:39, 11.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [05:31<13:24, 11.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [05:42<13:10, 10.98s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:53<12:56, 10.94s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [06:04<12:42, 10.89s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [06:15<12:29, 10.86s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [06:25<12:16, 10.84s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [06:36<12:04, 10.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [06:47<11:51, 10.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:57<11:39, 10.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [07:08<11:26, 10.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [07:19<11:13, 10.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [07:29<11:00, 10.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [07:40<10:44, 10.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [07:50<10:34, 10.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [08:01<10:23, 10.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [08:11<10:12, 10.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [08:22<10:01, 10.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [08:32<09:50, 10.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [08:43<09:38, 10.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [08:53<09:26, 10.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [09:04<09:13, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [09:14<09:02, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [09:24<08:50, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [09:35<08:39, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [09:45<08:27, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:55<08:15, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [10:05<08:03, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [10:16<07:52, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [10:26<07:40, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [10:36<07:29, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [10:46<07:17, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:56<07:06, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [11:06<06:55, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [11:16<06:44, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [11:26<06:34, 10.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [11:37<06:23, 10.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [11:47<06:12, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:57<06:02, 10.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [12:07<05:51, 10.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [12:17<05:40, 10.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [12:27<05:30, 10.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [12:37<05:19, 10.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [12:46<05:09,  9.98s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:56<04:58,  9.95s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [13:06<04:47,  9.92s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [13:16<04:36,  9.88s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [13:26<04:25,  9.85s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [13:35<04:15,  9.82s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [13:45<04:05,  9.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:55<03:55,  9.79s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [14:05<03:44,  9.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [14:14<03:34,  9.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [14:24<03:24,  9.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [14:34<03:14,  9.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [14:43<03:04,  9.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [14:53<02:54,  9.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [15:03<02:44,  9.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [15:12<02:34,  9.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [15:22<02:24,  9.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [15:31<02:14,  9.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [15:41<02:04,  9.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [15:50<01:54,  9.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [16:00<01:45,  9.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [16:10<01:35,  9.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [16:19<01:25,  9.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [16:29<01:16,  9.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [16:38<01:06,  9.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [16:48<00:57,  9.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:57<00:47,  9.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [17:07<00:37,  9.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [17:16<00:28,  9.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [17:25<00:18,  9.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [17:35<00:09,  9.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [17:44<00:00,  9.32s/it]100%|██████████| 100/100 [17:44<00:00, 10.64s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-03-23:20:04:22,057 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-03-23:20:04:22,058 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-03-23:20:04:22,058 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-03-23:20:04:22,411 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-03-23:20:04:26,484 INFO     [__main__.py:132] Verbosity set to INFO
2025-03-23:20:04:36,651 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-03-23:20:04:36,653 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-03-23:20:04:36,662 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-03-23:20:04:36,936 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  6.19it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  7.06it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  8.07it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  8.20it/s]
2025-03-23:20:04:58,072 INFO     [task.py:355] Building contexts for task on rank 0...
2025-03-23:20:04:58,091 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:612: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:17<29:07, 17.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:32<25:55, 15.87s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:46<24:33, 15.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [01:00<23:42, 14.82s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [01:14<22:45, 14.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:27<21:59, 14.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:40<21:16, 13.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:53<20:34, 13.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [02:06<19:55, 13.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [02:18<19:14, 12.82s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [02:30<18:39, 12.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:41<18:00, 12.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:53<17:26, 12.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [03:04<16:59, 11.85s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [03:16<16:35, 11.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [03:27<16:15, 11.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:39<15:57, 11.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:50<15:40, 11.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [04:01<15:23, 11.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [04:12<15:05, 11.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [04:23<14:50, 11.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [04:34<14:32, 11.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:45<14:16, 11.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:56<14:01, 11.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [05:07<13:46, 11.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [05:18<13:31, 10.96s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [05:29<13:16, 10.92s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [05:40<13:03, 10.88s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:50<12:49, 10.84s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [06:01<12:35, 10.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [06:12<12:22, 10.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [06:22<12:10, 10.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [06:33<11:57, 10.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [06:44<11:45, 10.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:54<11:33, 10.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [07:05<11:20, 10.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [07:15<11:07, 10.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [07:26<10:55, 10.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [07:36<10:39, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [07:47<10:28, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:57<10:18, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [08:08<10:07, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [08:18<09:56, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [08:28<09:44, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [08:39<09:33, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [08:49<09:21, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:59<09:08, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [09:10<08:57, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [09:20<08:46, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [09:30<08:34, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [09:40<08:23, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:51<08:10, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [10:01<08:01, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [10:11<07:49, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [10:21<07:37, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [10:31<07:25, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [10:41<07:14, 10.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:51<07:03, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [11:01<06:52, 10.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [11:11<06:41, 10.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [11:21<06:30, 10.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [11:31<06:19,  9.99s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [11:41<06:09,  9.98s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:51<05:58,  9.96s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [12:01<05:48,  9.95s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [12:11<05:37,  9.93s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [12:21<05:27,  9.92s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [12:30<05:16,  9.90s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [12:40<05:06,  9.89s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:50<04:55,  9.86s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [13:00<04:45,  9.83s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [13:10<04:34,  9.79s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [13:19<04:23,  9.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [13:29<04:13,  9.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [13:39<04:02,  9.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:48<03:52,  9.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:58<03:42,  9.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [14:08<03:32,  9.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [14:17<03:22,  9.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [14:27<03:12,  9.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [14:36<03:02,  9.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [14:46<02:52,  9.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:55<02:42,  9.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [15:05<02:32,  9.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [15:14<02:22,  9.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [15:24<02:12,  9.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [15:33<02:03,  9.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [15:43<01:53,  9.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:52<01:44,  9.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [16:01<01:34,  9.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [16:11<01:25,  9.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [16:20<01:15,  9.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [16:30<01:05,  9.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [16:39<00:56,  9.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:48<00:46,  9.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:58<00:37,  9.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [17:07<00:28,  9.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [17:16<00:18,  9.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [17:25<00:09,  9.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [17:35<00:00,  9.23s/it]100%|██████████| 100/100 [17:35<00:00, 10.55s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-03-23:20:23:09,197 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-03-23:20:23:09,198 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-03-23:20:23:09,198 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-03-23:20:23:09,562 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-03-23:20:23:13,661 INFO     [__main__.py:132] Verbosity set to INFO
2025-03-23:20:23:23,806 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-03-23:20:23:23,808 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-03-23:20:23:23,814 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-03-23:20:23:24,094 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  5.52it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  7.25it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  8.14it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  8.14it/s]
2025-03-23:20:23:43,282 INFO     [task.py:355] Building contexts for task on rank 0...
2025-03-23:20:23:43,301 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:612: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:17<29:04, 17.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:32<25:52, 15.84s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:46<24:30, 15.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [01:00<23:40, 14.79s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [01:14<22:42, 14.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:27<21:56, 14.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:40<21:13, 13.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:53<20:32, 13.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [02:05<19:52, 13.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [02:18<19:11, 12.79s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [02:30<18:36, 12.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:41<17:57, 12.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:53<17:23, 12.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [03:04<16:56, 11.82s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [03:15<16:33, 11.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [03:27<16:13, 11.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:38<15:59, 11.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:50<15:41, 11.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [04:01<15:23, 11.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [04:12<15:05, 11.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [04:23<14:49, 11.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [04:34<14:31, 11.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:45<14:15, 11.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:56<13:59, 11.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [05:07<13:44, 10.99s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [05:17<13:29, 10.93s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [05:28<13:14, 10.89s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [05:39<13:01, 10.85s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:50<12:47, 10.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [06:00<12:33, 10.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [06:11<12:20, 10.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [06:22<12:08, 10.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [06:32<11:55, 10.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [06:43<11:43, 10.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:53<11:31, 10.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [07:04<11:18, 10.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [07:14<11:05, 10.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [07:25<10:53, 10.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [07:35<10:37, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [07:46<10:26, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:56<10:16, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [08:06<10:05, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [08:17<09:54, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [08:27<09:43, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [08:38<09:31, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [08:48<09:19, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:58<09:07, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [09:08<08:55, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [09:19<08:44, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [09:29<08:33, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [09:39<08:21, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:49<08:09, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:59<07:57, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [10:09<07:46, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [10:19<07:34, 10.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [10:29<07:23, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [10:39<07:12, 10.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:49<07:01, 10.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:59<06:50, 10.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [11:09<06:39, 10.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [11:19<06:29,  9.98s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [11:29<06:18,  9.96s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [11:39<06:07,  9.94s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:49<05:57,  9.93s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:59<05:46,  9.91s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [12:09<05:36,  9.90s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [12:18<05:26,  9.88s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [12:28<05:15,  9.87s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [12:38<05:05,  9.85s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:48<04:54,  9.82s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:58<04:43,  9.79s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [13:07<04:33,  9.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [13:17<04:22,  9.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [13:27<04:12,  9.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [13:36<04:01,  9.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:46<03:51,  9.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:55<03:41,  9.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [14:05<03:31,  9.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [14:15<03:21,  9.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [14:24<03:11,  9.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [14:34<03:01,  9.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [14:43<02:51,  9.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:53<02:41,  9.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [15:02<02:31,  9.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [15:11<02:22,  9.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [15:21<02:12,  9.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [15:30<02:02,  9.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [15:40<01:53,  9.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:49<01:44,  9.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:59<01:34,  9.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [16:08<01:24,  9.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [16:17<01:15,  9.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [16:27<01:05,  9.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [16:36<00:56,  9.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:45<00:46,  9.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:55<00:37,  9.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [17:04<00:27,  9.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [17:13<00:18,  9.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [17:22<00:09,  9.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [17:31<00:00,  9.20s/it]100%|██████████| 100/100 [17:31<00:00, 10.52s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-03-23:20:41:51,366 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-03-23:20:41:51,366 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-03-23:20:41:51,367 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-03-23:20:41:51,723 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-03-23:20:41:55,993 INFO     [__main__.py:132] Verbosity set to INFO
2025-03-23:20:42:06,664 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-03-23:20:42:06,666 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-03-23:20:42:06,675 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-03-23:20:42:06,940 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  5.46it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  6.87it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  7.39it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  7.93it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  7.44it/s]
2025-03-23:20:42:23,737 INFO     [task.py:355] Building contexts for task on rank 0...
2025-03-23:20:42:23,758 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:612: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:17<29:07, 17.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:32<25:56, 15.88s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:46<24:34, 15.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [01:00<23:43, 14.83s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [01:14<22:46, 14.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:27<22:00, 14.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:41<21:17, 13.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:53<20:37, 13.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [02:06<19:59, 13.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [02:18<19:17, 12.86s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [02:30<18:41, 12.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:42<18:02, 12.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:53<17:27, 12.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [03:05<17:00, 11.86s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [03:16<16:36, 11.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [03:27<16:16, 11.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:39<15:58, 11.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:50<15:41, 11.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [04:01<15:23, 11.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [04:13<15:06, 11.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [04:24<14:51, 11.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [04:35<14:33, 11.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:46<14:17, 11.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:57<14:01, 11.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [05:07<13:46, 11.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [05:18<13:31, 10.97s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [05:29<13:17, 10.92s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [05:40<13:03, 10.89s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:51<12:50, 10.85s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [06:01<12:36, 10.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [06:12<12:23, 10.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [06:23<12:10, 10.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [06:33<11:58, 10.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [06:44<11:45, 10.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:55<11:33, 10.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [07:05<11:20, 10.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [07:16<11:07, 10.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [07:26<10:55, 10.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [07:37<10:39, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [07:47<10:29, 10.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:58<10:18, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [08:08<10:07, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [08:18<09:56, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [08:29<09:45, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [08:39<09:33, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [08:50<09:21, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [09:00<09:09, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [09:10<08:57, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [09:20<08:46, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [09:31<08:35, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [09:41<08:23, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:51<08:11, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [10:01<07:59, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [10:11<07:48, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [10:21<07:36, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [10:32<07:27, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [10:42<07:16, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:52<07:04, 10.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [11:02<06:53, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [11:12<06:42, 10.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [11:22<06:31, 10.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [11:32<06:20, 10.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [11:42<06:09, 10.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:52<05:59,  9.98s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [12:01<05:48,  9.96s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [12:11<05:38,  9.95s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [12:21<05:27,  9.93s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [12:31<05:17,  9.92s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [12:41<05:06,  9.90s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:51<04:56,  9.87s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [13:01<04:45,  9.84s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [13:10<04:34,  9.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [13:20<04:23,  9.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [13:30<04:13,  9.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [13:39<04:03,  9.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:49<03:52,  9.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:59<03:42,  9.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [14:08<03:32,  9.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [14:18<03:22,  9.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [14:28<03:12,  9.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [14:37<03:02,  9.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [14:47<02:52,  9.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:56<02:42,  9.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [15:06<02:32,  9.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [15:15<02:22,  9.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [15:25<02:13,  9.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [15:34<02:03,  9.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [15:43<01:53,  9.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:53<01:44,  9.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [16:02<01:34,  9.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [16:12<01:25,  9.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [16:21<01:15,  9.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [16:31<01:06,  9.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [16:40<00:56,  9.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:49<00:47,  9.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:59<00:37,  9.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [17:08<00:28,  9.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [17:17<00:18,  9.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [17:27<00:09,  9.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [17:36<00:00,  9.25s/it]100%|██████████| 100/100 [17:36<00:00, 10.56s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-03-23:21:01:45,970 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-03-23:21:01:45,971 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-03-23:21:01:45,971 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-03-23:21:01:46,309 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-03-23:21:01:50,644 INFO     [__main__.py:132] Verbosity set to INFO
2025-03-23:21:02:01,153 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-03-23:21:02:01,155 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-03-23:21:02:01,163 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-03-23:21:02:01,440 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  5.30it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  6.98it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  7.89it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  7.92it/s]
2025-03-23:21:02:20,233 INFO     [task.py:355] Building contexts for task on rank 0...
2025-03-23:21:02:20,252 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:612: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:18<30:32, 18.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:33<27:13, 16.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:49<25:48, 15.97s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [01:04<24:56, 15.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [01:18<23:56, 15.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:32<23:09, 14.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:46<22:26, 14.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:59<21:45, 14.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [02:13<21:06, 13.92s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [02:26<20:24, 13.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [02:38<19:49, 13.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:51<19:14, 13.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [03:03<18:39, 12.87s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [03:16<18:10, 12.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [03:28<17:45, 12.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [03:40<17:24, 12.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:52<17:05, 12.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [04:04<16:47, 12.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [04:16<16:29, 12.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [04:28<16:10, 12.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [04:40<15:52, 12.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [04:52<15:34, 11.98s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [05:04<15:17, 11.91s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [05:15<15:01, 11.86s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [05:27<14:45, 11.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [05:39<14:29, 11.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [05:50<14:14, 11.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [06:02<14:00, 11.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [06:13<13:45, 11.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [06:25<13:30, 11.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [06:36<13:17, 11.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [06:48<13:03, 11.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [06:59<12:50, 11.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [07:11<12:36, 11.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [07:22<12:24, 11.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [07:33<12:10, 11.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [07:45<11:57, 11.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [07:56<11:43, 11.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [08:07<11:30, 11.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [08:18<11:18, 11.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [08:30<11:06, 11.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [08:41<10:54, 11.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [08:52<10:41, 11.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [09:03<10:29, 11.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [09:15<10:17, 11.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [09:26<10:04, 11.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [09:37<09:51, 11.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [09:48<09:38, 11.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [09:59<09:26, 11.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [10:10<09:14, 11.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [10:21<09:02, 11.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [10:32<08:49, 11.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [10:43<08:36, 10.99s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [10:54<08:24, 10.96s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [11:05<08:11, 10.93s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [11:15<07:59, 10.90s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [11:26<07:47, 10.88s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [11:37<07:35, 10.85s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [11:48<07:24, 10.83s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [11:59<07:12, 10.82s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [12:09<07:01, 10.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [12:20<06:49, 10.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [12:31<06:38, 10.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [12:42<06:26, 10.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [12:52<06:15, 10.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [13:03<06:04, 10.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [13:14<05:53, 10.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [13:24<05:41, 10.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [13:35<05:30, 10.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [13:45<05:19, 10.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [13:56<05:07, 10.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [14:06<04:56, 10.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [14:17<04:44, 10.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [14:27<04:33, 10.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [14:38<04:22, 10.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [14:48<04:11, 10.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [14:59<04:00, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [15:09<03:50, 10.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [15:20<03:40, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [15:30<03:28, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [15:40<03:17, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [15:51<03:06, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [16:01<02:55, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [16:11<02:45, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [16:21<02:34, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [16:32<02:23, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [16:42<02:13, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [16:52<02:03, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [17:02<01:52, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [17:13<01:42, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [17:23<01:32, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [17:33<01:21, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [17:43<01:11, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [17:53<01:01, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [18:03<00:50, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [18:14<00:40, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [18:24<00:30, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [18:34<00:20, 10.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [18:44<00:10, 10.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [18:54<00:00, 10.01s/it]100%|██████████| 100/100 [18:54<00:00, 11.34s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-03-23:21:21:50,056 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-03-23:21:21:50,056 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-03-23:21:21:50,057 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-03-23:21:21:50,401 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-03-23:21:21:54,662 INFO     [__main__.py:132] Verbosity set to INFO
2025-03-23:21:22:04,943 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-03-23:21:22:04,945 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-03-23:21:22:04,953 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-03-23:21:22:05,224 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  5.81it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  7.39it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  7.52it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  7.84it/s]
2025-03-23:21:22:22,418 INFO     [task.py:355] Building contexts for task on rank 0...
2025-03-23:21:22:22,437 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:612: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:18<30:16, 18.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:33<27:02, 16.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:48<25:39, 15.87s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [01:03<24:47, 15.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [01:17<23:48, 15.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:31<23:01, 14.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:45<22:17, 14.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:59<21:37, 14.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [02:12<20:58, 13.83s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [02:25<20:17, 13.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [02:37<19:42, 13.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:50<19:03, 12.99s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [03:02<18:28, 12.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [03:14<18:00, 12.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [03:26<17:36, 12.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [03:38<17:15, 12.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:50<16:57, 12.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [04:02<16:39, 12.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [04:14<16:22, 12.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [04:26<16:03, 12.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [04:38<15:46, 11.98s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [04:50<15:27, 11.89s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [05:01<15:10, 11.83s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [05:13<14:55, 11.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [05:25<14:39, 11.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [05:36<14:23, 11.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [05:48<14:08, 11.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [05:59<13:54, 11.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [06:11<13:39, 11.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [06:22<13:25, 11.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [06:34<13:11, 11.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [06:45<12:58, 11.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [06:56<12:45, 11.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [07:08<12:31, 11.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [07:19<12:21, 11.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [07:30<12:08, 11.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [07:42<11:54, 11.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [07:53<11:41, 11.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [08:04<11:26, 11.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [08:15<11:14, 11.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [08:26<11:02, 11.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [08:38<10:49, 11.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [08:49<10:37, 11.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [09:00<10:25, 11.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [09:11<10:13, 11.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [09:22<10:00, 11.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [09:33<09:47, 11.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [09:44<09:34, 11.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [09:55<09:22, 11.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [10:06<09:10, 11.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [10:17<08:58, 10.99s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [10:28<08:45, 10.95s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [10:38<08:32, 10.91s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [10:49<08:20, 10.88s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [11:00<08:08, 10.85s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [11:11<07:56, 10.82s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [11:22<07:44, 10.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [11:32<07:32, 10.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [11:43<07:21, 10.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [11:54<07:09, 10.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [12:04<06:57, 10.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [12:15<06:46, 10.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [12:26<06:35, 10.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [12:36<06:24, 10.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [12:47<06:12, 10.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [12:58<06:01, 10.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [13:08<05:50, 10.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [13:19<05:39, 10.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [13:29<05:28, 10.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [13:40<05:16, 10.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [13:50<05:05, 10.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [14:01<04:53, 10.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [14:11<04:42, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [14:21<04:31, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [14:32<04:20, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [14:42<04:09, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [14:52<03:58, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [15:03<03:48, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [15:13<03:37, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [15:23<03:26, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [15:34<03:15, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [15:44<03:05, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [15:54<02:54, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [16:04<02:43, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [16:14<02:33, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [16:25<02:22, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [16:35<02:12, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [16:45<02:02, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [16:55<01:51, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [17:05<01:41, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [17:15<01:31, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [17:25<01:21, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [17:36<01:10, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [17:46<01:00, 10.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [17:56<00:50, 10.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [18:06<00:40, 10.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [18:16<00:30, 10.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [18:26<00:20, 10.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [18:36<00:09,  9.99s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [18:45<00:00,  9.94s/it]100%|██████████| 100/100 [18:45<00:00, 11.26s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-03-23:21:41:43,858 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-03-23:21:41:43,859 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-03-23:21:41:43,859 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-03-23:21:41:44,182 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-03-23:21:41:48,147 INFO     [__main__.py:132] Verbosity set to INFO
2025-03-23:21:41:57,944 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-03-23:21:41:57,946 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-03-23:21:41:57,954 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-03-23:21:41:58,219 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  5.79it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  6.59it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  7.49it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  8.22it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  7.61it/s]
2025-03-23:21:42:18,440 INFO     [task.py:355] Building contexts for task on rank 0...
2025-03-23:21:42:18,459 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:612: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:18<30:20, 18.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:33<27:08, 16.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:48<25:45, 15.94s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [01:03<24:54, 15.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [01:18<23:55, 15.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:32<23:08, 14.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:46<22:25, 14.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:59<21:44, 14.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [02:13<21:05, 13.91s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [02:25<20:24, 13.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [02:38<19:49, 13.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:51<19:09, 13.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [03:03<18:35, 12.82s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [03:15<18:07, 12.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [03:27<17:43, 12.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [03:39<17:21, 12.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:52<17:03, 12.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [04:04<16:45, 12.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [04:16<16:28, 12.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [04:28<16:09, 12.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [04:40<15:52, 12.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [04:51<15:34, 11.98s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [05:03<15:17, 11.91s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [05:15<15:01, 11.86s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [05:27<14:45, 11.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [05:38<14:29, 11.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [05:50<14:14, 11.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [06:01<14:00, 11.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [06:13<13:45, 11.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [06:24<13:30, 11.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [06:36<13:17, 11.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [06:47<13:03, 11.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [06:59<12:50, 11.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [07:10<12:36, 11.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [07:22<12:23, 11.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [07:33<12:09, 11.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [07:44<11:56, 11.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [07:56<11:43, 11.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [08:07<11:29, 11.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [08:18<11:17, 11.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [08:29<11:05, 11.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [08:40<10:53, 11.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [08:52<10:41, 11.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [09:03<10:29, 11.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [09:14<10:16, 11.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [09:25<10:03, 11.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [09:36<09:51, 11.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [09:47<09:38, 11.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [09:58<09:26, 11.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [10:09<09:14, 11.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [10:20<09:01, 11.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [10:31<08:48, 11.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [10:42<08:36, 10.98s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [10:53<08:23, 10.95s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [11:04<08:11, 10.92s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [11:15<07:59, 10.89s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [11:26<07:47, 10.87s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [11:36<07:36, 10.86s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [11:47<07:24, 10.84s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [11:58<07:12, 10.82s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [12:09<07:00, 10.79s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [12:19<06:49, 10.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [12:30<06:38, 10.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [12:41<06:26, 10.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [12:52<06:15, 10.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [13:02<06:05, 10.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [13:13<05:54, 10.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [13:24<05:43, 10.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [13:34<05:31, 10.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [13:45<05:20, 10.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [13:56<05:08, 10.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [14:06<04:56, 10.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [14:17<04:45, 10.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [14:27<04:33, 10.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [14:38<04:22, 10.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [14:48<04:11, 10.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [14:58<04:00, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [15:09<03:50, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [15:19<03:39, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [15:30<03:28, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [15:40<03:17, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [15:50<03:06, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [16:01<02:55, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [16:11<02:45, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [16:21<02:34, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [16:31<02:24, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [16:42<02:13, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [16:52<02:03, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [17:02<01:52, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [17:12<01:42, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [17:23<01:32, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [17:33<01:21, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [17:43<01:11, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [17:53<01:01, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [18:03<00:50, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [18:13<00:40, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [18:23<00:30, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [18:33<00:20, 10.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [18:43<00:10, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [18:53<00:00, 10.03s/it]100%|██████████| 100/100 [18:53<00:00, 11.34s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-03-23:22:01:48,382 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-03-23:22:01:48,383 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-03-23:22:01:48,383 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-03-23:22:01:48,743 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-03-23:22:01:53,089 INFO     [__main__.py:132] Verbosity set to INFO
2025-03-23:22:02:03,233 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-03-23:22:02:03,236 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-03-23:22:02:03,245 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-03-23:22:02:03,513 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  5.83it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  6.66it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  7.64it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  7.77it/s]
2025-03-23:22:02:21,758 INFO     [task.py:355] Building contexts for task on rank 0...
2025-03-23:22:02:21,776 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:612: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:18<30:14, 18.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:33<27:02, 16.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:48<25:40, 15.88s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [01:03<24:48, 15.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [01:17<23:49, 15.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:31<23:03, 14.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:45<22:19, 14.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:59<21:39, 14.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [02:12<21:00, 13.85s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [02:25<20:18, 13.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [02:38<19:43, 13.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:50<19:04, 13.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [03:02<18:30, 12.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [03:14<18:02, 12.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [03:26<17:38, 12.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [03:39<17:17, 12.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:51<16:58, 12.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [04:03<16:41, 12.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [04:15<16:23, 12.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [04:27<16:04, 12.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [04:38<15:47, 12.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [04:50<15:29, 11.91s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [05:02<15:12, 11.85s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [05:14<14:59, 11.83s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [05:25<14:43, 11.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [05:37<14:27, 11.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [05:48<14:12, 11.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [06:00<13:57, 11.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [06:11<13:42, 11.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [06:23<13:27, 11.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [06:34<13:13, 11.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [06:46<12:59, 11.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [06:57<12:46, 11.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [07:08<12:32, 11.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [07:20<12:19, 11.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [07:31<12:06, 11.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [07:42<11:52, 11.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [07:53<11:39, 11.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [08:05<11:26, 11.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [08:16<11:14, 11.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [08:27<11:02, 11.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [08:38<10:50, 11.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [08:49<10:38, 11.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [09:00<10:25, 11.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [09:12<10:13, 11.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [09:23<10:00, 11.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [09:34<09:47, 11.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [09:45<09:35, 11.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [09:56<09:23, 11.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [10:07<09:11, 11.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [10:18<08:58, 11.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [10:28<08:45, 10.96s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [10:39<08:33, 10.92s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [10:50<08:20, 10.89s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [11:01<08:08, 10.86s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [11:12<07:56, 10.83s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [11:22<07:44, 10.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [11:33<07:33, 10.79s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [11:44<07:21, 10.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [11:55<07:10, 10.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [12:05<06:58, 10.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [12:16<06:47, 10.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [12:27<06:35, 10.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [12:37<06:24, 10.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [12:48<06:13, 10.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [12:58<06:02, 10.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [13:09<05:50, 10.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [13:20<05:39, 10.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [13:30<05:28, 10.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [13:41<05:17, 10.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [13:51<05:05, 10.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [14:02<04:54, 10.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [14:12<04:42, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [14:22<04:31, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [14:33<04:20, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [14:43<04:09, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [14:54<03:59, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [15:04<03:48, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [15:14<03:37, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [15:24<03:26, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [15:35<03:15, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [15:45<03:05, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [15:55<02:54, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [16:05<02:43, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [16:16<02:33, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [16:26<02:22, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [16:36<02:12, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [16:46<02:02, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [16:56<01:51, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [17:06<01:41, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [17:17<01:31, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [17:27<01:21, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [17:37<01:11, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [17:47<01:00, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [17:57<00:50, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [18:07<00:40, 10.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [18:17<00:30, 10.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [18:27<00:20, 10.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [18:37<00:10, 10.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [18:47<00:00,  9.95s/it]100%|██████████| 100/100 [18:47<00:00, 11.27s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-03-23:22:21:45,095 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-03-23:22:21:45,096 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-03-23:22:21:45,096 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-03-23:22:21:45,380 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-03-23:22:21:50,044 INFO     [__main__.py:132] Verbosity set to INFO
2025-03-23:22:22:00,783 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-03-23:22:22:00,785 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-03-23:22:22:00,794 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-03-23:22:22:01,066 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  5.61it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  6.97it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  7.88it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  7.93it/s]
2025-03-23:22:22:19,603 INFO     [task.py:355] Building contexts for task on rank 0...
2025-03-23:22:22:19,622 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]/global/D1/homes/alireza/virtual_envs/code_bench/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:612: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:18<30:33, 18.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:33<27:14, 16.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:49<25:50, 15.99s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [01:04<24:58, 15.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [01:18<23:58, 15.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:32<23:12, 14.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:46<22:28, 14.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [02:00<21:47, 14.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [02:13<21:08, 13.94s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [02:26<20:26, 13.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [02:39<19:51, 13.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:51<19:12, 13.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [03:03<18:37, 12.85s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [03:16<18:09, 12.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [03:28<17:45, 12.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [03:40<17:24, 12.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:52<17:06, 12.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [04:04<16:48, 12.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [04:16<16:30, 12.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [04:28<16:11, 12.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [04:40<15:54, 12.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [04:52<15:36, 12.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [05:04<15:19, 11.94s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [05:16<15:03, 11.89s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [05:27<14:47, 11.83s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [05:39<14:31, 11.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [05:51<14:16, 11.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [06:02<14:02, 11.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [06:14<13:47, 11.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [06:25<13:32, 11.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [06:37<13:19, 11.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [06:48<13:05, 11.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [07:00<12:52, 11.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [07:11<12:38, 11.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [07:23<12:25, 11.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [07:34<12:11, 11.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [07:45<11:58, 11.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [07:57<11:45, 11.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [08:08<11:31, 11.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [08:19<11:19, 11.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [08:31<11:07, 11.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [08:42<10:55, 11.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [08:53<10:43, 11.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [09:04<10:30, 11.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [09:15<10:18, 11.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [09:27<10:05, 11.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [09:38<09:52, 11.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [09:49<09:42, 11.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [10:00<09:29, 11.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [10:11<09:16, 11.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [10:22<09:04, 11.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [10:33<08:50, 11.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [10:44<08:37, 11.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [10:55<08:25, 10.98s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [11:06<08:12, 10.95s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [11:17<08:00, 10.92s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [11:28<07:48, 10.90s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [11:38<07:36, 10.87s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [11:49<07:24, 10.85s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [12:00<07:13, 10.83s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [12:11<07:01, 10.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [12:21<06:50, 10.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [12:32<06:38, 10.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [12:43<06:27, 10.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [12:54<06:16, 10.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [13:04<06:05, 10.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [13:15<05:53, 10.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [13:26<05:42, 10.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [13:36<05:31, 10.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [13:47<05:19, 10.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [13:57<05:08, 10.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [14:08<04:56, 10.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [14:18<04:45, 10.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [14:29<04:34, 10.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [14:39<04:22, 10.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [14:50<04:11, 10.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [15:00<04:01, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [15:11<03:50, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [15:21<03:39, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [15:32<03:28, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [15:42<03:17, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [15:52<03:06, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [16:03<02:55, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [16:13<02:45, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [16:23<02:34, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [16:33<02:24, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [16:44<02:13, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [16:54<02:03, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [17:04<01:52, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [17:14<01:42, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [17:25<01:32, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [17:35<01:21, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [17:45<01:11, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [17:55<01:01, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [18:05<00:50, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [18:15<00:40, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [18:25<00:30, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [18:35<00:20, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [18:46<00:10, 10.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [18:55<00:00, 10.04s/it]100%|██████████| 100/100 [18:55<00:00, 11.36s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
