2025-01-15:00:16:39,920 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-01-15:00:16:39,920 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-01-15:00:16:39,920 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-01-15:00:16:40,291 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-01-15:00:16:44,478 INFO     [__main__.py:132] Verbosity set to INFO
2025-01-15:00:16:54,899 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-01-15:00:16:54,901 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-01-15:00:16:54,909 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-01-15:00:16:55,138 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:01,  6.20it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:00<00:00,  7.55it/s]Loading checkpoint shards:  38%|███▊      | 3/8 [00:00<00:00,  7.79it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:00<00:00,  8.34it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:00<00:00,  8.69it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:00<00:00,  8.95it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:00<00:00,  9.14it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  8.70it/s]
2025-01-15:00:17:17,024 INFO     [task.py:355] Building contexts for task on rank 0...
2025-01-15:00:17:17,042 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:13<21:28, 13.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:24<19:26, 11.90s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:35<18:30, 11.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:45<17:58, 11.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:56<17:31, 11.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:07<17:10, 10.97s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:18<16:52, 10.88s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:28<16:35, 10.82s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:39<16:20, 10.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:50<16:04, 10.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [02:00<15:50, 10.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:11<15:35, 10.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:21<15:21, 10.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:32<15:08, 10.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:42<14:56, 10.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:53<14:44, 10.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:03<14:33, 10.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:14<14:21, 10.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:24<14:11, 10.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:35<13:59, 10.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:45<13:47, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:56<13:35, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:06<13:24, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:16<13:12, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:27<13:01, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:37<12:50, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:48<12:39, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:58<12:28, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:08<12:17, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:19<12:07, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:29<11:56, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:39<11:45, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:50<11:34, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [06:00<11:24, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:11<11:13, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:21<11:03, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:31<10:52, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:42<10:41, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:52<10:31, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [07:02<10:20, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:13<10:10, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:23<09:59, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:33<09:49, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:44<09:38, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:54<09:28, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [08:04<09:17, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:14<09:06, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:25<08:56, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:35<08:45, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:45<08:35, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [08:56<08:24, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:06<08:14, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:16<08:03, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:27<07:55, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:37<07:44, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:47<07:33, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [09:58<07:22, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:08<07:12, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:18<07:01, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:28<06:51, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:39<06:40, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:49<06:29, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [10:59<06:19, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:09<06:09, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:20<05:58, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:30<05:48, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:40<05:37, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:50<05:27, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [12:01<05:17, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:11<05:06, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:21<04:56, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:31<04:46, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:41<04:35, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:52<04:25, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [13:02<04:15, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:12<04:06, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:22<03:55, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:33<03:45, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:43<03:34, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [13:53<03:24, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [14:03<03:13, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [14:13<03:03, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:23<02:53, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:34<02:42, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:44<02:32, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [14:54<02:22, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [15:04<02:13, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [15:14<02:02, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:25<01:52, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:35<01:41, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:45<01:31, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [15:55<01:21, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [16:05<01:11, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [16:15<01:00, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:25<00:50, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:36<00:40, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:46<00:30, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [16:56<00:20, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [17:06<00:10, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [17:16<00:00, 10.12s/it]100%|██████████| 100/100 [17:16<00:00, 10.37s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-01-15:00:35:09,758 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-01-15:00:35:09,758 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-01-15:00:35:09,758 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-01-15:00:35:10,125 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-01-15:00:35:14,452 INFO     [__main__.py:132] Verbosity set to INFO
2025-01-15:00:35:25,086 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-01-15:00:35:25,088 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-01-15:00:35:25,096 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-01-15:00:35:25,314 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:01,  5.41it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:00<00:00,  6.93it/s]Loading checkpoint shards:  38%|███▊      | 3/8 [00:00<00:00,  7.77it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:00<00:00,  8.30it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:00<00:00,  8.02it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:00<00:00,  8.46it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:00<00:00,  8.71it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  8.31it/s]
2025-01-15:00:35:47,116 INFO     [task.py:355] Building contexts for task on rank 0...
2025-01-15:00:35:47,134 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:51, 12.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<19:08, 11.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:25, 11.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:45<17:58, 11.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:56<17:35, 11.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:07<17:16, 11.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:18<16:58, 10.95s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:29<16:43, 10.90s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:39<16:27, 10.85s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:50<16:12, 10.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [02:01<15:58, 10.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:11<15:43, 10.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:22<15:29, 10.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:33<15:16, 10.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:43<15:04, 10.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:54<14:52, 10.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:04<14:40, 10.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:15<14:29, 10.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:25<14:18, 10.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:36<14:05, 10.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:46<13:54, 10.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:57<13:42, 10.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:08<13:31, 10.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:18<13:20, 10.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:29<13:08, 10.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:39<12:57, 10.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:49<12:46, 10.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [05:00<12:35, 10.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:10<12:24, 10.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:21<12:13, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:31<12:02, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:42<11:52, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:52<11:41, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [06:03<11:30, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:13<11:20, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:24<11:09, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:34<10:58, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:45<10:47, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:55<10:37, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [07:05<10:26, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:16<10:15, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:26<10:05, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:37<09:54, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:47<09:44, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:58<09:33, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [08:08<09:22, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:18<09:12, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:29<09:01, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:39<08:50, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:50<08:40, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [09:00<08:29, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:10<08:19, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:21<08:08, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:31<07:57, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:41<07:47, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:52<07:36, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [10:02<07:26, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:13<07:15, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:23<07:05, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:33<06:54, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:44<06:44, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:54<06:33, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [11:04<06:22, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:15<06:12, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:25<06:01, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:35<05:51, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:46<05:41, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:56<05:30, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [12:06<05:20, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:17<05:09, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:27<04:59, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:37<04:49, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:48<04:38, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:58<04:27, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [13:08<04:17, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:18<04:07, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:29<03:56, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:39<03:46, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:49<03:36, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [14:00<03:25, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [14:10<03:15, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [14:20<03:05, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:30<02:54, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:41<02:44, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:51<02:33, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [15:01<02:23, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [15:11<02:13, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [15:22<02:03, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:32<01:52, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:42<01:42, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:52<01:32, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [16:03<01:21, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [16:13<01:11, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [16:23<01:01, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:33<00:51, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:44<00:40, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:54<00:30, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [17:04<00:20, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [17:14<00:10, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [17:24<00:00, 10.21s/it]100%|██████████| 100/100 [17:24<00:00, 10.45s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-01-15:00:53:48,105 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-01-15:00:53:48,105 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-01-15:00:53:48,105 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-01-15:00:53:48,473 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-01-15:00:53:52,832 INFO     [__main__.py:132] Verbosity set to INFO
2025-01-15:00:54:03,152 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-01-15:00:54:03,154 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-01-15:00:54:03,163 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-01-15:00:54:03,383 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:01,  5.80it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:00<00:00,  6.65it/s]Loading checkpoint shards:  38%|███▊      | 3/8 [00:00<00:00,  7.66it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:00<00:00,  8.29it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:00<00:00,  8.66it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:00<00:00,  8.93it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:00<00:00,  9.13it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  8.56it/s]
2025-01-15:00:54:25,562 INFO     [task.py:355] Building contexts for task on rank 0...
2025-01-15:00:54:25,582 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:51, 12.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<19:07, 11.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:24, 11.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:45<17:58, 11.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:56<17:34, 11.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:07<17:15, 11.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:18<16:57, 10.95s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:29<16:42, 10.90s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:39<16:27, 10.85s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:50<16:11, 10.79s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [02:01<15:57, 10.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:11<15:42, 10.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:22<15:29, 10.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:32<15:16, 10.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:43<15:03, 10.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:54<14:51, 10.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:04<14:40, 10.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:15<14:28, 10.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:25<14:17, 10.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:36<14:05, 10.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:46<13:53, 10.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:57<13:41, 10.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:07<13:30, 10.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:18<13:19, 10.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:28<13:08, 10.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:39<12:57, 10.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:49<12:45, 10.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [05:00<12:35, 10.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:10<12:24, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:21<12:13, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:31<12:02, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:42<11:51, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:52<11:40, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [06:02<11:30, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:13<11:19, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:23<11:08, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:34<10:58, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:44<10:47, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:55<10:36, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [07:05<10:25, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:16<10:15, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:26<10:04, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:36<09:54, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:47<09:43, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:57<09:32, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [08:08<09:22, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:18<09:11, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:28<09:01, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:39<08:50, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:49<08:39, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [09:00<08:29, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:10<08:18, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:20<08:07, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:31<07:57, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:41<07:46, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:51<07:36, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [10:02<07:25, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:12<07:15, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:22<07:04, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:33<06:54, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:43<06:43, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:53<06:33, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [11:04<06:22, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:14<06:12, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:24<06:01, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:35<05:51, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:45<05:40, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:55<05:30, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [12:06<05:20, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:16<05:09, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:26<04:59, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:37<04:48, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:47<04:38, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:57<04:27, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [13:08<04:17, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:18<04:06, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:28<03:56, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:38<03:46, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:49<03:35, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [13:59<03:25, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [14:09<03:15, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [14:19<03:04, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:30<02:54, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:40<02:44, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:50<02:33, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [15:00<02:23, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [15:11<02:13, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [15:21<02:02, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:31<01:52, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:41<01:42, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:52<01:32, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [16:02<01:21, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [16:12<01:11, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [16:22<01:01, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:33<00:51, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:43<00:40, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:53<00:30, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [17:03<00:20, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [17:13<00:10, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [17:24<00:00, 10.20s/it]100%|██████████| 100/100 [17:24<00:00, 10.44s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-01-15:01:12:26,090 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-01-15:01:12:26,090 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-01-15:01:12:26,090 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-01-15:01:12:26,473 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-01-15:01:12:30,822 INFO     [__main__.py:132] Verbosity set to INFO
2025-01-15:01:12:41,143 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-01-15:01:12:41,146 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-01-15:01:12:41,153 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-01-15:01:12:41,374 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:01,  6.01it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:00<00:00,  7.24it/s]Loading checkpoint shards:  38%|███▊      | 3/8 [00:00<00:00,  7.61it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:00<00:00,  8.25it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:00<00:00,  8.65it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:00<00:00,  8.94it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:00<00:00,  9.15it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  8.63it/s]
2025-01-15:01:13:02,163 INFO     [task.py:355] Building contexts for task on rank 0...
2025-01-15:01:13:02,181 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:44, 12.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<19:00, 11.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:16, 11.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:45<17:50, 11.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:56<17:26, 11.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:06<17:07, 10.94s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:17<16:50, 10.86s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:28<16:34, 10.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:39<16:19, 10.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:49<16:04, 10.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [02:00<15:50, 10.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:10<15:35, 10.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:21<15:21, 10.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:31<15:09, 10.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:42<14:56, 10.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:52<14:44, 10.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:03<14:33, 10.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:13<14:22, 10.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:24<14:10, 10.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:34<13:58, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:45<13:47, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:55<13:35, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:05<13:24, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:16<13:13, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:26<13:01, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:37<12:50, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:47<12:39, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:57<12:29, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:08<12:18, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:18<12:07, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:29<11:56, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:39<11:45, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:49<11:35, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [06:00<11:24, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:10<11:14, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:20<11:03, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:31<10:52, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:41<10:42, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:51<10:31, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [07:02<10:21, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:12<10:10, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:22<09:59, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:33<09:49, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:43<09:39, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:53<09:28, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [08:04<09:17, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:14<09:07, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:24<08:56, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:35<08:46, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:45<08:35, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [08:55<08:25, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:06<08:14, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:16<08:04, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:26<07:53, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:36<07:43, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:47<07:32, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [09:57<07:22, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:07<07:11, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:18<07:01, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:28<06:51, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:38<06:40, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:48<06:30, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [10:59<06:19, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:09<06:09, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:19<05:58, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:29<05:48, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:40<05:38, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:50<05:27, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [12:00<05:17, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:10<05:07, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:21<04:56, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:31<04:46, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:41<04:35, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:51<04:25, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [13:01<04:15, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:12<04:04, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:22<03:54, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:32<03:44, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:42<03:34, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [13:52<03:23, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [14:02<03:13, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [14:13<03:03, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:23<02:53, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:33<02:42, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:43<02:32, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [14:53<02:22, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [15:04<02:12, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [15:14<02:01, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:24<01:51, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:34<01:41, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:44<01:31, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [15:54<01:21, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [16:04<01:11, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [16:15<01:00, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:25<00:50, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:35<00:40, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:45<00:30, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [16:55<00:20, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [17:05<00:10, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [17:15<00:00, 10.12s/it]100%|██████████| 100/100 [17:15<00:00, 10.36s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-01-15:01:30:53,951 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-01-15:01:30:53,951 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-01-15:01:30:53,951 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-01-15:01:30:54,290 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-01-15:01:30:58,313 INFO     [__main__.py:132] Verbosity set to INFO
2025-01-15:01:31:08,002 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-01-15:01:31:08,004 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-01-15:01:31:08,011 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-01-15:01:31:08,232 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:01,  5.43it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:00<00:00,  7.15it/s]Loading checkpoint shards:  38%|███▊      | 3/8 [00:00<00:00,  8.01it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:00<00:00,  8.03it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:00<00:00,  8.26it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:00<00:00,  8.66it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:00<00:00,  8.94it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  8.98it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  8.34it/s]
2025-01-15:01:31:28,889 INFO     [task.py:355] Building contexts for task on rank 0...
2025-01-15:01:31:28,907 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:43, 12.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<19:03, 11.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:21, 11.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:45<17:55, 11.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:56<17:32, 11.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:07<17:13, 11.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:18<16:56, 10.93s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:28<16:40, 10.88s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:39<16:25, 10.83s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:50<16:09, 10.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [02:00<15:55, 10.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:11<15:41, 10.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:22<15:27, 10.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:32<15:14, 10.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:43<15:02, 10.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:53<14:50, 10.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:04<14:38, 10.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:14<14:27, 10.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:25<14:16, 10.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:35<14:04, 10.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:46<13:52, 10.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:56<13:40, 10.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:07<13:29, 10.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:17<13:18, 10.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:28<13:06, 10.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:38<12:55, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:49<12:44, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:59<12:33, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:10<12:22, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:20<12:11, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:31<12:01, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:41<11:50, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:51<11:39, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [06:02<11:29, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:12<11:18, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:23<11:07, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:33<10:57, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:44<10:46, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:54<10:35, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [07:04<10:24, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:15<10:14, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:25<10:03, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:36<09:53, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:46<09:42, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:56<09:31, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [08:07<09:21, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:17<09:10, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:27<09:00, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:38<08:49, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:48<08:39, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [08:59<08:28, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:09<08:17, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:19<08:07, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:30<07:56, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:40<07:46, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:50<07:35, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [10:01<07:25, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:11<07:14, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:21<07:04, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:32<06:53, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:42<06:43, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:52<06:32, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [11:03<06:22, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:13<06:11, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:23<06:01, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:34<05:50, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:44<05:40, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:54<05:29, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [12:04<05:19, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:15<05:09, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:25<04:58, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:35<04:48, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:46<04:37, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:56<04:27, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [13:06<04:16, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:16<04:06, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:27<03:56, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:37<03:45, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:47<03:35, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [13:57<03:25, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [14:08<03:14, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [14:18<03:04, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:28<02:54, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:38<02:43, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:49<02:33, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [14:59<02:23, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [15:09<02:13, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [15:19<02:02, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:30<01:52, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:40<01:42, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:50<01:32, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [16:00<01:21, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [16:10<01:11, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [16:21<01:01, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:31<00:51, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:41<00:40, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:51<00:30, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [17:01<00:20, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [17:12<00:10, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [17:22<00:00, 10.19s/it]100%|██████████| 100/100 [17:22<00:00, 10.42s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-01-15:01:50:37,804 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-01-15:01:50:37,804 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-01-15:01:50:37,804 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-01-15:01:50:38,169 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-01-15:01:50:42,453 INFO     [__main__.py:132] Verbosity set to INFO
2025-01-15:01:50:52,564 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-01-15:01:50:52,566 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-01-15:01:50:52,574 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-01-15:01:50:53,389 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:01,  5.89it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:00<00:00,  6.77it/s]Loading checkpoint shards:  38%|███▊      | 3/8 [00:00<00:00,  7.77it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:00<00:00,  8.39it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:00<00:00,  8.77it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:00<00:00,  9.04it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:00<00:00,  9.21it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  8.66it/s]
2025-01-15:01:51:14,337 INFO     [task.py:355] Building contexts for task on rank 0...
2025-01-15:01:51:14,359 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:49, 12.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<19:06, 11.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:23, 11.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:45<17:57, 11.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:56<17:33, 11.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:07<17:14, 11.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:18<16:57, 10.94s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:28<16:41, 10.89s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:39<16:26, 10.84s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:50<16:10, 10.79s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [02:01<15:56, 10.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:11<15:42, 10.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:22<15:28, 10.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:32<15:15, 10.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:43<15:03, 10.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:53<14:51, 10.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:04<14:39, 10.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:15<14:28, 10.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:25<14:17, 10.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:36<14:04, 10.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:46<13:53, 10.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:57<13:41, 10.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:07<13:30, 10.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:18<13:18, 10.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:28<13:07, 10.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:39<12:56, 10.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:49<12:45, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [05:00<12:34, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:10<12:23, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:20<12:12, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:31<12:01, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:41<11:50, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:52<11:40, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [06:02<11:29, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:13<11:19, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:23<11:08, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:34<10:57, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:44<10:46, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:54<10:36, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [07:05<10:25, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:15<10:14, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:26<10:04, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:36<09:53, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:46<09:43, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:57<09:32, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [08:07<09:21, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:18<09:11, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:28<09:00, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:38<08:50, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:49<08:39, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [08:59<08:28, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:09<08:18, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:20<08:07, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:30<07:57, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:41<07:46, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:51<07:36, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [10:01<07:25, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:12<07:15, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:22<07:04, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:32<06:53, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:43<06:43, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:53<06:32, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [11:03<06:22, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:14<06:11, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:24<06:01, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:34<05:51, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:45<05:40, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:55<05:30, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [12:05<05:19, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:16<05:09, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:26<04:58, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:36<04:48, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:46<04:38, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:57<04:27, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [13:07<04:17, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:17<04:06, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:27<03:56, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:38<03:46, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:48<03:35, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [13:58<03:25, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [14:09<03:15, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [14:19<03:04, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:29<02:54, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:39<02:44, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:50<02:33, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [15:00<02:23, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [15:10<02:13, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [15:20<02:02, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:30<01:52, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:41<01:42, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:51<01:32, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [16:01<01:21, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [16:11<01:11, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [16:22<01:01, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:32<00:51, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:42<00:40, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:52<00:30, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [17:02<00:20, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [17:13<00:10, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [17:23<00:00, 10.19s/it]100%|██████████| 100/100 [17:23<00:00, 10.43s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-01-15:02:09:13,582 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-01-15:02:09:13,582 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-01-15:02:09:13,582 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-01-15:02:09:13,941 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-01-15:02:09:18,139 INFO     [__main__.py:132] Verbosity set to INFO
2025-01-15:02:09:28,134 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-01-15:02:09:28,136 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-01-15:02:09:28,144 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-01-15:02:09:28,361 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:01,  5.43it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:00<00:00,  7.08it/s]Loading checkpoint shards:  38%|███▊      | 3/8 [00:00<00:00,  7.93it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:00<00:00,  7.96it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:00<00:00,  8.22it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:00<00:00,  8.65it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:00<00:00,  8.92it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  8.85it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  8.27it/s]
2025-01-15:02:09:49,268 INFO     [task.py:355] Building contexts for task on rank 0...
2025-01-15:02:09:49,287 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:48, 12.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<19:07, 11.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:25, 11.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:45<17:59, 11.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:56<17:35, 11.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:07<17:17, 11.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:18<16:59, 10.96s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:29<16:43, 10.91s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:39<16:28, 10.86s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:50<16:12, 10.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [02:01<15:58, 10.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:11<15:44, 10.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:22<15:30, 10.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:33<15:17, 10.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:43<15:05, 10.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:54<14:53, 10.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:04<14:41, 10.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:15<14:30, 10.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:26<14:18, 10.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:36<14:06, 10.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:47<13:55, 10.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:57<13:43, 10.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:08<13:31, 10.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:18<13:20, 10.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:29<13:09, 10.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:39<12:58, 10.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:50<12:47, 10.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [05:00<12:36, 10.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:11<12:25, 10.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:21<12:14, 10.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:32<12:03, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:42<11:52, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:53<11:41, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [06:03<11:31, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:14<11:20, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:24<11:10, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:34<10:59, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:45<10:48, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:55<10:37, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [07:06<10:26, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:16<10:16, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:27<10:05, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:37<09:55, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:47<09:44, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:58<09:33, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [08:08<09:23, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:19<09:12, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:29<09:01, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:40<08:51, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:50<08:40, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [09:00<08:30, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:11<08:19, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:21<08:08, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:32<07:58, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:42<07:47, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:52<07:37, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [10:03<07:26, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:13<07:16, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:23<07:05, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:34<06:55, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:44<06:44, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:55<06:33, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [11:05<06:23, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:15<06:12, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:26<06:02, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:36<05:51, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:46<05:41, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:57<05:31, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [12:07<05:20, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:17<05:10, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:28<04:59, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:38<04:49, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:48<04:38, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:59<04:28, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [13:09<04:17, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:19<04:07, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:29<03:57, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:40<03:46, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:50<03:36, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [14:00<03:25, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [14:11<03:15, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [14:21<03:05, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:31<02:54, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:41<02:44, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:52<02:34, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [15:02<02:23, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [15:12<02:13, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [15:22<02:03, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:33<01:52, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:43<01:42, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:53<01:32, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [16:03<01:22, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [16:14<01:11, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [16:24<01:01, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:34<00:51, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:44<00:40, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:55<00:30, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [17:05<00:20, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [17:15<00:10, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [17:25<00:00, 10.22s/it]100%|██████████| 100/100 [17:25<00:00, 10.46s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-01-15:02:27:50,921 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-01-15:02:27:50,921 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-01-15:02:27:50,921 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-01-15:02:27:51,268 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-01-15:02:27:55,364 INFO     [__main__.py:132] Verbosity set to INFO
2025-01-15:02:28:05,172 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-01-15:02:28:05,174 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-01-15:02:28:05,183 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-01-15:02:28:05,406 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:01,  5.53it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:00<00:00,  6.96it/s]Loading checkpoint shards:  38%|███▊      | 3/8 [00:00<00:00,  7.79it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:00<00:00,  8.27it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:00<00:00,  7.93it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:00<00:00,  8.35it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:00<00:00,  8.65it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  8.27it/s]
2025-01-15:02:28:26,069 INFO     [task.py:355] Building contexts for task on rank 0...
2025-01-15:02:28:26,087 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:50, 12.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<19:08, 11.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:26, 11.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:45<17:59, 11.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:56<17:36, 11.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:07<17:17, 11.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:18<16:59, 10.97s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:29<16:44, 10.92s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:39<16:29, 10.87s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:50<16:13, 10.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [02:01<15:59, 10.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:11<15:44, 10.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:22<15:31, 10.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:33<15:18, 10.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:43<15:05, 10.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:54<14:53, 10.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:04<14:42, 10.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:15<14:30, 10.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:26<14:19, 10.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:36<14:07, 10.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:47<13:55, 10.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:57<13:41, 10.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:08<13:29, 10.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:18<13:17, 10.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:29<13:05, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:39<12:54, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:49<12:42, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [05:00<12:31, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:10<12:20, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:21<12:09, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:31<11:58, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:41<11:48, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:52<11:37, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [06:02<11:26, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:13<11:16, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:23<11:05, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:33<10:54, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:44<10:44, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:54<10:33, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [07:05<10:22, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:15<10:12, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:25<10:01, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:36<09:51, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:46<09:40, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:56<09:30, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [08:07<09:19, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:17<09:08, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:27<08:58, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:38<08:47, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:48<08:37, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [08:58<08:26, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:09<08:16, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:19<08:05, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:29<07:55, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:40<07:44, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:50<07:34, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [10:00<07:23, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:11<07:13, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:21<07:02, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:31<06:52, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:42<06:41, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:52<06:31, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [11:02<06:20, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:12<06:10, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:23<05:59, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:33<05:49, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:43<05:39, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:53<05:28, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [12:04<05:18, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:14<05:08, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:24<04:57, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:35<04:47, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:45<04:36, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:55<04:26, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [13:05<04:16, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:15<04:05, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:26<03:55, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:36<03:45, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:46<03:34, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [13:56<03:24, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [14:07<03:14, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [14:17<03:03, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:27<02:53, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:37<02:43, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:47<02:33, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [14:58<02:22, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [15:08<02:12, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [15:18<02:02, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:28<01:52, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:38<01:41, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:49<01:31, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [15:59<01:21, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [16:09<01:11, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [16:19<01:01, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:29<00:50, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:39<00:40, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:50<00:30, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [17:00<00:20, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [17:10<00:10, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [17:20<00:00, 10.15s/it]100%|██████████| 100/100 [17:20<00:00, 10.41s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-01-15:02:46:22,372 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-01-15:02:46:22,373 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-01-15:02:46:22,373 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-01-15:02:46:22,697 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-01-15:02:46:26,769 INFO     [__main__.py:132] Verbosity set to INFO
2025-01-15:02:46:36,526 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-01-15:02:46:36,528 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-01-15:02:46:36,534 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-01-15:02:46:36,760 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:01,  5.42it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:00<00:00,  7.13it/s]Loading checkpoint shards:  38%|███▊      | 3/8 [00:00<00:00,  8.01it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:00<00:00,  8.53it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:00<00:00,  8.16it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:00<00:00,  8.60it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:00<00:00,  8.90it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  8.48it/s]
2025-01-15:02:46:57,530 INFO     [task.py:355] Building contexts for task on rank 0...
2025-01-15:02:46:57,549 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:43, 12.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<19:04, 11.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:22, 11.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:45<17:56, 11.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:56<17:33, 11.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:07<17:14, 11.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:18<16:57, 10.94s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:28<16:41, 10.89s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:39<16:26, 10.84s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:50<16:10, 10.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [02:00<15:56, 10.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:11<15:42, 10.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:22<15:28, 10.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:32<15:15, 10.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:43<15:03, 10.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:53<14:51, 10.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:04<14:39, 10.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:15<14:28, 10.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:25<14:17, 10.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:36<14:04, 10.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:46<13:53, 10.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:57<13:41, 10.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:07<13:29, 10.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:18<13:18, 10.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:28<13:07, 10.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:39<12:56, 10.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:49<12:45, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:59<12:34, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:10<12:23, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:20<12:12, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:31<12:01, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:41<11:50, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:52<11:40, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [06:02<11:29, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:13<11:19, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:23<11:08, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:33<10:57, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:44<10:46, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:54<10:36, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [07:05<10:25, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:15<10:14, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:26<10:04, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:36<09:53, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:46<09:43, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:57<09:32, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [08:07<09:21, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:18<09:11, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:28<09:00, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:38<08:50, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:49<08:39, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [08:59<08:28, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:09<08:18, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:20<08:07, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:30<07:57, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:41<07:46, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:51<07:35, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [10:01<07:25, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:12<07:15, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:22<07:04, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:32<06:53, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:43<06:43, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:53<06:32, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [11:03<06:22, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:14<06:11, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:24<06:01, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:34<05:50, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:44<05:40, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:55<05:30, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [12:05<05:19, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:15<05:09, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:26<04:58, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:36<04:48, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:46<04:37, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:57<04:27, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [13:07<04:17, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:17<04:06, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:27<03:56, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:38<03:46, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:48<03:35, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [13:58<03:25, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [14:08<03:15, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [14:19<03:04, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:29<02:54, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:39<02:44, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:49<02:33, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [15:00<02:23, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [15:10<02:13, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [15:20<02:02, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:30<01:52, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:41<01:42, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:51<01:32, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [16:01<01:21, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [16:11<01:11, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [16:21<01:01, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:32<00:51, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:42<00:40, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:52<00:30, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [17:02<00:20, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [17:12<00:10, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [17:23<00:00, 10.19s/it]100%|██████████| 100/100 [17:23<00:00, 10.43s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-01-15:03:04:56,890 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-01-15:03:04:56,890 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-01-15:03:04:56,890 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-01-15:03:04:57,219 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-01-15:03:05:01,241 INFO     [__main__.py:132] Verbosity set to INFO
2025-01-15:03:05:11,046 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-01-15:03:05:11,048 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-01-15:03:05:11,054 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-01-15:03:05:11,274 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:01,  5.63it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:00<00:00,  7.32it/s]Loading checkpoint shards:  38%|███▊      | 3/8 [00:00<00:00,  8.14it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:00<00:00,  7.97it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:00<00:00,  8.46it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:00<00:00,  8.80it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:00<00:00,  9.04it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  8.56it/s]
2025-01-15:03:05:32,542 INFO     [task.py:355] Building contexts for task on rank 0...
2025-01-15:03:05:32,560 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:39, 12.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<18:57, 11.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:15, 11.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:45<17:49, 11.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:56<17:26, 11.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:06<17:07, 10.93s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:17<16:49, 10.86s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:28<16:34, 10.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:38<16:19, 10.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:49<16:03, 10.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [02:00<15:49, 10.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:10<15:35, 10.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:21<15:21, 10.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:31<15:09, 10.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:42<14:56, 10.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:52<14:44, 10.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:03<14:33, 10.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:13<14:22, 10.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:24<14:10, 10.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:34<13:58, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:45<13:47, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:55<13:35, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:05<13:24, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:16<13:12, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:26<13:01, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:37<12:50, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:47<12:39, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:57<12:28, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:08<12:18, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:18<12:07, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:28<11:56, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:39<11:45, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:49<11:35, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [06:00<11:24, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:10<11:14, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:20<11:03, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:31<10:52, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:41<10:42, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:51<10:31, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [07:02<10:20, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:12<10:10, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:22<09:59, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:33<09:49, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:43<09:38, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:53<09:28, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [08:04<09:17, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:14<09:07, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:24<08:56, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:35<08:46, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:45<08:35, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [08:55<08:25, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:05<08:14, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:16<08:04, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:26<07:53, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:36<07:43, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:47<07:32, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [09:57<07:22, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:07<07:11, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:17<07:01, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:28<06:51, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:38<06:40, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:48<06:30, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [10:58<06:19, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:09<06:09, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:19<05:58, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:29<05:48, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:39<05:38, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:50<05:27, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [12:00<05:17, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:10<05:07, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:20<04:56, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:31<04:46, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:41<04:35, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:51<04:25, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [13:01<04:15, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:11<04:04, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:22<03:54, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:32<03:44, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:42<03:34, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [13:52<03:23, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [14:02<03:13, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [14:13<03:03, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:23<02:53, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:33<02:42, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:43<02:32, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [14:53<02:22, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [15:03<02:12, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [15:13<02:01, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:24<01:51, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:34<01:41, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:44<01:31, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [15:54<01:21, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [16:04<01:11, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [16:14<01:00, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:25<00:50, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:35<00:40, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:45<00:30, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [16:55<00:20, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [17:05<00:10, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [17:15<00:00, 10.12s/it]100%|██████████| 100/100 [17:15<00:00, 10.36s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-01-15:03:24:34,529 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-01-15:03:24:34,529 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-01-15:03:24:34,529 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-01-15:03:24:34,861 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-01-15:03:24:38,856 INFO     [__main__.py:132] Verbosity set to INFO
2025-01-15:03:24:48,671 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-01-15:03:24:48,673 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-01-15:03:24:48,680 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-01-15:03:24:48,921 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:01,  5.64it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:00<00:00,  6.47it/s]Loading checkpoint shards:  38%|███▊      | 3/8 [00:00<00:00,  7.48it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:00<00:00,  8.08it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:00<00:00,  8.46it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:00<00:00,  8.73it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:00<00:00,  8.91it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  9.21it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  8.35it/s]
2025-01-15:03:25:10,913 INFO     [task.py:355] Building contexts for task on rank 0...
2025-01-15:03:25:10,931 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:57, 12.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<19:11, 11.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:28, 11.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:45<18:01, 11.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:56<17:37, 11.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:07<17:18, 11.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:18<17:00, 10.97s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:29<16:44, 10.92s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:40<16:29, 10.87s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:50<16:13, 10.82s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [02:01<15:59, 10.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:12<15:45, 10.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:22<15:31, 10.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:33<15:18, 10.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:43<15:06, 10.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:54<14:53, 10.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:05<14:42, 10.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:15<14:30, 10.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:26<14:19, 10.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:36<14:07, 10.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:47<13:55, 10.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:57<13:43, 10.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:08<13:32, 10.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:18<13:21, 10.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:29<13:09, 10.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:39<12:58, 10.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:50<12:47, 10.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [05:00<12:36, 10.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:11<12:25, 10.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:21<12:14, 10.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:32<12:03, 10.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:42<11:53, 10.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:53<11:42, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [06:03<11:31, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:14<11:21, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:24<11:10, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:35<10:59, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:45<10:48, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:56<10:38, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [07:06<10:27, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:17<10:16, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:27<10:06, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:37<09:55, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:48<09:45, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:58<09:34, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [08:09<09:23, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:19<09:13, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:30<09:02, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:40<08:51, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:50<08:41, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [09:01<08:30, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:11<08:19, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:22<08:09, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:32<07:58, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:42<07:48, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:53<07:37, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [10:03<07:26, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:14<07:16, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:24<07:05, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:34<06:55, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:45<06:44, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:55<06:34, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [11:05<06:23, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:16<06:13, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:26<06:02, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:36<05:52, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:47<05:41, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:57<05:31, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [12:08<05:20, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:18<05:10, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:28<04:59, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:39<04:49, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:49<04:38, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:59<04:28, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [13:09<04:17, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:20<04:07, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:30<03:57, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:40<03:46, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:51<03:36, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [14:01<03:26, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [14:11<03:15, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [14:22<03:05, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:32<02:54, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:42<02:44, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:52<02:34, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [15:03<02:23, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [15:13<02:13, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [15:23<02:03, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:33<01:52, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:44<01:42, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:54<01:32, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [16:04<01:22, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [16:14<01:11, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [16:25<01:01, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:35<00:51, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:45<00:41, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:55<00:30, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [17:06<00:20, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [17:16<00:10, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [17:26<00:00, 10.23s/it]100%|██████████| 100/100 [17:26<00:00, 10.47s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-01-15:03:43:14,065 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-01-15:03:43:14,065 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-01-15:03:43:14,065 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-01-15:03:43:14,411 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-01-15:03:43:18,887 INFO     [__main__.py:132] Verbosity set to INFO
2025-01-15:03:43:29,154 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-01-15:03:43:29,156 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-01-15:03:43:29,164 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-01-15:03:43:29,392 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:01,  5.50it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:00<00:00,  7.17it/s]Loading checkpoint shards:  38%|███▊      | 3/8 [00:00<00:00,  8.00it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:00<00:00,  7.89it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:00<00:00,  8.40it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:00<00:00,  8.76it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:00<00:00,  9.01it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  8.49it/s]
2025-01-15:03:43:50,750 INFO     [task.py:355] Building contexts for task on rank 0...
2025-01-15:03:43:50,769 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:50, 12.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<19:08, 11.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:25, 11.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:45<17:59, 11.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:56<17:35, 11.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:07<17:17, 11.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:18<16:59, 10.96s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:29<16:43, 10.91s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:39<16:28, 10.86s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:50<16:12, 10.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [02:01<15:58, 10.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:11<15:44, 10.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:22<15:30, 10.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:33<15:17, 10.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:43<15:05, 10.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:54<14:53, 10.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:04<14:41, 10.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:15<14:30, 10.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:26<14:18, 10.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:36<14:06, 10.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:47<13:55, 10.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:57<13:43, 10.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:08<13:31, 10.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:18<13:20, 10.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:29<13:09, 10.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:39<12:58, 10.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:50<12:47, 10.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [05:00<12:36, 10.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:11<12:25, 10.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:21<12:14, 10.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:32<12:03, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:42<11:52, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:53<11:41, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [06:03<11:31, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:13<11:20, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:24<11:09, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:34<10:59, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:45<10:48, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:55<10:37, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [07:06<10:26, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:16<10:16, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:27<10:05, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:37<09:55, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:47<09:44, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:58<09:33, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [08:08<09:23, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:19<09:12, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:29<09:01, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:40<08:51, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:50<08:40, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [09:00<08:30, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:11<08:19, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:21<08:08, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:32<07:58, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:42<07:47, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:52<07:37, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [10:03<07:26, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:13<07:16, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:23<07:05, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:34<06:54, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:44<06:44, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:54<06:33, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [11:05<06:23, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:15<06:12, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:26<06:02, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:36<05:51, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:46<05:41, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:57<05:30, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [12:07<05:20, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:17<05:10, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:28<04:59, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:38<04:49, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:48<04:38, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:58<04:28, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [13:09<04:17, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:19<04:07, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:29<03:57, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:40<03:46, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:50<03:36, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [14:00<03:25, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [14:11<03:15, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [14:21<03:05, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:31<02:54, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:41<02:44, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:52<02:34, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [15:02<02:23, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [15:12<02:13, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [15:22<02:03, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:33<01:52, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:43<01:42, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:53<01:32, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [16:03<01:22, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [16:14<01:11, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [16:24<01:01, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:34<00:51, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:44<00:40, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:55<00:30, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [17:05<00:20, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [17:15<00:10, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [17:25<00:00, 10.22s/it]100%|██████████| 100/100 [17:25<00:00, 10.46s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-01-15:04:01:52,665 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-01-15:04:01:52,665 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-01-15:04:01:52,665 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-01-15:04:01:53,027 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-01-15:04:01:57,389 INFO     [__main__.py:132] Verbosity set to INFO
2025-01-15:04:02:08,003 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-01-15:04:02:08,005 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-01-15:04:02:08,013 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-01-15:04:02:08,232 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:01,  5.42it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:00<00:00,  6.76it/s]Loading checkpoint shards:  38%|███▊      | 3/8 [00:00<00:00,  7.75it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:00<00:00,  8.37it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:00<00:00,  8.10it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:00<00:00,  8.53it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:00<00:00,  8.86it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  8.38it/s]
2025-01-15:04:02:30,002 INFO     [task.py:355] Building contexts for task on rank 0...
2025-01-15:04:02:30,020 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:52, 12.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<19:04, 11.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:20, 11.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:45<17:53, 11.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:56<17:29, 11.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:07<17:10, 10.96s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:17<16:52, 10.89s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:28<16:37, 10.84s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:39<16:21, 10.79s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:49<16:06, 10.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [02:00<15:52, 10.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:11<15:37, 10.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:21<15:23, 10.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:32<15:10, 10.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:42<14:58, 10.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:53<14:46, 10.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:03<14:35, 10.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:14<14:22, 10.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:24<14:09, 10.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:34<13:56, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:45<13:44, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:55<13:32, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:06<13:20, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:16<13:09, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:26<12:58, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:37<12:47, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:47<12:36, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:57<12:25, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:08<12:14, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:18<12:03, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:28<11:52, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:39<11:42, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:49<11:31, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [05:59<11:21, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:09<11:10, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:20<11:00, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:30<10:49, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:40<10:38, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:51<10:28, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [07:01<10:17, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:11<10:07, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:22<09:56, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:32<09:46, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:42<09:36, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:52<09:25, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [08:03<09:14, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:13<09:04, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:23<08:54, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:33<08:43, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:44<08:33, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [08:54<08:22, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:04<08:12, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:14<08:01, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:25<07:51, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:35<07:40, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:45<07:30, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [09:55<07:20, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:06<07:09, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:16<06:59, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:26<06:48, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:36<06:38, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:46<06:27, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [10:57<06:17, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:07<06:07, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:17<05:56, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:27<05:46, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:37<05:36, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:48<05:26, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [11:58<05:15, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:08<05:05, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:18<04:55, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:28<04:44, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:38<04:34, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:49<04:24, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [12:59<04:14, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:09<04:03, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:19<03:53, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:29<03:43, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:39<03:33, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [13:49<03:22, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [14:00<03:12, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [14:10<03:02, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:20<02:52, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:30<02:42, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:40<02:31, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [14:50<02:21, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [15:00<02:11, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [15:10<02:01, 10.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:20<01:51, 10.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:31<01:41, 10.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:41<01:30, 10.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [15:51<01:20, 10.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [16:01<01:10, 10.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [16:11<01:00, 10.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:21<00:50, 10.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:31<00:40, 10.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:41<00:30, 10.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [16:51<00:20, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [17:01<00:10, 10.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [17:11<00:00, 10.07s/it]100%|██████████| 100/100 [17:11<00:00, 10.32s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-01-15:04:20:17,906 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-01-15:04:20:17,906 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-01-15:04:20:17,906 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-01-15:04:20:18,244 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-01-15:04:20:22,522 INFO     [__main__.py:132] Verbosity set to INFO
2025-01-15:04:20:32,857 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-01-15:04:20:32,859 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-01-15:04:20:32,868 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-01-15:04:20:33,079 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:01,  5.88it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:00<00:00,  7.53it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:00<00:00,  8.65it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:00<00:00,  8.83it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:00<00:00,  9.41it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  9.03it/s]
2025-01-15:04:20:53,481 INFO     [task.py:355] Building contexts for task on rank 0...
2025-01-15:04:20:53,500 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:49, 12.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<19:07, 11.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:25, 11.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:45<17:59, 11.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:56<17:35, 11.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:07<17:16, 11.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:18<16:59, 10.96s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:29<16:43, 10.91s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:39<16:28, 10.86s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:50<16:12, 10.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [02:01<15:58, 10.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:11<15:43, 10.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:22<15:30, 10.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:33<15:17, 10.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:43<15:04, 10.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:54<14:52, 10.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:04<14:41, 10.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:15<14:29, 10.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:25<14:18, 10.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:36<14:06, 10.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:47<13:54, 10.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:57<13:42, 10.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:08<13:31, 10.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:18<13:20, 10.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:29<13:08, 10.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:39<12:57, 10.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:50<12:46, 10.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [05:00<12:35, 10.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:11<12:24, 10.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:21<12:13, 10.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:31<12:02, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:42<11:52, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:52<11:41, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [06:03<11:30, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:13<11:20, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:24<11:09, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:34<10:58, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:45<10:48, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:55<10:37, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [07:06<10:26, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:16<10:16, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:26<10:05, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:37<09:54, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:47<09:44, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:58<09:33, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [08:08<09:22, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:18<09:12, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:29<09:01, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:39<08:51, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:50<08:40, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [09:00<08:29, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:10<08:19, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:21<08:08, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:31<07:57, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:42<07:47, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:52<07:36, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [10:02<07:26, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:13<07:15, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:23<07:05, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:33<06:54, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:44<06:44, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:54<06:33, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [11:05<06:23, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:15<06:12, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:25<06:02, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:36<05:51, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:46<05:41, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:56<05:30, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [12:07<05:20, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:17<05:09, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:27<04:59, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:37<04:49, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:48<04:38, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:58<04:28, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [13:08<04:17, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:19<04:07, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:29<03:56, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:39<03:46, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:50<03:36, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [14:00<03:25, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [14:10<03:15, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [14:20<03:05, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:31<02:54, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:41<02:44, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:51<02:34, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [15:01<02:23, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [15:12<02:13, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [15:22<02:03, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:32<01:52, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:42<01:42, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:53<01:32, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [16:03<01:22, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [16:13<01:11, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [16:23<01:01, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:34<00:51, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:44<00:40, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:54<00:30, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [17:04<00:20, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [17:14<00:10, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [17:25<00:00, 10.21s/it]100%|██████████| 100/100 [17:25<00:00, 10.45s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-01-15:04:38:55,058 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-01-15:04:38:55,059 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-01-15:04:38:55,059 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-01-15:04:38:55,437 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-01-15:04:38:59,833 INFO     [__main__.py:132] Verbosity set to INFO
2025-01-15:04:39:10,407 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-01-15:04:39:10,409 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-01-15:04:39:10,418 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-01-15:04:39:10,639 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:01,  5.63it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:00<00:00,  6.72it/s]Loading checkpoint shards:  38%|███▊      | 3/8 [00:00<00:00,  7.61it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:00<00:00,  8.11it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:00<00:00,  8.03it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:00<00:00,  8.21it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:00<00:00,  8.47it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  8.15it/s]
2025-01-15:04:39:31,612 INFO     [task.py:355] Building contexts for task on rank 0...
2025-01-15:04:39:31,631 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:52, 12.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<19:09, 11.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:26, 11.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:45<17:59, 11.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:56<17:36, 11.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:07<17:17, 11.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:18<16:59, 10.96s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:29<16:43, 10.91s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:39<16:28, 10.86s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:50<16:12, 10.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [02:01<15:58, 10.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:11<15:44, 10.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:22<15:30, 10.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:33<15:17, 10.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:43<15:05, 10.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:54<14:53, 10.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:04<14:41, 10.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:15<14:30, 10.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:26<14:18, 10.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:36<14:06, 10.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:47<13:54, 10.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:57<13:42, 10.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:08<13:31, 10.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:18<13:20, 10.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:29<13:09, 10.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:39<12:58, 10.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:50<12:46, 10.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [05:00<12:36, 10.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:11<12:25, 10.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:21<12:14, 10.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:32<12:03, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:42<11:52, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:53<11:41, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [06:03<11:31, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:13<11:20, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:24<11:09, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:34<10:59, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:45<10:48, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:55<10:37, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [07:06<10:26, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:16<10:16, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:27<10:05, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:37<09:55, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:47<09:44, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:58<09:33, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [08:08<09:23, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:19<09:12, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:29<09:01, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:39<08:51, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:50<08:40, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [09:00<08:30, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:11<08:19, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:21<08:08, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:31<07:58, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:42<07:47, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:52<07:37, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [10:03<07:26, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:13<07:15, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:23<07:05, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:34<06:54, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:44<06:44, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:54<06:33, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [11:05<06:23, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:15<06:12, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:25<06:02, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:36<05:51, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:46<05:41, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:56<05:30, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [12:07<05:20, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:17<05:10, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:27<04:59, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:38<04:49, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:48<04:38, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:58<04:28, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [13:09<04:17, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:19<04:07, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:29<03:56, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:40<03:46, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:50<03:36, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [14:00<03:25, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [14:10<03:15, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [14:21<03:05, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:31<02:54, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:41<02:44, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:52<02:34, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [15:02<02:23, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [15:12<02:13, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [15:22<02:03, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:33<01:52, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:43<01:42, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:53<01:32, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [16:03<01:22, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [16:14<01:11, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [16:24<01:01, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:34<00:51, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:44<00:40, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:54<00:30, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [17:05<00:20, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [17:15<00:10, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [17:25<00:00, 10.22s/it]100%|██████████| 100/100 [17:25<00:00, 10.46s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-01-15:04:58:43,400 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-01-15:04:58:43,400 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-01-15:04:58:43,400 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-01-15:04:58:43,748 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-01-15:04:58:48,098 INFO     [__main__.py:132] Verbosity set to INFO
2025-01-15:04:58:58,520 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-01-15:04:58:58,522 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-01-15:04:58:58,530 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-01-15:04:58:58,751 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:01,  5.79it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:00<00:00,  6.55it/s]Loading checkpoint shards:  38%|███▊      | 3/8 [00:00<00:00,  7.48it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:00<00:00,  8.08it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:00<00:00,  8.48it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:00<00:00,  8.74it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:00<00:00,  8.91it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  8.40it/s]
2025-01-15:04:59:21,062 INFO     [task.py:355] Building contexts for task on rank 0...
2025-01-15:04:59:21,080 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:59, 12.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<19:06, 11.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:20, 11.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:45<17:52, 11.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:56<17:28, 11.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:07<17:09, 10.95s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:17<16:51, 10.88s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:28<16:35, 10.82s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:39<16:20, 10.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:49<16:04, 10.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [02:00<15:50, 10.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:10<15:36, 10.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:21<15:22, 10.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:32<15:09, 10.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:42<14:57, 10.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:53<14:45, 10.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:03<14:34, 10.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:14<14:22, 10.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:24<14:11, 10.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:34<13:59, 10.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:45<13:47, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:55<13:35, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:06<13:24, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:16<13:13, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:27<13:02, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:37<12:51, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:47<12:40, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:58<12:29, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:08<12:18, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:19<12:07, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:29<11:56, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:39<11:46, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:50<11:35, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [06:00<11:25, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:10<11:14, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:21<11:04, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:31<10:53, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:42<10:42, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:52<10:31, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [07:02<10:21, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:13<10:10, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:23<10:00, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:33<09:49, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:44<09:39, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:54<09:28, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [08:04<09:18, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:15<09:07, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:25<08:57, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:35<08:46, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:46<08:36, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [08:56<08:25, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:06<08:15, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:16<08:04, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:27<07:53, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:37<07:43, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:47<07:33, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [09:58<07:22, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:08<07:12, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:18<07:01, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:28<06:51, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:39<06:40, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:49<06:30, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [10:59<06:19, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:09<06:09, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:20<05:59, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:30<05:48, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:40<05:38, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:50<05:28, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [12:01<05:17, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:11<05:07, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:21<04:56, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:31<04:46, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:42<04:36, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:52<04:25, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [13:02<04:15, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:12<04:05, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:22<03:54, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:33<03:44, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:43<03:34, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [13:53<03:24, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [14:03<03:13, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [14:13<03:03, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:24<02:53, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:34<02:42, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:44<02:32, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [14:54<02:22, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [15:04<02:12, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [15:14<02:02, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:25<01:51, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:35<01:41, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:45<01:31, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [15:55<01:21, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [16:05<01:11, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [16:15<01:00, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:26<00:50, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:36<00:40, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:46<00:30, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [16:56<00:20, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [17:06<00:10, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [17:16<00:00, 10.13s/it]100%|██████████| 100/100 [17:16<00:00, 10.37s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-01-15:05:17:13,903 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-01-15:05:17:13,903 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-01-15:05:17:13,903 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-01-15:05:17:14,265 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-01-15:05:17:18,685 INFO     [__main__.py:132] Verbosity set to INFO
2025-01-15:05:17:29,361 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-01-15:05:17:29,362 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-01-15:05:17:29,370 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-01-15:05:17:29,587 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:01,  5.62it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:00<00:00,  6.99it/s]Loading checkpoint shards:  38%|███▊      | 3/8 [00:00<00:00,  7.11it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:00<00:00,  7.79it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:00<00:00,  8.22it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:00<00:00,  8.38it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:00<00:00,  8.62it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  8.94it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  8.16it/s]
2025-01-15:05:17:49,147 INFO     [task.py:355] Building contexts for task on rank 0...
2025-01-15:05:17:49,165 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:57, 12.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<19:11, 11.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:28, 11.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:45<18:01, 11.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:56<17:37, 11.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:07<17:18, 11.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:18<17:00, 10.98s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:29<16:45, 10.93s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:40<16:29, 10.88s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:50<16:14, 10.82s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [02:01<16:00, 10.79s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:12<15:45, 10.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:22<15:31, 10.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:33<15:18, 10.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:43<15:06, 10.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:54<14:54, 10.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:05<14:42, 10.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:15<14:31, 10.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:26<14:19, 10.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:36<14:07, 10.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:47<13:55, 10.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:58<13:44, 10.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:08<13:32, 10.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:19<13:21, 10.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:29<13:10, 10.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:40<12:59, 10.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:50<12:47, 10.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [05:01<12:37, 10.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:11<12:26, 10.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:22<12:15, 10.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:32<12:04, 10.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:43<11:53, 10.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:53<11:42, 10.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [06:03<11:32, 10.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:14<11:21, 10.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:24<11:10, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:35<10:59, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:45<10:49, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:56<10:38, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [07:06<10:27, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:17<10:16, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:27<10:06, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:38<09:55, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:48<09:45, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:58<09:34, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [08:09<09:23, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:19<09:13, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:30<09:02, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:40<08:52, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:51<08:41, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [09:01<08:30, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:11<08:20, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:22<08:09, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:32<07:58, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:43<07:48, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:53<07:37, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [10:03<07:27, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:14<07:16, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:24<07:06, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:35<06:55, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:45<06:44, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:55<06:34, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [11:06<06:23, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:16<06:13, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:26<06:02, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:37<05:52, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:47<05:41, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:57<05:31, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [12:08<05:20, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:18<05:10, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:28<04:59, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:39<04:49, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:49<04:38, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:59<04:28, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [13:10<04:18, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:20<04:07, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:30<03:57, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:41<03:46, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:51<03:36, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [14:01<03:26, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [14:12<03:15, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [14:22<03:05, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:32<02:55, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:42<02:44, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:53<02:34, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [15:03<02:23, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [15:13<02:13, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [15:24<02:03, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:34<01:53, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:44<01:42, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:54<01:32, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [16:05<01:22, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [16:15<01:11, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [16:25<01:01, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:35<00:51, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:46<00:41, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:56<00:30, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [17:06<00:20, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [17:16<00:10, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [17:26<00:00, 10.23s/it]100%|██████████| 100/100 [17:26<00:00, 10.47s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-01-15:05:35:52,282 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-01-15:05:35:52,282 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-01-15:05:35:52,282 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-01-15:05:35:52,639 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-01-15:05:35:56,882 INFO     [__main__.py:132] Verbosity set to INFO
2025-01-15:05:36:07,567 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-01-15:05:36:07,569 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-01-15:05:36:07,577 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-01-15:05:36:07,799 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:01,  6.12it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:00<00:00,  7.03it/s]Loading checkpoint shards:  38%|███▊      | 3/8 [00:00<00:00,  7.66it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:00<00:00,  8.22it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:00<00:00,  8.55it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:00<00:00,  8.79it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:00<00:00,  8.93it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  8.52it/s]
2025-01-15:05:36:29,365 INFO     [task.py:355] Building contexts for task on rank 0...
2025-01-15:05:36:29,384 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:51, 12.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<19:07, 11.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:25, 11.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:45<17:58, 11.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:56<17:34, 11.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:07<17:16, 11.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:18<16:58, 10.95s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:29<16:42, 10.90s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:39<16:27, 10.85s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:50<16:11, 10.79s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [02:01<15:57, 10.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:11<15:42, 10.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:22<15:29, 10.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:32<15:16, 10.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:43<15:03, 10.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:54<14:51, 10.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:04<14:40, 10.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:15<14:28, 10.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:25<14:17, 10.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:36<14:05, 10.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:46<13:53, 10.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:57<13:41, 10.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:07<13:30, 10.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:18<13:19, 10.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:28<13:08, 10.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:39<12:57, 10.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:49<12:45, 10.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [05:00<12:35, 10.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:10<12:24, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:21<12:13, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:31<12:02, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:42<11:51, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:52<11:40, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [06:03<11:30, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:13<11:19, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:23<11:08, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:34<10:58, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:44<10:47, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:55<10:36, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [07:05<10:26, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:16<10:15, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:26<10:04, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:36<09:54, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:47<09:43, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:57<09:32, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [08:08<09:22, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:18<09:11, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:28<09:01, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:39<08:50, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:49<08:40, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [09:00<08:29, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:10<08:18, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:20<08:08, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:31<07:57, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:41<07:47, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:51<07:36, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [10:02<07:25, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:12<07:15, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:23<07:04, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:33<06:54, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:43<06:43, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:54<06:33, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [11:04<06:22, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:14<06:12, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:25<06:01, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:35<05:51, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:45<05:40, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:56<05:30, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [12:06<05:20, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:16<05:09, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:26<04:59, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:37<04:48, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:47<04:38, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:57<04:27, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [13:08<04:17, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:18<04:06, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:28<03:56, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:38<03:46, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:49<03:35, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [13:59<03:25, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [14:09<03:15, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [14:20<03:04, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:30<02:54, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:40<02:44, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:50<02:33, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [15:01<02:23, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [15:11<02:13, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [15:21<02:02, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:31<01:52, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:42<01:42, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:52<01:32, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [16:02<01:21, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [16:12<01:11, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [16:22<01:01, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:33<00:51, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:43<00:40, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:53<00:30, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [17:03<00:20, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [17:14<00:10, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [17:24<00:00, 10.20s/it]100%|██████████| 100/100 [17:24<00:00, 10.44s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-01-15:05:54:29,724 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-01-15:05:54:29,724 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-01-15:05:54:29,724 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-01-15:05:54:30,053 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-01-15:05:54:34,375 INFO     [__main__.py:132] Verbosity set to INFO
2025-01-15:05:54:44,820 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-01-15:05:54:44,822 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-01-15:05:54:44,830 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-01-15:05:54:45,059 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:01,  5.82it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:00<00:00,  6.62it/s]Loading checkpoint shards:  38%|███▊      | 3/8 [00:00<00:00,  7.53it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:00<00:00,  8.09it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:00<00:00,  8.44it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:00<00:00,  8.71it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:00<00:00,  8.88it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  9.17it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  8.37it/s]
2025-01-15:05:55:04,340 INFO     [task.py:355] Building contexts for task on rank 0...
2025-01-15:05:55:04,358 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:50, 12.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<19:08, 11.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:25, 11.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:45<17:59, 11.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:56<17:35, 11.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:07<17:16, 11.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:18<16:59, 10.96s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:29<16:43, 10.91s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:39<16:28, 10.86s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:50<16:12, 10.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [02:01<15:58, 10.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:11<15:43, 10.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:22<15:30, 10.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:33<15:17, 10.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:43<15:04, 10.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:54<14:52, 10.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:04<14:41, 10.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:15<14:29, 10.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:26<14:18, 10.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:36<14:06, 10.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:47<13:54, 10.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:57<13:42, 10.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:08<13:31, 10.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:18<13:20, 10.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:29<13:08, 10.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:39<12:57, 10.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:50<12:46, 10.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [05:00<12:35, 10.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:11<12:24, 10.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:21<12:14, 10.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:31<12:03, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:42<11:52, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:52<11:41, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [06:03<11:31, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:13<11:20, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:24<11:09, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:34<10:58, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:45<10:48, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:55<10:37, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [07:06<10:26, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:16<10:16, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:26<10:05, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:37<09:54, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:47<09:44, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:58<09:33, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [08:08<09:23, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:19<09:12, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:29<09:01, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:39<08:51, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:50<08:40, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [09:00<08:29, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:11<08:19, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:21<08:08, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:31<07:58, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:42<07:47, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:52<07:36, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [10:02<07:26, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:13<07:15, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:23<07:05, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:34<06:54, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:44<06:44, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:54<06:33, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [11:05<06:23, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:15<06:12, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:25<06:02, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:36<05:51, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:46<05:41, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:56<05:30, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [12:07<05:20, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:17<05:10, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:27<04:59, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:38<04:49, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:48<04:38, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:58<04:28, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [13:08<04:17, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:19<04:07, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:29<03:56, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:39<03:46, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:50<03:36, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [14:00<03:25, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [14:10<03:15, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [14:20<03:05, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:31<02:54, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:41<02:44, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:51<02:34, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [15:02<02:23, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [15:12<02:13, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [15:22<02:03, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:32<01:52, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:43<01:42, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:53<01:32, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [16:03<01:22, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [16:13<01:11, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [16:24<01:01, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:34<00:51, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:44<00:40, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:54<00:30, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [17:04<00:20, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [17:15<00:10, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [17:25<00:00, 10.22s/it]100%|██████████| 100/100 [17:25<00:00, 10.45s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-01-15:06:13:05,854 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-01-15:06:13:05,854 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-01-15:06:13:05,854 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-01-15:06:13:06,216 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-01-15:06:13:10,510 INFO     [__main__.py:132] Verbosity set to INFO
2025-01-15:06:13:21,097 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-01-15:06:13:21,099 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-01-15:06:13:21,106 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-01-15:06:13:21,327 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:01,  6.38it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:00<00:00,  7.46it/s]Loading checkpoint shards:  38%|███▊      | 3/8 [00:00<00:00,  8.05it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:00<00:00,  8.65it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:00<00:00,  9.02it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:00<00:00,  9.22it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:00<00:00,  9.36it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  8.92it/s]
2025-01-15:06:13:41,949 INFO     [task.py:355] Building contexts for task on rank 0...
2025-01-15:06:13:41,967 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:46, 12.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<19:05, 11.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:23, 11.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:45<17:56, 11.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:56<17:33, 11.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:07<17:14, 11.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:18<16:57, 10.94s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:28<16:41, 10.89s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:39<16:26, 10.84s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:50<16:10, 10.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [02:00<15:56, 10.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:11<15:42, 10.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:22<15:28, 10.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:32<15:15, 10.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:43<15:03, 10.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:53<14:51, 10.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:04<14:39, 10.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:15<14:28, 10.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:25<14:16, 10.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:36<14:04, 10.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:46<13:53, 10.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:57<13:41, 10.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:07<13:29, 10.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:18<13:18, 10.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:28<13:07, 10.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:39<12:56, 10.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:49<12:45, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:59<12:34, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:10<12:23, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:20<12:12, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:31<12:01, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:41<11:50, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:52<11:40, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [06:02<11:29, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:13<11:19, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:23<11:08, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:33<10:57, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:44<10:46, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:54<10:36, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [07:05<10:25, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:15<10:14, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:26<10:04, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:36<09:53, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:46<09:43, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:57<09:32, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [08:07<09:21, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:18<09:11, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:28<09:00, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:38<08:50, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:49<08:39, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [08:59<08:28, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:09<08:18, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:20<08:07, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:30<07:57, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:41<07:46, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:51<07:36, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [10:01<07:25, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:12<07:15, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:22<07:04, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:32<06:54, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:43<06:43, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:53<06:32, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [11:03<06:22, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:14<06:11, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:24<06:01, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:34<05:51, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:45<05:40, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:55<05:30, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [12:05<05:19, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:15<05:09, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:26<04:58, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:36<04:48, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:46<04:38, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:57<04:27, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [13:07<04:17, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:17<04:06, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:27<03:56, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:38<03:46, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:48<03:35, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [13:58<03:25, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [14:09<03:15, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [14:19<03:04, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:29<02:54, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:39<02:44, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:49<02:33, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [15:00<02:23, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [15:10<02:13, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [15:20<02:02, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:30<01:52, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:41<01:42, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:51<01:32, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [16:01<01:21, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [16:11<01:11, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [16:22<01:01, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:32<00:51, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:42<00:40, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:52<00:30, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [17:02<00:20, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [17:13<00:10, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [17:23<00:00, 10.19s/it]100%|██████████| 100/100 [17:23<00:00, 10.43s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-01-15:06:32:52,108 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-01-15:06:32:52,108 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-01-15:06:32:52,108 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-01-15:06:32:52,487 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-01-15:06:32:56,948 INFO     [__main__.py:132] Verbosity set to INFO
2025-01-15:06:33:07,509 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-01-15:06:33:07,511 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-01-15:06:33:07,520 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-01-15:06:33:07,736 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:01,  5.87it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:00<00:00,  6.58it/s]Loading checkpoint shards:  38%|███▊      | 3/8 [00:00<00:00,  7.53it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:00<00:00,  8.20it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:00<00:00,  8.53it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:00<00:00,  8.80it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:00<00:00,  8.98it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  8.46it/s]
2025-01-15:06:33:29,224 INFO     [task.py:355] Building contexts for task on rank 0...
2025-01-15:06:33:29,243 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:44, 12.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<19:01, 11.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:19, 11.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:45<17:52, 11.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:56<17:28, 11.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:07<17:10, 10.96s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:17<16:52, 10.89s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:28<16:37, 10.84s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:39<16:21, 10.79s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:49<16:06, 10.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [02:00<15:52, 10.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:11<15:37, 10.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:21<15:23, 10.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:32<15:11, 10.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:42<14:58, 10.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:53<14:46, 10.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:03<14:35, 10.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:14<14:23, 10.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:24<14:12, 10.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:35<14:00, 10.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:45<13:48, 10.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:56<13:37, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:06<13:25, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:16<13:14, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:27<13:03, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:37<12:52, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:48<12:41, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:58<12:30, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:08<12:19, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:19<12:08, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:29<11:58, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:40<11:47, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:50<11:36, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [06:00<11:26, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:11<11:15, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:21<11:05, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:32<10:54, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:42<10:43, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:52<10:32, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [07:03<10:22, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:13<10:08, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:23<09:58, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:34<09:49, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:44<09:39, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:54<09:28, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [08:05<09:18, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:15<09:08, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:25<08:57, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:36<08:47, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:46<08:36, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [08:56<08:26, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:07<08:15, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:17<08:05, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:27<07:54, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:38<07:44, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:48<07:33, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [09:58<07:23, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:08<07:12, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:19<07:02, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:29<06:52, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:39<06:41, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:50<06:31, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [11:00<06:20, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:10<06:10, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:20<05:59, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:31<05:49, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:41<05:38, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:51<05:28, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [12:02<05:18, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:12<05:07, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:22<04:57, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:32<04:47, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:42<04:36, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:53<04:26, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [13:03<04:16, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:13<04:05, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:23<03:55, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:34<03:45, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:44<03:34, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [13:54<03:24, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [14:04<03:14, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [14:14<03:03, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:25<02:53, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:35<02:43, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:45<02:33, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [14:55<02:22, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [15:05<02:12, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [15:16<02:02, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:26<01:52, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:36<01:41, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:46<01:31, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [15:56<01:21, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [16:07<01:11, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [16:17<01:01, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:27<00:50, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:37<00:40, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:47<00:30, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [16:57<00:20, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [17:07<00:10, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [17:18<00:00, 10.15s/it]100%|██████████| 100/100 [17:18<00:00, 10.38s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-01-15:06:51:23,334 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-01-15:06:51:23,334 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-01-15:06:51:23,334 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-01-15:06:51:23,704 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-01-15:06:51:28,073 INFO     [__main__.py:132] Verbosity set to INFO
2025-01-15:06:51:38,479 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-01-15:06:51:38,481 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-01-15:06:51:38,489 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-01-15:06:51:38,699 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:01,  5.95it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:00<00:00,  7.78it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:00<00:00,  9.07it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:00<00:00,  8.82it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:00<00:00,  9.40it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  9.10it/s]
2025-01-15:06:51:59,746 INFO     [task.py:355] Building contexts for task on rank 0...
2025-01-15:06:51:59,764 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:44, 12.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<19:04, 11.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:23, 11.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:45<17:57, 11.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:56<17:34, 11.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:07<17:15, 11.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:18<16:58, 10.95s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:28<16:42, 10.90s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:39<16:27, 10.85s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:50<16:11, 10.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [02:01<15:57, 10.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:11<15:43, 10.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:22<15:29, 10.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:32<15:16, 10.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:43<15:04, 10.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:54<14:52, 10.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:04<14:40, 10.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:15<14:29, 10.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:25<14:17, 10.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:36<14:05, 10.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:46<13:54, 10.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:57<13:42, 10.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:07<13:30, 10.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:18<13:19, 10.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:28<13:08, 10.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:39<12:57, 10.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:49<12:46, 10.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [05:00<12:35, 10.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:10<12:24, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:21<12:13, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:31<12:02, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:42<11:51, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:52<11:41, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [06:03<11:30, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:13<11:19, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:23<11:09, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:34<10:58, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:44<10:47, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:55<10:36, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [07:05<10:26, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:15<10:11, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:26<10:02, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:36<09:52, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:47<09:42, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:57<09:32, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [08:07<09:22, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:18<09:11, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:28<09:01, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:39<08:50, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:49<08:40, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [08:59<08:29, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:10<08:18, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:20<08:08, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:31<07:57, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:41<07:47, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:51<07:36, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [10:02<07:26, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:12<07:15, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:22<07:04, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:33<06:54, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:43<06:43, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:53<06:33, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [11:04<06:22, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:14<06:12, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:24<06:01, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:35<05:51, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:45<05:40, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:55<05:30, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [12:06<05:20, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:16<05:09, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:26<04:59, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:37<04:48, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:47<04:38, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:57<04:27, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [13:08<04:17, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:18<04:07, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:28<03:56, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:38<03:46, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:49<03:36, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [13:59<03:25, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [14:09<03:15, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [14:19<03:04, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:30<02:54, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:40<02:44, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:50<02:33, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [15:01<02:23, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [15:11<02:13, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [15:21<02:03, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:31<01:52, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:41<01:42, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:52<01:32, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [16:02<01:21, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [16:12<01:11, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [16:22<01:01, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:33<00:51, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:43<00:40, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:53<00:30, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [17:03<00:20, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [17:14<00:10, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [17:24<00:00, 10.21s/it]100%|██████████| 100/100 [17:24<00:00, 10.44s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-01-15:07:10:00,101 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-01-15:07:10:00,101 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-01-15:07:10:00,101 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-01-15:07:10:00,442 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-01-15:07:10:04,918 INFO     [__main__.py:132] Verbosity set to INFO
2025-01-15:07:10:15,336 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-01-15:07:10:15,339 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-01-15:07:10:15,347 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-01-15:07:10:15,583 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:01,  5.54it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:00<00:00,  7.27it/s]Loading checkpoint shards:  38%|███▊      | 3/8 [00:00<00:00,  8.14it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:00<00:00,  8.24it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:00<00:00,  8.41it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:00<00:00,  8.81it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:00<00:00,  9.10it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  8.61it/s]
2025-01-15:07:10:37,302 INFO     [task.py:355] Building contexts for task on rank 0...
2025-01-15:07:10:37,320 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:43, 12.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<18:59, 11.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:17, 11.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:45<17:50, 11.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:56<17:43, 11.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:07<17:18, 11.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:18<16:57, 10.94s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:28<16:40, 10.87s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:39<16:23, 10.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:50<16:06, 10.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [02:00<15:52, 10.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:11<15:37, 10.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:21<15:23, 10.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:32<15:10, 10.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:42<14:57, 10.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:53<14:45, 10.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:03<14:34, 10.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:14<14:22, 10.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:24<14:11, 10.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:35<13:59, 10.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:45<13:47, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:56<13:36, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:06<13:24, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:16<13:13, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:27<13:02, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:37<12:51, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:48<12:40, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:58<12:29, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:08<12:18, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:19<12:07, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:29<11:56, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:40<11:46, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:50<11:35, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [06:00<11:25, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:11<11:14, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:21<11:03, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:31<10:53, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:42<10:42, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:52<10:31, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [07:02<10:21, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:13<10:07, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:23<09:57, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:33<09:48, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:44<09:38, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:54<09:27, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [08:04<09:17, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:15<09:07, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:25<08:56, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:35<08:46, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:46<08:35, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [08:56<08:25, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:06<08:14, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:16<08:04, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:27<07:53, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:37<07:43, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:47<07:33, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [09:58<07:22, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:08<07:12, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:18<07:01, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:28<06:51, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:39<06:40, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:49<06:30, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [10:59<06:19, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:09<06:09, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:20<05:59, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:30<05:48, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:40<05:38, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:50<05:27, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [12:01<05:17, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:11<05:07, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:21<04:56, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:31<04:46, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:42<04:36, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:52<04:25, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [13:02<04:15, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:12<04:05, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:22<03:54, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:33<03:44, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:43<03:34, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [13:53<03:24, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [14:03<03:13, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [14:13<03:03, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:24<02:53, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:34<02:42, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:44<02:32, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [14:54<02:22, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [15:04<02:12, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [15:14<02:02, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:25<01:51, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:35<01:41, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:45<01:31, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [15:55<01:21, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [16:05<01:11, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [16:15<01:00, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:26<00:50, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:36<00:40, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:46<00:30, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [16:56<00:20, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [17:06<00:10, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [17:16<00:00, 10.13s/it]100%|██████████| 100/100 [17:16<00:00, 10.37s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-01-15:07:28:30,273 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-01-15:07:28:30,273 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-01-15:07:28:30,273 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-01-15:07:28:30,642 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-01-15:07:28:35,038 INFO     [__main__.py:132] Verbosity set to INFO
2025-01-15:07:28:45,461 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-01-15:07:28:45,463 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-01-15:07:28:45,471 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-01-15:07:28:45,687 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:01,  5.35it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:00<00:00,  7.10it/s]Loading checkpoint shards:  38%|███▊      | 3/8 [00:00<00:00,  7.94it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:00<00:00,  8.46it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:00<00:00,  8.18it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:00<00:00,  8.59it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:00<00:00,  8.88it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  8.44it/s]
2025-01-15:07:29:07,154 INFO     [task.py:355] Building contexts for task on rank 0...
2025-01-15:07:29:07,174 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:41, 12.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<18:58, 11.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:16, 11.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:45<17:50, 11.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:56<17:48, 11.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:07<17:22, 11.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:18<17:00, 10.97s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:28<16:41, 10.89s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:39<16:24, 10.82s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:50<16:07, 10.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [02:00<15:52, 10.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:11<15:37, 10.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:21<15:23, 10.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:32<15:10, 10.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:42<14:57, 10.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:53<14:45, 10.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:03<14:33, 10.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:14<14:22, 10.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:24<14:11, 10.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:35<13:58, 10.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:45<13:47, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:56<13:35, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:06<13:24, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:17<13:13, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:27<13:02, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:37<12:51, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:48<12:40, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:58<12:29, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:09<12:18, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:19<12:07, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:29<11:56, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:40<11:45, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:50<11:35, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [06:00<11:24, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:11<11:14, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:21<11:03, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:31<10:53, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:42<10:42, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:52<10:31, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [07:03<10:21, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:13<10:07, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:23<10:00, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:33<09:49, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:44<09:39, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:54<09:28, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [08:04<09:17, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:15<09:07, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:25<08:56, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:35<08:46, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:46<08:35, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [08:56<08:25, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:06<08:14, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:17<08:04, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:27<07:53, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:37<07:43, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:47<07:32, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [09:58<07:22, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:08<07:12, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:18<07:01, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:29<06:51, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:39<06:40, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:49<06:30, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [10:59<06:19, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:10<06:09, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:20<05:58, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:30<05:48, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:40<05:38, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:51<05:27, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [12:01<05:17, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:11<05:07, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:21<04:56, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:31<04:46, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:42<04:36, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:52<04:25, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [13:02<04:15, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:12<04:05, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:22<03:54, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:33<03:44, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:43<03:34, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [13:53<03:23, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [14:03<03:13, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [14:13<03:03, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:24<02:53, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:34<02:42, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:44<02:32, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [14:54<02:22, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [15:04<02:12, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [15:14<02:02, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:25<01:51, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:35<01:41, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:45<01:31, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [15:55<01:21, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [16:05<01:11, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [16:15<01:00, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:26<00:50, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:36<00:40, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:46<00:30, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [16:56<00:20, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [17:06<00:10, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [17:16<00:00, 10.12s/it]100%|██████████| 100/100 [17:16<00:00, 10.37s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-01-15:07:46:59,872 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-01-15:07:46:59,872 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-01-15:07:46:59,872 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-01-15:07:47:00,239 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-01-15:07:47:04,617 INFO     [__main__.py:132] Verbosity set to INFO
2025-01-15:07:47:15,133 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-01-15:07:47:15,135 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-01-15:07:47:15,143 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-01-15:07:47:15,367 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:01,  5.02it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:00<00:00,  6.51it/s]Loading checkpoint shards:  38%|███▊      | 3/8 [00:00<00:00,  7.40it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:00<00:00,  7.96it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:00<00:00,  7.92it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:00<00:00,  8.17it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:00<00:00,  8.51it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  8.88it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  8.02it/s]
2025-01-15:07:47:35,659 INFO     [task.py:355] Building contexts for task on rank 0...
2025-01-15:07:47:35,677 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:48, 12.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<19:03, 11.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:20, 11.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:45<17:53, 11.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:56<17:29, 11.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:07<17:10, 10.97s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:17<16:53, 10.89s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:28<16:37, 10.84s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:39<16:22, 10.79s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:49<16:06, 10.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [02:00<15:52, 10.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:11<15:38, 10.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:21<15:24, 10.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:32<15:11, 10.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:42<14:59, 10.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:53<14:47, 10.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:03<14:35, 10.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:14<14:24, 10.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:24<14:13, 10.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:35<14:00, 10.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:45<13:49, 10.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:56<13:37, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:06<13:26, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:17<13:15, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:27<13:03, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:37<12:52, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:48<12:41, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:58<12:31, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:09<12:20, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:19<12:09, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:29<11:58, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:40<11:47, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:50<11:37, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [06:01<11:26, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:11<11:16, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:21<11:05, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:32<10:54, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:42<10:43, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:53<10:33, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [07:03<10:22, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:13<10:08, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:23<09:59, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:34<09:49, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:44<09:39, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:55<09:29, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [08:05<09:18, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:15<09:08, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:26<08:58, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:36<08:47, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:46<08:37, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [08:57<08:26, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:07<08:16, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:17<08:05, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:28<07:55, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:38<07:44, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:48<07:33, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [09:58<07:23, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:09<07:13, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:19<07:02, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:29<06:52, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:40<06:41, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:50<06:31, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [11:00<06:20, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:10<06:10, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:21<05:59, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:31<05:49, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:41<05:39, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:52<05:28, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [12:02<05:18, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:12<05:08, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:22<04:57, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:33<04:47, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:43<04:36, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:53<04:26, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [13:03<04:16, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:14<04:05, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:24<03:55, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:34<03:45, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:44<03:34, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [13:54<03:24, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [14:05<03:14, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [14:15<03:03, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:25<02:53, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:35<02:43, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:45<02:33, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [14:56<02:22, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [15:06<02:12, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [15:16<02:02, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:26<01:52, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:36<01:41, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:47<01:31, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [15:57<01:21, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [16:07<01:11, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [16:17<01:01, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:27<00:50, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:37<00:40, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:48<00:30, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [16:58<00:20, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [17:08<00:10, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [17:18<00:00, 10.15s/it]100%|██████████| 100/100 [17:18<00:00, 10.38s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-01-15:08:06:40,267 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-01-15:08:06:40,268 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-01-15:08:06:40,268 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-01-15:08:06:40,623 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-01-15:08:06:44,956 INFO     [__main__.py:132] Verbosity set to INFO
2025-01-15:08:06:55,361 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-01-15:08:06:55,363 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-01-15:08:06:55,371 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-01-15:08:06:55,618 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:01,  5.12it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:00<00:00,  6.85it/s]Loading checkpoint shards:  38%|███▊      | 3/8 [00:00<00:00,  7.78it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:00<00:00,  8.28it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:00<00:00,  8.01it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:00<00:00,  8.41it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:00<00:00,  8.69it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  9.05it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  8.24it/s]
2025-01-15:08:07:14,934 INFO     [task.py:355] Building contexts for task on rank 0...
2025-01-15:08:07:14,952 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:45, 12.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<19:00, 11.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:17, 11.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:45<17:51, 11.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:56<17:27, 11.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:06<17:08, 10.94s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:17<16:51, 10.87s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:28<16:35, 10.82s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:39<16:20, 10.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:49<16:04, 10.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [02:00<15:50, 10.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:10<15:36, 10.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:21<15:22, 10.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:31<15:09, 10.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:42<14:57, 10.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:52<14:45, 10.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:03<14:34, 10.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:13<14:22, 10.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:24<14:11, 10.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:34<13:59, 10.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:45<13:47, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:55<13:36, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:06<13:24, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:16<13:13, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:26<13:02, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:37<12:51, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:47<12:40, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:58<12:29, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:08<12:18, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:18<12:07, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:29<11:57, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:39<11:46, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:50<11:35, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [06:00<11:25, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:10<11:14, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:21<11:04, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:31<10:53, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:41<10:42, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:52<10:31, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [07:02<10:21, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:12<10:10, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:23<10:00, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:33<09:49, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:43<09:39, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:54<09:28, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [08:04<09:18, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:14<09:07, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:25<08:57, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:35<08:46, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:45<08:36, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [08:56<08:25, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:06<08:15, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:16<08:04, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:27<07:54, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:37<07:43, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:47<07:33, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [09:57<07:22, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:08<07:12, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:18<07:01, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:28<06:51, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:39<06:40, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:49<06:30, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [10:59<06:19, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:09<06:09, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:20<05:59, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:30<05:48, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:40<05:38, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:50<05:28, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [12:01<05:17, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:11<05:07, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:21<04:56, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:31<04:46, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:37<03:55,  8.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:47<03:58,  9.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [12:57<03:57,  9.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:07<03:52,  9.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:17<03:46,  9.85s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:28<03:39,  9.96s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:38<03:30, 10.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [13:48<03:21, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [13:58<03:12, 10.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [14:08<03:02, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:18<02:52, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:29<02:42, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:39<02:32, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [14:49<02:22, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [14:59<02:12, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [15:09<02:02, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:20<01:51, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:30<01:41, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:40<01:31, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [15:50<01:21, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [16:00<01:11, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [16:10<01:00, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:20<00:50, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:31<00:40, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:41<00:30, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [16:51<00:20, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [17:01<00:10, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [17:11<00:00, 10.13s/it]100%|██████████| 100/100 [17:11<00:00, 10.32s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-01-15:08:25:02,763 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-01-15:08:25:02,763 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-01-15:08:25:02,763 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-01-15:08:25:03,134 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-01-15:08:25:07,497 INFO     [__main__.py:132] Verbosity set to INFO
2025-01-15:08:25:18,001 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-01-15:08:25:18,003 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-01-15:08:25:18,011 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-01-15:08:25:18,231 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:01,  5.89it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:00<00:00,  6.75it/s]Loading checkpoint shards:  38%|███▊      | 3/8 [00:00<00:00,  7.76it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:00<00:00,  8.36it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:00<00:00,  8.74it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:00<00:00,  8.99it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:00<00:00,  9.17it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  8.62it/s]
2025-01-15:08:25:40,221 INFO     [task.py:355] Building contexts for task on rank 0...
2025-01-15:08:25:40,240 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:50, 12.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<19:08, 11.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:25, 11.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:45<17:58, 11.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:56<17:35, 11.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:07<17:16, 11.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:18<16:58, 10.96s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:29<16:43, 10.91s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:39<16:27, 10.86s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:50<16:12, 10.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [02:01<15:58, 10.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:11<15:43, 10.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:22<15:29, 10.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:33<15:17, 10.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:43<15:04, 10.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:54<14:52, 10.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:04<14:41, 10.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:15<14:29, 10.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:25<14:18, 10.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:36<14:05, 10.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:47<13:54, 10.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:57<13:42, 10.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:08<13:31, 10.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:18<13:19, 10.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:29<13:08, 10.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:39<12:57, 10.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:49<12:46, 10.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [05:00<12:35, 10.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:10<12:24, 10.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:21<12:13, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:31<12:02, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:42<11:52, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:52<11:41, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [06:03<11:30, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:13<11:20, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:24<11:09, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:34<10:58, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:45<10:47, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:55<10:37, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [07:05<10:26, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:16<10:15, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:26<10:05, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:37<09:54, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:47<09:44, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:58<09:33, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [08:08<09:22, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:18<09:12, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:29<09:01, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:39<08:50, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:50<08:40, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [09:00<08:29, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:10<08:19, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:21<08:08, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:31<07:57, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:41<07:47, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:52<07:36, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [10:02<07:26, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:13<07:15, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:23<07:05, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:33<06:54, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:44<06:44, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:54<06:33, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [11:04<06:23, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:15<06:12, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:25<06:02, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:35<05:51, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:46<05:41, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:56<05:30, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [12:06<05:20, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:17<05:09, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:27<04:59, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:37<04:49, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:43<03:57,  8.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:53<04:00,  9.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [13:03<03:59,  9.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:13<03:54,  9.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:24<03:48,  9.93s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:34<03:40, 10.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:44<03:32, 10.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [13:55<03:23, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [14:05<03:13, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [14:15<03:03, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:25<02:53, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:36<02:43, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:46<02:33, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [14:56<02:23, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [15:06<02:13, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [15:17<02:03, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:27<01:52, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:37<01:42, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:47<01:32, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [15:58<01:21, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [16:08<01:11, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [16:18<01:01, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:28<00:51, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:39<00:41, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:49<00:30, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [16:59<00:20, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [17:09<00:10, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [17:19<00:00, 10.22s/it]100%|██████████| 100/100 [17:19<00:00, 10.40s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-01-15:08:43:36,480 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-01-15:08:43:36,480 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-01-15:08:43:36,480 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-01-15:08:43:36,836 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-01-15:08:43:41,270 INFO     [__main__.py:132] Verbosity set to INFO
2025-01-15:08:43:51,729 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-01-15:08:43:51,731 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-01-15:08:43:51,739 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-01-15:08:43:51,961 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:01,  5.62it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:00<00:00,  6.46it/s]Loading checkpoint shards:  38%|███▊      | 3/8 [00:00<00:00,  7.44it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:00<00:00,  8.04it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:00<00:00,  8.42it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:00<00:00,  8.69it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:00<00:00,  8.88it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  9.18it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  8.32it/s]
2025-01-15:08:44:14,065 INFO     [task.py:355] Building contexts for task on rank 0...
2025-01-15:08:44:14,084 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:39, 12.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<18:57, 11.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:15, 11.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:45<17:49, 11.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:56<17:25, 11.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:06<17:07, 10.93s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:17<16:49, 10.86s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:28<16:34, 10.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:38<16:19, 10.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:49<16:03, 10.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [02:00<15:49, 10.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:10<15:35, 10.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:21<15:21, 10.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:31<15:08, 10.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:42<14:56, 10.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:52<14:44, 10.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:03<14:33, 10.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:13<14:21, 10.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:24<14:10, 10.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:34<13:58, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:44<13:46, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:55<13:35, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:05<13:24, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:16<13:12, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:26<13:01, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:37<12:50, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:47<12:39, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:57<12:28, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:08<12:17, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:18<12:07, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:28<11:56, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:39<11:45, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:49<11:35, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [06:00<11:24, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:10<11:14, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:20<11:03, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:31<10:52, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:41<10:42, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:51<10:31, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [07:02<10:20, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:12<10:10, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:22<09:59, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:33<09:49, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:43<09:38, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:53<09:28, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [08:04<09:17, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:14<09:07, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:24<08:56, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:35<08:46, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:45<08:35, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [08:55<08:24, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:05<08:14, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:16<08:03, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:26<07:53, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:36<07:43, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:47<07:32, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [09:57<07:22, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:07<07:11, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:17<07:01, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:28<06:50, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:38<06:40, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:48<06:29, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [10:58<06:19, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:09<06:09, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:19<05:58, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:29<05:48, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:39<05:38, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:50<05:27, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [12:00<05:17, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:10<05:07, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:20<04:56, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:30<04:46, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:36<03:55,  8.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:46<03:58,  9.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [12:56<03:56,  9.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:06<03:52,  9.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:16<03:46,  9.84s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:27<03:38,  9.95s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:37<03:30, 10.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [13:47<03:21, 10.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [13:57<03:11, 10.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [14:07<03:02, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:18<02:52, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:28<02:42, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:38<02:32, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [14:48<02:22, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [14:58<02:12, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [15:08<02:01, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:18<01:51, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:29<01:41, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:39<01:31, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [15:49<01:21, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [15:59<01:11, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [16:09<01:00, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:19<00:50, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:29<00:40, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:40<00:30, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [16:50<00:20, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [17:00<00:10, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [17:10<00:00, 10.12s/it]100%|██████████| 100/100 [17:10<00:00, 10.30s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-01-15:09:02:00,677 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-01-15:09:02:00,677 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-01-15:09:02:00,677 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-01-15:09:02:01,037 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-01-15:09:02:05,348 INFO     [__main__.py:132] Verbosity set to INFO
2025-01-15:09:02:15,812 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-01-15:09:02:15,814 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-01-15:09:02:15,822 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-01-15:09:02:16,042 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:01,  5.04it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:00<00:00,  6.71it/s]Loading checkpoint shards:  38%|███▊      | 3/8 [00:00<00:00,  7.62it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:00<00:00,  8.17it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:00<00:00,  7.90it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:00<00:00,  8.33it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:00<00:00,  8.62it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  9.00it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  8.15it/s]
2025-01-15:09:02:37,820 INFO     [task.py:355] Building contexts for task on rank 0...
2025-01-15:09:02:37,838 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:44, 12.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<19:00, 11.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:17, 11.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:45<17:50, 11.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:56<17:32, 11.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:07<17:12, 10.98s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:17<16:53, 10.89s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:28<16:36, 10.84s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:39<16:21, 10.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:49<16:05, 10.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [02:00<15:50, 10.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:10<15:36, 10.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:21<15:22, 10.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:31<15:09, 10.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:42<14:57, 10.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:52<14:45, 10.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:03<14:33, 10.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:13<14:22, 10.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:24<14:11, 10.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:34<13:59, 10.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:45<13:47, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:55<13:35, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:06<13:24, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:16<13:13, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:27<13:02, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:37<12:51, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:47<12:40, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:58<12:29, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:08<12:18, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:19<12:07, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:29<11:56, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:39<11:46, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:50<11:35, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [06:00<11:25, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:10<11:14, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:21<11:03, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:31<10:53, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:41<10:42, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:52<10:31, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [07:02<10:21, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:13<10:10, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:23<10:00, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:33<09:49, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:44<09:39, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:54<09:28, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [08:04<09:18, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:15<09:07, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:25<08:57, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:35<08:46, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:45<08:36, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [08:56<08:25, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:06<08:15, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:16<08:04, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:27<07:53, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:37<07:43, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:47<07:33, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [09:58<07:22, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:08<07:12, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:18<07:01, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:28<06:51, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:39<06:40, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:49<06:30, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [10:59<06:19, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:09<06:09, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:20<05:59, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:30<05:48, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:40<05:38, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:50<05:28, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [12:01<05:17, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:11<05:07, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:21<04:56, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:31<04:46, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:37<03:55,  8.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:47<03:58,  9.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [12:57<03:57,  9.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:07<03:52,  9.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:17<03:46,  9.85s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:28<03:39,  9.96s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:38<03:30, 10.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [13:48<03:21, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [13:58<03:12, 10.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [14:08<03:02, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:19<02:52, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:29<02:42, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:39<02:32, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [14:49<02:22, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [14:59<02:12, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [15:09<02:01, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:20<01:51, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:30<01:41, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:40<01:31, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [15:50<01:21, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [16:00<01:11, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [16:10<01:00, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:20<00:50, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:31<00:40, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:41<00:30, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [16:51<00:20, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [17:01<00:10, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [17:11<00:00, 10.13s/it]100%|██████████| 100/100 [17:11<00:00, 10.32s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-01-15:09:20:25,565 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-01-15:09:20:25,565 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-01-15:09:20:25,565 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-01-15:09:20:25,936 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-01-15:09:20:30,293 INFO     [__main__.py:132] Verbosity set to INFO
2025-01-15:09:20:40,985 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-01-15:09:20:40,987 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-01-15:09:20:40,993 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-01-15:09:20:41,219 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:01,  5.88it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:00<00:00,  6.89it/s]Loading checkpoint shards:  38%|███▊      | 3/8 [00:00<00:00,  7.60it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:00<00:00,  8.20it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:00<00:00,  8.59it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:00<00:00,  8.85it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:00<00:00,  9.01it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  8.51it/s]
2025-01-15:09:21:01,723 INFO     [task.py:355] Building contexts for task on rank 0...
2025-01-15:09:21:01,742 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:42, 12.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<18:59, 11.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:16, 11.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:45<17:50, 11.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:56<17:26, 11.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:06<17:07, 10.93s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:17<16:50, 10.86s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:28<16:34, 10.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:38<16:19, 10.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:49<16:03, 10.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [02:00<15:50, 10.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:10<15:35, 10.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:21<15:21, 10.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:31<15:09, 10.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:42<14:56, 10.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:52<14:44, 10.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:03<14:33, 10.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:13<14:22, 10.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:24<14:10, 10.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:34<13:58, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:45<13:47, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:55<13:35, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:05<13:24, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:16<13:13, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:26<13:01, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:37<12:50, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:47<12:39, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:57<12:29, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:08<12:18, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:18<12:07, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:29<11:56, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:39<11:45, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:49<11:35, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [06:00<11:24, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:10<11:14, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:20<11:03, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:31<10:52, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:41<10:42, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:51<10:31, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [07:02<10:21, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:12<10:10, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:22<09:59, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:33<09:49, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:43<09:39, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:53<09:28, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [08:04<09:17, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:14<09:07, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:24<08:56, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:35<08:46, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:45<08:35, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [08:55<08:25, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:06<08:14, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:16<08:04, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:26<07:53, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:36<07:43, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:47<07:32, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [09:57<07:22, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:07<07:11, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:18<07:01, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:28<06:51, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:38<06:40, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:48<06:29, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [10:59<06:19, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:09<06:09, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:19<05:58, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:29<05:48, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:40<05:38, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:50<05:27, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [12:00<05:17, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:10<05:07, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:20<04:56, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:31<04:46, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:36<03:55,  8.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:46<03:58,  9.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [12:56<03:57,  9.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:07<03:52,  9.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:17<03:46,  9.84s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:27<03:38,  9.95s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:37<03:30, 10.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [13:47<03:21, 10.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [13:57<03:11, 10.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [14:08<03:02, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:18<02:52, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:28<02:42, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:38<02:32, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [14:48<02:22, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [14:58<02:12, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [15:09<02:01, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:19<01:51, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:29<01:41, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:39<01:31, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [15:49<01:21, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [15:59<01:11, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [16:10<01:00, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:20<00:50, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:30<00:40, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:40<00:30, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [16:50<00:20, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [17:00<00:10, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [17:10<00:00, 10.12s/it]100%|██████████| 100/100 [17:10<00:00, 10.31s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-01-15:09:38:19,446 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-01-15:09:38:19,446 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-01-15:09:38:19,446 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-01-15:09:38:19,854 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-01-15:09:38:24,213 INFO     [__main__.py:132] Verbosity set to INFO
2025-01-15:09:38:34,305 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-01-15:09:38:34,307 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-01-15:09:38:34,315 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-01-15:09:38:34,582 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:01,  5.30it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:00<00:00,  6.85it/s]Loading checkpoint shards:  38%|███▊      | 3/8 [00:00<00:00,  7.67it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:00<00:00,  7.69it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:00<00:00,  7.99it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:00<00:00,  8.33it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:00<00:00,  8.56it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:01<00:00,  8.51it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:01<00:00,  7.98it/s]
2025-01-15:09:38:56,692 INFO     [task.py:355] Building contexts for task on rank 0...
2025-01-15:09:38:56,710 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:52, 12.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<19:04, 11.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:20, 11.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:45<17:53, 11.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:56<17:29, 11.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:07<17:10, 10.96s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:17<16:52, 10.88s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:28<16:36, 10.83s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:39<16:20, 10.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:49<16:05, 10.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [02:00<15:51, 10.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:11<15:37, 10.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:21<15:23, 10.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:32<15:10, 10.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:42<14:58, 10.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:53<14:46, 10.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:03<14:35, 10.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:14<14:23, 10.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:24<14:12, 10.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:35<14:00, 10.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:45<13:49, 10.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:56<13:37, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:06<13:26, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:16<13:14, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:27<13:03, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:37<12:52, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:48<12:41, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:58<12:30, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:08<12:19, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:19<12:08, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:29<11:57, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:40<11:47, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:50<11:36, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [06:00<11:26, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:11<11:15, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:21<11:04, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:32<10:54, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:42<10:43, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:52<10:33, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [07:03<10:22, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:13<10:12, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:23<10:01, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:34<09:51, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:44<09:40, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:54<09:29, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [08:05<09:19, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:15<09:08, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:26<08:58, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:36<08:47, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:46<08:37, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [08:57<08:26, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:07<08:16, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:17<08:05, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:27<07:55, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:38<07:44, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:48<07:33, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [09:58<07:23, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:09<07:12, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:19<07:02, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:29<06:51, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:40<06:41, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:50<06:30, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [11:00<06:20, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:10<06:10, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:21<05:59, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:31<05:49, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:41<05:38, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:51<05:28, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [12:02<05:18, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:12<05:07, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:22<04:57, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:32<04:47, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:43<04:36, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:53<04:26, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [13:03<04:15, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:13<04:05, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:24<03:55, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:34<03:44, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:44<03:34, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [13:54<03:24, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [14:04<03:14, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [14:15<03:03, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:25<02:53, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:35<02:43, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:45<02:33, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [14:55<02:22, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [15:06<02:12, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [15:16<02:02, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:26<01:52, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:36<01:41, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:46<01:31, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [15:57<01:21, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [16:07<01:11, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [16:17<01:01, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:27<00:50, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:37<00:40, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:47<00:30, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [16:57<00:20, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [17:08<00:10, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [17:18<00:00, 10.15s/it]100%|██████████| 100/100 [17:18<00:00, 10.38s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-01-15:09:56:51,056 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-01-15:09:56:51,056 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-01-15:09:56:51,056 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-01-15:09:56:51,420 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-01-15:09:56:55,712 INFO     [__main__.py:132] Verbosity set to INFO
2025-01-15:09:57:06,277 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-01-15:09:57:06,279 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-01-15:09:57:06,287 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-01-15:09:57:06,509 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:01,  5.96it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:00<00:00,  6.82it/s]Loading checkpoint shards:  38%|███▊      | 3/8 [00:00<00:00,  7.65it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:00<00:00,  8.16it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:00<00:00,  8.47it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:00<00:00,  8.69it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:00<00:00,  8.92it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  9.22it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  8.44it/s]
2025-01-15:09:57:27,111 INFO     [task.py:355] Building contexts for task on rank 0...
2025-01-15:09:57:27,130 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:32, 12.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<18:50, 11.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:08, 11.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:45<17:41, 11.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:55<17:18, 10.93s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:06<16:59, 10.85s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:17<16:42, 10.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:27<16:26, 10.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:38<16:11, 10.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:48<15:56, 10.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [01:59<15:42, 10.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:09<15:28, 10.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:20<15:14, 10.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:30<15:01, 10.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:40<14:49, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:51<14:37, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:01<14:26, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:12<14:15, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:22<14:04, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:32<13:52, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:43<13:40, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:53<13:29, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:03<13:18, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:14<13:06, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:24<12:55, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:34<12:44, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:45<12:33, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:55<12:23, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:05<12:12, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:16<12:01, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:26<11:50, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:36<11:40, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:47<11:29, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [05:57<11:19, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:07<11:08, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:17<10:58, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:28<10:47, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:38<10:37, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:48<10:26, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [06:58<10:16, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:09<10:06, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:19<09:55, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:29<09:45, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:39<09:34, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:50<09:24, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [08:00<09:13, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:10<09:03, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:20<08:52, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:31<08:42, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:41<08:32, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [08:51<08:21, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:01<08:11, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:12<08:00, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:22<07:50, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:32<07:39, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:42<07:29, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [09:52<07:19, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:03<07:08, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:13<06:58, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:23<06:47, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:33<06:37, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:43<06:27, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [10:54<06:16, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:04<06:06, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:14<05:56, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:24<05:45, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:34<05:35, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:44<05:25, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [11:54<05:15, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:05<05:04, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:15<04:54, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:25<04:44, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:35<04:33, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:45<04:23, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [12:55<04:13, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:05<04:03, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:16<03:52, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:26<03:42, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:36<03:32, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [13:46<03:22, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [13:56<03:12, 10.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [14:06<03:01, 10.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:16<02:51, 10.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:26<02:41, 10.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:36<02:31, 10.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [14:46<02:21, 10.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [14:57<02:11, 10.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [15:07<02:01, 10.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:17<01:50, 10.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:27<01:40, 10.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:37<01:30, 10.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [15:47<01:20, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [15:57<01:10, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [16:07<01:00, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:17<00:50, 10.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:27<00:40, 10.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:37<00:30, 10.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [16:47<00:20, 10.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [16:57<00:10, 10.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [17:07<00:00, 10.05s/it]100%|██████████| 100/100 [17:07<00:00, 10.28s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-01-15:10:15:11,156 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-01-15:10:15:11,156 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-01-15:10:15:11,156 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-01-15:10:15:11,553 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-01-15:10:15:16,155 INFO     [__main__.py:132] Verbosity set to INFO
2025-01-15:10:15:26,464 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-01-15:10:15:26,466 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-01-15:10:15:26,473 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-01-15:10:15:26,710 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:01,  6.18it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:00<00:00,  7.69it/s]Loading checkpoint shards:  38%|███▊      | 3/8 [00:00<00:00,  7.69it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:00<00:00,  8.29it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:00<00:00,  8.67it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:00<00:00,  8.94it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:00<00:00,  9.13it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  8.69it/s]
2025-01-15:10:15:47,047 INFO     [task.py:355] Building contexts for task on rank 0...
2025-01-15:10:15:47,066 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:40, 12.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<18:58, 11.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:16, 11.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:45<17:50, 11.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:56<17:26, 11.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:06<17:07, 10.93s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:17<16:50, 10.86s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:28<16:34, 10.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:38<16:19, 10.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:49<16:03, 10.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [02:00<15:49, 10.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:10<15:35, 10.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:21<15:21, 10.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:31<15:09, 10.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:42<14:56, 10.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:52<14:45, 10.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:03<14:33, 10.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:13<14:22, 10.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:24<14:11, 10.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:34<13:59, 10.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:45<13:47, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:55<13:35, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:05<13:24, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:16<13:13, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:26<13:02, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:37<12:51, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:47<12:40, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:57<12:29, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:08<12:18, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:18<12:07, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:29<11:56, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:39<11:46, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:49<11:35, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [06:00<11:24, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:10<11:14, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:20<11:03, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:31<10:53, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:41<10:42, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:51<10:32, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [07:02<10:21, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:12<10:11, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:23<10:00, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:33<09:49, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:43<09:39, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:54<09:28, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [08:04<09:18, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:14<09:07, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:25<08:57, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:35<08:46, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:45<08:36, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [08:55<08:25, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:06<08:15, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:16<08:04, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:26<07:54, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:37<07:43, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:47<07:33, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [09:57<07:22, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:08<07:12, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:18<07:01, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:28<06:51, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:38<06:40, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:49<06:30, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [10:59<06:19, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:09<06:09, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:19<05:58, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:30<05:48, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:40<05:38, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:50<05:27, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [12:00<05:17, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:11<05:07, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:21<04:56, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:31<04:46, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:41<04:36, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:51<04:25, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [13:02<04:15, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:12<04:05, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:22<03:54, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:32<03:44, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:42<03:34, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [13:53<03:23, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [14:03<03:13, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [14:13<03:03, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:23<02:53, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:33<02:42, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:44<02:32, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [14:54<02:22, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [15:04<02:12, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [15:14<02:02, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:24<01:51, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:34<01:41, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:45<01:31, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [15:55<01:21, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [16:05<01:11, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [16:15<01:00, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:25<00:50, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:35<00:40, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:45<00:30, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [16:56<00:20, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [17:06<00:10, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [17:16<00:00, 10.13s/it]100%|██████████| 100/100 [17:16<00:00, 10.36s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-01-15:10:33:39,489 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-01-15:10:33:39,489 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-01-15:10:33:39,489 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-01-15:10:33:39,853 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-01-15:10:33:44,240 INFO     [__main__.py:132] Verbosity set to INFO
2025-01-15:10:33:55,027 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-01-15:10:33:55,029 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-01-15:10:33:55,037 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-01-15:10:33:55,286 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:01,  6.11it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:00<00:00,  6.88it/s]Loading checkpoint shards:  38%|███▊      | 3/8 [00:00<00:00,  7.81it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:00<00:00,  8.33it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:00<00:00,  8.67it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:00<00:00,  8.93it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:00<00:00,  9.06it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  8.61it/s]
2025-01-15:10:34:16,460 INFO     [task.py:355] Building contexts for task on rank 0...
2025-01-15:10:34:16,478 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:42, 12.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<18:58, 11.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:15, 11.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:45<17:49, 11.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:56<17:25, 11.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:06<17:06, 10.92s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:17<16:48, 10.85s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:28<16:33, 10.79s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:38<16:17, 10.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:49<16:02, 10.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [02:00<15:48, 10.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:10<15:34, 10.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:21<15:20, 10.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:31<15:07, 10.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:42<14:55, 10.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:52<14:43, 10.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:02<14:32, 10.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:13<14:20, 10.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:23<14:09, 10.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:34<13:57, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:44<13:46, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:55<13:34, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:05<13:23, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:15<13:11, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:26<13:00, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:36<12:49, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:47<12:38, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:57<12:28, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:07<12:17, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:18<12:06, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:28<11:55, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:38<11:44, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:49<11:34, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [05:59<11:23, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:10<11:13, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:20<11:02, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:30<10:52, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:41<10:41, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:51<10:30, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [07:01<10:20, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:12<10:10, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:22<09:59, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:32<09:48, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:43<09:38, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:53<09:27, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [08:03<09:17, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:13<09:06, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:24<08:56, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:34<08:45, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:44<08:35, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [08:55<08:24, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:05<08:14, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:15<08:03, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:26<07:53, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:36<07:42, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:46<07:32, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [09:56<07:22, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:07<07:11, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:17<07:01, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:27<06:50, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:37<06:40, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:48<06:29, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [10:58<06:19, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:08<06:08, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:18<05:58, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:29<05:48, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:39<05:37, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:49<05:27, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [11:59<05:17, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:09<05:06, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:20<04:56, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:30<04:46, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:40<04:35, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:50<04:25, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [13:00<04:15, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:11<04:04, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:21<03:54, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:31<03:44, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:41<03:33, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [13:51<03:23, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [14:02<03:13, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [14:12<03:03, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:22<02:52, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:32<02:42, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:42<02:32, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [14:52<02:22, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [15:02<02:12, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [15:13<02:01, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:23<01:51, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:33<01:41, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:43<01:31, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [15:53<01:21, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [16:03<01:11, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [16:14<01:00, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:24<00:50, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:34<00:40, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:44<00:30, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [16:54<00:20, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [17:04<00:10, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [17:14<00:00, 10.11s/it]100%|██████████| 100/100 [17:14<00:00, 10.35s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-01-15:10:52:07,275 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-01-15:10:52:07,275 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-01-15:10:52:07,275 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-01-15:10:52:07,641 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-01-15:10:52:11,889 INFO     [__main__.py:132] Verbosity set to INFO
2025-01-15:10:52:22,303 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-01-15:10:52:22,305 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-01-15:10:52:22,314 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-01-15:10:52:22,920 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:01,  5.82it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:00<00:00,  6.81it/s]Loading checkpoint shards:  38%|███▊      | 3/8 [00:00<00:00,  7.30it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:00<00:00,  7.90it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:00<00:00,  8.27it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:00<00:00,  8.55it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:00<00:00,  8.70it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  9.02it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  8.24it/s]
2025-01-15:10:52:43,052 INFO     [task.py:355] Building contexts for task on rank 0...
2025-01-15:10:52:43,070 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:42, 12.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<18:59, 11.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:17, 11.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:45<17:51, 11.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:56<17:27, 11.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:06<17:09, 10.95s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:17<16:51, 10.87s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:28<16:35, 10.82s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:39<16:20, 10.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:49<16:05, 10.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [02:00<15:51, 10.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:10<15:36, 10.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:21<15:23, 10.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:31<15:10, 10.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:42<14:58, 10.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:52<14:46, 10.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:03<14:34, 10.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:13<14:23, 10.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:24<14:12, 10.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:34<14:00, 10.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:45<13:48, 10.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:55<13:37, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:06<13:25, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:16<13:14, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:27<13:03, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:37<12:52, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:47<12:41, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:58<12:30, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:08<12:19, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:19<12:08, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:29<11:57, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:39<11:47, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:50<11:36, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [06:00<11:25, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:11<11:15, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:21<11:04, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:31<10:53, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:42<10:43, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:52<10:32, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [07:02<10:22, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:13<10:11, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:23<10:01, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:34<09:50, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:44<09:40, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:54<09:29, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [08:05<09:19, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:15<09:08, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:25<08:57, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:36<08:47, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:46<08:36, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [08:56<08:26, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:07<08:15, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:17<08:05, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:27<07:54, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:37<07:44, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:48<07:33, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [09:58<07:23, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:08<07:12, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:19<07:02, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:29<06:51, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:39<06:41, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:50<06:30, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [11:00<06:20, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:10<06:09, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:20<05:59, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:31<05:49, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:41<05:38, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:51<05:28, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [12:01<05:18, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:12<05:07, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:22<04:57, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:32<04:46, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:42<04:36, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:53<04:26, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [13:03<04:15, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:13<04:05, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:23<03:55, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:33<03:44, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:44<03:34, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [13:54<03:24, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [14:04<03:14, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [14:14<03:03, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:24<02:53, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:35<02:43, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:45<02:32, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [14:55<02:22, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [15:05<02:12, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [15:15<02:02, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:26<01:52, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:36<01:41, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:46<01:31, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [15:56<01:21, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [16:06<01:11, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [16:16<01:01, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:27<00:50, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:37<00:40, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:47<00:30, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [16:57<00:20, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [17:07<00:10, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [17:17<00:00, 10.15s/it]100%|██████████| 100/100 [17:17<00:00, 10.38s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-01-15:11:11:47,041 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-01-15:11:11:47,041 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-01-15:11:11:47,041 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-01-15:11:11:47,416 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-01-15:11:11:51,843 INFO     [__main__.py:132] Verbosity set to INFO
2025-01-15:11:12:02,254 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-01-15:11:12:02,257 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-01-15:11:12:02,265 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-01-15:11:12:02,488 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:01,  5.40it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:00<00:00,  7.04it/s]Loading checkpoint shards:  38%|███▊      | 3/8 [00:00<00:00,  7.86it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:00<00:00,  7.84it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:00<00:00,  8.06it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:00<00:00,  8.42it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:00<00:00,  8.72it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  8.59it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  8.10it/s]
2025-01-15:11:12:23,766 INFO     [task.py:355] Building contexts for task on rank 0...
2025-01-15:11:12:23,785 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:35, 12.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<18:53, 11.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:11, 11.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:45<17:44, 11.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:55<17:21, 10.96s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:06<17:02, 10.88s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:17<16:45, 10.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:27<16:29, 10.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:38<16:14, 10.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:49<15:59, 10.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [01:59<15:45, 10.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:10<15:30, 10.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:20<15:17, 10.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:30<15:04, 10.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:41<14:52, 10.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:51<14:40, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:02<14:29, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:12<14:18, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:23<14:06, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:33<13:55, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:43<13:43, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:54<13:31, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:04<13:20, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:15<13:09, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:25<12:57, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:35<12:46, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:46<12:36, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:56<12:25, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:06<12:14, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:17<12:03, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:27<11:52, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:37<11:42, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:48<11:31, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [05:58<11:21, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:08<11:10, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:19<11:00, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:29<10:49, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:39<10:39, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:49<10:28, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [07:00<10:18, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:10<10:07, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:20<09:57, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:31<09:46, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:41<09:36, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:51<09:25, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [08:01<09:15, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:12<09:04, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:22<08:54, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:32<08:43, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:43<08:33, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [08:53<08:23, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:03<08:12, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:13<08:02, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:24<07:51, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:34<07:41, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:44<07:30, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [09:54<07:20, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:04<07:09, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:15<06:59, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:25<06:49, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:35<06:38, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:45<06:28, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [10:55<06:17, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:06<06:07, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:16<05:56, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:26<05:46, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:36<05:36, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:46<05:26, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [11:57<05:15, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:07<05:05, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:17<04:55, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:27<04:45, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:37<04:34, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:47<04:24, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [12:58<04:14, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:08<04:03, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:18<03:53, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:28<03:43, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:38<03:33, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [13:48<03:22, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [13:58<03:12, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [14:09<03:02, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:19<02:52, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:29<02:42, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:39<02:31, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [14:49<02:21, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [14:59<02:11, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [15:09<02:01, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:19<01:51, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:30<01:41, 10.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:40<01:31, 10.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [15:50<01:20, 10.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [16:00<01:10, 10.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [16:10<01:00, 10.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:20<00:50, 10.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:30<00:40, 10.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:40<00:30, 10.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [16:50<00:19,  9.90s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [17:00<00:09,  9.95s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [17:10<00:00,  9.98s/it]100%|██████████| 100/100 [17:10<00:00, 10.30s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-01-15:11:30:10,264 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-01-15:11:30:10,264 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-01-15:11:30:10,264 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-01-15:11:30:10,630 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-01-15:11:30:14,868 INFO     [__main__.py:132] Verbosity set to INFO
2025-01-15:11:30:25,783 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-01-15:11:30:25,785 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-01-15:11:30:25,793 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-01-15:11:30:26,021 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:01,  5.64it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:00<00:00,  7.10it/s]Loading checkpoint shards:  38%|███▊      | 3/8 [00:00<00:00,  7.14it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:00<00:00,  7.74it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:00<00:00,  8.13it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:00<00:00,  8.40it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:00<00:00,  8.57it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  8.89it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  8.13it/s]
2025-01-15:11:30:45,596 INFO     [task.py:355] Building contexts for task on rank 0...
2025-01-15:11:30:45,614 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:45, 12.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<19:02, 11.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:20, 11.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:45<17:54, 11.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:56<17:30, 11.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:07<17:11, 10.98s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:17<16:53, 10.90s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:28<16:38, 10.85s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:39<16:23, 10.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:49<16:07, 10.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [02:00<15:53, 10.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:11<15:39, 10.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:21<15:25, 10.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:32<15:12, 10.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:42<15:00, 10.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:53<14:48, 10.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:03<14:37, 10.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:14<14:25, 10.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:25<14:14, 10.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:35<14:02, 10.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:46<13:51, 10.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:56<13:39, 10.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:06<13:27, 10.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:17<13:16, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:27<13:04, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:38<12:53, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:48<12:43, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:59<12:32, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:09<12:21, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:19<12:10, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:30<11:59, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:40<11:48, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:51<11:37, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [06:01<11:27, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:12<11:16, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:22<11:06, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:32<10:55, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:43<10:44, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:53<10:34, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [07:04<10:23, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:14<10:13, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:24<10:02, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:35<09:52, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:45<09:41, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:55<09:31, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [08:06<09:20, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:16<09:09, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:27<08:59, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:37<08:48, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:47<08:38, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [08:58<08:27, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:08<08:17, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:18<08:06, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:29<07:56, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:39<07:45, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:49<07:34, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [10:00<07:24, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:10<07:13, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:20<07:03, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:31<06:52, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:41<06:42, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:51<06:31, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [11:01<06:21, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:12<06:10, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:22<06:00, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:32<05:49, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:43<05:39, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:53<05:29, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [12:03<05:18, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:13<05:08, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:24<04:58, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:34<04:47, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:44<04:37, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:54<04:26, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [13:05<04:16, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:15<04:06, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:25<03:55, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:35<03:45, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:46<03:35, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [13:56<03:24, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [14:06<03:14, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [14:16<03:04, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:27<02:53, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:37<02:43, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:47<02:33, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [14:57<02:23, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [15:07<02:12, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [15:18<02:02, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:28<01:52, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:38<01:42, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:48<01:31, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [15:58<01:21, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [16:09<01:11, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [16:19<01:01, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:29<00:50, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:39<00:40, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:49<00:30, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [16:59<00:19,  9.99s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [17:09<00:10, 10.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [17:19<00:00, 10.08s/it]100%|██████████| 100/100 [17:19<00:00, 10.40s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-01-15:11:48:41,357 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-01-15:11:48:41,357 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-01-15:11:48:41,357 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-01-15:11:48:41,710 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-01-15:11:48:45,917 INFO     [__main__.py:132] Verbosity set to INFO
2025-01-15:11:48:56,333 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-01-15:11:48:56,335 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-01-15:11:48:56,343 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-01-15:11:48:56,558 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:01,  6.14it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:00<00:00,  6.94it/s]Loading checkpoint shards:  38%|███▊      | 3/8 [00:00<00:00,  7.84it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:00<00:00,  8.40it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:00<00:00,  8.75it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:00<00:00,  8.97it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:00<00:00,  9.14it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  8.66it/s]
2025-01-15:11:49:17,127 INFO     [task.py:355] Building contexts for task on rank 0...
2025-01-15:11:49:17,145 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:47, 12.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<19:03, 11.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:21, 11.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:45<17:54, 11.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:56<17:31, 11.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:07<17:12, 10.98s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:17<16:54, 10.91s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:28<16:38, 10.85s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:39<16:23, 10.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:50<16:08, 10.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [02:00<15:54, 10.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:11<15:39, 10.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:21<15:26, 10.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:32<15:13, 10.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:42<15:00, 10.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:53<14:48, 10.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:04<14:37, 10.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:14<14:26, 10.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:25<14:14, 10.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:35<14:03, 10.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:46<13:51, 10.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:56<13:39, 10.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:07<13:28, 10.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:17<13:16, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:27<13:05, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:38<12:54, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:48<12:43, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:59<12:32, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:09<12:21, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:20<12:10, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:30<11:59, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:40<11:49, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:51<11:38, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [06:01<11:27, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:12<11:17, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:22<11:06, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:33<10:56, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:43<10:45, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:53<10:34, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [07:04<10:24, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:14<10:13, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:25<10:03, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:35<09:52, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:45<09:42, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:56<09:31, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [08:06<09:20, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:16<09:10, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:27<08:59, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:37<08:48, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:47<08:38, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [08:58<08:28, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:08<08:17, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:19<08:06, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:29<07:56, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:39<07:45, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:50<07:35, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [10:00<07:24, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:10<07:13, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:21<07:03, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:31<06:53, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:41<06:42, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:51<06:31, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [11:02<06:21, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:12<06:10, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:22<06:00, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:33<05:50, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:43<05:39, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:53<05:29, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [12:03<05:18, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:14<05:08, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:24<04:58, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:34<04:47, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:45<04:37, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:55<04:26, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [13:05<04:16, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:15<04:06, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:26<03:55, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:36<03:45, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:46<03:35, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [13:56<03:24, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [14:07<03:14, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [14:17<03:04, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:27<02:54, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:37<02:43, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:47<02:33, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [14:58<02:23, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [15:08<02:12, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [15:18<02:02, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:28<01:52, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:39<01:42, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:49<01:31, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [15:59<01:21, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [16:09<01:11, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [16:19<01:01, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:30<00:51, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:40<00:40, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:50<00:30, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [16:59<00:19, 10.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [17:10<00:10, 10.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [17:20<00:00, 10.08s/it]100%|██████████| 100/100 [17:20<00:00, 10.40s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-01-15:12:07:13,475 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-01-15:12:07:13,475 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-01-15:12:07:13,475 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-01-15:12:07:13,838 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-01-15:12:07:18,127 INFO     [__main__.py:132] Verbosity set to INFO
2025-01-15:12:07:28,559 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-01-15:12:07:28,562 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-01-15:12:07:28,569 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-01-15:12:07:28,830 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:01,  5.69it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:00<00:00,  6.49it/s]Loading checkpoint shards:  38%|███▊      | 3/8 [00:00<00:00,  7.33it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:00<00:00,  7.88it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:00<00:00,  8.26it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:00<00:00,  8.51it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:00<00:00,  8.71it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  9.01it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  8.19it/s]
2025-01-15:12:07:48,308 INFO     [task.py:355] Building contexts for task on rank 0...
2025-01-15:12:07:48,326 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:40, 12.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<18:57, 11.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:14, 11.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:45<17:48, 11.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:56<17:24, 11.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:06<17:05, 10.91s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:17<16:47, 10.84s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:28<16:32, 10.79s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:38<16:16, 10.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:49<16:01, 10.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [01:59<15:48, 10.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:10<15:33, 10.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:20<15:19, 10.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:31<15:07, 10.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:41<14:54, 10.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:52<14:42, 10.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:02<14:31, 10.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:13<14:20, 10.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:23<14:09, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:34<13:57, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:44<13:45, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:55<13:33, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:05<13:22, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:15<13:11, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:26<13:00, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:36<12:49, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:46<12:38, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:57<12:27, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:07<12:16, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:17<12:05, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:28<11:54, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:38<11:44, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:49<11:33, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [05:59<11:23, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:09<11:12, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:20<11:02, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:30<10:51, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:40<10:40, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:51<10:30, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [07:01<10:19, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:11<10:09, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:22<09:59, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:32<09:48, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:42<09:38, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:52<09:27, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [08:03<09:16, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:13<09:06, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:23<08:55, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:34<08:45, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:44<08:34, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [08:54<08:24, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:05<08:13, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:15<08:03, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:25<07:53, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:35<07:42, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:46<07:31, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [09:56<07:21, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:06<07:11, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:16<07:00, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:27<06:50, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:37<06:39, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:47<06:29, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [10:57<06:18, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:07<06:08, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:18<05:57, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:28<05:47, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:38<05:37, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:48<05:27, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [11:59<05:16, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:09<05:06, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:19<04:56, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:29<04:45, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:39<04:35, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:50<04:25, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [13:00<04:14, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:10<04:04, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:20<03:54, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:30<03:44, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:40<03:33, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [13:51<03:23, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [14:01<03:13, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [14:11<03:03, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:21<02:52, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:31<02:42, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:41<02:32, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [14:52<02:22, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [15:02<02:11, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [15:12<02:01, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:22<01:51, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:32<01:41, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:42<01:31, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [15:52<01:21, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [16:03<01:10, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [16:13<01:00, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:23<00:50, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:33<00:40, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:43<00:30, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [16:53<00:19,  9.93s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [17:03<00:09,  9.98s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [17:13<00:00, 10.01s/it]100%|██████████| 100/100 [17:13<00:00, 10.33s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-01-15:12:25:37,785 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-01-15:12:25:37,785 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-01-15:12:25:37,785 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-01-15:12:25:38,154 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-01-15:12:25:42,524 INFO     [__main__.py:132] Verbosity set to INFO
2025-01-15:12:25:52,896 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-01-15:12:25:52,898 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-01-15:12:25:52,906 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-01-15:12:25:53,473 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:01,  5.83it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:00<00:00,  6.82it/s]Loading checkpoint shards:  38%|███▊      | 3/8 [00:00<00:00,  7.71it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:00<00:00,  8.27it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:00<00:00,  8.20it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:00<00:00,  8.35it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:00<00:00,  8.63it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  8.29it/s]
2025-01-15:12:26:14,289 INFO     [task.py:355] Building contexts for task on rank 0...
2025-01-15:12:26:14,307 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:34, 12.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<18:52, 11.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:11, 11.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:45<17:44, 11.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:55<17:21, 10.96s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:06<17:02, 10.88s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:17<16:45, 10.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:27<16:29, 10.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:38<16:14, 10.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:49<15:59, 10.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [01:59<15:45, 10.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:10<15:30, 10.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:20<15:17, 10.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:30<15:04, 10.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:41<14:52, 10.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:51<14:40, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:02<14:29, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:12<14:18, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:23<14:06, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:33<13:55, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:44<13:43, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:54<13:31, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:04<13:20, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:15<13:09, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:25<12:58, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:35<12:47, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:46<12:36, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:56<12:25, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:06<12:14, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:17<12:03, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:27<11:53, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:37<11:42, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:48<11:31, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [05:58<11:21, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:08<11:10, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:19<11:00, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:29<10:49, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:39<10:39, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:49<10:28, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [07:00<10:18, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:10<10:07, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:20<09:57, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:31<09:46, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:41<09:36, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:51<09:26, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [08:01<09:15, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:12<09:04, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:22<08:54, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:32<08:43, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:43<08:33, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [08:53<08:23, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:03<08:12, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:13<08:02, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:24<07:51, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:34<07:41, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:44<07:30, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [09:54<07:20, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:04<07:09, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:15<06:59, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:25<06:49, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:35<06:38, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:45<06:28, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [10:56<06:17, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:06<06:07, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:16<05:57, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:26<05:46, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:36<05:36, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:46<05:26, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [11:57<05:15, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:07<05:05, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:17<04:55, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:27<04:45, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:37<04:34, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:47<04:24, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [12:58<04:14, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:08<04:03, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:18<03:53, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:28<03:43, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:38<03:33, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [13:48<03:23, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [13:59<03:12, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [14:09<03:02, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:19<02:52, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:29<02:42, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:39<02:32, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [14:49<02:21, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [14:59<02:11, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [15:09<02:01, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:20<01:51, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:30<01:41, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:40<01:31, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [15:50<01:20, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [16:00<01:10, 10.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [16:10<01:00, 10.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:20<00:50, 10.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:30<00:40, 10.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:40<00:30, 10.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [16:50<00:19,  9.90s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [17:00<00:09,  9.95s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [17:10<00:00,  9.98s/it]100%|██████████| 100/100 [17:10<00:00, 10.30s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-01-15:12:45:10,618 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-01-15:12:45:10,619 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-01-15:12:45:10,619 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-01-15:12:45:10,966 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-01-15:12:45:15,191 INFO     [__main__.py:132] Verbosity set to INFO
2025-01-15:12:45:25,486 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-01-15:12:45:25,488 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-01-15:12:45:25,498 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-01-15:12:45:25,736 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:01,  6.12it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:00<00:00,  6.96it/s]Loading checkpoint shards:  38%|███▊      | 3/8 [00:00<00:00,  7.90it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:00<00:00,  8.46it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:00<00:00,  8.80it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:00<00:00,  9.05it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:00<00:00,  9.21it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  8.71it/s]
2025-01-15:12:45:46,219 INFO     [task.py:355] Building contexts for task on rank 0...
2025-01-15:12:45:46,237 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:33, 12.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<18:50, 11.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:08, 11.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:45<17:41, 11.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:55<17:17, 10.93s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:06<16:59, 10.84s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:16<16:41, 10.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:27<16:26, 10.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:38<16:10, 10.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:48<15:55, 10.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [01:59<15:41, 10.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:09<15:27, 10.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:20<15:13, 10.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:30<15:00, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:40<14:48, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:51<14:37, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:01<14:25, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:12<14:14, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:22<14:03, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:32<13:51, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:43<13:39, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:53<13:28, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:03<13:17, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:14<13:05, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:24<12:54, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:34<12:44, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:45<12:33, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:55<12:22, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:05<12:11, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:15<12:00, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:26<11:50, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:36<11:39, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:46<11:28, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [05:57<11:18, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:07<11:07, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:17<10:57, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:27<10:47, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:38<10:36, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:48<10:26, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [06:58<10:15, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:08<10:05, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:19<09:55, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:29<09:44, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:39<09:34, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:49<09:23, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [08:00<09:13, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:10<09:02, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:20<08:52, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:30<08:41, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:40<08:31, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [08:51<08:21, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:01<08:10, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:11<08:00, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:21<07:49, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:32<07:39, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:42<07:28, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [09:52<07:18, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:02<07:08, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:12<06:57, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:22<06:47, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:33<06:37, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:43<06:26, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [10:53<06:16, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:03<06:06, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:13<05:55, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:23<05:45, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:34<05:35, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:44<05:25, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [11:54<05:14, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:04<05:04, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:14<04:54, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:24<04:43, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:34<04:33, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:44<04:23, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [12:55<04:13, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:05<04:02, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:15<03:52, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:25<03:42, 10.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:35<03:32, 10.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [13:45<03:22, 10.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [13:55<03:11, 10.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [14:05<03:01, 10.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:15<02:51, 10.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:25<02:41, 10.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:36<02:31, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [14:46<02:21, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [14:56<02:11, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [15:06<02:00, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:16<01:50, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:26<01:40, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:36<01:30, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [15:46<01:20, 10.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [15:56<01:10, 10.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [16:06<01:00, 10.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:16<00:50, 10.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:26<00:40, 10.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:36<00:30, 10.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [16:46<00:20, 10.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [16:56<00:10, 10.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [17:06<00:00, 10.03s/it]100%|██████████| 100/100 [17:06<00:00, 10.27s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-01-15:13:03:29,199 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-01-15:13:03:29,199 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-01-15:13:03:29,199 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-01-15:13:03:29,575 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-01-15:13:03:33,987 INFO     [__main__.py:132] Verbosity set to INFO
2025-01-15:13:03:44,536 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-01-15:13:03:44,538 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-01-15:13:03:44,545 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-01-15:13:03:44,766 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:01,  5.93it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:00<00:00,  7.58it/s]Loading checkpoint shards:  38%|███▊      | 3/8 [00:00<00:00,  8.37it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:00<00:00,  8.85it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:00<00:00,  9.14it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:00<00:00,  9.33it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:00<00:00,  8.93it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  9.20it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  8.77it/s]
2025-01-15:13:04:06,607 INFO     [task.py:355] Building contexts for task on rank 0...
2025-01-15:13:04:06,626 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:40, 12.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<18:57, 11.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:14, 11.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:45<17:48, 11.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:56<17:24, 10.99s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:06<17:05, 10.91s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:17<16:48, 10.84s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:28<16:32, 10.79s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:38<16:17, 10.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:49<16:02, 10.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [01:59<15:47, 10.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:10<15:33, 10.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:20<15:20, 10.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:31<15:06, 10.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:41<14:54, 10.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:52<14:42, 10.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:02<14:31, 10.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:13<14:20, 10.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:23<14:09, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:34<13:57, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:44<13:45, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:55<13:33, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:05<13:22, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:15<13:11, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:26<13:00, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:36<12:49, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:46<12:38, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:57<12:27, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:07<12:16, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:17<12:05, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:28<11:55, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:38<11:44, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:49<11:33, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [05:59<11:22, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:09<11:12, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:20<11:02, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:30<10:51, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:40<10:40, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:51<10:30, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [07:01<10:19, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:11<10:09, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:22<09:59, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:32<09:48, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:42<09:38, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:52<09:27, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [08:03<09:17, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:13<09:06, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:23<08:55, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:34<08:45, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:44<08:34, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [08:54<08:24, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:05<08:13, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:15<08:03, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:25<07:52, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:35<07:42, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:46<07:31, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [09:56<07:21, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:06<07:11, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:16<07:00, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:27<06:50, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:37<06:39, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:47<06:29, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [10:57<06:18, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:08<06:08, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:18<05:58, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:28<05:47, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:38<05:37, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:48<05:27, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [11:59<05:16, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:09<05:06, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:19<04:56, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:29<04:45, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:39<04:35, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:50<04:25, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [13:00<04:14, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:10<04:04, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:20<03:54, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:30<03:44, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:41<03:33, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [13:51<03:23, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [14:01<03:13, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [14:11<03:03, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:21<02:52, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:31<02:42, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:41<02:32, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [14:52<02:22, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [15:02<02:11, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [15:12<02:01, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:22<01:51, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:32<01:41, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:42<01:31, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [15:52<01:21, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [16:03<01:10, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [16:13<01:00, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:23<00:50, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:33<00:40, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:43<00:30, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [16:53<00:20, 10.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [17:03<00:10, 10.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [17:13<00:00, 10.10s/it]100%|██████████| 100/100 [17:13<00:00, 10.34s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-01-15:13:21:56,852 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-01-15:13:21:56,852 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-01-15:13:21:56,852 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-01-15:13:21:57,206 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-01-15:13:22:01,410 INFO     [__main__.py:132] Verbosity set to INFO
2025-01-15:13:22:11,768 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-01-15:13:22:11,770 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-01-15:13:22:11,776 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-01-15:13:22:11,998 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:01,  4.79it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:00<00:01,  5.84it/s]Loading checkpoint shards:  38%|███▊      | 3/8 [00:00<00:00,  6.56it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:00<00:00,  6.62it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:00<00:00,  7.05it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:00<00:00,  7.11it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:01<00:00,  7.26it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:01<00:00,  7.60it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:01<00:00,  6.97it/s]
2025-01-15:13:22:33,290 INFO     [task.py:355] Building contexts for task on rank 0...
2025-01-15:13:22:33,308 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:30, 12.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<18:53, 11.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:13, 11.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:45<17:48, 11.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:56<17:26, 11.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:06<17:07, 10.93s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:17<16:49, 10.85s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:28<16:33, 10.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:38<16:18, 10.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:49<16:03, 10.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [01:59<15:48, 10.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:10<15:34, 10.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:21<15:20, 10.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:31<15:07, 10.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:41<14:55, 10.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:52<14:43, 10.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:02<14:32, 10.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:13<14:20, 10.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:23<14:09, 10.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:34<13:57, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:44<13:46, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:55<13:34, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:05<13:23, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:15<13:11, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:26<13:00, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:36<12:49, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:47<12:39, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:57<12:28, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:07<12:17, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:18<12:06, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:28<11:55, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:38<11:45, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:49<11:33, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [05:59<11:23, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:09<11:13, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:20<11:02, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:30<10:52, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:41<10:41, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:51<10:31, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [07:01<10:20, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:12<10:10, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:22<09:59, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:32<09:49, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:43<09:38, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:53<09:28, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [08:03<09:17, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:13<09:06, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:24<08:56, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:34<08:45, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:44<08:35, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [08:55<08:25, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:05<08:14, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:15<08:03, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:26<07:53, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:36<07:42, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:46<07:32, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [09:56<07:21, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:07<07:11, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:17<07:01, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:27<06:50, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:37<06:40, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:48<06:29, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [10:58<06:19, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:08<06:08, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:18<05:58, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:29<05:48, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:39<05:37, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:49<05:27, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [11:59<05:17, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:09<05:06, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:20<04:56, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:30<04:46, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:40<04:35, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:50<04:25, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [13:00<04:15, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:11<04:04, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:21<03:54, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:31<03:44, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:41<03:33, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [13:51<03:23, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [14:02<03:13, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [14:12<03:03, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:22<02:52, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:32<02:42, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:42<02:32, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [14:52<02:22, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [15:03<02:12, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [15:13<02:01, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:23<01:51, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:33<01:41, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:43<01:31, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [15:53<01:21, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [16:03<01:11, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [16:14<01:00, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:24<00:50, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:34<00:40, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:44<00:30, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [16:54<00:20, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [17:04<00:10, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [17:14<00:00, 10.11s/it]100%|██████████| 100/100 [17:14<00:00, 10.35s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-01-15:13:40:24,068 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-01-15:13:40:24,068 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-01-15:13:40:24,068 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-01-15:13:40:24,424 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-01-15:13:40:28,749 INFO     [__main__.py:132] Verbosity set to INFO
2025-01-15:13:40:39,349 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-01-15:13:40:39,351 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-01-15:13:40:39,359 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-01-15:13:40:39,583 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:01,  5.60it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:00<00:00,  7.23it/s]Loading checkpoint shards:  38%|███▊      | 3/8 [00:00<00:00,  7.97it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:00<00:00,  8.42it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:00<00:00,  8.10it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:00<00:00,  8.52it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:00<00:00,  8.77it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  8.41it/s]
2025-01-15:13:40:59,812 INFO     [task.py:355] Building contexts for task on rank 0...
2025-01-15:13:40:59,831 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:33, 12.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<18:51, 11.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:09, 11.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:45<17:44, 11.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:55<17:20, 10.95s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:06<17:01, 10.87s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:17<16:43, 10.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:27<16:28, 10.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:38<16:13, 10.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:48<15:58, 10.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [01:59<15:44, 10.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:09<15:29, 10.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:20<15:16, 10.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:30<15:03, 10.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:41<14:51, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:51<14:39, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:02<14:27, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:12<14:16, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:22<14:05, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:33<13:53, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:43<13:41, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:54<13:30, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:04<13:17, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:14<13:05, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:24<12:53, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:35<12:41, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:45<12:30, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:55<12:19, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:05<12:08, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:16<11:57, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:26<11:47, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:36<11:36, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:46<11:25, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [05:57<11:15, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:07<11:05, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:17<10:54, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:27<10:44, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:37<10:33, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:48<10:23, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [06:58<10:12, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:08<10:02, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:18<09:52, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:28<09:42, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:39<09:31, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:49<09:21, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [07:59<09:10, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:09<09:00, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:19<08:49, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:30<08:39, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:40<08:29, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [08:50<08:18, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:00<08:08, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:10<07:57, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:20<07:47, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:31<07:37, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:41<07:26, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [09:51<07:16, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:01<07:06, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:11<06:55, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:21<06:45, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:31<06:35, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:41<06:24, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [10:52<06:14, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:02<06:04, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:12<05:54, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:22<05:43, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:32<05:33, 10.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:42<05:23, 10.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [11:52<05:13, 10.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:02<05:02, 10.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:12<04:52, 10.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:22<04:42, 10.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:33<04:32, 10.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:43<04:22, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [12:53<04:11, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:03<04:01, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:13<03:51, 10.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:23<03:41, 10.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:33<03:31, 10.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [13:43<03:21, 10.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [13:53<03:11, 10.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [14:03<03:00, 10.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:13<02:50, 10.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:23<02:40, 10.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:33<02:30, 10.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [14:43<02:20, 10.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [14:53<02:10, 10.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [15:03<02:00, 10.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:13<01:50, 10.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:23<01:40, 10.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:33<01:30, 10.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [15:43<01:20, 10.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [15:53<01:10, 10.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [16:03<01:00, 10.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:13<00:50, 10.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:23<00:40, 10.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:33<00:30, 10.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [16:43<00:19, 10.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [16:53<00:09,  9.99s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [17:03<00:00,  9.99s/it]100%|██████████| 100/100 [17:03<00:00, 10.24s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-01-15:13:58:39,835 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-01-15:13:58:39,835 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-01-15:13:58:39,835 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-01-15:13:58:40,202 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-01-15:13:58:44,600 INFO     [__main__.py:132] Verbosity set to INFO
2025-01-15:13:58:55,524 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-01-15:13:58:55,527 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-01-15:13:58:55,535 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-01-15:13:58:55,755 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:01,  5.66it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:00<00:00,  7.12it/s]Loading checkpoint shards:  38%|███▊      | 3/8 [00:00<00:00,  7.37it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:00<00:00,  8.00it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:00<00:00,  8.40it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:00<00:00,  8.69it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:00<00:00,  8.88it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  9.18it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  8.38it/s]
2025-01-15:13:59:17,107 INFO     [task.py:355] Building contexts for task on rank 0...
2025-01-15:13:59:17,125 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:41, 12.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<18:58, 11.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:16, 11.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:45<17:49, 11.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:56<17:25, 11.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:06<17:06, 10.92s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:17<16:49, 10.85s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:28<16:33, 10.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:38<16:18, 10.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:49<16:03, 10.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [02:00<15:49, 10.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:10<15:34, 10.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:21<15:21, 10.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:31<15:08, 10.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:42<14:55, 10.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:52<14:44, 10.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:03<14:32, 10.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:13<14:21, 10.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:24<14:10, 10.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:34<13:58, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:44<13:46, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:55<13:34, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:05<13:23, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:16<13:12, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:26<13:01, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:36<12:50, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:47<12:39, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:57<12:28, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:08<12:17, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:18<12:06, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:28<11:56, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:39<11:45, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:49<11:34, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [05:59<11:23, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:10<11:13, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:20<11:03, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:30<10:52, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:41<10:41, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:51<10:31, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [07:01<10:20, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:12<10:10, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:22<10:00, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:32<09:49, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:43<09:38, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:53<09:28, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [08:03<09:17, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:14<09:07, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:24<08:56, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:34<08:46, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:45<08:35, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [08:55<08:25, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:05<08:14, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:16<08:04, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:26<07:53, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:36<07:43, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:46<07:32, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [09:57<07:22, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:07<07:11, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:17<07:01, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:27<06:50, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:38<06:40, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:48<06:29, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [10:58<06:19, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:08<06:09, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:19<05:58, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:29<05:48, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:39<05:37, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:49<05:27, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [12:00<05:17, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:10<05:06, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:20<04:56, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:30<04:46, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:41<04:35, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:51<04:25, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [13:01<04:15, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:11<04:04, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:21<03:54, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:31<03:44, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:42<03:34, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [13:52<03:23, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [14:02<03:13, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [14:12<03:03, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:22<02:53, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:33<02:42, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:43<02:32, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [14:53<02:22, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [15:03<02:12, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [15:13<02:01, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:23<01:51, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:34<01:41, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:44<01:31, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [15:54<01:21, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [16:04<01:11, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [16:14<01:00, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:24<00:50, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:34<00:40, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:44<00:30, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [16:55<00:20, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [17:05<00:10, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [17:15<00:00, 10.12s/it]100%|██████████| 100/100 [17:15<00:00, 10.35s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-01-15:14:18:19,084 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-01-15:14:18:19,084 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-01-15:14:18:19,084 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-01-15:14:18:19,450 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-01-15:14:18:23,687 INFO     [__main__.py:132] Verbosity set to INFO
2025-01-15:14:18:34,013 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-01-15:14:18:34,015 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-01-15:14:18:34,024 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-01-15:14:18:34,238 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:01,  5.41it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:00<00:00,  7.02it/s]Loading checkpoint shards:  38%|███▊      | 3/8 [00:00<00:00,  7.86it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:00<00:00,  7.74it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:00<00:00,  8.25it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:00<00:00,  8.61it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:00<00:00,  8.88it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  8.35it/s]
2025-01-15:14:18:55,015 INFO     [task.py:355] Building contexts for task on rank 0...
2025-01-15:14:18:55,033 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:41, 12.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<18:58, 11.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:16, 11.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:45<17:50, 11.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:56<17:27, 11.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:07<17:18, 11.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:17<16:57, 10.94s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:28<16:39, 10.86s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:39<16:22, 10.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:49<16:06, 10.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [02:00<15:52, 10.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:11<15:37, 10.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:21<15:23, 10.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:32<15:10, 10.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:42<14:57, 10.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:53<14:45, 10.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:03<14:34, 10.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:14<14:22, 10.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:24<14:11, 10.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:35<13:59, 10.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:45<13:48, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:55<13:36, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:06<13:25, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:16<13:13, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:27<13:02, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:37<12:51, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:48<12:40, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:58<12:29, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:08<12:18, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:19<12:07, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:29<11:57, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:39<11:46, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:50<11:35, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [06:00<11:25, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:11<11:14, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:21<11:04, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:31<10:53, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:42<10:42, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:52<10:32, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [07:02<10:21, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:13<10:11, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:23<10:01, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:33<09:50, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:44<09:39, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:54<09:29, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [08:04<09:18, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:15<09:08, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:25<08:57, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:35<08:46, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:46<08:36, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [08:56<08:26, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:06<08:15, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:17<08:04, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:27<07:54, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:37<07:43, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:48<07:33, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [09:58<07:23, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:08<07:12, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:18<07:01, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:29<06:51, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:39<06:40, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:49<06:30, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [11:00<06:19, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:10<06:09, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:20<05:59, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:30<05:48, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:41<05:38, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:51<05:28, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [12:01<05:17, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:11<05:07, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:22<04:57, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:32<04:46, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:42<04:36, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:52<04:25, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [13:02<04:15, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:13<04:05, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:23<03:54, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:33<03:44, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:43<03:34, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [13:53<03:24, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [14:04<03:13, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [14:14<03:03, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:24<02:53, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:34<02:43, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:44<02:32, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [14:55<02:22, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [15:05<02:12, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [15:15<02:02, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:25<01:51, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:35<01:41, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:45<01:31, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [15:56<01:21, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [16:06<01:11, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [16:16<01:00, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:26<00:50, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:36<00:40, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:46<00:30, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [16:56<00:20, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [17:07<00:10, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [17:17<00:00, 10.14s/it]100%|██████████| 100/100 [17:17<00:00, 10.37s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-01-15:14:36:48,500 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-01-15:14:36:48,500 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-01-15:14:36:48,500 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-01-15:14:36:48,860 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-01-15:14:36:53,259 INFO     [__main__.py:132] Verbosity set to INFO
2025-01-15:14:37:03,648 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-01-15:14:37:03,649 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-01-15:14:37:03,657 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-01-15:14:37:03,877 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:01,  5.15it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:00<00:00,  6.92it/s]Loading checkpoint shards:  38%|███▊      | 3/8 [00:00<00:00,  7.84it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:00<00:00,  8.38it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:00<00:00,  8.10it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:00<00:00,  8.51it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:00<00:00,  8.79it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  9.14it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  8.32it/s]
2025-01-15:14:37:23,564 INFO     [task.py:355] Building contexts for task on rank 0...
2025-01-15:14:37:23,582 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:41, 12.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<18:56, 11.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:14, 11.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:45<17:47, 11.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:56<17:24, 10.99s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:06<17:05, 10.91s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:17<16:47, 10.84s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:28<16:32, 10.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:38<16:16, 10.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:49<16:01, 10.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [01:59<15:47, 10.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:10<15:33, 10.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:20<15:19, 10.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:31<15:06, 10.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:41<14:54, 10.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:52<14:42, 10.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:02<14:31, 10.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:13<14:19, 10.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:23<14:08, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:34<13:56, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:44<13:45, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:54<13:33, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:05<13:22, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:15<13:10, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:26<12:59, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:36<12:48, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:46<12:37, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:57<12:27, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:07<12:16, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:17<12:05, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:28<11:54, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:38<11:44, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:48<11:33, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [05:59<11:22, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:09<11:12, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:19<11:01, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:30<10:51, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:40<10:40, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:50<10:30, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [07:01<10:19, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:11<10:09, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:21<09:58, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:32<09:48, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:42<09:37, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:52<09:27, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [08:03<09:16, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:13<09:06, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:23<08:55, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:34<08:45, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:44<08:34, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [08:54<08:24, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:04<08:13, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:15<08:03, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:25<07:52, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:35<07:42, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:45<07:31, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [09:56<07:21, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:06<07:10, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:16<07:00, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:26<06:50, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:37<06:39, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:47<06:29, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [10:57<06:18, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:07<06:08, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:18<05:57, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:28<05:47, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:38<05:37, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:48<05:26, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [11:58<05:16, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:09<05:06, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:19<04:56, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:29<04:45, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:39<04:35, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:49<04:24, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [13:00<04:14, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:10<04:04, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:20<03:54, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:30<03:43, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:40<03:33, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [13:50<03:23, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [14:01<03:13, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [14:11<03:02, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:21<02:52, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:31<02:42, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:41<02:32, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [14:51<02:22, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [15:01<02:11, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [15:12<02:01, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:22<01:51, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:32<01:41, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:42<01:31, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [15:52<01:21, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [16:02<01:10, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [16:12<01:00, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:22<00:50, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:33<00:40, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:43<00:30, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [16:53<00:20, 10.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [17:03<00:10, 10.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [17:13<00:00, 10.10s/it]100%|██████████| 100/100 [17:13<00:00, 10.33s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-01-15:14:55:12,983 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-01-15:14:55:12,983 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-01-15:14:55:12,983 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-01-15:14:55:13,341 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-01-15:14:55:17,637 INFO     [__main__.py:132] Verbosity set to INFO
2025-01-15:14:55:28,003 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-01-15:14:55:28,005 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-01-15:14:55:28,012 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-01-15:14:55:28,230 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:01,  5.48it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:00<00:00,  7.24it/s]Loading checkpoint shards:  38%|███▊      | 3/8 [00:00<00:00,  8.17it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:00<00:00,  8.74it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:00<00:00,  8.51it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:00<00:00,  8.92it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:00<00:00,  9.21it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  8.72it/s]
2025-01-15:14:55:47,440 INFO     [task.py:355] Building contexts for task on rank 0...
2025-01-15:14:55:47,459 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:38, 12.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<18:56, 11.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:14, 11.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:45<17:48, 11.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:56<17:25, 11.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:06<17:06, 10.92s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:17<16:48, 10.85s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:28<16:33, 10.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:38<16:18, 10.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:49<16:02, 10.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [02:00<15:48, 10.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:10<15:34, 10.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:21<15:20, 10.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:31<15:08, 10.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:42<14:55, 10.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:52<14:44, 10.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:03<14:32, 10.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:13<14:21, 10.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:23<14:10, 10.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:34<13:58, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:44<13:46, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:55<13:35, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:05<13:23, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:16<13:12, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:26<13:01, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:36<12:50, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:47<12:39, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:57<12:28, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:07<12:17, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:18<12:06, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:28<11:56, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:39<11:45, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:49<11:34, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [05:59<11:24, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:10<11:13, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:20<11:02, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:30<10:52, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:41<10:41, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:51<10:31, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [07:01<10:20, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:12<10:10, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:22<10:00, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:32<09:49, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:43<09:38, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:53<09:28, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [08:03<09:17, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:14<09:07, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:24<08:56, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:34<08:46, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:45<08:35, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [08:55<08:25, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:05<08:14, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:16<08:04, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:26<07:53, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:36<07:43, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:46<07:32, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [09:57<07:22, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:07<07:11, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:17<07:01, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:27<06:50, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:38<06:40, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:48<06:29, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [10:58<06:19, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:08<06:08, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:19<05:58, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:29<05:48, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:39<05:37, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:49<05:27, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [12:00<05:17, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:10<05:06, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:20<04:56, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:30<04:46, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:40<04:35, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:51<04:25, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [13:01<04:15, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:11<04:04, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:21<03:54, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:31<03:44, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:42<03:34, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [13:52<03:23, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [14:02<03:13, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [14:12<03:03, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:22<02:53, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:32<02:42, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:43<02:32, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [14:53<02:22, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [15:03<02:12, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [15:13<02:01, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:23<01:51, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:33<01:41, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:44<01:31, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [15:54<01:21, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [16:04<01:11, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [16:14<01:00, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:24<00:50, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:34<00:40, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:44<00:30, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [16:54<00:20, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [17:05<00:10, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [17:15<00:00, 10.12s/it]100%|██████████| 100/100 [17:15<00:00, 10.35s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-01-15:15:13:38,651 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-01-15:15:13:38,651 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-01-15:15:13:38,651 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-01-15:15:13:39,012 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-01-15:15:13:43,218 INFO     [__main__.py:132] Verbosity set to INFO
2025-01-15:15:13:53,544 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-01-15:15:13:53,546 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-01-15:15:13:53,554 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-01-15:15:13:53,771 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:01,  5.77it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:00<00:00,  6.90it/s]Loading checkpoint shards:  38%|███▊      | 3/8 [00:00<00:00,  7.47it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:00<00:00,  8.04it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:00<00:00,  8.43it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:00<00:00,  8.72it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:00<00:00,  8.90it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  9.22it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  8.40it/s]
2025-01-15:15:14:13,713 INFO     [task.py:355] Building contexts for task on rank 0...
2025-01-15:15:14:13,731 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:23, 12.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<18:45, 11.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:04, 11.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:44<17:39, 11.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:55<17:15, 10.91s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:06<16:57, 10.82s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:16<16:39, 10.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:27<16:24, 10.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:37<16:09, 10.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:48<15:54, 10.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [01:58<15:40, 10.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:09<15:26, 10.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:19<15:12, 10.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:30<14:59, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:40<14:47, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:50<14:35, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:01<14:24, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:11<14:13, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:22<14:02, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:32<13:50, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:42<13:39, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:53<13:27, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:03<13:16, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:13<13:04, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:24<12:53, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:34<12:43, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:44<12:32, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:54<12:21, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:05<12:10, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:15<12:00, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:25<11:49, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:35<11:38, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:46<11:28, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [05:56<11:18, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:06<11:07, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:17<10:57, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:27<10:46, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:37<10:36, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:47<10:25, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [06:58<10:15, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:08<10:04, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:18<09:54, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:28<09:43, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:38<09:33, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:49<09:22, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [07:59<09:12, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:09<09:01, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:19<08:51, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:30<08:41, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:40<08:30, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [08:50<08:20, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:00<08:09, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:10<07:59, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:21<07:49, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:31<07:38, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:41<07:28, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [09:51<07:18, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:01<07:07, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:11<06:57, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:22<06:46, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:32<06:36, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:42<06:26, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [10:52<06:15, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:02<06:05, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:12<05:55, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:22<05:44, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:33<05:34, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:43<05:24, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [11:53<05:14, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:03<05:04, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:13<04:53, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:23<04:43, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:33<04:33, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:43<04:22, 10.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [12:54<04:12, 10.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:04<04:02, 10.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:14<03:52, 10.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:24<03:42, 10.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:34<03:31, 10.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [13:44<03:21, 10.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [13:54<03:11, 10.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [14:04<03:01, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:14<02:51, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:24<02:41, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:34<02:31, 10.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [14:44<02:20, 10.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [14:54<02:10, 10.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [15:05<02:00, 10.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:15<01:50, 10.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:25<01:40, 10.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:35<01:30, 10.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [15:45<01:20, 10.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [15:55<01:10, 10.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [16:05<01:00, 10.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:15<00:50, 10.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:25<00:40, 10.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:35<00:30, 10.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [16:45<00:20, 10.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [16:55<00:10, 10.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [17:05<00:00, 10.02s/it]100%|██████████| 100/100 [17:05<00:00, 10.26s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-01-15:15:31:55,456 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-01-15:15:31:55,456 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-01-15:15:31:55,456 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-01-15:15:31:55,825 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-01-15:15:32:00,054 INFO     [__main__.py:132] Verbosity set to INFO
2025-01-15:15:32:10,253 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-01-15:15:32:10,255 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-01-15:15:32:10,264 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-01-15:15:32:10,487 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:01,  6.27it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:00<00:00,  8.00it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:00<00:00,  9.21it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:00<00:00,  9.65it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  9.57it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  9.23it/s]
2025-01-15:15:32:30,771 INFO     [task.py:355] Building contexts for task on rank 0...
2025-01-15:15:32:30,789 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:28, 12.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<18:47, 11.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:06, 11.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:44<17:40, 11.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:55<17:16, 10.91s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:06<16:58, 10.83s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:16<16:40, 10.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:27<16:25, 10.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:38<16:09, 10.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:48<15:54, 10.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [01:59<15:40, 10.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:09<15:26, 10.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:19<15:12, 10.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:30<15:00, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:40<14:48, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:51<14:36, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:01<14:25, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:11<14:13, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:22<14:02, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:32<13:51, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:42<13:39, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:53<13:28, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:03<13:16, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:13<13:05, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:24<12:54, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:34<12:43, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:44<12:32, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:55<12:22, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:05<12:11, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:15<12:00, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:25<11:49, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:36<11:39, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:46<11:28, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [05:56<11:18, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:07<11:07, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:17<10:57, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:27<10:46, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:37<10:36, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:48<10:25, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [06:58<10:15, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:08<10:05, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:18<09:56, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:29<09:45, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:39<09:34, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:49<09:23, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [07:59<09:13, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:10<09:02, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:20<08:52, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:30<08:41, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:40<08:31, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [08:50<08:21, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:01<08:10, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:11<07:59, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:21<07:49, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:31<07:39, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:41<07:28, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [09:52<07:18, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:02<07:07, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:12<06:57, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:22<06:47, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:32<06:36, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:42<06:26, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [10:53<06:16, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:03<06:05, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:13<05:55, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:23<05:45, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:33<05:34, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:43<05:24, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [11:53<05:14, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:04<05:04, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:14<04:53, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:24<04:43, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:34<04:33, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:44<04:23, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [12:54<04:12, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:04<04:02, 10.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:14<03:52, 10.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:24<03:42, 10.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:35<03:32, 10.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [13:45<03:21, 10.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [13:55<03:11, 10.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [14:05<03:01, 10.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:15<02:51, 10.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:25<02:41, 10.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:35<02:31, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [14:45<02:21, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [14:55<02:11, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [15:05<02:00, 10.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:15<01:50, 10.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:25<01:40, 10.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:36<01:30, 10.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [15:46<01:20, 10.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [15:56<01:10, 10.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [16:06<01:00, 10.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:16<00:50, 10.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:26<00:40, 10.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:36<00:30, 10.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [16:46<00:20, 10.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [16:56<00:10, 10.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [17:06<00:00, 10.03s/it]100%|██████████| 100/100 [17:06<00:00, 10.26s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-01-15:15:51:23,178 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-01-15:15:51:23,178 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-01-15:15:51:23,178 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-01-15:15:51:23,516 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-01-15:15:51:27,835 INFO     [__main__.py:132] Verbosity set to INFO
2025-01-15:15:51:38,235 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-01-15:15:51:38,237 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-01-15:15:51:38,245 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-01-15:15:51:38,467 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:01,  6.14it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:00<00:00,  7.70it/s]Loading checkpoint shards:  38%|███▊      | 3/8 [00:00<00:00,  7.64it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:00<00:00,  8.26it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:00<00:00,  8.62it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:00<00:00,  8.90it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:00<00:00,  9.10it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  8.66it/s]
2025-01-15:15:51:58,675 INFO     [task.py:355] Building contexts for task on rank 0...
2025-01-15:15:51:58,694 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:28, 12.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<18:47, 11.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:05, 11.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:44<17:39, 11.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:55<17:16, 10.91s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:06<16:58, 10.83s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:16<16:40, 10.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:27<16:24, 10.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:38<16:09, 10.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:48<15:54, 10.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [01:58<15:40, 10.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:09<15:26, 10.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:19<15:12, 10.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:30<15:00, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:40<14:47, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:51<14:36, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:01<14:25, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:11<14:13, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:22<14:02, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:32<13:50, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:42<13:39, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:53<13:27, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:03<13:16, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:13<13:05, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:24<12:54, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:34<12:41, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:44<12:30, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:54<12:18, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:05<12:07, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:15<11:56, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:25<11:45, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:35<11:34, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:45<11:24, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [05:56<11:13, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:06<11:03, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:16<10:53, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:26<10:42, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:36<10:32, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:47<10:21, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [06:57<10:11, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:07<10:01, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:17<09:50, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:27<09:40, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:37<09:29, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:48<09:19, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [07:58<09:09, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:08<08:58, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:18<08:48, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:28<08:38, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:38<08:27, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [08:48<08:17, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [08:59<08:07, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:09<07:56, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:19<07:46, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:29<07:35, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:39<07:25, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [09:49<07:15, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [09:59<07:04, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:09<06:54, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:20<06:44, 10.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:30<06:34, 10.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:40<06:23, 10.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [10:50<06:13, 10.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:00<06:03, 10.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:10<05:53, 10.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:20<05:42, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:30<05:32, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:40<05:22, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [11:50<05:12, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:00<05:02, 10.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:10<04:52, 10.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:20<04:41, 10.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:30<04:31, 10.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:41<04:21, 10.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [12:51<04:11, 10.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:01<04:01, 10.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:11<03:50, 10.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:21<03:40, 10.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:31<03:30, 10.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [13:41<03:20, 10.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [13:51<03:10, 10.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [14:01<03:00, 10.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:11<02:50, 10.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:21<02:40, 10.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:31<02:30, 10.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [14:41<02:20, 10.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [14:51<02:10, 10.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [15:01<02:00, 10.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:11<01:50, 10.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:21<01:40, 10.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:31<01:30, 10.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [15:41<01:19, 10.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [15:51<01:09,  9.99s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [16:01<00:59,  9.99s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:11<00:49,  9.99s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:21<00:39,  9.98s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:31<00:29,  9.98s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [16:41<00:19,  9.97s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [16:51<00:09,  9.97s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [17:01<00:00,  9.96s/it]100%|██████████| 100/100 [17:01<00:00, 10.21s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-01-15:16:09:35,815 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-01-15:16:09:35,816 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-01-15:16:09:35,816 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-01-15:16:09:36,178 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-01-15:16:09:40,737 INFO     [__main__.py:132] Verbosity set to INFO
2025-01-15:16:09:51,262 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-01-15:16:09:51,264 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-01-15:16:09:51,271 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-01-15:16:09:51,493 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:01,  6.12it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:00<00:00,  6.83it/s]Loading checkpoint shards:  38%|███▊      | 3/8 [00:00<00:00,  7.64it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:00<00:00,  8.15it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:00<00:00,  8.48it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:00<00:00,  8.63it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:00<00:00,  8.80it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  8.41it/s]
2025-01-15:16:10:12,162 INFO     [task.py:355] Building contexts for task on rank 0...
2025-01-15:16:10:12,180 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:37, 12.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<18:56, 11.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:14, 11.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:45<17:49, 11.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:56<17:25, 11.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:06<17:06, 10.92s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:17<16:49, 10.85s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:28<16:33, 10.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:38<16:18, 10.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:49<16:03, 10.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [02:00<15:49, 10.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:10<15:34, 10.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:21<15:21, 10.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:31<15:08, 10.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:42<14:56, 10.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:52<14:44, 10.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:03<14:32, 10.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:13<14:21, 10.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:24<14:10, 10.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:34<13:58, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:44<13:47, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:55<13:35, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:05<13:24, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:16<13:12, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:26<13:01, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:36<12:50, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:47<12:39, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:57<12:28, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:08<12:17, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:18<12:07, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:28<11:56, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:39<11:45, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:49<11:34, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [05:59<11:24, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:10<11:13, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:20<11:03, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:31<10:52, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:41<10:42, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:51<10:31, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [07:02<10:21, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:12<10:10, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:22<10:00, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:33<09:49, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:43<09:39, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:53<09:28, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [08:04<09:18, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:14<09:07, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:24<08:56, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:35<08:46, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:45<08:35, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [08:55<08:25, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:05<08:14, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:16<08:04, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:26<07:53, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:36<07:43, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:47<07:32, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [09:57<07:22, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:07<07:11, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:17<07:01, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:28<06:50, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:38<06:40, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:48<06:29, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [10:58<06:19, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:09<06:09, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:19<05:58, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:29<05:48, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:39<05:38, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:50<05:27, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [12:00<05:17, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:10<05:07, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:20<04:56, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:31<04:46, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:41<04:35, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:51<04:25, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [13:01<04:15, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:11<04:04, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:22<03:54, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:32<03:44, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:42<03:34, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [13:52<03:23, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [14:02<03:13, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [14:12<03:03, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:23<02:53, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:33<02:42, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:43<02:32, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [14:53<02:22, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [15:03<02:12, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [15:13<02:02, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:24<01:51, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:34<01:41, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:44<01:31, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [15:54<01:21, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [16:04<01:11, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [16:14<01:00, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:25<00:50, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:35<00:40, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:45<00:30, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [16:55<00:20, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [17:05<00:10, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [17:15<00:00, 10.12s/it]100%|██████████| 100/100 [17:15<00:00, 10.36s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-01-15:16:28:03,805 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-01-15:16:28:03,805 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-01-15:16:28:03,806 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-01-15:16:28:04,170 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-01-15:16:28:08,475 INFO     [__main__.py:132] Verbosity set to INFO
2025-01-15:16:28:19,303 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-01-15:16:28:19,305 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-01-15:16:28:19,313 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-01-15:16:28:19,531 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:01,  5.95it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:00<00:00,  6.97it/s]Loading checkpoint shards:  38%|███▊      | 3/8 [00:00<00:00,  7.61it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:00<00:00,  8.21it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:00<00:00,  8.59it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:00<00:00,  8.83it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:00<00:00,  9.01it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  9.30it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  8.52it/s]
2025-01-15:16:28:40,171 INFO     [task.py:355] Building contexts for task on rank 0...
2025-01-15:16:28:40,190 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:37, 12.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<18:56, 11.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:14, 11.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:45<17:48, 11.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:56<17:25, 11.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:06<17:06, 10.92s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:17<16:48, 10.85s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:28<16:33, 10.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:38<16:18, 10.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:49<16:02, 10.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [02:00<15:49, 10.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:10<15:34, 10.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:21<15:20, 10.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:31<15:08, 10.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:42<14:55, 10.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:52<14:44, 10.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:03<14:32, 10.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:13<14:21, 10.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:23<14:10, 10.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:34<13:58, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:44<13:46, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:55<13:35, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:05<13:23, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:16<13:12, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:26<13:01, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:36<12:50, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:47<12:39, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:57<12:28, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:08<12:17, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:18<12:06, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:28<11:56, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:39<11:45, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:49<11:34, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [05:59<11:24, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:10<11:13, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:20<11:02, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:30<10:52, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:41<10:41, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:51<10:31, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [07:01<10:20, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:12<10:10, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:22<10:00, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:32<09:49, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:43<09:38, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:53<09:28, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [08:03<09:17, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:14<09:07, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:24<08:56, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:34<08:46, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:45<08:35, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [08:55<08:25, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:05<08:14, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:16<08:04, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:26<07:53, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:36<07:43, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:46<07:32, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [09:57<07:22, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:07<07:11, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:17<07:01, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:27<06:50, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:38<06:40, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:48<06:29, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [10:58<06:19, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:08<06:09, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:19<05:58, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:29<05:48, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:39<05:37, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:49<05:27, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [12:00<05:17, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:10<05:06, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:20<04:56, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:30<04:46, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:40<04:35, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:51<04:25, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [13:01<04:15, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:11<04:04, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:21<03:54, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:31<03:44, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:42<03:34, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [13:52<03:23, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [14:02<03:13, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [14:12<03:03, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:22<02:53, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:33<02:42, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:43<02:32, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [14:53<02:22, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [15:03<02:12, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [15:13<02:01, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:23<01:51, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:33<01:41, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:44<01:31, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [15:54<01:21, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [16:04<01:11, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [16:14<01:00, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:24<00:50, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:34<00:40, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:44<00:30, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [16:55<00:20, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [17:05<00:10, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [17:15<00:00, 10.12s/it]100%|██████████| 100/100 [17:15<00:00, 10.35s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-01-15:16:46:31,580 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-01-15:16:46:31,580 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-01-15:16:46:31,580 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-01-15:16:46:31,940 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-01-15:16:46:36,182 INFO     [__main__.py:132] Verbosity set to INFO
2025-01-15:16:46:46,349 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-01-15:16:46:46,351 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-01-15:16:46:46,358 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-01-15:16:46:46,583 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:01,  5.18it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:00<00:00,  6.83it/s]Loading checkpoint shards:  38%|███▊      | 3/8 [00:00<00:00,  7.78it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:00<00:00,  8.38it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:00<00:00,  8.18it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:00<00:00,  8.60it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:00<00:00,  8.88it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  8.37it/s]
2025-01-15:16:47:09,553 INFO     [task.py:355] Building contexts for task on rank 0...
2025-01-15:16:47:09,573 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:36, 12.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<18:54, 11.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:12, 11.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:45<17:46, 11.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:55<17:22, 10.98s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:06<17:04, 10.89s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:17<16:46, 10.82s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:28<16:30, 10.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:38<16:15, 10.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:49<16:00, 10.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [01:59<15:46, 10.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:10<15:32, 10.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:20<15:18, 10.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:31<15:05, 10.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:41<14:53, 10.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:52<14:41, 10.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:02<14:30, 10.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:13<14:19, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:23<14:08, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:33<13:56, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:44<13:44, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:54<13:33, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:05<13:21, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:15<13:10, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:25<12:59, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:36<12:48, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:46<12:37, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:56<12:26, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:07<12:15, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:17<12:04, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:27<11:54, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:38<11:43, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:48<11:32, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [05:58<11:22, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:09<11:11, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:19<11:01, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:29<10:50, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:40<10:40, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:50<10:29, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [07:00<10:19, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:11<10:08, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:21<09:58, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:31<09:47, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:42<09:37, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:52<09:26, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [08:02<09:16, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:12<09:05, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:23<08:55, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:33<08:44, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:43<08:34, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [08:54<08:23, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:04<08:13, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:14<08:02, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:24<07:52, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:35<07:41, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:45<07:31, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [09:55<07:21, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:05<07:10, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:16<07:00, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:26<06:49, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:36<06:39, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:46<06:28, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [10:56<06:18, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:07<06:08, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:17<05:57, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:27<05:47, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:37<05:36, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:48<05:26, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [11:58<05:16, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:08<05:06, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:18<04:55, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:28<04:45, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:38<04:35, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:49<04:24, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [12:59<04:14, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:09<04:04, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:19<03:53, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:29<03:43, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:39<03:33, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [13:50<03:23, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [14:00<03:13, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [14:10<03:02, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:20<02:52, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:30<02:42, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:40<02:32, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [14:50<02:21, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [15:01<02:11, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [15:11<02:01, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:21<01:51, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:31<01:41, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:41<01:31, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [15:51<01:21, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [16:01<01:10, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [16:11<01:00, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:22<00:50, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:32<00:40, 10.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:42<00:30, 10.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [16:52<00:20, 10.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [17:02<00:10, 10.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [17:12<00:00, 10.09s/it]100%|██████████| 100/100 [17:12<00:00, 10.33s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-01-15:17:04:58,132 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-01-15:17:04:58,132 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-01-15:17:04:58,132 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-01-15:17:04:58,486 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-01-15:17:05:02,758 INFO     [__main__.py:132] Verbosity set to INFO
2025-01-15:17:05:13,040 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-01-15:17:05:13,042 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-01-15:17:05:13,050 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-01-15:17:05:13,267 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:01,  5.60it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:00<00:00,  7.24it/s]Loading checkpoint shards:  38%|███▊      | 3/8 [00:00<00:00,  8.10it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:00<00:00,  8.13it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:00<00:00,  8.36it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:00<00:00,  8.76it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:00<00:00,  9.04it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  9.11it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  8.46it/s]
2025-01-15:17:05:32,357 INFO     [task.py:355] Building contexts for task on rank 0...
2025-01-15:17:05:32,375 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:38, 12.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<18:56, 11.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:14, 11.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:45<17:48, 11.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:56<17:25, 11.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:06<17:06, 10.92s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:17<16:48, 10.85s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:28<16:32, 10.79s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:38<16:17, 10.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:49<16:02, 10.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [01:59<15:48, 10.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:10<15:34, 10.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:21<15:20, 10.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:31<15:07, 10.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:41<14:55, 10.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:52<14:43, 10.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:02<14:32, 10.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:13<14:21, 10.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:23<14:10, 10.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:34<13:58, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:44<13:46, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:55<13:34, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:05<13:23, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:15<13:11, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:26<13:00, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:36<12:49, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:47<12:38, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:57<12:28, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:07<12:17, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:18<12:06, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:28<11:55, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:38<11:45, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:49<11:34, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [05:59<11:23, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:10<11:13, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:20<11:02, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:30<10:52, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:41<10:41, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:51<10:31, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [07:01<10:20, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:12<10:10, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:22<09:59, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:32<09:49, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:43<09:38, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:53<09:28, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [08:03<09:17, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:14<09:06, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:24<08:56, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:34<08:45, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:44<08:35, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [08:55<08:25, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:05<08:14, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:15<08:03, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:26<07:53, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:36<07:42, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:46<07:32, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [09:56<07:22, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:07<07:11, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:17<07:01, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:27<06:50, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:37<06:40, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:48<06:29, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [10:58<06:19, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:08<06:08, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:18<05:58, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:29<05:48, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:39<05:37, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:49<05:27, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [11:59<05:17, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:10<05:06, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:20<04:56, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:30<04:46, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:40<04:35, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:50<04:25, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [13:01<04:15, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:11<04:04, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:21<03:54, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:31<03:44, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:41<03:33, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [13:51<03:23, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [14:02<03:13, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [14:12<03:03, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:22<02:52, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:32<02:42, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:42<02:32, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [14:52<02:22, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [15:03<02:12, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [15:13<02:01, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:23<01:51, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:33<01:41, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:43<01:31, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [15:53<01:21, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [16:03<01:11, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [16:14<01:00, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:24<00:50, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:34<00:40, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:44<00:30, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [16:54<00:20, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [17:04<00:10, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [17:14<00:00, 10.11s/it]100%|██████████| 100/100 [17:14<00:00, 10.35s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-01-15:17:24:33,212 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-01-15:17:24:33,212 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-01-15:17:24:33,212 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-01-15:17:24:33,573 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-01-15:17:24:38,132 INFO     [__main__.py:132] Verbosity set to INFO
2025-01-15:17:24:48,555 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-01-15:17:24:48,557 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-01-15:17:24:48,564 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-01-15:17:24:48,805 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:01,  5.86it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:00<00:00,  6.71it/s]Loading checkpoint shards:  38%|███▊      | 3/8 [00:00<00:00,  7.67it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:00<00:00,  8.27it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:00<00:00,  8.66it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:00<00:00,  8.93it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:00<00:00,  9.13it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  8.57it/s]
2025-01-15:17:25:11,685 INFO     [task.py:355] Building contexts for task on rank 0...
2025-01-15:17:25:11,704 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:35, 12.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<18:51, 11.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:08, 11.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:45<17:41, 11.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:55<17:18, 10.93s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:06<16:59, 10.85s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:17<16:42, 10.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:27<16:27, 10.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:38<16:11, 10.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:48<15:56, 10.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [01:59<15:42, 10.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:09<15:27, 10.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:20<15:14, 10.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:30<15:01, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:40<14:49, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:51<14:37, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:01<14:26, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:12<14:15, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:22<14:03, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:32<13:51, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:43<13:40, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:53<13:28, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:03<13:17, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:14<13:06, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:24<12:55, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:34<12:44, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:45<12:33, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:55<12:22, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:05<12:11, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:16<12:01, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:26<11:50, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:36<11:40, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:46<11:29, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [05:57<11:19, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:07<11:08, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:17<10:57, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:28<10:47, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:38<10:36, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:48<10:26, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [06:58<10:15, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:09<10:05, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:19<09:54, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:29<09:44, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:39<09:34, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:50<09:23, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [08:00<09:13, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:10<09:03, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:20<08:52, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:30<08:42, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:41<08:31, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [08:51<08:21, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:01<08:10, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:11<08:00, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:22<07:49, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:32<07:39, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:42<07:29, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [09:52<07:18, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:02<07:08, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:13<06:58, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:23<06:47, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:33<06:37, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:43<06:26, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [10:53<06:16, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:03<06:06, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:14<05:55, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:24<05:45, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:34<05:35, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:44<05:25, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [11:54<05:14, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:04<05:04, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:14<04:54, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:25<04:44, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:35<04:33, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:45<04:23, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [12:55<04:13, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:05<04:02, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:15<03:52, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:25<03:42, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:35<03:32, 10.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [13:45<03:22, 10.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [13:56<03:12, 10.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [14:06<03:01, 10.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:16<02:51, 10.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:26<02:41, 10.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:36<02:31, 10.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [14:46<02:21, 10.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [14:56<02:11, 10.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [15:06<02:01, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:16<01:50, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:26<01:40, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:36<01:30, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [15:46<01:20, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [15:57<01:10, 10.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [16:07<01:00, 10.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:17<00:50, 10.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:27<00:40, 10.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:37<00:30, 10.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [16:47<00:20, 10.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [16:57<00:10, 10.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [17:07<00:00, 10.04s/it]100%|██████████| 100/100 [17:07<00:00, 10.27s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-01-15:17:42:55,188 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-01-15:17:42:55,188 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-01-15:17:42:55,188 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-01-15:17:42:55,553 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-01-15:17:43:00,052 INFO     [__main__.py:132] Verbosity set to INFO
2025-01-15:17:43:10,771 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-01-15:17:43:10,773 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-01-15:17:43:10,781 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-01-15:17:43:11,010 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:01,  6.07it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:00<00:00,  7.35it/s]Loading checkpoint shards:  38%|███▊      | 3/8 [00:00<00:00,  7.73it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:00<00:00,  8.33it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:00<00:00,  8.71it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:00<00:00,  8.99it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:00<00:00,  9.17it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  8.68it/s]
2025-01-15:17:43:33,332 INFO     [task.py:355] Building contexts for task on rank 0...
2025-01-15:17:43:33,350 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:32, 12.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<18:54, 11.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:13, 11.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:45<17:47, 11.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:55<17:24, 10.99s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:06<17:05, 10.91s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:17<16:49, 10.85s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:28<16:33, 10.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:38<16:18, 10.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:49<16:02, 10.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [01:59<15:48, 10.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:10<15:34, 10.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:20<15:20, 10.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:31<15:07, 10.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:41<14:55, 10.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:52<14:44, 10.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:02<14:32, 10.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:13<14:21, 10.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:23<14:10, 10.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:34<13:57, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:44<13:46, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:55<13:32, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:05<13:20, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:15<13:08, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:26<12:56, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:36<12:45, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:46<12:34, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:56<12:23, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:07<12:12, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:17<12:01, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:27<11:50, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:38<11:40, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:48<11:29, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [05:58<11:19, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:08<11:08, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:19<10:58, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:29<10:47, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:39<10:36, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:50<10:26, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [07:00<10:15, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:10<10:05, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:20<09:54, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:31<09:44, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:41<09:34, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:51<09:23, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [08:01<09:13, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:12<09:03, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:22<08:52, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:32<08:42, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:42<08:31, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [08:52<08:21, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:03<08:10, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:13<08:00, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:23<07:50, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:33<07:39, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:43<07:29, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [09:54<07:18, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:04<07:08, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:14<06:58, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:24<06:47, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:34<06:37, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:45<06:26, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [10:55<06:16, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:05<06:06, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:15<05:56, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:25<05:45, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:35<05:35, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:46<05:25, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [11:56<05:14, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:06<05:04, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:16<04:54, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:26<04:44, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:36<04:33, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:46<04:23, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [12:57<04:13, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:07<04:03, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:17<03:52, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:27<03:42, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:37<03:32, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [13:47<03:22, 10.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [13:57<03:12, 10.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [14:07<03:01, 10.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:17<02:51, 10.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:27<02:41, 10.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:38<02:31, 10.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [14:48<02:21, 10.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [14:58<02:11, 10.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [15:08<02:01, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:18<01:50, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:28<01:40, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:38<01:30, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [15:48<01:20, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [15:58<01:10, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [16:08<01:00, 10.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:18<00:50, 10.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:28<00:40, 10.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:38<00:30, 10.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [16:48<00:20, 10.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [16:58<00:10, 10.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [17:08<00:00, 10.04s/it]100%|██████████| 100/100 [17:08<00:00, 10.29s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-01-15:18:01:18,479 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-01-15:18:01:18,479 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-01-15:18:01:18,480 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-01-15:18:01:18,840 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-01-15:18:01:23,597 INFO     [__main__.py:132] Verbosity set to INFO
2025-01-15:18:01:34,161 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-01-15:18:01:34,163 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-01-15:18:01:34,171 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-01-15:18:01:34,382 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:01,  5.98it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:00<00:00,  7.35it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:00<00:00,  8.81it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:00<00:00,  9.11it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:00<00:00,  8.84it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  9.52it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  8.93it/s]
2025-01-15:18:01:54,599 INFO     [task.py:355] Building contexts for task on rank 0...
2025-01-15:18:01:54,617 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:27, 12.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<18:46, 11.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:05, 11.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:44<17:39, 11.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:55<17:15, 10.90s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:06<16:57, 10.82s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:16<16:40, 10.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:27<16:25, 10.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:37<16:09, 10.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:48<15:54, 10.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [01:58<15:40, 10.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:09<15:26, 10.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:19<15:12, 10.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:30<14:59, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:40<14:47, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:51<14:36, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:01<14:25, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:11<14:13, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:22<14:02, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:32<13:50, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:42<13:39, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:53<13:27, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:03<13:15, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:13<13:04, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:24<12:53, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:34<12:43, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:44<12:32, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:54<12:21, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:05<12:10, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:15<11:59, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:25<11:49, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:36<11:38, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:46<11:28, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [05:56<11:17, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:06<11:07, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:17<10:56, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:27<10:46, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:37<10:35, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:47<10:25, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [06:58<10:14, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:08<10:04, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:18<09:53, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:28<09:43, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:38<09:33, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:49<09:22, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [07:59<09:12, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:09<09:02, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:19<08:51, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:30<08:41, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:40<08:30, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [08:50<08:20, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:00<08:10, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:10<07:59, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:21<07:49, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:31<07:38, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:41<07:28, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [09:51<07:17, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:01<07:07, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:11<06:57, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:22<06:46, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:32<06:36, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:42<06:26, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [10:52<06:15, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:02<06:05, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:12<05:55, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:22<05:44, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:33<05:34, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:43<05:24, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [11:53<05:14, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:03<05:04, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:13<04:53, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:23<04:43, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:33<04:33, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:43<04:23, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [12:54<04:12, 10.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:04<04:02, 10.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:14<03:52, 10.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:24<03:42, 10.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:34<03:32, 10.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [13:44<03:21, 10.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [13:54<03:11, 10.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [14:04<03:01, 10.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:14<02:51, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:24<02:41, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:34<02:31, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [14:44<02:21, 10.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [14:55<02:10, 10.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [15:05<02:00, 10.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:15<01:50, 10.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:25<01:40, 10.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:35<01:30, 10.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [15:45<01:20, 10.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [15:55<01:10, 10.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [16:05<01:00, 10.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:15<00:50, 10.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:25<00:40, 10.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:35<00:30, 10.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [16:45<00:20, 10.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [16:55<00:10, 10.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [17:05<00:00, 10.02s/it]100%|██████████| 100/100 [17:05<00:00, 10.26s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-01-15:18:19:36,227 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-01-15:18:19:36,227 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-01-15:18:19:36,227 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-01-15:18:19:36,582 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-01-15:18:19:41,141 INFO     [__main__.py:132] Verbosity set to INFO
2025-01-15:18:19:51,454 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-01-15:18:19:51,456 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-01-15:18:19:51,466 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-01-15:18:19:51,683 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:01,  5.86it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:00<00:00,  6.67it/s]Loading checkpoint shards:  38%|███▊      | 3/8 [00:00<00:00,  7.45it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:00<00:00,  7.95it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:00<00:00,  8.28it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:00<00:00,  8.55it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:00<00:00,  8.76it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  8.30it/s]
2025-01-15:18:20:11,690 INFO     [task.py:355] Building contexts for task on rank 0...
2025-01-15:18:20:11,709 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:28, 12.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<18:47, 11.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:06, 11.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:44<17:40, 11.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:55<17:16, 10.91s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:06<16:58, 10.83s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:16<16:41, 10.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:27<16:25, 10.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:38<16:10, 10.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:48<15:55, 10.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [01:59<15:40, 10.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:09<15:26, 10.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:19<15:13, 10.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:30<15:00, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:40<14:48, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:51<14:36, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:01<14:25, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:11<14:14, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:22<14:02, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:32<13:51, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:42<13:39, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:53<13:27, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:03<13:16, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:13<13:05, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:24<12:54, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:34<12:43, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:44<12:32, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:55<12:21, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:05<12:11, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:15<12:00, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:25<11:49, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:36<11:39, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:46<11:28, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [05:56<11:16, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:06<11:05, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:17<10:54, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:27<10:43, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:37<10:32, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:47<10:21, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [06:57<10:11, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:08<10:01, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:18<09:50, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:28<09:40, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:38<09:29, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:48<09:19, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [07:58<09:09, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:08<08:58, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:19<08:48, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:29<08:38, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:39<08:27, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [08:49<08:17, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [08:59<08:07, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:09<07:56, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:19<07:46, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:30<07:36, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:40<07:25, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [09:50<07:15, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:00<07:05, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:10<06:54, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:20<06:44, 10.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:30<06:34, 10.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:40<06:23, 10.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [10:50<06:13, 10.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:01<06:03, 10.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:11<05:53, 10.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:21<05:43, 10.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:31<05:32, 10.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:41<05:22, 10.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [11:51<05:12, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:01<05:02, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:11<04:52, 10.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:21<04:42, 10.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:31<04:31, 10.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:41<04:21, 10.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [12:51<04:11, 10.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:01<04:01, 10.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:11<03:51, 10.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:21<03:40, 10.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:31<03:30, 10.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [13:41<03:20, 10.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [13:51<03:10, 10.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [14:02<03:00, 10.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:12<02:50, 10.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:22<02:40, 10.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:32<02:30, 10.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [14:42<02:20, 10.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [14:52<02:10, 10.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [15:02<02:00, 10.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:12<01:50, 10.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:22<01:40, 10.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:32<01:30, 10.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [15:42<01:20, 10.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [15:52<01:10, 10.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [16:02<00:59, 10.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:12<00:49,  9.99s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:22<00:39,  9.99s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:31<00:29,  9.98s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [16:41<00:19,  9.98s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [16:51<00:09,  9.97s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [17:01<00:00,  9.97s/it]100%|██████████| 100/100 [17:01<00:00, 10.22s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-01-15:18:37:49,673 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-01-15:18:37:49,673 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-01-15:18:37:49,673 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-01-15:18:37:50,046 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-01-15:18:37:54,625 INFO     [__main__.py:132] Verbosity set to INFO
2025-01-15:18:38:05,253 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-01-15:18:38:05,254 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-01-15:18:38:05,262 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-01-15:18:38:05,482 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:01,  6.10it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:00<00:00,  6.88it/s]Loading checkpoint shards:  38%|███▊      | 3/8 [00:00<00:00,  7.82it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:00<00:00,  8.39it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:00<00:00,  8.74it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:00<00:00,  8.99it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:00<00:00,  9.17it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  8.67it/s]
2025-01-15:18:38:26,738 INFO     [task.py:355] Building contexts for task on rank 0...
2025-01-15:18:38:26,756 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:27, 12.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<18:46, 11.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:05, 11.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:44<17:39, 11.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:55<17:15, 10.90s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:06<16:57, 10.82s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:16<16:40, 10.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:27<16:25, 10.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:37<16:09, 10.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:48<15:54, 10.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [01:58<15:40, 10.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:09<15:26, 10.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:19<15:12, 10.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:30<14:59, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:40<14:47, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:51<14:36, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:01<14:25, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:11<14:13, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:22<14:02, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:32<13:50, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:42<13:39, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:53<13:27, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:03<13:15, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:13<13:04, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:24<12:53, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:34<12:43, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:44<12:32, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:54<12:21, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:05<12:10, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:15<11:58, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:25<11:46, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:35<11:35, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:45<11:24, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [05:56<11:14, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:06<11:03, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:16<10:52, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:26<10:42, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:36<10:31, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:47<10:21, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [06:57<10:10, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:07<10:00, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:17<09:49, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:27<09:39, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:37<09:29, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:48<09:18, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [07:58<09:08, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:08<08:58, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:18<08:47, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:28<08:37, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:38<08:27, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [08:48<08:17, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [08:59<08:06, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:09<07:56, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:19<07:45, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:29<07:35, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:39<07:25, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [09:49<07:15, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [09:59<07:04, 10.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:09<06:54, 10.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:19<06:44, 10.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:29<06:33, 10.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:40<06:23, 10.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [10:50<06:13, 10.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:00<06:03, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:10<05:52, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:20<05:42, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:30<05:32, 10.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:40<05:22, 10.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [11:50<05:12, 10.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:00<05:02, 10.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:10<04:51, 10.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:20<04:41, 10.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:30<04:31, 10.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:40<04:21, 10.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [12:50<04:11, 10.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:00<04:00, 10.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:10<03:50, 10.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:20<03:40, 10.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:30<03:30, 10.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [13:40<03:20, 10.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [13:50<03:10, 10.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [14:00<03:00, 10.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:10<02:50, 10.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:20<02:40, 10.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:30<02:30, 10.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [14:40<02:20, 10.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [14:50<02:10, 10.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [15:00<01:59, 10.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:10<01:49, 10.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:20<01:39,  9.99s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:30<01:29,  9.99s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [15:40<01:19,  9.99s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [15:50<01:09,  9.99s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [16:00<00:59,  9.98s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:10<00:49,  9.98s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:20<00:39,  9.97s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:30<00:29,  9.97s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [16:40<00:19,  9.97s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [16:50<00:09,  9.96s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [17:00<00:00,  9.95s/it]100%|██████████| 100/100 [17:00<00:00, 10.21s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-01-15:18:57:13,572 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-01-15:18:57:13,572 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-01-15:18:57:13,572 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-01-15:18:57:13,932 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-01-15:18:57:18,164 INFO     [__main__.py:132] Verbosity set to INFO
2025-01-15:18:57:28,535 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-01-15:18:57:28,537 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-01-15:18:57:28,545 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-01-15:18:57:28,767 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:01,  5.92it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:00<00:00,  7.21it/s]Loading checkpoint shards:  38%|███▊      | 3/8 [00:00<00:00,  7.52it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:00<00:00,  8.12it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:00<00:00,  8.49it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:00<00:00,  8.75it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:00<00:00,  8.90it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  8.47it/s]
2025-01-15:18:57:49,378 INFO     [task.py:355] Building contexts for task on rank 0...
2025-01-15:18:57:49,397 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:24, 12.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<18:45, 11.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:04, 11.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:44<17:39, 11.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:55<17:16, 10.91s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:06<16:57, 10.83s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:16<16:40, 10.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:27<16:25, 10.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:37<16:10, 10.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:48<15:54, 10.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [01:58<15:41, 10.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:09<15:26, 10.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:19<15:13, 10.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:30<15:00, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:40<14:48, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:51<14:36, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:01<14:25, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:11<14:14, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:22<14:03, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:32<13:51, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:42<13:39, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:53<13:28, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:03<13:16, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:13<13:05, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:24<12:54, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:34<12:43, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:44<12:32, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:55<12:22, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:05<12:11, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:15<12:00, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:25<11:49, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:36<11:39, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:46<11:28, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [05:56<11:18, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:07<11:07, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:17<10:57, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:27<10:46, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:37<10:36, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:48<10:25, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [06:58<10:15, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:08<10:05, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:18<09:54, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:29<09:44, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:39<09:33, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:49<09:23, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [07:59<09:12, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:09<09:02, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:20<08:52, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:30<08:41, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:40<08:31, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [08:50<08:20, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:01<08:10, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:11<07:59, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:21<07:49, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:31<07:39, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:41<07:28, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [09:51<07:18, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:02<07:07, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:12<06:57, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:22<06:47, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:32<06:36, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:42<06:26, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [10:52<06:16, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:03<06:05, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:13<05:55, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:23<05:45, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:33<05:34, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:43<05:24, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [11:53<05:14, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:03<05:04, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:14<04:53, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:24<04:43, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:34<04:33, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:44<04:23, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [12:54<04:12, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:04<04:02, 10.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:14<03:52, 10.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:24<03:42, 10.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:34<03:32, 10.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [13:45<03:21, 10.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [13:55<03:11, 10.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [14:05<03:01, 10.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:15<02:51, 10.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:25<02:41, 10.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:35<02:31, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [14:45<02:21, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [14:55<02:11, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [15:05<02:00, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:15<01:50, 10.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:25<01:40, 10.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:35<01:30, 10.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [15:45<01:20, 10.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [15:56<01:10, 10.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [16:06<01:00, 10.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:16<00:50, 10.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:26<00:40, 10.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:36<00:30, 10.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [16:46<00:20, 10.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [16:56<00:10, 10.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [17:06<00:00, 10.03s/it]100%|██████████| 100/100 [17:06<00:00, 10.26s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-01-15:19:15:32,186 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-01-15:19:15:32,187 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-01-15:19:15:32,187 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-01-15:19:15:32,545 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-01-15:19:15:36,772 INFO     [__main__.py:132] Verbosity set to INFO
2025-01-15:19:15:47,139 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-01-15:19:15:47,141 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-01-15:19:15:47,149 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-01-15:19:15:47,371 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:01,  5.27it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:00<00:00,  6.92it/s]Loading checkpoint shards:  38%|███▊      | 3/8 [00:00<00:00,  7.88it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:00<00:00,  8.46it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:00<00:00,  8.14it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:00<00:00,  8.55it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:00<00:00,  8.84it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  8.38it/s]
2025-01-15:19:16:08,798 INFO     [task.py:355] Building contexts for task on rank 0...
2025-01-15:19:16:08,817 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:33, 12.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<18:55, 11.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:14, 11.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:45<17:48, 11.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:56<17:25, 11.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:06<17:06, 10.92s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:17<16:49, 10.85s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:28<16:33, 10.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:38<16:18, 10.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:49<16:03, 10.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [02:00<15:49, 10.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:10<15:34, 10.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:21<15:21, 10.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:31<15:08, 10.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:42<14:56, 10.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:52<14:44, 10.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:03<14:32, 10.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:13<14:21, 10.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:23<14:10, 10.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:34<13:58, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:44<13:47, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:55<13:35, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:05<13:24, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:16<13:12, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:26<13:01, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:36<12:50, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:47<12:39, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:57<12:28, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:08<12:17, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:18<12:06, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:28<11:56, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:39<11:45, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:49<11:34, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [05:59<11:24, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:10<11:13, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:20<11:03, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:30<10:52, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:41<10:41, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:51<10:31, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [07:01<10:21, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:12<10:10, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:22<10:00, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:33<09:49, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:43<09:39, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:53<09:28, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [08:03<09:18, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:14<09:07, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:24<08:56, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:34<08:46, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:45<08:35, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [08:55<08:25, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:05<08:14, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:16<08:04, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:26<07:53, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:36<07:43, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:47<07:32, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [09:57<07:22, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:07<07:11, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:17<07:01, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:28<06:50, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:38<06:40, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:48<06:29, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [10:58<06:19, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:09<06:09, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:19<05:58, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:29<05:48, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:39<05:38, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:50<05:27, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [12:00<05:17, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:10<05:07, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:20<04:56, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:30<04:46, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:41<04:35, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:51<04:25, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [13:01<04:15, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:11<04:04, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:21<03:54, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:32<03:44, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:42<03:34, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [13:52<03:23, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [14:02<03:13, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [14:12<03:03, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:23<02:53, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:33<02:42, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:43<02:32, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [14:53<02:22, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [15:03<02:12, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [15:13<02:02, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:24<01:51, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:34<01:41, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:44<01:31, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [15:54<01:21, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [16:04<01:11, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [16:14<01:00, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:24<00:50, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:35<00:40, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:45<00:30, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [16:55<00:20, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [17:05<00:10, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [17:15<00:00, 10.12s/it]100%|██████████| 100/100 [17:15<00:00, 10.36s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-01-15:19:34:00,367 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-01-15:19:34:00,367 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-01-15:19:34:00,367 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-01-15:19:34:00,675 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-01-15:19:34:05,022 INFO     [__main__.py:132] Verbosity set to INFO
2025-01-15:19:34:15,213 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-01-15:19:34:15,215 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-01-15:19:34:15,221 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-01-15:19:34:15,442 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:01,  5.34it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:00<00:00,  6.94it/s]Loading checkpoint shards:  38%|███▊      | 3/8 [00:00<00:00,  7.84it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:00<00:00,  8.37it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:00<00:00,  8.08it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:00<00:00,  8.49it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:00<00:00,  8.82it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  8.36it/s]
2025-01-15:19:34:37,533 INFO     [task.py:355] Building contexts for task on rank 0...
2025-01-15:19:34:37,551 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:39, 12.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<18:57, 11.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:15, 11.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:45<17:49, 11.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:56<17:32, 11.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:07<17:11, 10.97s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:17<16:52, 10.88s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:28<16:35, 10.82s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:39<16:19, 10.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:49<16:04, 10.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [02:00<15:49, 10.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:10<15:35, 10.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:21<15:21, 10.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:31<15:08, 10.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:42<14:56, 10.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:52<14:44, 10.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:03<14:32, 10.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:13<14:21, 10.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:24<14:10, 10.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:34<13:58, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:45<13:47, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:55<13:35, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:05<13:24, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:16<13:12, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:26<13:01, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:37<12:50, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:47<12:39, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:57<12:28, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:08<12:17, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:18<12:06, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:29<11:56, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:39<11:45, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:49<11:34, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [06:00<11:24, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:10<11:13, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:20<11:03, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:31<10:52, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:41<10:41, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:51<10:31, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [07:02<10:21, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:12<10:10, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:22<10:00, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:33<09:49, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:43<09:38, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:53<09:28, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [08:04<09:17, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:14<09:07, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:24<08:56, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:35<08:46, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:45<08:35, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [08:55<08:25, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:06<08:14, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:16<08:04, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:26<07:53, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:36<07:43, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:47<07:32, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [09:57<07:22, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:07<07:11, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:18<07:01, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:28<06:50, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:38<06:40, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:48<06:29, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [10:59<06:19, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:09<06:09, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:19<05:58, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:29<05:48, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:40<05:38, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:50<05:27, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [12:00<05:17, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:10<05:07, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:20<04:56, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:31<04:46, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:41<04:35, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:51<04:25, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [13:01<04:15, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:11<04:04, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:22<03:54, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:32<03:44, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:42<03:34, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [13:52<03:23, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [14:02<03:13, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [14:13<03:03, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:23<02:53, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:33<02:42, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:43<02:32, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [14:53<02:22, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [15:03<02:12, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [15:14<02:02, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:24<01:51, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:34<01:41, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:44<01:31, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [15:54<01:21, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [16:04<01:11, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [16:15<01:00, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:25<00:50, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:35<00:40, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:45<00:30, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [16:55<00:20, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [17:05<00:10, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [17:15<00:00, 10.12s/it]100%|██████████| 100/100 [17:15<00:00, 10.36s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-01-15:19:52:29,428 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-01-15:19:52:29,428 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-01-15:19:52:29,428 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-01-15:19:52:29,785 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-01-15:19:52:34,308 INFO     [__main__.py:132] Verbosity set to INFO
2025-01-15:19:52:44,651 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-01-15:19:52:44,653 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-01-15:19:52:44,660 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-01-15:19:52:44,879 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:01,  5.80it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:00<00:00,  7.16it/s]Loading checkpoint shards:  38%|███▊      | 3/8 [00:00<00:00,  7.51it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:00<00:00,  8.15it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:00<00:00,  8.58it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:00<00:00,  8.85it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:00<00:00,  9.07it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  8.55it/s]
2025-01-15:19:53:06,014 INFO     [task.py:355] Building contexts for task on rank 0...
2025-01-15:19:53:06,032 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:33, 12.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<18:54, 11.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:13, 11.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:45<17:48, 11.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:56<17:25, 11.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:06<17:06, 10.92s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:17<16:48, 10.85s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:28<16:33, 10.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:38<16:15, 10.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:49<15:59, 10.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [01:59<15:44, 10.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:10<15:29, 10.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:20<15:15, 10.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:31<15:02, 10.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:41<14:50, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:51<14:38, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:02<14:26, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:12<14:15, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:23<14:04, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:33<13:52, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:43<13:40, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:54<13:29, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:04<13:18, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:14<13:06, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:25<12:55, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:35<12:44, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:45<12:33, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:56<12:23, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:06<12:12, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:16<12:01, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:26<11:50, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:37<11:40, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:47<11:29, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [05:57<11:19, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:08<11:08, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:18<10:58, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:28<10:47, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:38<10:37, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:49<10:26, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [06:59<10:16, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:09<10:06, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:20<09:55, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:30<09:45, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:40<09:34, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:50<09:24, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [08:01<09:13, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:11<09:03, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:21<08:52, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:31<08:42, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:41<08:32, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [08:52<08:21, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:02<08:11, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:12<08:00, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:22<07:50, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:33<07:39, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:43<07:29, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [09:53<07:19, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:03<07:08, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:13<06:58, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:24<06:47, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:34<06:37, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:44<06:27, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [10:54<06:16, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:04<06:06, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:14<05:55, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:25<05:45, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:35<05:35, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:45<05:25, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [11:55<05:14, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:05<05:04, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:15<04:54, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:25<04:44, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:36<04:33, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:46<04:23, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [12:56<04:13, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:06<04:03, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:16<03:52, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:26<03:42, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:36<03:32, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [13:46<03:22, 10.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [13:56<03:12, 10.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [14:07<03:01, 10.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:17<02:51, 10.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:27<02:41, 10.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:37<02:31, 10.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [14:47<02:21, 10.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [14:57<02:11, 10.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [15:07<02:01, 10.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:17<01:50, 10.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:27<01:40, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:37<01:30, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [15:47<01:20, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [15:57<01:10, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [16:08<01:00, 10.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:18<00:50, 10.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:28<00:40, 10.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:38<00:30, 10.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [16:48<00:20, 10.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [16:58<00:10, 10.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [17:08<00:00, 10.04s/it]100%|██████████| 100/100 [17:08<00:00, 10.28s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-01-15:20:10:50,515 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-01-15:20:10:50,515 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-01-15:20:10:50,515 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-01-15:20:10:50,885 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-01-15:20:10:55,236 INFO     [__main__.py:132] Verbosity set to INFO
2025-01-15:20:11:05,813 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-01-15:20:11:05,815 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-01-15:20:11:05,824 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-01-15:20:11:06,051 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:01,  5.54it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:00<00:00,  6.79it/s]Loading checkpoint shards:  38%|███▊      | 3/8 [00:00<00:00,  7.80it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:00<00:00,  8.37it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:00<00:00,  8.32it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:00<00:00,  8.51it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:00<00:00,  8.83it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  8.39it/s]
2025-01-15:20:11:28,148 INFO     [task.py:355] Building contexts for task on rank 0...
2025-01-15:20:11:28,166 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:31, 12.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<18:49, 11.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:06, 11.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:44<17:40, 11.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:55<17:17, 10.92s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:06<16:58, 10.84s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:16<16:41, 10.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:27<16:25, 10.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:38<16:10, 10.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:48<15:55, 10.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [01:59<15:41, 10.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:09<15:27, 10.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:19<15:13, 10.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:30<15:00, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:40<14:48, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:51<14:37, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:01<14:25, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:11<14:14, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:22<14:03, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:32<13:51, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:43<13:40, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:53<13:28, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:03<13:17, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:14<13:05, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:24<12:53, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:34<12:41, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:44<12:29, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:54<12:18, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:05<12:07, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:15<11:56, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:25<11:46, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:35<11:35, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:46<11:24, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [05:56<11:14, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:06<11:03, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:16<10:53, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:26<10:42, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:37<10:32, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:47<10:22, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [06:57<10:11, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:07<10:01, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:17<09:51, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:28<09:40, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:38<09:30, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:48<09:19, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [07:58<09:09, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:08<08:59, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:18<08:48, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:29<08:38, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:39<08:28, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [08:49<08:17, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [08:59<08:07, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:09<07:57, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:19<07:46, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:29<07:36, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:40<07:26, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [09:50<07:15, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:00<07:05, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:10<06:55, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:20<06:44, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:30<06:34, 10.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:40<06:24, 10.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [10:50<06:13, 10.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:00<06:03, 10.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:10<05:53, 10.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:21<05:43, 10.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:31<05:32, 10.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:41<05:22, 10.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [11:51<05:12, 10.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:01<05:02, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:11<04:52, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:21<04:42, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:31<04:31, 10.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:41<04:21, 10.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [12:51<04:11, 10.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:01<04:01, 10.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:11<03:51, 10.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:21<03:41, 10.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:31<03:30, 10.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [13:41<03:20, 10.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [13:51<03:10, 10.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [14:01<03:00, 10.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:11<02:50, 10.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:21<02:40, 10.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:31<02:30, 10.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [14:41<02:20, 10.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [14:51<02:10, 10.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [15:01<02:00, 10.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:11<01:50, 10.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:21<01:40, 10.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:31<01:30, 10.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [15:41<01:20, 10.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [15:51<01:10, 10.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [16:01<00:59, 10.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:11<00:49, 10.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:21<00:39,  9.99s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:31<00:29,  9.99s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [16:41<00:19,  9.98s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [16:51<00:09,  9.98s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [17:01<00:00,  9.97s/it]100%|██████████| 100/100 [17:01<00:00, 10.22s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-01-15:20:30:16,040 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-01-15:20:30:16,040 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-01-15:20:30:16,040 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-01-15:20:30:16,401 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-01-15:20:30:20,715 INFO     [__main__.py:132] Verbosity set to INFO
2025-01-15:20:30:31,266 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-01-15:20:30:31,268 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-01-15:20:30:31,277 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-01-15:20:30:31,475 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:01,  5.95it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:00<00:00,  6.85it/s]Loading checkpoint shards:  38%|███▊      | 3/8 [00:00<00:00,  7.61it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:00<00:00,  8.15it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:00<00:00,  8.49it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:00<00:00,  8.73it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:00<00:00,  8.90it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  9.20it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  8.44it/s]
2025-01-15:20:30:53,922 INFO     [task.py:355] Building contexts for task on rank 0...
2025-01-15:20:30:53,940 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:28, 12.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<18:47, 11.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:05, 11.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:44<17:39, 11.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:55<17:16, 10.91s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:06<16:57, 10.83s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:16<16:39, 10.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:27<16:24, 10.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:37<16:09, 10.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:48<15:54, 10.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [01:58<15:40, 10.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:09<15:25, 10.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:19<15:12, 10.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:30<14:59, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:40<14:47, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:50<14:35, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:01<14:24, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:11<14:13, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:22<14:02, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:32<13:50, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:42<13:39, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:53<13:27, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:03<13:16, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:13<13:04, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:24<12:53, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:34<12:43, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:44<12:32, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:54<12:21, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:05<12:10, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:15<12:00, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:25<11:49, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:35<11:38, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:46<11:28, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [05:56<11:17, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:06<11:07, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:17<10:56, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:27<10:46, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:37<10:35, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:47<10:25, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [06:57<10:14, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:08<10:04, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:18<09:54, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:28<09:43, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:38<09:33, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:49<09:22, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [07:59<09:12, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:09<09:02, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:19<08:51, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:30<08:41, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:40<08:30, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [08:50<08:20, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:00<08:09, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:10<07:59, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:21<07:49, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:31<07:38, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:41<07:28, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [09:51<07:18, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:01<07:07, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:11<06:57, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:22<06:46, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:32<06:36, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:42<06:26, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [10:52<06:15, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:02<06:05, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:12<05:55, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:22<05:44, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:33<05:34, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:43<05:24, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [11:53<05:14, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:03<05:04, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:13<04:53, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:23<04:43, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:33<04:33, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:43<04:22, 10.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [12:54<04:12, 10.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:04<04:02, 10.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:14<03:52, 10.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:24<03:42, 10.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:34<03:31, 10.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [13:44<03:21, 10.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [13:54<03:11, 10.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [14:04<03:01, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:10<02:31,  8.88s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:20<02:27,  9.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:30<02:22,  9.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [14:40<02:15,  9.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [14:50<02:07,  9.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [15:01<01:58,  9.87s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:11<01:49,  9.93s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:21<01:39,  9.96s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:31<01:29,  9.99s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [15:41<01:20, 10.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [15:51<01:10, 10.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [16:01<01:00, 10.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:11<00:50, 10.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:21<00:40, 10.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:31<00:30, 10.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [16:41<00:20, 10.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [16:51<00:10, 10.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [17:01<00:00, 10.02s/it]100%|██████████| 100/100 [17:01<00:00, 10.21s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-01-15:20:48:31,340 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-01-15:20:48:31,340 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-01-15:20:48:31,340 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-01-15:20:48:31,699 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-01-15:20:48:36,050 INFO     [__main__.py:132] Verbosity set to INFO
2025-01-15:20:48:46,612 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-01-15:20:48:46,614 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-01-15:20:48:46,622 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-01-15:20:48:46,840 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:01,  5.83it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:00<00:00,  7.43it/s]Loading checkpoint shards:  38%|███▊      | 3/8 [00:00<00:00,  7.98it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:00<00:00,  8.15it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:00<00:00,  8.61it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:00<00:00,  8.96it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:00<00:00,  9.21it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  8.69it/s]
2025-01-15:20:49:08,495 INFO     [task.py:355] Building contexts for task on rank 0...
2025-01-15:20:49:08,513 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:39, 12.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<18:58, 11.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:16, 11.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:45<17:50, 11.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:56<17:26, 11.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:06<17:08, 10.94s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:17<16:50, 10.87s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:28<16:35, 10.82s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:39<16:19, 10.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:49<16:04, 10.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [02:00<15:50, 10.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:10<15:36, 10.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:21<15:22, 10.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:31<15:09, 10.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:42<14:57, 10.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:52<14:45, 10.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:03<14:34, 10.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:13<14:22, 10.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:24<14:11, 10.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:34<13:59, 10.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:45<13:48, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:55<13:36, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:06<13:25, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:16<13:13, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:26<13:02, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:37<12:51, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:47<12:40, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:58<12:29, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:08<12:18, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:18<12:07, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:29<11:57, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:39<11:46, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:50<11:35, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [06:00<11:25, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:10<11:14, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:21<11:04, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:31<10:53, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:41<10:42, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:52<10:32, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [07:02<10:21, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:12<10:11, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:23<10:00, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:33<09:50, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:43<09:39, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:54<09:29, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [08:04<09:18, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:15<09:08, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:25<08:57, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:35<08:46, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:45<08:36, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [08:56<08:26, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:06<08:15, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:16<08:04, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:27<07:54, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:37<07:43, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:47<07:33, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [09:58<07:23, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:08<07:12, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:18<07:02, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:28<06:51, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:39<06:40, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:49<06:30, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [10:59<06:19, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:09<06:09, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:20<05:59, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:30<05:48, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:40<05:38, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:50<05:28, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [12:01<05:17, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:11<05:07, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:21<04:57, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:31<04:46, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:42<04:36, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:52<04:25, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [13:02<04:15, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:12<04:05, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:23<03:55, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:33<03:44, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:43<03:34, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [13:53<03:24, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [14:03<03:13, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [14:14<03:03, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:20<02:32,  8.99s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:30<02:29,  9.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:40<02:23,  9.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [14:50<02:16,  9.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [15:00<02:08,  9.89s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [15:11<01:59,  9.98s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:21<01:50, 10.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:31<01:40, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:41<01:30, 10.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [15:51<01:21, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [16:01<01:10, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [16:12<01:00, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:22<00:50, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:32<00:40, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:42<00:30, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [16:52<00:20, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [17:02<00:10, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [17:12<00:00, 10.13s/it]100%|██████████| 100/100 [17:12<00:00, 10.33s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-01-15:21:06:57,515 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-01-15:21:06:57,516 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-01-15:21:06:57,516 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-01-15:21:06:57,874 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-01-15:21:07:02,308 INFO     [__main__.py:132] Verbosity set to INFO
2025-01-15:21:07:12,754 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-01-15:21:07:12,756 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-01-15:21:07:12,764 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-01-15:21:07:12,993 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:01,  5.72it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:00<00:00,  7.34it/s]Loading checkpoint shards:  38%|███▊      | 3/8 [00:00<00:00,  8.17it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:00<00:00,  8.10it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:00<00:00,  8.41it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:00<00:00,  8.72it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:00<00:00,  8.85it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  8.75it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  8.34it/s]
2025-01-15:21:07:34,110 INFO     [task.py:355] Building contexts for task on rank 0...
2025-01-15:21:07:34,129 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:26, 12.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<18:48, 11.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:08, 11.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:44<17:42, 11.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:55<17:19, 10.94s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:06<17:00, 10.86s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:17<16:43, 10.79s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:27<16:27, 10.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:38<16:12, 10.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:48<15:57, 10.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [01:59<15:43, 10.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:09<15:29, 10.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:20<15:15, 10.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:30<15:02, 10.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:41<14:50, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:51<14:39, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:01<14:27, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:12<14:16, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:22<14:05, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:33<13:53, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:43<13:41, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:53<13:30, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:04<13:18, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:14<13:07, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:24<12:56, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:35<12:45, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:45<12:34, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:55<12:24, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:06<12:13, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:16<12:02, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:26<11:51, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:37<11:41, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:47<11:30, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [05:57<11:20, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:07<11:09, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:18<10:59, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:28<10:48, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:38<10:37, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:49<10:27, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [06:59<10:17, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:09<10:06, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:19<09:56, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:30<09:45, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:40<09:35, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:50<09:24, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [08:01<09:14, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:11<09:03, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:21<08:53, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:31<08:43, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:42<08:32, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [08:52<08:22, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:02<08:11, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:12<08:01, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:22<07:50, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:33<07:40, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:43<07:30, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [09:53<07:19, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:03<07:09, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:14<06:58, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:24<06:48, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:34<06:37, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:44<06:27, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [10:54<06:17, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:04<06:06, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:15<05:56, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:25<05:46, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:35<05:35, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:45<05:25, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [11:55<05:15, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:05<05:05, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:16<04:54, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:26<04:44, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:36<04:34, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:46<04:23, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [12:56<04:13, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:06<04:03, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:16<03:53, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:27<03:42, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:37<03:32, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [13:47<03:22, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [13:57<03:12, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [14:07<03:02, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:13<02:31,  8.92s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:23<02:28,  9.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:33<02:22,  9.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [14:43<02:15,  9.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [14:54<02:07,  9.82s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [15:04<01:58,  9.90s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:14<01:49,  9.96s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:24<01:40, 10.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:34<01:30, 10.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [15:44<01:20, 10.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [15:54<01:10, 10.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [16:04<01:00, 10.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:14<00:50, 10.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:24<00:40, 10.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:34<00:30, 10.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [16:44<00:20, 10.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [16:55<00:10, 10.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [17:05<00:00, 10.06s/it]100%|██████████| 100/100 [17:05<00:00, 10.25s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-01-15:21:25:15,017 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-01-15:21:25:15,017 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-01-15:21:25:15,017 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-01-15:21:25:15,384 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-01-15:21:25:19,603 INFO     [__main__.py:132] Verbosity set to INFO
2025-01-15:21:25:30,012 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-01-15:21:25:30,013 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-01-15:21:25:30,020 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-01-15:21:25:30,230 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:01,  5.26it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:00<00:00,  6.88it/s]Loading checkpoint shards:  38%|███▊      | 3/8 [00:00<00:00,  7.68it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:00<00:00,  7.98it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:00<00:00,  7.86it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:00<00:00,  8.23it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:00<00:00,  8.52it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  8.74it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  8.06it/s]
2025-01-15:21:25:51,530 INFO     [task.py:355] Building contexts for task on rank 0...
2025-01-15:21:25:51,548 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:13<21:38, 13.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:24<19:22, 11.86s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:35<18:29, 11.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:45<17:58, 11.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:56<17:32, 11.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:07<17:11, 10.98s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:18<16:53, 10.89s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:28<16:36, 10.84s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:39<16:21, 10.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:50<16:05, 10.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [02:00<15:51, 10.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:11<15:36, 10.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:21<15:23, 10.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:32<15:10, 10.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:42<14:57, 10.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:53<14:46, 10.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:03<14:34, 10.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:14<14:23, 10.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:25<14:12, 10.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:35<14:00, 10.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:45<13:48, 10.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:56<13:36, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:06<13:25, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:17<13:14, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:27<13:02, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:38<12:51, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:48<12:40, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:58<12:30, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:09<12:19, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:19<12:08, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:30<11:57, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:40<11:46, 10.40s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:50<11:36, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [06:01<11:25, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:11<11:15, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:21<11:04, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:32<10:53, 10.38s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:42<10:43, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:53<10:32, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [07:03<10:22, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:13<10:11, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:24<10:01, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:34<09:50, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:44<09:40, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:55<09:29, 10.36s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [08:05<09:18, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:15<09:08, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:26<08:57, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:36<08:47, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:46<08:36, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [08:57<08:26, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:07<08:15, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:17<08:05, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:28<07:54, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:38<07:44, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:48<07:33, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [09:59<07:23, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:09<07:12, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:19<07:02, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:29<06:51, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:40<06:41, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:50<06:30, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [11:00<06:20, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:10<06:09, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:21<05:59, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:31<05:48, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:41<05:38, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:51<05:28, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [12:02<05:18, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:12<05:07, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:22<04:57, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:32<04:46, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:43<04:36, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:53<04:26, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [13:03<04:15, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:13<04:05, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:24<03:55, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:34<03:44, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:44<03:34, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [13:54<03:24, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [14:04<03:14, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [14:15<03:03, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:21<02:32,  8.99s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:31<02:29,  9.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:41<02:24,  9.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [14:51<02:16,  9.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [15:01<02:08,  9.90s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [15:12<01:59,  9.98s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:22<01:50, 10.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:32<01:40, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:42<01:31, 10.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [15:52<01:21, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [16:03<01:10, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [16:13<01:00, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:23<00:50, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:33<00:40, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:43<00:30, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [16:53<00:20, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [17:03<00:10, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [17:14<00:00, 10.14s/it]100%|██████████| 100/100 [17:14<00:00, 10.34s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-01-15:21:43:41,688 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-01-15:21:43:41,689 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-01-15:21:43:41,689 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-01-15:21:43:42,064 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-01-15:21:43:46,542 INFO     [__main__.py:132] Verbosity set to INFO
2025-01-15:21:43:56,952 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-01-15:21:43:56,954 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-01-15:21:43:56,961 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-01-15:21:43:57,178 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:01,  6.02it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:00<00:00,  6.78it/s]Loading checkpoint shards:  38%|███▊      | 3/8 [00:00<00:00,  7.73it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:00<00:00,  8.30it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:00<00:00,  8.64it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:00<00:00,  8.89it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:00<00:00,  9.05it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  8.57it/s]
2025-01-15:21:44:17,665 INFO     [task.py:355] Building contexts for task on rank 0...
2025-01-15:21:44:17,683 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:31, 12.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<18:48, 11.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:06, 11.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:44<17:40, 11.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:55<17:17, 10.92s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:06<16:58, 10.83s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:16<16:40, 10.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:27<16:25, 10.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:38<16:10, 10.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:48<15:54, 10.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [01:59<15:41, 10.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:09<15:26, 10.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:19<15:13, 10.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:30<15:00, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:40<14:48, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:51<14:36, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:01<14:25, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:11<14:12, 10.39s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:22<14:00, 10.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:32<13:47, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:42<13:35, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:52<13:23, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:03<13:12, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:13<13:00, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:23<12:49, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:33<12:38, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:44<12:27, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:54<12:17, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:04<12:06, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:14<11:55, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:25<11:45, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:35<11:34, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:45<11:23, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [05:55<11:13, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:05<11:03, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:15<10:52, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:26<10:42, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:36<10:31, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:46<10:21, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [06:56<10:11, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:06<10:00, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:17<09:50, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:27<09:40, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:37<09:29, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:47<09:19, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [07:57<09:09, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:07<08:58, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:18<08:48, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:28<08:38, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:38<08:27, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [08:48<08:17, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [08:58<08:07, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:08<07:56, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:18<07:46, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:29<07:36, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:39<07:25, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [09:49<07:15, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [09:59<07:04, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:09<06:54, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:19<06:44, 10.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:29<06:34, 10.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:39<06:23, 10.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [10:49<06:13, 10.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [10:59<06:03, 10.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:10<05:53, 10.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:20<05:42, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:30<05:32, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:40<05:22, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [11:50<05:12, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:00<05:02, 10.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:10<04:51, 10.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:20<04:41, 10.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:30<04:31, 10.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:40<04:21, 10.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [12:50<04:11, 10.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:00<04:01, 10.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:10<03:50, 10.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:20<03:40, 10.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:30<03:30, 10.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [13:40<03:20, 10.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [13:50<03:10, 10.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [14:00<03:00, 10.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:06<02:30,  8.83s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:16<02:26,  9.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:26<02:21,  9.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [14:36<02:14,  9.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [14:46<02:06,  9.72s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [14:56<01:57,  9.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:06<01:48,  9.86s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:16<01:39,  9.90s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:26<01:29,  9.93s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [15:36<01:19,  9.95s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [15:46<01:09,  9.96s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [15:56<00:59,  9.97s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:06<00:49,  9.97s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:16<00:39,  9.97s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:26<00:29,  9.97s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [16:36<00:19,  9.97s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [16:46<00:09,  9.96s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [16:56<00:00,  9.96s/it]100%|██████████| 100/100 [16:56<00:00, 10.17s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-01-15:22:03:00,247 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-01-15:22:03:00,248 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-01-15:22:03:00,248 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-01-15:22:03:00,605 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-01-15:22:03:04,858 INFO     [__main__.py:132] Verbosity set to INFO
2025-01-15:22:03:15,356 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-01-15:22:03:15,358 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-01-15:22:03:15,367 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-01-15:22:03:15,588 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:01,  5.81it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:00<00:00,  7.07it/s]Loading checkpoint shards:  38%|███▊      | 3/8 [00:00<00:00,  7.60it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:00<00:00,  8.24it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:00<00:00,  8.63it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:00<00:00,  8.93it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:00<00:00,  9.15it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  8.60it/s]
2025-01-15:22:03:37,891 INFO     [task.py:355] Building contexts for task on rank 0...
2025-01-15:22:03:37,910 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:30, 12.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<18:48, 11.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:06, 11.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:44<17:40, 11.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:55<17:24, 10.99s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:06<17:03, 10.89s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:17<16:44, 10.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:27<16:27, 10.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:38<16:11, 10.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:48<15:56, 10.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [01:59<15:42, 10.59s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:09<15:27, 10.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:20<15:13, 10.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:30<15:01, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:40<14:48, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:51<14:37, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:01<14:25, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:12<14:14, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:22<14:03, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:30<12:46,  9.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:40<12:55,  9.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:50<12:57,  9.97s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:01<12:55, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:11<12:51, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:21<12:44, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:32<12:37, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:42<12:28, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:52<12:18, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:03<12:09, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:13<11:59, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:23<11:49, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:33<11:38, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:44<11:28, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [05:54<11:18, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:04<11:07, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:14<10:57, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:25<10:46, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:35<10:36, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:45<10:25, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [06:55<10:15, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:06<10:04, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:16<09:54, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:26<09:44, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:36<09:33, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:47<09:23, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [07:57<09:12, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:07<09:00, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:17<08:49, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:27<08:39, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:38<08:28, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [08:48<08:18, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [08:58<08:07, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:08<07:57, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:18<07:46, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:28<07:36, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:38<07:25, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [09:48<07:15, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [09:59<07:05, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:09<06:54, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:19<06:44, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:29<06:34, 10.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:39<06:24, 10.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [10:49<06:13, 10.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [10:59<06:03, 10.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:09<05:53, 10.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:19<05:43, 10.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:29<05:32, 10.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:39<05:22, 10.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [11:50<05:12, 10.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:00<05:02, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:10<04:52, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:20<04:42, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:30<04:31, 10.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:40<04:21, 10.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [12:50<04:11, 10.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [12:53<03:14,  8.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:03<03:19,  8.68s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:14<03:19,  9.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:24<03:16,  9.37s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [13:34<03:11,  9.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [13:44<03:04,  9.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [13:54<02:56,  9.80s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:04<02:47,  9.87s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:14<02:38,  9.91s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:24<02:29,  9.94s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [14:34<02:19,  9.96s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [14:44<02:09,  9.98s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [14:54<01:59,  9.99s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:04<01:49,  9.99s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:14<01:39, 10.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:24<01:29, 10.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [15:34<01:20, 10.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [15:44<01:09, 10.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [15:54<00:59, 10.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:04<00:49,  9.99s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:14<00:39,  9.99s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:24<00:29,  9.98s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [16:34<00:19,  9.98s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [16:44<00:09,  9.97s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [16:54<00:00,  9.97s/it]100%|██████████| 100/100 [16:54<00:00, 10.14s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-01-15:22:21:08,076 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-01-15:22:21:08,076 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-01-15:22:21:08,076 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-01-15:22:21:08,445 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-01-15:22:21:12,912 INFO     [__main__.py:132] Verbosity set to INFO
2025-01-15:22:21:23,333 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-01-15:22:21:23,335 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-01-15:22:21:23,343 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-01-15:22:21:23,650 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:01,  5.74it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:00<00:00,  6.64it/s]Loading checkpoint shards:  38%|███▊      | 3/8 [00:00<00:00,  7.44it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:00<00:00,  8.09it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:00<00:00,  8.51it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:00<00:00,  8.77it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:00<00:00,  8.91it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  8.39it/s]
2025-01-15:22:21:45,163 INFO     [task.py:355] Building contexts for task on rank 0...
2025-01-15:22:21:45,182 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:32, 12.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<18:51, 11.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:09, 11.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:45<17:43, 11.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:55<17:20, 10.95s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:06<17:01, 10.87s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:17<16:43, 10.79s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:27<16:28, 10.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:38<16:12, 10.69s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:48<15:57, 10.64s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [01:59<15:43, 10.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:09<15:29, 10.56s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:20<15:15, 10.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:30<15:03, 10.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:41<14:50, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:51<14:39, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:02<14:27, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:12<14:16, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:22<14:05, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:30<12:48,  9.60s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:40<12:56,  9.83s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:51<12:59,  9.99s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:01<12:57, 10.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:11<12:53, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:22<12:46, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:32<12:38, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:42<12:29, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:53<12:20, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:03<12:11, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:13<12:01, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:24<11:50, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:34<11:40, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:44<11:30, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [05:55<11:19, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:05<11:09, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:15<10:58, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:25<10:48, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:36<10:37, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:46<10:27, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [06:56<10:16, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:07<10:06, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:17<09:56, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:27<09:45, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:37<09:35, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:48<09:24, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [07:58<09:14, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:08<09:03, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:18<08:53, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:29<08:43, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:39<08:32, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [08:49<08:22, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [08:59<08:11, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:10<08:01, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:20<07:50, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:30<07:40, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:40<07:29, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [09:50<07:19, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:01<07:09, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:11<06:58, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:21<06:48, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:31<06:37, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:41<06:27, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [10:52<06:17, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:02<06:06, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:12<05:56, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:22<05:46, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:32<05:35, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:43<05:25, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [11:53<05:15, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:03<05:05, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:13<04:54, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:23<04:44, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:33<04:34, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:43<04:24, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [12:54<04:13, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [12:57<03:15,  8.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:07<03:21,  8.75s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:17<03:21,  9.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:28<03:18,  9.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [13:38<03:13,  9.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [13:48<03:06,  9.79s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [13:58<02:57,  9.89s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:08<02:49,  9.95s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:18<02:40, 10.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:28<02:30, 10.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [14:38<02:20, 10.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [14:48<02:10, 10.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [14:58<02:00, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:09<01:50, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:19<01:40, 10.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:29<01:30, 10.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [15:39<01:20, 10.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [15:49<01:10, 10.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [15:59<01:00, 10.09s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:09<00:50, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:19<00:40, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:29<00:30, 10.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [16:39<00:20, 10.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [16:49<00:10, 10.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [16:59<00:00, 10.06s/it]100%|██████████| 100/100 [16:59<00:00, 10.20s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-01-15:22:39:21,271 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-01-15:22:39:21,271 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-01-15:22:39:21,271 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-01-15:22:39:21,643 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-01-15:22:39:26,096 INFO     [__main__.py:132] Verbosity set to INFO
2025-01-15:22:39:36,786 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-01-15:22:39:36,788 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-01-15:22:39:36,795 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-01-15:22:39:37,010 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:01,  6.15it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:00<00:00,  7.45it/s]Loading checkpoint shards:  38%|███▊      | 3/8 [00:00<00:00,  8.07it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:00<00:00,  9.07it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:00<00:00,  9.49it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  9.08it/s]
2025-01-15:22:39:58,226 INFO     [task.py:355] Building contexts for task on rank 0...
2025-01-15:22:39:58,244 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:37, 12.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<18:51, 11.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:07, 11.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:45<17:41, 11.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:55<17:17, 10.92s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:06<16:58, 10.84s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:16<16:40, 10.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:27<16:25, 10.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:38<16:09, 10.66s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:48<15:54, 10.61s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [01:59<15:40, 10.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:09<15:26, 10.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:19<15:12, 10.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:30<15:00, 10.47s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:40<14:48, 10.45s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:51<14:36, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:01<14:25, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:11<14:13, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:22<14:02, 10.41s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:29<12:46,  9.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:40<12:54,  9.81s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:50<12:56,  9.96s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:00<12:55, 10.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:11<12:50, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:21<12:44, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:31<12:36, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:42<12:27, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:52<12:18, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:02<12:08, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:13<11:58, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:23<11:48, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:33<11:38, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:43<11:28, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [05:54<11:18, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:04<11:07, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:14<10:57, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:24<10:46, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:35<10:36, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:45<10:25, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [06:55<10:15, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:05<10:04, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:16<09:54, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:26<09:44, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:36<09:33, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:46<09:23, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [07:57<09:12, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:07<09:02, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:17<08:51, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:27<08:41, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:37<08:31, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [08:48<08:20, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [08:58<08:10, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:08<07:59, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:18<07:49, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:28<07:38, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:39<07:28, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [09:49<07:18, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [09:59<07:07, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:09<06:57, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:19<06:47, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:29<06:36, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:40<06:26, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [10:50<06:16, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:00<06:05, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:10<05:55, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:20<05:45, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:30<05:34, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:41<05:24, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [11:51<05:14, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:01<05:04, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:11<04:53, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:21<04:43, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:31<04:33, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:41<04:23, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [12:51<04:12, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [12:55<03:15,  8.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:05<03:20,  8.73s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:15<03:21,  9.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:25<03:17,  9.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [13:35<03:12,  9.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [13:45<03:05,  9.76s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [13:55<02:57,  9.86s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:06<02:48,  9.92s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:16<02:39,  9.97s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:26<02:30, 10.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [14:36<02:20, 10.02s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [14:46<02:10, 10.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [14:56<02:00, 10.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:06<01:50, 10.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:16<01:40, 10.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:26<01:30, 10.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [15:36<01:20, 10.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [15:46<01:10, 10.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [15:56<01:00, 10.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:06<00:50, 10.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:16<00:40, 10.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:26<00:30, 10.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [16:36<00:20, 10.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [16:46<00:10, 10.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [16:56<00:00, 10.03s/it]100%|██████████| 100/100 [16:56<00:00, 10.17s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-01-15:22:57:31,280 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-01-15:22:57:31,280 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-01-15:22:57:31,280 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-01-15:22:57:31,640 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-01-15:22:57:36,025 INFO     [__main__.py:132] Verbosity set to INFO
2025-01-15:22:57:46,483 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-01-15:22:57:46,485 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-01-15:22:57:46,493 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-01-15:22:57:46,717 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:01,  5.97it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:00<00:00,  7.55it/s]Loading checkpoint shards:  38%|███▊      | 3/8 [00:00<00:00,  7.62it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:00<00:00,  8.25it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:00<00:00,  8.65it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:00<00:00,  8.95it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:00<00:00,  9.13it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  8.65it/s]
2025-01-15:22:58:07,277 INFO     [task.py:355] Building contexts for task on rank 0...
2025-01-15:22:58:07,295 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:33, 12.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<18:54, 11.57s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:12, 11.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:45<17:47, 11.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:56<17:42, 11.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:07<17:17, 11.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:17<16:55, 10.92s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:28<16:37, 10.84s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:39<16:20, 10.78s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:49<16:04, 10.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [02:00<15:49, 10.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:10<15:34, 10.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:21<15:20, 10.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:31<15:07, 10.55s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:42<14:54, 10.53s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:52<14:43, 10.51s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:03<14:31, 10.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:13<14:20, 10.49s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:24<14:09, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:31<12:51,  9.65s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:42<13:00,  9.88s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:52<13:02, 10.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:03<13:01, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:13<12:56, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:23<12:50, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:34<12:42, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:44<12:33, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:55<12:24, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:05<12:14, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:15<12:04, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:26<11:54, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:36<11:43, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:46<11:33, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [05:57<11:23, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:07<11:12, 10.35s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:17<11:02, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:28<10:51, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:38<10:40, 10.34s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:48<10:30, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [06:59<10:19, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:09<10:09, 10.33s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:19<09:58, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:30<09:48, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:40<09:37, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:50<09:27, 10.32s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [08:01<09:16, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:11<09:06, 10.31s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:21<08:55, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:31<08:45, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:42<08:34, 10.30s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [08:52<08:24, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [09:02<08:13, 10.29s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:13<08:03, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:23<07:52, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:33<07:42, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:43<07:31, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [09:54<07:21, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [10:04<07:11, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:14<07:00, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:24<06:50, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:35<06:39, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:45<06:29, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [10:55<06:18, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:05<06:08, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:15<05:58, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:26<05:47, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:36<05:37, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:46<05:27, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [11:56<05:16, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:07<05:06, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:17<04:56, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:27<04:45, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:37<04:35, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:47<04:25, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [12:58<04:14, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [13:01<03:16,  8.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:11<03:22,  8.79s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:21<03:22,  9.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:32<03:19,  9.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [13:42<03:13,  9.70s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [13:52<03:06,  9.84s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [14:02<02:58,  9.93s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:12<02:49, 10.00s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:22<02:40, 10.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:33<02:31, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [14:43<02:21, 10.10s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [14:53<02:11, 10.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [15:03<02:01, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:13<01:51, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:23<01:41, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:33<01:31, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [15:44<01:21, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [15:54<01:10, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [16:04<01:00, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:14<00:50, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:24<00:40, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:34<00:30, 10.12s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [16:44<00:20, 10.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [16:54<00:10, 10.11s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [17:04<00:00, 10.10s/it]100%|██████████| 100/100 [17:04<00:00, 10.25s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-01-15:23:15:48,181 INFO     [utils.py:145] Note: detected 256 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
2025-01-15:23:15:48,181 INFO     [utils.py:148] Note: NumExpr detected 256 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
2025-01-15:23:15:48,181 INFO     [utils.py:161] NumExpr defaulting to 16 threads.
2025-01-15:23:15:48,530 INFO     [config.py:58] PyTorch version 2.4.1 available.
2025-01-15:23:15:52,826 INFO     [__main__.py:132] Verbosity set to INFO
2025-01-15:23:16:03,126 WARNING  [__main__.py:138]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-01-15:23:16:03,128 INFO     [__main__.py:205] Selected Tasks: ['code2text_javascript']
2025-01-15:23:16:03,137 WARNING  [evaluator.py:93] generation_kwargs specified through cli, these settings will be used over set parameters in yaml tasks.
2025-01-15:23:16:03,358 INFO     [huggingface.py:120] Using device 'cuda'
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:01,  5.77it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:00<00:00,  6.93it/s]Loading checkpoint shards:  38%|███▊      | 3/8 [00:00<00:00,  7.52it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:00<00:00,  8.16it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:00<00:00,  8.57it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:00<00:00,  8.85it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:00<00:00,  9.04it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  9.32it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:00<00:00,  8.49it/s]
2025-01-15:23:16:23,857 INFO     [task.py:355] Building contexts for task on rank 0...
2025-01-15:23:16:23,875 INFO     [evaluator.py:319] Running generate_until requests
  0%|          | 0/100 [00:00<?, ?it/s]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  1%|          | 1/100 [00:12<20:30, 12.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  2%|▏         | 2/100 [00:23<18:48, 11.52s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  3%|▎         | 3/100 [00:34<18:07, 11.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  4%|▍         | 4/100 [00:44<17:41, 11.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  5%|▌         | 5/100 [00:55<17:17, 10.92s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  6%|▌         | 6/100 [01:06<16:58, 10.84s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  7%|▋         | 7/100 [01:16<16:41, 10.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  8%|▊         | 8/100 [01:27<16:25, 10.71s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
  9%|▉         | 9/100 [01:38<16:10, 10.67s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 10%|█         | 10/100 [01:48<15:55, 10.62s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 11%|█         | 11/100 [01:59<15:41, 10.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 12%|█▏        | 12/100 [02:09<15:27, 10.54s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 13%|█▎        | 13/100 [02:19<15:13, 10.50s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 14%|█▍        | 14/100 [02:30<15:01, 10.48s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 15%|█▌        | 15/100 [02:40<14:48, 10.46s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 16%|█▌        | 16/100 [02:51<14:37, 10.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 17%|█▋        | 17/100 [03:01<14:25, 10.43s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 18%|█▊        | 18/100 [03:12<14:14, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 19%|█▉        | 19/100 [03:22<14:03, 10.42s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 20%|██        | 20/100 [03:30<12:46,  9.58s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 21%|██        | 21/100 [03:40<12:55,  9.82s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 22%|██▏       | 22/100 [03:50<12:57,  9.97s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 23%|██▎       | 23/100 [04:01<12:55, 10.08s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 24%|██▍       | 24/100 [04:11<12:51, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 25%|██▌       | 25/100 [04:21<12:44, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 26%|██▌       | 26/100 [04:32<12:37, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 27%|██▋       | 27/100 [04:42<12:28, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 28%|██▊       | 28/100 [04:52<12:19, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 29%|██▉       | 29/100 [05:02<12:09, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 30%|███       | 30/100 [05:13<11:59, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 31%|███       | 31/100 [05:23<11:49, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 32%|███▏      | 32/100 [05:33<11:39, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 33%|███▎      | 33/100 [05:44<11:28, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 34%|███▍      | 34/100 [05:54<11:18, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 35%|███▌      | 35/100 [06:04<11:08, 10.28s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 36%|███▌      | 36/100 [06:14<10:57, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 37%|███▋      | 37/100 [06:25<10:46, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 38%|███▊      | 38/100 [06:35<10:36, 10.27s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 39%|███▉      | 39/100 [06:45<10:26, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 40%|████      | 40/100 [06:55<10:15, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 41%|████      | 41/100 [07:06<10:05, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 42%|████▏     | 42/100 [07:16<09:54, 10.26s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 43%|████▎     | 43/100 [07:26<09:44, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 44%|████▍     | 44/100 [07:36<09:34, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 45%|████▌     | 45/100 [07:47<09:23, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 46%|████▌     | 46/100 [07:57<09:13, 10.25s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 47%|████▋     | 47/100 [08:07<09:02, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 48%|████▊     | 48/100 [08:17<08:52, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 49%|████▉     | 49/100 [08:28<08:42, 10.24s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 50%|█████     | 50/100 [08:38<08:31, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 51%|█████     | 51/100 [08:48<08:21, 10.23s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 52%|█████▏    | 52/100 [08:58<08:10, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 53%|█████▎    | 53/100 [09:08<08:00, 10.22s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 54%|█████▍    | 54/100 [09:19<07:49, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 55%|█████▌    | 55/100 [09:29<07:39, 10.21s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 56%|█████▌    | 56/100 [09:39<07:28, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 57%|█████▋    | 57/100 [09:49<07:18, 10.20s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 58%|█████▊    | 58/100 [09:59<07:08, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 59%|█████▉    | 59/100 [10:10<06:57, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 60%|██████    | 60/100 [10:20<06:47, 10.19s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 61%|██████    | 61/100 [10:30<06:36, 10.18s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 62%|██████▏   | 62/100 [10:40<06:26, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 63%|██████▎   | 63/100 [10:50<06:16, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 64%|██████▍   | 64/100 [11:00<06:06, 10.17s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 65%|██████▌   | 65/100 [11:11<05:55, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 66%|██████▌   | 66/100 [11:21<05:45, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 67%|██████▋   | 67/100 [11:31<05:35, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 68%|██████▊   | 68/100 [11:41<05:24, 10.16s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 69%|██████▉   | 69/100 [11:51<05:14, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 70%|███████   | 70/100 [12:01<05:04, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 71%|███████   | 71/100 [12:11<04:54, 10.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 72%|███████▏  | 72/100 [12:22<04:44, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 73%|███████▎  | 73/100 [12:32<04:33, 10.14s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 74%|███████▍  | 74/100 [12:42<04:23, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 75%|███████▌  | 75/100 [12:52<04:13, 10.13s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 76%|███████▌  | 76/100 [12:55<03:15,  8.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 77%|███████▋  | 77/100 [13:06<03:20,  8.74s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 78%|███████▊  | 78/100 [13:16<03:21,  9.15s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 79%|███████▉  | 79/100 [13:26<03:18,  9.44s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 80%|████████  | 80/100 [13:36<03:12,  9.63s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 81%|████████  | 81/100 [13:46<03:05,  9.77s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 82%|████████▏ | 82/100 [13:56<02:57,  9.87s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 83%|████████▎ | 83/100 [14:06<02:48,  9.93s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 84%|████████▍ | 84/100 [14:16<02:39,  9.98s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 85%|████████▌ | 85/100 [14:26<02:30, 10.01s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 86%|████████▌ | 86/100 [14:36<02:20, 10.03s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 87%|████████▋ | 87/100 [14:46<02:10, 10.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 88%|████████▊ | 88/100 [14:57<02:00, 10.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 89%|████████▉ | 89/100 [15:07<01:50, 10.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 90%|█████████ | 90/100 [15:17<01:40, 10.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 91%|█████████ | 91/100 [15:27<01:30, 10.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 92%|█████████▏| 92/100 [15:37<01:20, 10.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 93%|█████████▎| 93/100 [15:47<01:10, 10.07s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 94%|█████████▍| 94/100 [15:57<01:00, 10.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 95%|█████████▌| 95/100 [16:07<00:50, 10.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 96%|█████████▌| 96/100 [16:17<00:40, 10.06s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 97%|█████████▋| 97/100 [16:27<00:30, 10.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 98%|█████████▊| 98/100 [16:37<00:20, 10.05s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
 99%|█████████▉| 99/100 [16:47<00:10, 10.04s/it]Both `max_new_tokens` (=250) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
100%|██████████| 100/100 [16:57<00:00, 10.04s/it]100%|██████████| 100/100 [16:57<00:00, 10.18s/it]
fatal: not a git repository (or any parent up to mount point /global)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
new_script.sh: line 212: syntax error near unexpected token `fi'
new_script.sh: line 212: `        fi '
